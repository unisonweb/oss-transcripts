structural type articles.distributedDatasets.coreIdea.SimpleTree a
  = SimpleTree.One a
  | SimpleTree.Empty
  | SimpleTree.Two
      (articles.distributedDatasets.coreIdea.SimpleTree a)
      (articles.distributedDatasets.coreIdea.SimpleTree a)

structural ability blog.jitAnnounce.Control r where
  control :
    ((a ->{blog.jitAnnounce.Control r} r) -> r)
    ->{blog.jitAnnounce.Control r} a

structural ability blog.jitAnnounce.Shift r where
  shift : ((a -> r) -> r) ->{blog.jitAnnounce.Shift r} a

structural type docs.exercises.controlFlow.ex2.answers.Shape
  = Rectangle Nat Nat
  | Square Nat

ability docs.fundamentals.abilities.usingAbilitiesPt1.Cache k v where
  Cache.get :
    k ->{IO, Exception, docs.fundamentals.abilities.usingAbilitiesPt1.Cache} v
  Cache.put :
    k
    -> v
    ->{IO, Exception, docs.fundamentals.abilities.usingAbilitiesPt1.Cache} ()

type docs.fundamentals.abilities.usingAbilitiesTut.Animal
  = Squirrel
  | Bird

type docs.fundamentals.abilities.usingAbilitiesTut.BirdFeeder
  = BirdFeeder Nat

type docs.fundamentals.abilities.usingAbilitiesTut.Message
  = TextMessage Text

ability docs.fundamentals.abilities.writingAbilities.KVStore a b where
  get :
    a ->{docs.fundamentals.abilities.writingAbilities.KVStore a b} Optional b
  put : a -> b ->{docs.fundamentals.abilities.writingAbilities.KVStore a b} ()

type docs.fundamentals.controlFlow.Color
  = RGB Nat Nat Nat

type docs.fundamentals.controlFlow.exceptionHandling.failure.example1.DatabaseError
  = DuplicateValuesForUniqueColumn
  | NumericValueOutOfRange
  | NonNullConstraintViolated

type docs.fundamentals.controlFlow.exceptionHandling.failure.example1.User
  = User Text

type docs.fundamentals.controlFlow.exceptionHandling.optional.Cake
  = Cake Text

type docs.fundamentals.controlFlow.exceptionHandling.optional.Ingredient
  = Egg
  | Flour
  | Sugar
  | Kale

type docs.fundamentals.controlFlow.patternMatching.Lunch
  = Soup Text
  | Salad Text
  | Mystery Text Boolean

type docs.fundamentals.controlFlow.patternMatching.Utensil
  = Fork
  | Knife
  | Spoon

type docs.fundamentals.controlFlow._asPatterns.Hydra
  = Heads Nat Nat Nat Nat Nat

type docs.fundamentals.dataTypes.uniqueAndStructuralTypes.Genre
  = Fiction
  | Poetry
  | CookBooks
  | Science
  | Biography

structural type docs.fundamentals.dataTypes.uniqueAndStructuralTypes.Weekday
  = Mon
  | Tues
  | Wed
  | Thurs
  | Fri

structural type docs.fundamentals.dataTypes._recordTypes.DaysOfWeek
  = Sun
  | Mon
  | Tues
  | Wed
  | Thurs
  | Fri
  | Sat

structural type docs.fundamentals.dataTypes._recordTypes.Volunteer
  = { preferredName : Text,
      age : Nat,
      desiredStartDate : Text,
      endDate : Optional Text,
      daysAvailable : Set DaysOfWeek }

structural type docs.fundamentals.dataTypes._uniqueAndStructuralTypes.struct.Author
  = struct.Author.Author Text Nat (Set Genre)

type docs.fundamentals.dataTypes._uniqueAndStructuralTypes.uniqueVersion.Author
  = uniqueVersion.Author.Author Text Nat

type docs.fundamentals.dataTypes._uniqueAndStructuralTypes.uniqueVersion.Book
  = Book Text Nat

type docs.glance.LivingThings
  = Animal
  | Plant
  | Fungi
  | Protists
  | Monera

type docs.glance.Pet
  = { age : Nat, species : Text, foodPreferences : [Text] }

structural type docs.glance.Tree a
  = Empty
  | Node a (docs.glance.Tree a) (docs.glance.Tree a)

type docs.labs.wordle.solutions.basic.Guess
  = Guess [(Char, Nat)]

type docs.labs.wordle.solutions.basic.Result
  = NotFound Char
  | Exists Char
  | InPlace Char

type docs.labs.wordle.solutions.basic.Target
  = Target (Map Char Nat) (Set (Char, Nat))

type docs.labs.wordle.solutions.stubs.Guess
  = Guess TODO

type docs.labs.wordle.solutions.stubs.Result
  = NotFound TODO
  | Exists TODO
  | InPlace TODO

type docs.labs.wordle.solutions.stubs.Target
  = Target TODO

type docs.labs.wordle.solutions.stubs.TODO
  = TODO

type docs.labs.wordle.utils.Callout
  = { emoji : Doc, title : Doc, body : Doc }

type docs.languageReference.destructuringBinds.Box a
  = Box a

structural type docs.languageReference.recordType.examples.Point1
  = Point2 Nat Nat

type docs.languageReference.recordType.examples.Point2
  = { x : Nat, y : Nat }

type docs.languageReference.uniqueTypes.Direction
  = North
  | South
  | East
  | West

type docs.languageReference.uniqueTypes.Suit
  = Hearts
  | Spades
  | Diamonds
  | Clubs

type docs.languageReference.userDefinedDataTypes.UserId
  = Phone Nat
  | Email Text

articles.distributedDatasets.additionalTopics : Doc
articles.distributedDatasets.additionalTopics =
  use Seq flatMap
  use Value pure
  use parallel Tree.reduce
  {{
  # Additional topics

    Here we'll cover some additional topics you may have wondered about while
    reading the article:

    * [What about error handling?](#errors)
    * [{type Seq} vs {type lib.Tree} and controlling the granularity of
      parallelism](#seq-vs-tree)
    * [How do I create a distributed sequence?](#creating-seqs)

    ## {{ Anchor "errors" {{ Error handling }} }}

       While the {type Remote} ability does support fine-grained error handling
       via functions like {Remote.try} and {tryAwait}, for batch computing
       workloads like the one we've developed here, coarse-grained error
       handling policies applied to an entire computation are often
       appropriate. Some example policies:

       * In the event of a failure, retry repeatedly (possibly with exponential
         backoff). If the failure keeps happening, a human will eventually
         intervene to kill the job.
       * In the event of a failure, retry up to 4 times, then reraise the
         failure.

       These sorts of general policies can be provided by "middleware" handlers
       of {type Remote} rather than needing to pollute nice implementations
       like {Seq.reduce} with retry logic.

    ## {{
    Anchor
      "seq-vs-tree"
      {{
      `Tree` vs `Seq` and controlling granularity of parallelism
      }} }}

       The {type lib.Tree} we used in the tutorial is a bit different than the
       {type Seq} used in the
       [distributed library](https://share.unison-lang.org/@unison/distributed).
       This is subtle stuff. Let's take a look at the differences:

           @source{type lib.Tree, type Seq, type Two}

       What's going on here? Well, first, ignore that {type Seq} has an extra
       `k` parameter. Also ignore for now the {type Mode} parameter for
       controlling granularity of parallelism—we'll discuss that shortly. {{
       docAside
         {{
         The `k` parameter is used to track whether the {type Seq} is memoized,
         or if it will trigger evaluation each time it is inspected. Tracking
         this info in the types helps guard against accidentally writing
         inefficient programs that repeat the same work over and over.
         }} }}

       More substantially, {type Seq} is defined via mutual recursion between
       two types, {type Seq} and {type Two}. This is a little brain bending if
       you haven't seen this sort of thing before, but the usage here just
       enforces that there is a {type Remote.Value} wrapping each level of the
       tree, including the root. Recall that {type Remote.Value} is lazy, so
       this means we can't know if a {type Seq} is empty, a leaf or a branch
       without first forcing the {type Remote.Value}.

       It's instructive to compare how the two types represent a few example
       trees:

       @typecheck ```
       emptyTree = lib.Tree.Empty
       emptySeq = Seq (pure Two.Empty)
       leafTree = Tree.One (pure "A")
       leafSeq = Seq (pure (Two.One "A"))
       branchTree = Tree.Two (pure leafTree) (pure leafTree)
       branchSeq mode = Seq (pure (Two.Two mode leafSeq leafSeq))
       ```

       {type lib.Tree} isn't fully lazy. Without looking inside any
       {type Remote.Value}, we can tell whether the tree is empty, a leaf, or a
       brach. The laziness only kicks in when we try to see what is __inside__
       a leaf, or what subtrees are one level down from a {Tree.Two}.

       In contrast, {type Seq} is __fully lazy:__ we can't obtain __any__
       information about its structure without calling either {Value.map} or
       {Value.get}. We can't even tell if the data structure is empty or not!
       We can tell that it is a {type Seq}, but any information about its
       internal structure is guarded by a {type Remote.Value}.

           @source{type lib.Tree, type Seq, type Two}

       For an ordinary data in-memory data structure, the difference in these
       two phrasings might not matter much in practice. For distributed data
       structures, it's a more substantive decision. Consider the function
       {flatMap}, and imagine calling it with a function that does some serious
       work:

           @foldedSource{flatMap}

       The above implementation is nicely lazy and does no work until the
       sequence is later forced (by a {Seq.reduce} say). In contrast, imagine
       writing `flatMap` for {type lib.Tree}. If the tree happens to be a leaf
       it will have to __strictly__ apply the function, which means that
       `flatMap` now requires access to {type Remote}.

       This is a bit of an awkward programming model, where some computation is
       run strictly some of the time, while other computations are evaluated
       lazily only when needed, and the difference depends on the size of the
       tree! {type Seq} has a more uniform representation that ensures no work
       ever happens until the {type Seq} is forced by a function like
       {Seq.reduce}, and this is often a good choice.

       ### Controlling chunking and the granularity of parallelism

           Let's look at the implementation of
           {{ docLink (docEmbedTermLink do Tree.reduce) }}:

           {{ docSource [docSourceElement (docEmbedTermLink do Tree.reduce) []]
           }}

           This does a parallel reduce of the tree, forking threads at each
           {Tree.Two}. This is fine if each subtree represents a large chunk of
           work. But for say a `Tree Nat`, close to the leaves of such a tree,
           there's so little data that the overhead of forking a thread to
           process may not pay for itself, even with Unison's lightweight
           threads.

           The {type Seq} type allows branches to be annotated with a
           {type Mode} indicating whether they should be {Parallel} or
           {Sequential}. Functions like {Seq.reduce} respect the annotation and
           only fork threads if annotation indicates it's worthwhile, and
           functions like {Seq.map} leave the annotation alone:

               @foldedSource{Seq.reduce}

               @foldedSource{Seq.map}

           When building up a distributed sequence, you can control the
           granularity of parallelism by picking {Parallel} or {Sequential} for
           constructed {Two.Two} nodes, and functions like {fromChunkedList}
           will do this automatically. We'll talk more about constructing
           sequences in the next section.

           In addition to using the {type Mode} annotation, you can also work
           with trees whose leaf values are some chunk type. So rather than
           working with a `Tree Nat`, you could instead work with `Tree [Nat]`
           or use some more specialized chunk type. This sort of explicit
           chunking isn't as nice to program with but it can offer better
           performance.

    ## {{ Anchor "creating-seqs" {{ Creating distributed sequences }} }}

       It's nice that we can write functions like {Seq.map} that preserve the
       existing partitioning of the data onto multiple nodes. But how do we
       actually create a distributed sequence in the first place? This section
       gives the basic idea of how to construct distributed sequences in terms
       of the {type Location} type used within {type Remote}.

       {{
       docAside
         {{
         The actual physical locations of your data will be determined by the
         infrastructure that you're using to run your computations, as
         determined by your {type Remote} handler. We'll discuss that in more
         detail in a later article.
         }} }}

       Distributed sequences will typically be created lazily, by repeatedly
       splitting some state in half and producing a leaf or the empty once the
       state hits some base case. For instance, here's a function that produces
       a {type Seq} from a list, placing every `chunkSize` subtree together at
       a single location:

           @foldedSource{fromListAt}

       As a sample use case, we might call this with a list of urls or file
       names from S3. A subsequent {Seq.map} or {flatMap} can then be used to
       fetch (or "hydrate") the contents of those urls. The loading happens
       lazily, only when the resulting {type Seq} is forced.

       If the sequence is so large that not even the names of all the files can
       fit in memory, we might recursively build the sequence using
       {fromListAt} (to list top level directory names) and {flatMap} (to
       recursively build a sequence for the files under each directory).

       We can also use more general combinators like {Seq.unfold} or
       {skewUnfoldAt}.
  }}

articles.distributedDatasets.coreIdea : Doc
articles.distributedDatasets.coreIdea =
  use Value get pure
  {{
  # How to make any immutable data structure distributed

    In this post we'll build our own distributed data structure from first
    principles. The version developed here is a little simpler than the
    {type Seq} used in the "real" version of the library. We'll get to the real
    {type Seq} in Part 5 of this article.

    First, let's look at a simple in-memory tree data structure and understand
    how it can be modified to represent data spread across multiple nodes.
    Here's the in-memory version:

        @source{type SimpleTree}

    A {type SimpleTree} is either {SimpleTree.Empty}, a leaf: {SimpleTree.One},
    or a branch: {SimpleTree.Two}. All the leaves and subtrees in a
    {type SimpleTree} are references to values which are in local memory on the
    same machine. If instead we want it to contain references to values that
    may exist at another location, we can write the following instead:

        @source{type lib.Tree}

    All we've done here is wrap each branch and leaf of the tree in a data
    type, {type Remote.Value}, which represents a __lazy__ value at a possibly
    remote location.

    {{
    docCallout
      (Some {{ 👉 }})
      {{
      Making a distributed data type in Unison can be as simple as wrapping the
      fields in {type Remote.Value}.

      There are some choices you can make here. For instance you can put
      {type Remote.Value} around all the fields in the data constructor or only
      some, and you can also have laziness "start at the root" or only when
      looking at subtrees. We'll discuss these subtleties in the last part of
      the series.
      }} }}

    With this simple type definition, we can now implement functions like a
    distributed `map`, `reduce`, and so on without needing to write any
    networking or serialization code.

    {{
    docAside
      {{
      All distributed programs in Unison eventually get translated into calls
      into the {type Remote} ability, and it's the handler of that ability that
      does serialization and networking. Your actual code stays nice and clean!
      }} }}

    Let's try it for our {type lib.Tree}. This will be instructive!

        @source{stub.Tree.map}

    We know we'll need to pattern match on the data constructors of
    {type lib.Tree} and perform a recursive call of some kind, but now that the
    leaf and branch are both wrapped in {type Remote.Value}, what should we do?
    There are two ways to do this that typecheck.

    The first is not what quite what we want but it's instructive nonetheless.
    It makes ample use of @inlineSignature{get} to force the lazy
    {type Remote.Value} and @inlineSignature{pure} for creating a remote value
    from an in-memory value:

        @source{eager.Tree.map}

    To see why this isn't what we want, let's look at the documentation of
    {get} and {pure}:

    {{ docBlockquote {{ **`Value.get`** {{ Value.get.doc }} }} }}

    {{ docBlockquote {{ **`Value.pure`** {{ Value.pure.doc }} }} }}

    We're **summoning** the value from a potentially remote location with
    {get}, and then {pure} creates a value in memory at the location where it's
    called. Our implementation of {{
    docLink (docEmbedTermLink do eager.Tree.map) }} will thus end up sending
    the entire tree to the original caller of the function, applying the
    function there, and storing the resulting tree in memory at that location.
    That's no good—presumably the whole reason we're using a distributed data
    structure is the data is too big to fit in memory on a single machine.

    The version of `map` we want will do its work lazily, when the resulting
    {type lib.Tree} is forced, and it will do the mapping in parallel at the
    locations where the data lives rather shipping everything to the caller. {{
    docAside
      {{
      It's often more efficient to "move the computation to the data" than it
      is to "move the data to the computation".
      }} }}

    A good rule of thumb when implementing functions like Tree.map is to
    __never call {get}__. Instead we will use {Value.map} to lazily apply a
    function at the location where the remote value lives. {{
    docAside
      {{
      [The documentation]({Value.map}) for {Value.map} has more details on when
      and how to use {Value.map} vs {get}.
      }} }}

        @source{lib.Tree.map}

    While you can perhaps see how this code typechecks, what this code does is
    a bit brain-bending. First, because our {lib.Tree.map} function does not
    call {get}, {lib.Tree.map} is just the blueprint for the data
    transformation, not the transformed data itself. Not until the tree is
    evaluated (by say, the `reduce` function we'll cover in Part 3) does any
    mapping actually happen. This laziness gives us fusion {{
    docAside {{ {{ distributedDatasets.glossary.fusion }} }} }} "for free", so
    if we {{ docLink (docEmbedTermLink do lib.Tree.map) }} multiple times, the
    functions will get composed together and applied in the same pass over the
    data as the `reduce`.

    Morever, because we are using {Value.map}, the function will be applied at
    the location where the data lives, rather than shipping the entire tree to
    the caller and applying the transformation function there.

    {{
    Folded
      true
      {{
      **Optional but fun exercises** 😎
      }}
      {{
      See if you can write more functions for {type lib.Tree}. We've provided a
      codebase with the necessary dependencies sand stubbed functions. To pull
      in the codebase, run the following in the UCM:

      ``` ucm
      .> pull git@github.com:unisonweb/website:.articles.distributedDatasets .article1
      ```

      The {type lib.Tree} function stubs are under `Tree`.

      {{ ex1a }}

      {{ ex3a }}
      }} }}

    ## Takeaways

       We learned a few things in this part:

       * To make a data structure distributed, wrap {type Remote.Value} around
         the fields it defines in its data constructors. This lets the data
         structure represent the data being "elsewhere" with a minimum amount
         of ceremony.
       * Use {Value.map} judiciously to build lazy computations like {{
         docLink (docEmbedTermLink do lib.Tree.map) }} where the function is
         brought to the data.

       We also saw how to obtain different runtime behaviors for your
       distributed programs through implementations of the `Tree.map` function
       using {Value.map} or {get}.

       As a library author, you do have to be explicit when describing how your
       program should behave, and we consider this a good thing: you can
       achieve exactly what you want with a tiny amount of code, and you can
       wrap up common patterns in reusable functions like {{
       docLink (docEmbedTermLink do lib.Tree.map) }} that anyone can use
       without being a distributed systems expert!

       If you've been wondering "how do I evaluate this in some way?" we'll
       cover that next, in Part 3. Again there will be some instructive
       decisions to make: how we implement functions like `reduce` will
       determine whether the work happens in parallel close to the data or
       whether the data gets sent to the caller and reduced there.
  }}

articles.distributedDatasets.coreIdea.eager.Tree.map :
  (a ->{Remote} b) -> lib.Tree a ->{Remote} lib.Tree b
articles.distributedDatasets.coreIdea.eager.Tree.map f = cases
  lib.Tree.Empty -> lib.Tree.Empty
  Tree.One valueA -> Tree.One (Value.pure (f (Value.get valueA)))
  Tree.Two leftValue rightValue ->
    Tree.Two
      (Value.pure
        (articles.distributedDatasets.coreIdea.eager.Tree.map
          f (Value.get leftValue)))
      (Value.pure
        (articles.distributedDatasets.coreIdea.eager.Tree.map
          f (Value.get rightValue)))

articles.distributedDatasets.coreIdea.stub.Tree.map :
  (a ->{Remote} b) -> lib.Tree a ->{Remote} lib.Tree b
articles.distributedDatasets.coreIdea.stub.Tree.map f = cases
  lib.Tree.Empty                -> lib.Tree.Empty
  Tree.One valueA               -> todo "🧐 hmmm, apply f to Value"
  Tree.Two leftValue rightValue -> todo "something recursive goes here 🤨"

articles.distributedDatasets.exercises.ex1 : Doc
articles.distributedDatasets.exercises.ex1 =
  use ex1.Tree reverse
  {{
  **📓 A basic {type lib.Tree} transformation**

  {{ docLink (docEmbedTermLink do stub.Tree.map) }} is a structure preserving
  transformation that doesn't force the distributed data to be evaluated. In a
  similar vein, write `Tree.reverse` which swaps the left and right branches of
  the tree but doesn't force the evaluation of the tree.

  {{ docSignature [docEmbedSignatureLink do reverse] }}

  {{
  Folded
    true
    {{
    Answer:
    }}
    {{
    {{ (docSource [docSourceElement (docEmbedTermLink do reverse) []]) }}
    }} }}
  }}

articles.distributedDatasets.exercises.ex1.Tree.reverse :
  lib.Tree a -> lib.Tree a
articles.distributedDatasets.exercises.ex1.Tree.reverse = cases
  Tree.Two left right ->
    use Value map
    use articles.distributedDatasets.exercises.ex1.Tree reverse
    l = map reverse left
    r = map reverse right
    Tree.Two r l
  remainder           -> remainder

articles.distributedDatasets.exercises.ex1a : Doc
articles.distributedDatasets.exercises.ex1a =
  title = {{ Another basic {type lib.Tree} transformation }}
  body =
    {{
    {{ docLink (docEmbedTermLink do stub.Tree.map) }} is a structure preserving
    transformation that doesn't force the distributed data to be evaluated. In
    a similar vein write `Tree.reverse : Tree a -> Tree a` which swaps the left
    and right branches of the tree but doesn't force the evaluation of the
    tree.
    }}
  answer =
    {{
    {{ docSource [docSourceElement (docEmbedTermLink do ex1.Tree.reverse) []]
    }}
    }}
  make title body answer

articles.distributedDatasets.exercises.ex2 : Doc
articles.distributedDatasets.exercises.ex2 =
  use lib.Tree take
  {{
  **📓 More challenging {type lib.Tree} functions**

  Implement {{ docLink (docEmbedTermLink do take) }} without forcing the
  evaluation of the entire {type lib.Tree}

  How might you generalize the {{ docLink (docEmbedTermLink do take) }}
  function into a {{ docLink (docEmbedTermLink do src.Tree.reduce) }} function?
  }}

articles.distributedDatasets.exercises.ex3 : Doc
articles.distributedDatasets.exercises.ex3 =
  use ex3.Tree fromList
  {{
  **📓 Making an in-memory {type lib.Tree} for testing**

  For testing purposes, it would be great if we had an easy way to make a
  {type lib.Tree} from a {type List}.

  Implement `Tree.fromList`. It might be nice if the Tree was roughly balanced.
  😊

  {{ docSignature [docEmbedSignatureLink do fromList] }}

  {{
  Folded
    true
    {{
    Answer:
    }}
    {{
    {{ (docSource [docSourceElement (docEmbedTermLink do fromList) []]) }}
    }} }}
  }}

articles.distributedDatasets.exercises.ex3.Tree.fromList : [a] -> lib.Tree a
articles.distributedDatasets.exercises.ex3.Tree.fromList = cases
  [] -> lib.Tree.Empty
  [a] -> Tree.One (Value.pure a)
  as ->
    (left, right) = List.halve as
    Tree.Two
      (Value.pure
        (articles.distributedDatasets.exercises.ex3.Tree.fromList left))
      (Value.pure
        (articles.distributedDatasets.exercises.ex3.Tree.fromList right))

articles.distributedDatasets.exercises.ex3a : Doc
articles.distributedDatasets.exercises.ex3a =
  title = {{ Building a {type lib.Tree} from a list }}
  body =
    {{
    For testing purposes, it would be great if we had an easy way to make an
    in-memory {type lib.Tree} from a {type List}.

    Implement `Tree.fromList : [a] -> Tree a`. It might be nice if the Tree was
    roughly balanced. 😊
    }}
  answer =
    {{
    {{ docSource [docSourceElement (docEmbedTermLink do ex3.Tree.fromList) []]
    }}
    }}
  make title body answer

articles.distributedDatasets.exercises.ex4 : Doc
articles.distributedDatasets.exercises.ex4 =
  use answers.Tree memo
  title = {{ Implement a `Tree.memo` function }}
  body =
    {{
    Write a `Tree.memo` function which at every level memoizes the evaluation
    of a {type lib.Tree}.

    {{ docSignature [docEmbedSignatureLink do memo] }}
    }}
  answer =
    {{ {{ docSource [docSourceElement (docEmbedTermLink do memo) []] }} }}
  make title body answer

articles.distributedDatasets.exercises.ex5 : Doc
articles.distributedDatasets.exercises.ex5 =
  {{
  **Write a `Tree.toList` function for testing**

  For ease of viewing interim results of the transformations on
  {type lib.Tree}, write a function that takes in a {type lib.Tree} as its
  argument and returns a {type List}.

  It would be nice if this function was symmetrical with your earlier
  `fromList` function, so that
  `[1,2,3] |> Tree.fromList |> Tree.toList === [1,2,3]`
  }}

articles.distributedDatasets.exercises.ex6 : Doc
articles.distributedDatasets.exercises.ex6 =
  {{
  {{
  docCallout
    (Some {{ 📓 }})
    {{
    {{
    (docBold {{ Exercise: Write a test program using the pure interpreter }})
    }}

    This exercise is up to the reader 😎. See if you can use the functions we've
    written on {type lib.Tree}, to write a simple map reduce program.
    [`run.pure`](https://share.unison-lang.org/@unison/distributed/code/releases/5.2.0/latest/terms/Remote/run/pure)
    is an in memory interpreter for for the {type Remote} ability.
    }} }}
  }}

articles.distributedDatasets.exercises.ex7 : Doc
articles.distributedDatasets.exercises.ex7 =
  use lazy.Tree reduce
  title = {{ Implement lazy reduce }}
  body =
    {{
    Try to generalize the lazy {{ docLink (docEmbedTermLink do lib.Tree.take)
    }} function into a lazy `reduce` function:

    {{ docSignature [docEmbedSignatureLink do reduce] }}
    }}
  answer =
    {{ {{ docSource [docSourceElement (docEmbedTermLink do reduce) []] }} }}
  make title body answer

articles.distributedDatasets.exercises.ex8 : Doc
articles.distributedDatasets.exercises.ex8 =
  title = {{ Implement a lazy takeWhile function }}
  body =
    {{
    In the same vein of `take`, `takeWhile` shouldn't need to evaluate the
    entire tree structure. Write a take function that lazily evaluates the tree
    to get the first `n` leaf nodes that satisfy the given function, starting
    from the left of the tree.
    }}
  answer = {{  }}
  make title body answer

articles.distributedDatasets.exercises.make : Doc -> Doc -> Doc -> Doc
articles.distributedDatasets.exercises.make title body answer =
  docCallout
    (Some {{ 📓 }}) {{
    {{ (docBold {{ Exercise: {{ title }} }}) }}

    {{ body }}

    {{ (Folded true {{ **Show me the answer** }} answer) }}
    }}

articles.distributedDatasets.glossary.fusion : Doc
articles.distributedDatasets.glossary.fusion =
  use List map
  use Nat +
  {{
  # Fusion

    Fusion, or map-fusion, is a property of the evaluation of a data structure
    where multiple transformations over the data structure do not require
    building up intermediate representations of the structure. Instead, the
    desired transformations can be "fused" together, resulting in a more
    efficient overall computation.

    Strict data structures, like {type List} do not support the fusion
    optimization, so the expression

    ```
    [1, 2, 3] |> map (x -> x + 1) |> map (y -> y + 2)
    ```

    will build an intermediate {type List} as a result of applying ``
    x -> x + 1 `` in the {map} function.
  }}

articles.distributedDatasets.incrementalEvaluation : Doc
articles.distributedDatasets.incrementalEvaluation =
  use answers Tree.memo
  use lib Tree.map
  {{
  # Incremental evaluation via memoization

    Let's imagine the following scenario: you're MegaCorp's Chief WordCount
    Scientist. Every day you receive a file containing a list of all
    Shakespeare quotations found when crawling the internet, each paired with
    the url where it was spotted. For instance,
    [this article](https://unison-lang.org/articles/distributed-datasets/incremental-evaluation)
    quotes the line "Shall I compare thee to a summer's day?"... right now, in
    the sentence you are currently reading.

    You're charged with computing various statistics about this dataset (say, a
    histogram for the top 10 Shakespeare quotes), and enabling MegaCorp's
    Business Intelligence team to answer Very Important Questions ("does
    Shakespeare get quoted more often on Twitter, reddit, the NY Times, or in
    YouTube comment threads?").

    {{
    docAside
      {{ Spoiler: It's [not YouTube comment threads.](https://xkcd.com/202/) }}
    }}

    Now, since there isn't any new Shakespeare being written (he is dead after
    all), and people admittedly aren't dropping Shakespeare quotes all that
    often in new content posted to the internet, it's likely much of the
    dataset will be the same from one day to the next. It would be nice to not
    have to process it from scratch every time if not much has changed.

    More generally, we'd prefer it if __incremental changes to a dataset__
    required incremental computation to produce an answer. We don't want to
    rerun an entire batch job just because one or two new pieces of data
    filtered in! In this part, we'll show a nice solution to this problem for
    computations defined on the {type lib.Tree} type we've developed so far.

    {{
    docCallout
      Optional.None
      {{
      This issue also arises for batch jobs that run on what is effectively an
      "append-only" dataset, like a collection of log files.

      While it's possible to rewrite such batch jobs in a way that takes
      advantage of the append-only nature of a dataset, this can require
      awkward rephrasing of the computation, not to mention serialization
      boilerplate.
      }} }}

    A good solution for computing results incrementally can be a huge deal for
    larger batch jobs: the difference between a job that finishes in seconds
    and gets run and refined interactively vs a job that's run overnight. In
    principle, incremental evaluation "just" requires caching deterministic
    computations whose results you've computed before. {{
    docAside
      {{
      Controlling the memoization of computations whose determinism is unknown
      requires some additional thinking; we'll talk about that in a later
      section.
      }} }} Doing this robustly and accurately requires a way of uniquely
    identifying computations that will change whenever the computation or any
    of its dependencies change.

    In Unison, we'll use the hash of a computation as its identity. The hash of
    a function incorporates the hashes of all of its dependencies and will
    change if any of its dependencies change.

    Our {type lib.Tree} is nicely set up to take advantage of caching. Imagine
    we're computing a `reduce` of the tree. If any subtree of the reduction has
    been seen before (if it has the same hash), we can just return the reduced
    result immediately from the cache rather than descending into that subtree.

    The same idea also applies to, say, a
    {{ docLink (docEmbedTermLink do Tree.map) }}. Suppose we have
    {{ docExample 2 do expensiveFn t -> Tree.map expensiveFn t }}. If
    `expensiveFn` has already been applied at some subtree and cached, the
    resulting transformed tree can be retrieved from the cache.

    Fortunately, {type Remote.Value} includes a function for memoizing remote
    values, caching them at the location where the data resides, and we can use
    it to implement a "memoized reduce" and other operations:

        @signature{Value.memo}

    `` Value.memo loc v `` returns a new {type Remote.Value} that intercept
    calls to {Value.get} on `v`. Such calls first consult a cache, keyed by the
    hash of `v`. If a result is found in the cache, it's returned immediately.
    Otherwise it forces `v` and inserts the result in the cache for next time.

    The caching happens at the location of `v`, and if that location doesn't
    support this capability, another {type Location} within `loc` will be
    consulted as a fallback. The exact ability required here is {type Scratch},
    an abstract API for ephemeral local caching (using a combination of RAM
    and/or disk), but the basic logic of {Value.memo} would look similar when
    the cache provider is some other ability besides {type Scratch}.

    {{
    docAside
      {{
      In a later article, we'll develop an interesting distributed cache
      implementation suitable for very large-scale use, as in a CDN (Content
      Delivery Network) or an [IPFS](https://ipfs.io/)-like library.
      }} }}

    {{
    docCallout
      (Some {{ 📓 }})
      {{
      The {type Location} type is used throughout the {type Remote} ability to
      represent "places where data can live or computations can happen" in an
      abstract way. It will be mapped to, say, a hostname and port by a
      {type Remote} handler that does actual distributed execution.
      }} }}

    Let's look at an implementation of `reduce` that produces memoized results.
    Such an implementation will support efficient incremental recomputation
    when the input changes slightly, because the results of subtrees will be
    cached.

    {{ docSource [docSourceElement (docEmbedTermLink do memo1.Tree.reduce) []]
    }}

    The call to {Value.memo} happens when we handle the {Tree.One} and
    {Tree.Two} cases. So this reduce function caches the values at the leaf
    nodes, but it also caches the computation of each branch in the tree by
    wrapping the calls to {Value.map} in {Value.memo}.

    {{
    docAside
      {{
      In practice we might want to memoize only larger chunks of the tree.
      We'll say more about this in the last part of this article when
      discussing the differences between {type lib.Tree} and {type Seq}.
      }} }}

    When run a second time, recursion into subtrees will be cut off whenever a
    subtree has been previously computed and resides in the cache.

    This reduce function also requires that a {type Location} argument be
    provided now that we're calling {Value.memo} which requires.

    {{
    Folded
      true
      {{
      **An exercise: Memoize the tree**
      }}
      {{
      {{ distributedDatasets.exercises.ex4 }}
      }} }}

    After a particularily expensive computation runs on the {type lib.Tree},
    one thing you might do to speed up subsequent computations is call the {{
    docLink (docEmbedTermLink do Tree.memo) }} function written above as a
    caching strategy. In addition to caching already run data in between jobs,
    you might use {{ docLink (docEmbedTermLink do Tree.memo) }} between
    transformations in a data pipeline so sub-stages of the pipeline don't need
    to re-compute data.

    {{ Folded true {{ **Try your own map-reduce** }} {{ {{ exercises.ex6 }} }}
    }}

    The use of {Value.memo} provides clear efficiency gains: cached data means
    faster jobs. But we also are saving on engineering costs: we don't need to
    contort our code or deal with manual serialization of cached state, nor do
    we need additional infrastructure beyond the general infrastructure used to
    run {type Remote} computations.

    ## Conclusions

       Phew! We've covered a lot of ground in this article. Here's a quick
       recap:

       * We got a preview of the distributed {type Seq} type and how it enables
         Spark-like distributed computations. The type is just a few lines of
         code but lets us nicely express many distributed operations like
         {Seq.map}, {Seq.reduce}, and lots more.
       * We learned the general method for making any immutable data structure
         distributed, and how to implement functions like `map` and `reduce` in
         a way that "brings the computation to the data".
       * We showed how computations over distributed datasets could be memoized
         to enable efficient incremental evaluation.

       We hope you enjoyed this article. It's the first of a series on
       __compositional distributed systems__, each showing how powerful
       libraries for distributed computing can be assembled from reusable
       components in a tiny amount of Unison code. The examples shown in this
       series aren't big frameworks siloed from your "regular" code. These are
       just ordinary libraries that are a function call away, and that can be
       combined with the aid of a typechecker rather than a mess of glue and
       duct tape.

       Distributed programming __can__ be fun and approachable. While there are
       new things to think about ("where do I want the data to live and the
       computation to happen?"), Unison helps you say exactly what you mean
       with a minimum of ceremony, letting you focus on the interesting parts
       and not on the tedious particulars of simply moving data and
       computations from one place to another.

       We'll cover some additional topics in the last section. Read on to learn
       about approaches to error handling, smarter chunking and granularity of
       parallelism, and more.

       Got questions or comments? Feel free to
       [open a discussion tagged 'distributed-api' here](https://github.com/unisonweb/unison/discussions)
       or chat with us in the #distributed channel of the
       [Unison Slack](https://unisonweb.org/slack).
  }}

articles.distributedDatasets.incrementalEvaluation.answers.Tree.memo :
  Location {Scratch} -> lib.Tree a -> lib.Tree a
articles.distributedDatasets.incrementalEvaluation.answers.Tree.memo location = cases
  lib.Tree.Empty -> lib.Tree.Empty
  Tree.One valueA -> Tree.One (Value.memo location valueA)
  Tree.Two l r ->
    Tree.Two
      (Value.memo
        location
        (Value.map
          (articles.distributedDatasets.incrementalEvaluation.answers.Tree.memo
            location)
          l))
      (Value.memo
        location
        (Value.map
          (articles.distributedDatasets.incrementalEvaluation.answers.Tree.memo
            location)
          r))

articles.distributedDatasets.incrementalEvaluation.memo1.Tree.reduce :
  Location {Scratch, g}
  -> a
  -> (a -> '{Remote} a ->{Remote} a)
  -> lib.Tree a
  ->{Remote} a
articles.distributedDatasets.incrementalEvaluation.memo1.Tree.reduce
  scratch a combine = cases
  lib.Tree.Empty -> a
  Tree.One valueA -> Value.get (Value.memo scratch valueA)
  Tree.Two l r ->
    use Remote fork
    use Value get map memo
    use articles.distributedDatasets.incrementalEvaluation.memo1.Tree reduce
    lValue =
      memo scratch (map (leftTree -> reduce scratch a combine leftTree) l)
    rValue =
      memo scratch (map (rightTree -> reduce scratch a combine rightTree) r)
    l' = fork here! do get lValue
    r' = fork here! do get rValue
    combine (await l') do await r'

articles.distributedDatasets.index : Doc
articles.distributedDatasets.index =
  use distributedDatasets ex1
  {{
  # Spark-like distributed datasets in under 100 lines of Unison

    Hi there! This is the first in a series of articles on
    __compositional distributed systems,__ showing various neat things you can
    do with Unison's distributed programming support. This article presents an
    API for computations on distributed datasets. It's a bit like Spark, though
    we'll make different design choices in a few key areas. Our library will be
    absolutely tiny — the core data type is 3 lines of code, and operations
    like {Seq.map} are just a handful of lines each.

    {{
    docCallout
      (Some {{ 🌱 }})
      {{
      You can try writing programs with this API today, using local
      interpreters for {type Remote}. Programs written using {type Remote} can
      run unchanged on actual distributed infrastructure such as
      [Unison Cloud](http://unison.cloud).
      }} }}

    Spark is a huge project (over a million lines of code) with lots of
    functionality, but we're interested in just the core idea of a distributed
    immutable dataset that can be operated on in parallel.

    Here's a quick preview of what we'll get to in this article:

    {{ docSource [docSourceElement (docEmbedTermLink do ex1) []] }}

    This code will operate in parallel on a distributed sequence of whatever
    size, spread across any number of machines. The functions are "moved to the
    data" so there's little network traffic during execution, and the
    distributed sequence {type Seq} is lazy so nothing actually happens until
    the {Seq.reduce}. Also, the data structure fuses all operations so they
    happen in one pass over the data.

    Any stage of the computation can be cached via functions like {Seq.memo} or
    {memoReduce}. These functions cache subtrees of the computation as well,
    not just the root, so repeated runs of related jobs only have to compute on
    the diff of what's new. Imagine batch jobs that finish in seconds rather
    than hours.

    Developing distributed programs doesn't require building containers or
    deploying jar files. Due to Unison's design, dependency conflicts are
    impossible and there's no serialization code to write. We can focus on the
    core data structures, algorithms, and business logic.

    To test your code, we can use a simple local interpreter such as `run`:

    ```
    docs.run do ex1 (fromChunkedList 10 (Nat.range 0 100))
    ```

    ... or perhaps a more interesting "chaos monkey" local interpreter that
    injects failures and delays and simulated network partitions. Interpreters
    are also possible that determine the network usage of your program by local
    simulation ("Oh no! This sort is shuffling lots of data over the network!")
    allowing you to diagnose and fix performance problems without having to
    deploy or run jobs in production.

    We get all this from a library that is tiny (the core data type is just 3
    lines) and extensible. For instance, {Seq.map} is a few lines of
    straightforward code, and any user is empowered to add new operations.
    We'll explain this code and how it works next in the tutorial:

        @source{Seq.map}

    Operations on the distributed data structure end up looking similar to an
    in-memory version, just with an extra {Value.map} to move the computation
    inside a __remote {type Remote.Value}__. Any immutable data structure can
    be turned into a distributed version by wrapping references in remote
    values.

    Continue on to the tutorial for a detailed explanation.
  }}

articles.distributedDatasets.index.tutorial : Doc
articles.distributedDatasets.index.tutorial =
  {{ 🚧 UNDER CONSTRUCTION 🚧 🚧 CHECK BACK SOON! 🚧 }}

articles.distributedDatasets.reductions : Doc
articles.distributedDatasets.reductions =
  use Remote fork
  use Tree Two
  use Value get
  use lib Tree.map
  use lib.Tree take
  {{
  # Distributed and parallel reductions

    In the previous part of this series, we introduced a simple distributed
    tree type and showed how to implement transformation functions like {{
    docLink (docEmbedTermLink do Tree.map) }} in a way that "brings the
    computation to the data". We saw how functions like {{
    docLink (docEmbedTermLink do Tree.map) }} are lazy: they don't do any work
    when called but merely set up a pending transformation that will be applied
    as the data structure is forced.

    In this part of the series we'll focus on functions for our {type lib.Tree}
    data type that evalute or force the data structure in some way. We'll use a
    `reduce` function as an example. Again, this will illuminate how small
    tweaks to the code can cause different runtime behavior.

    {{
    docExample 3 do
      zero combine tree -> sequential.Tree.reduce zero combine tree }} has
    three parameters: a "zero" value to return if a subtree is empty, `combine`
    for combining the results of two subtrees, and the tree to be reduced.
    Reduce functions for in-memory data structures deal with a set of familiar
    concerns: do you want to reduce the left or right subtree first, should the
    reduce implementation be tail-recursive or maintain state on the stack, but
    because we're now working with distributed computations, our reduce
    implmentation needs to manage the additional dimensions of __where__ and
    __when__ the combine function for `reduce` should be run.

    We could write a `reduce` function that behaved in either one of the
    following ways:

    * __Send the function down:__ Push the combining function __down__ the tree
      to the data, and send the resulting {type Nat} reduced value back to the
      parent for combining.
    * __Send the subtrees up:__ Send each forced `Tree Nat` __up__ to its
      parent {Two}, which calls `reduce` on each subtrees, then `combines` the
      two {type Nat} results.

    We ultimately want the __Send the function down__ option, since sending a
    {type Nat} to the parent will be cheaper than sending a `Tree Nat` (only to
    immediately `reduce` that to a `Nat`), but we'll illustrate both here. Take
    a look at the recursive case in processing the {Two} branch in the
    following implementation:

    {{
    docSource
      [docSourceElement (docEmbedTermLink do sequential.Tree.reduce) []] }}

    It does the following:

    1. Evaluate the left subtree and send it to the current location.
    2. Evaluate the right subtree and send it to the current location.
    3. Recursively `reduce` the left subtree.
    4. Recursively `reduce` the right subtree.
    5. Apply the `combine` function to the two results from (3) and (4).

    We've implemented the __send the subtrees up__ approach. If the subtrees
    are at the same location as the parent, this is fine. But since this is
    meant to be used in situations where the data cannot fit on one location,
    there will be nodes in the tree where the parent resides at a different
    location than one of its subtrees. In these places we're sending more data
    over the network than we should.

    There's another problem with the __send the subtrees up__ approach: the
    reducing and combining is always happening where the parent resides. Since
    this is a recursive function, this means that all the work is ultimately
    happening at whatever location calls
    {{ docLink (docEmbedTermLink do sequential.Tree.reduce) }}. That is going
    to be bad when we try to add parallelism later—we can't have one location
    doing all the work!

    Let's try to write a version of `reduce` that implements the
    __send the function down__ approach, using {Value.map} instead:

    {{
    docSource [docSourceElement (docEmbedTermLink do withMap.Tree.reduce) []]
    }}

    This version will:

    1. `reduce` the left subtree at its location.
    2. `reduce` the right subtree at its location.
    3. Send the __reduced__ left value to the parent.
    4. Send the __reduced__ right value to the parent.
    5. Combine the two __reduced__ values at the parent.

    This is the __send the function down__ approach. Notice at at no point are
    we sending a {type lib.Tree} to the parent (there are no calls to {get}
    that return a {type lib.Tree}, only calls to {get} that return reduced
    values).

    While this is an improvement in our execution strategy for
    {{ docLink (docEmbedTermLink do sequential.Tree.reduce) }}, we are still
    reducing the left and the right subtrees sequentially, first the left, then
    the right. Why not reduce the two subtrees in parallel?

    To make this into a parallel reduce, we can use {fork} to start a
    computation running in a background {type Task}. An {await} blocks until
    the forked {type Task} completes and returns its result (or raises a
    failure if the forked task failed).

    {{
    docAside
      {{
      For very small subtrees and a cheap `combine` function, it might not
      always be worth forking a task, since even spawning one of Unison's
      lightweight threads has some overhead. The {type Seq} type we discuss in
      the last part of the article has support for controlling the granularity
      of parallelism.
      }} }}

    Using {fork} and {await} in our `reduce` function yields something like
    this:

    {{
    docSource [docSourceElement (docEmbedTermLink do parallel.Tree.reduce) []]
    }}

    Our left and right {type lib.Tree} branches are now being reduced in
    parallel through the use of {fork} and {await}. Moreover, all the pending
    transformations that have been applied to the tree (for instance via
    {{ docLink (docEmbedTermLink do Tree.map) }}) will be forced in parallel in
    the same pass as the
    {{ docLink (docEmbedTermLink do parallel.Tree.reduce) }}.

    {{
    docCallout
      (Some {{ 🤯 }})
      {{
      Wowser! So our distributed map and parallel reduce functions are just a
      few lines of code each. It's remarkable that we can obtain exactly the
      runtime behavior we want just by phrasing our functions in the right way.

      This is what writing distributed programs is like in Unison. You have to
      consider where and when you want computations to happen, and express
      those decisions with code, but it's a tiny amount of code that deals with
      the essence of the important decisions, not serialization or networking
      boilerplate, or deployment scripts or YAML files or building
      containers...
      }} }}

    ## Operations that only partially evaluate a structure

       Suppose we want to write a function that doesn't require us to fully
       evaluate the tree? Let's say we want a function {{
       docLink (docEmbedTermLink do take) }} that lists the first `n` elements
       it finds in the tree. Let's write a function that may not need to force
       the right subtree at all:

       {{ docSource [docSourceElement (docEmbedTermLink do take) []] }}

       The trick is we have to guard the right branch from being evaluated by
       keeping it wrapped in a {type Remote.Value}. So the function that joins
       together the left and right branches has to be more careful about the
       circumstances in which it evaluates the right branch via calls to {get}.

       {{ Folded true {{ **An exercise for the reader** 😎 }} {{ {{ ex7 }} }} }}

    ## Takeaways

       * {get} will force the evaluation of a {type Remote} value, bringing it
         to the location of the caller. You'll see it in functions which
         interpret the distributed data structure.
       * Use {Value.map} and {get} in tandem to control __where__ and __when__
         a computation should be run.
       * Unison's {fork} and {await} functions provide a way to introduce
         parallelization to remote computations.

       Whatever runtime behavior you want for your distributed computations can
       be achieved with only tiny code changes, and the decisions you make are
       then codified in reusable functions that others can use without needing
       to be experts in distributed systems.

       In the next part, we'll go further, showing how computations on
       distributed data structures can be made __incremental__, avoiding work
       that has already been done in a previous execution.
  }}

articles.distributedDatasets.reductions.lazy.Tree.reduce :
  a -> (a -> Remote.Value a ->{Remote} a) -> lib.Tree a ->{Remote} a
articles.distributedDatasets.reductions.lazy.Tree.reduce zero combine = cases
  lib.Tree.Empty                -> zero
  Tree.One valueA               -> Value.get valueA
  Tree.Two leftValue rightValue ->
    use Value map
    use articles.distributedDatasets.reductions.lazy.Tree reduce
    left' = map (t -> reduce zero combine t) leftValue
    right' = map (t -> reduce zero combine t) rightValue
    combine (Value.get left') right'

articles.distributedDatasets.reductions.parallel.Tree.reduce :
  a -> (a ->{Remote} a ->{Remote} a) -> lib.Tree a ->{Remote} a
articles.distributedDatasets.reductions.parallel.Tree.reduce zero combine = cases
  lib.Tree.Empty                -> zero
  Tree.One valueA               -> Value.get valueA
  Tree.Two leftValue rightValue ->
    use Remote fork
    use Value get map
    use articles.distributedDatasets.reductions.parallel.Tree reduce
    leftTask = fork here! do get (map (t -> reduce zero combine t) leftValue)
    rightTask = fork here! do get (map (t -> reduce zero combine t) rightValue)
    left' = await leftTask
    right' = await rightTask
    combine left' right'

articles.distributedDatasets.reductions.sequential.Tree.reduce :
  a -> (a ->{Remote} a ->{Remote} a) -> lib.Tree a ->{Remote} a
articles.distributedDatasets.reductions.sequential.Tree.reduce zero combine = cases
  lib.Tree.Empty -> zero
  Tree.One valueA -> Value.get valueA
  Tree.Two leftValue rightValue ->
    combine
      (articles.distributedDatasets.reductions.sequential.Tree.reduce
        zero combine (Value.get leftValue))
      (articles.distributedDatasets.reductions.sequential.Tree.reduce
        zero combine (Value.get rightValue))

articles.distributedDatasets.reductions.withFlatmap.Tree.reduce :
  zero
  -> (zero ->{Remote} zero ->{Remote} zero)
  -> lib.Tree zero
  ->{Remote} zero
articles.distributedDatasets.reductions.withFlatmap.Tree.reduce zero combine = cases
  lib.Tree.Empty -> zero
  Tree.One valueA -> Value.get valueA
  Tree.Two leftValue rightValue ->
    use Value map
    use withMap.Tree reduce
    left' = map (t -> reduce zero combine t) leftValue
    right' = map (t -> reduce zero combine t) rightValue
    reduced =
      Value.flatMap
        (leftTree -> map (rightTree -> combine leftTree rightTree) right')
        left'
    Value.get reduced

articles.distributedDatasets.reductions.withMap.Tree.reduce :
  a -> (a ->{Remote} a ->{Remote} a) -> lib.Tree a ->{Remote} a
articles.distributedDatasets.reductions.withMap.Tree.reduce zero combine = cases
  lib.Tree.Empty                -> zero
  Tree.One valueA               -> Value.get valueA
  Tree.Two leftValue rightValue ->
    use Value get map
    use articles.distributedDatasets.reductions.withMap.Tree reduce
    left' = map (t -> reduce zero combine t) leftValue
    right' = map (t -> reduce zero combine t) rightValue
    combine (get left') (get right')

articles.distributedDatasets.src.Tree.fromList : [a] -> lib.Tree a
articles.distributedDatasets.src.Tree.fromList = todo "implement Tree.fromList"

articles.distributedDatasets.src.Tree.map :
  (a ->{Remote} b) -> lib.Tree a -> lib.Tree b
articles.distributedDatasets.src.Tree.map f = cases
  lib.Tree.Empty -> lib.Tree.Empty
  Tree.One a     -> Tree.One (Value.map f a)
  Tree.Two l r   ->
    use lib Tree.map
    l' = Value.map (Tree.map f) l
    r' = Value.map (Tree.map f) r
    Tree.Two l' r'

articles.distributedDatasets.src.Tree.memo :
  Location {Scratch} -> lib.Tree a -> lib.Tree a
articles.distributedDatasets.src.Tree.memo location tree =
  todo "implement Tree.memo"

articles.distributedDatasets.src.Tree.reduce :
  a -> (a ->{g} 'a ->{Remote} a) -> lib.Tree a ->{Remote} a
articles.distributedDatasets.src.Tree.reduce n = todo "implement lazyReduce"

articles.distributedDatasets.src.Tree.reverse : lib.Tree a -> lib.Tree a
articles.distributedDatasets.src.Tree.reverse tree = todo "implement reverse"

articles.distributedDatasets.src.Tree.take : Nat -> lib.Tree a ->{Remote} [a]
articles.distributedDatasets.src.Tree.take n = cases
  lib.Tree.Empty            -> []
  Tree.One valueA           -> List.singleton (Value.get valueA)
  Tree.Two leftVal rightVal ->
    use List ++ size
    use Nat - >=
    use Value get map
    use lib Tree.take
    combine l r =
      if size l >= n then List.take n l
      else
        nextN = n - size l
        l ++ get (map (Tree.take nextN) r)
    combine (get (map (Tree.take n) leftVal)) rightVal

articles.distributedDatasets._authors : Doc
articles.distributedDatasets._authors =
  {{
  * Rebecca Mark
  * Paul Chiusano
  }}

articles.distributedDatasets._sidebar : Doc
articles.distributedDatasets._sidebar =
  {{
  * [Spark-like distributed datasets in under 100 lines of Unison]({{
    docLink (docEmbedTermLink do distributedDatasets.index)
    }})
  * [How to make any immutable data structure distributed]({{
    docLink (docEmbedTermLink do coreIdea)
    }})
  * [Distributed and parallel reductions]({{
    docLink (docEmbedTermLink do reductions)
    }})
  * [Incremental evaluation via memoization]({{
    docLink (docEmbedTermLink do incrementalEvaluation)
    }})
  * [Additional topics and FAQs]({{
    docLink (docEmbedTermLink do additionalTopics)
    }})
  }}

articles.distributedDatasets._summary : Doc
articles.distributedDatasets._summary =
  {{
  Spark-style distributed datasets can be modeled with a few lines of code,
  using Unison's distributed computing library. This article teaches you how.
  }}

articles.distributedDatasets._title : Doc
articles.distributedDatasets._title = {{ Spark-like datasets in Unison }}

blog.adventOfCode2022.index : Doc
blog.adventOfCode2022.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "📯 'Twas the month before Christmas, when all through the house, not a programmer was coding, with their keyboard or mouse..."
      )
    , ("date", "2022-11-29")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/aoc-2022.svg")
    , ("status", "published")
    ] }}

  # A Unison Advent of Code announcement in verse

    Twas the month before Christmas, when all through the house

    Not a programmer was coding, with their keyboard or mouse;

    [This README](https://share.unison-lang.org/@unison/code/latest/namespaces/public/advent_of_code/)
    was bookmarked on Unison Share

    In hopes that a puzzle would soon be there;

    [The advent was oauth'ed with my chosen creds](https://adventofcode.com/2022/auth/login),

    While visions of Unison danced in my head;

    And though I had
    [installed the UCM app](https://www.unison-lang.org/learn/quickstart/#step-1-install-unison),

    I had just settled down for a long winter's nap,

    When at 12 PM Eastern there came such a clatter,

    I sprang from the bed to see what was the matter.

    Away to my laptop I flew in a dash,

    To download the puzzle and code in a flash.

    The moon on the silvery laptop did show,

    A page still downloading, my network was slow!

    When what to my wondering eyes should appear,

    But a fun coding puzzle, the first of this year!

    With a two part solution, each download's a click,

    But a client exists for this, just
    [`solveAndSubmit`](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/;/terms/advent_of_code/submitSolution).

    "Don't copy your input", the
    [instructions explained](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/;/terms/advent_of_code/README),

    And when solving the puzzle you enter `run main`.

    To the {{
    docTooltip
      {{
      Unison leaderboard
      }}
      {{
      Join our Unison Leaderboard using the code 96155-309fe9eb
      }} }} my browser did fly,

    Filled with my fellow coders, all having a try.

    To the top of the leaderboard! With each http call!

    Now code away! code away! code away all!

    As submissions came in to the board in a queue,

    On a list full of friends, I saw my handle too!

    So to all those who join us, with every function and byte,

    Merry Advent of Code, and to all a good night!
  }}

blog.adventOfCodeALookBack.index : Doc
blog.adventOfCodeALookBack.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The ghost of Advent-of-Code past comes to visit in this recap of our favorite writeups from last year"
      )
    , ("date", "2024-11-24")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/aoc-2022.svg")
    , ("status", "published")
    ] }}

  # 🎁 These are a few of our favorite things

    Advent of Code is a yearly event that challenges programmers to solve a
    series of puzzles in the days leading up to Christmas. Unison programmers
    have
    [a wonderful history of documenting their solutions]({adventOfCodeHighlights2022.index})
    for others to follow along.

    Last year, we featured the many Unison solutions to the Advent of Code
    puzzles in
    [our holiday card](https://www.unison-lang.org/blog/holiday-card-2023/).
    Here's a recap with links to some of our favorite solution guides in case
    you missed it!

    ## 2023 Advent of Code Highlights



    ## Day 1

       Day 1: Trebuchet features an excellent {type List} pattern matching demo
       by @gfinol while @rlmark discusses combining the Parse and Ask abilities
       to reduce boilerplate when writing Unison.

       * [@gfinol's writeup](https://share.unison-lang.org/@gfinol/advent-of-code-2023/code/main/latest/terms/day01/README)
       * [@rlmark's writeup](https://share.unison-lang.org/@rlmark/aoc2023/code/main/latest/terms/day01/README)

    ## Day 2

       Day 2: Cube Conundrum, features @kemiller writing up a solution using
       Lists with a clever use of {uncollate}, a little known standard lib
       function. @jcwilk sums up this day nicely, "It was a lot of fun to
       explore how to best leverage folding and pattern matching to solve these
       problems." Calls to [foldMap]({List.foldBalanced}) abound!

       * [@jcwilk's writeup](https://share.unison-lang.org/@jcwilk/advent-of-code-2023/code/main/latest/terms/day02/README)
       * [@kemiller's writeup](https://share.unison-lang.org/@kemiller/advent-of-code-2023/code/main/latest/terms/day02/README)

    ## Day 3

       For Day 3: Gear Ratios, @ceedubs produced a beautiful explanation of his
       solution. It even includes mermaid diagrams using another Unison library
       by @alvaroc1 to better display the problem. @systemfw offers us a
       pro-tip about representing matrices as `Map` values, and leverages the
       {type Each} ability in his algorithm.

       * [@ceedubs' writeup](https://share.unison-lang.org/@ceedubs/advent-of-code-2023/code/main/latest/terms/day03/README)
       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day03/README)

    ## Day 4

       Day 4: Scratchcards has the Unison community sharing some wisdom when
       writing parsers. @cpenner's writeup includes a lesson on backtracking in
       parser combinator libraries and @systemfw and @rlmark sing the virtues
       of writing small parser combinators to test iteratively. @kemiller and
       @systemfw use two of Unison's data structures optimized for natural
       numbers, {type NatSet} and {type NatMap}, respectively.

       * [@chrispenner's writeup](https://share.unison-lang.org/@chrispenner/aoc/code/main/latest/namespaces/day04)
       * [@kemiller's writeup](https://share.unison-lang.org/@kemiller/advent-of-code-2023/code/main/latest/terms/day04/README)
       * [@rlmark's writeup](https://share.unison-lang.org/@rlmark/aoc2023/code/main/latest/terms/day04/README)
       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day04/README)

    ## Day 5

       In Day 5: If You Give A Seed A Fertilizer, @systemfw explored some
       optimizations. From his Readme: "I couldn't keep ucm churning all day
       since I had to...you know, work." Instead, his implementation explores
       an Interval map for greater efficiency. @jcwilk's writeup discusses the
       process of writing Unison programs itself, "I was able to follow a
       pattern of leaning hard into composition, building tiny one-line
       functions, and relying heavily on the typing system to assert correct
       program behavior."

       * [@jcwilk's writeup](https://share.unison-lang.org/@jcwilk/advent-of-code-2023/code/main/latest/terms/day05/README)
       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day05/README)

    ## Day 6

       For Day 6: Wait for it, @stew's lovely solution includes play-by-play
       descriptions of the functions which constitute his solution and a
       discussion wherein he uses mathematical reasoning to cut down on the
       problem space. Thank you @stew!

       * [@stew's writeup](https://share.unison-lang.org/@stew/advent-of-code/code/main/latest/terms/day06/README)

    ## Day 7

       Day 7: Camel Cards includes a pattern matching primer by @hagl, who
       exercises tuple decomposition, list pattern matching, and pattern guards
       in his algorithm! @systemfw's work includes a great discussion about
       when to use custom types or rely on more primitive abstractions in a
       language. Both are very educational reads!

       * [@hagl's writeup](https://share.unison-lang.org/@hagl/advent-of-code-2023/code/main/latest/terms/day07/README)
       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day07/README)

    ## Day 8

       Day 8: Haunted Wasteland, was a challenging day! @systemfw boldly went
       where many feared to tread and his solution discusses, among other
       things, the vicissitudes of cycle detection! It's wonderful to follow
       along with his problem solving process.

       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day08/README)

    ## Day 9

       For Day 9: Mirage Maintenance @dvberkel relates the problem to one which
       Douglas Hofstadter (of Goedel Escher Bach fame) studied. Very cool! He
       also uses a custom domain `Sequence` type to help clarify the problem
       space. It makes for a very readable writeup. Both @johanwinter and
       @kemiller explore more of the standard library, with lots of folds and
       unfolding over lists.

       * [@dvberkel's writeup](https://share.unison-lang.org/@dvberkel/advent-of-code-2023/code/main/latest/terms/day09/README)
       * [@johanwinther's writeup](https://share.unison-lang.org/@johanwinther/advent-of-code-2023/code/main/latest/namespaces/day09)
       * [@kemiller's writeup](https://share.unison-lang.org/@kemiller/advent-of-code-2023/code/main/latest/terms/day09/README)

    ## Day 10

       We love @ceedubs writeup for Day 10 because he takes the time to walk s
       through his problem solving logic and edge cases with humor and wisdom.
       It includes an interlude where he takes a walk away from his computer
       and he returns with a ray-casting inspired solution! Eureka!

       * [@ceedubs' writeup](https://share.unison-lang.org/@ceedubs/advent-of-code-2023/code/main/latest/terms/day10/README)

    ## Day 11

       To solve Day 11: Cosmic Expansion, @systemfw uses a Map based
       representation of the X,Y grid again. Unison's Map standard lib utility
       functions offer a rich set of options for this solution. We love @hagl's
       write-ups because he includes links to the helper functions that he adds
       or finds useful in the standard lib. This solution used "allPairs,"
       which is a function we'll keep in mind for generating pairs from a list.

       * [@hagl's writeup](https://share.unison-lang.org/@hagl/advent-of-code-2023/code/main/latest/terms/day11/README)
       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day11/README)

    ## Day 12

       In Day 12: Hot Springs, @hagl used a handy library for memoization to
       cut down his runtime from 7 hours (yay! an excuse to sleep!) to less
       than 4 minutes. @systemfw brought out the heavy artillery for the
       solutions for day 12, using both dynamic programming and parallelism.
       Any time we get the chance to listen to Fabio about concurrency, we'll
       take it!

       * [@hagl's writeup](https://share.unison-lang.org/@hagl/advent-of-code-2023/code/main/latest/terms/day12/README)
       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day12/README)

    ## Day 13

       For Day 13: Point of Incidence, @systemfw's solution writeup includes
       some beautiful ascii art to help explain his algorithm and also breaks
       down some efficiency shortcuts for part 2 of the problem.

       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day13/README)

    ## Day 14

       For Day 14: Parabolic Reflector Dish, @systemfw wrote a Shakespearean
       play in 5 acts. Just kidding! No really, there is a whole introduction
       section to the problem, a section dedicated to the core algorithm, and
       two sections dedicated to writing a custom memoization ability and
       ability handler. Truly a masterclass!

       * [@systemfw's writeup](https://share.unison-lang.org/@systemfw/aoc-2023/code/main/latest/terms/day14/README)
  }}

blog.adventOfCodeHighlights2022.index : Doc
blog.adventOfCodeHighlights2022.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "On the nth day of Advent, I found in your README's... Four hill climbing algorithms, three parser libraries, two livestreams, and the best of the Unison community."
      )
    , ("date", "2022-12-20")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/aoc-2022.svg")
    , ("status", "published")
    ] }}

  # The Unison Advent-of-Code mega writeup

    We've been blown away by the creativity and ingenuity of the Advent of Code
    2022 solutions that have been shared by members of the community. In a
    surprising and unprompted gesture of generosity, many community members
    have taken the time to __annotate their solutions__ with README's
    describing their thought processes and algorithms. We love seeing the
    community come together to share their work and learn from each other.

    Advent of Code has brought a lot of new faces to the Unison community.
    Welcome! We're happy you're here! It has also brought a lot of fresh
    [base](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/base/latest)
    library functions and data type libraries into being. We're grateful for
    the contributions of the community in helping us to fill in the gaps.

    In celebration of the season, we've collected a smattering of of our
    favorite solutions. Here's to you! 🥂

    The remainder of this post contains spoilers for the Advent of Code 2022
    puzzles. We've tried to highlight unique solutions and illuminating
    writeups. Often, we present multiple approaches to solving the puzzles from
    the community so you can see the diverse and brilliant (and at times
    comical) minds at work in Unison. There were __a lot__ to choose from so
    the selection here is somewhat arbitrary. The links and notes are hidden
    behind a folded doc, so you can choose whether to peek or not if you intend
    to catch up. {{ docAside {{ 🎅🏻 Just know, he's watching. }} }}

    {{ _day1 }}

    {{ _day2 }}

    {{ _day3 }}

    {{ _day4 }}

    {{ _day5 }}

    {{ _day6 }}

    {{ _day7 }}

    {{ _day8 }}

    {{ _day9 }}

    {{ _day10 }}

    {{ _day11 }}

    {{ _day12 }}

    {{ _day13 }}

    {{ _day14 }}

    {{ _day15 }}

    {{ _day17 }}

    {{ _day18 }}
  }}

blog.adventOfCodeHighlights2022._day1 : Doc
blog.adventOfCodeHighlights2022._day1 =
  _foldDoc
    {{
    Day 1: Calorie Counting with Stew O'Connor 🔢
    }}
    {{
    If you thought [Day 1](https://adventofcode.com/2022/day/1) was gonna be
    quick, you should know, we can turn most exercises into a chance to
    yak-shave.

    We love
    [Stew O'Connor's solution to Day 1](https://share.unison-lang.org/@stew/p/code/latest/namespaces/public/advent_of_code_2022/day01/)
    because he used the input parsing step as an opportunity to improve the
    [Uniparsec library](https://share.unison-lang.org/@stew/p/code/latest/namespaces/public/projects/uniparsec/main).
    As a result of this puzzle, the Uniparsec library can parse input directly
    into a `Monoid` data type. The
    [advent of code day 1 README](https://share.unison-lang.org/@stew/p/code/latest/namespaces/public/advent_of_code_2022/day01/)
    explains these changes in detail.
    }}

blog.adventOfCodeHighlights2022._day10 : Doc
blog.adventOfCodeHighlights2022._day10 =
  _foldDoc
    {{
    Day 10: Cathode-ray tube featuring Joe Harrison and Calvin Sauer 📺
    }}
    {{
    🐣 What's a cathode ray tube? Just kidding, Unison is a young language but
    we remember the cathode ray tube's
    [familiar buzz](https://en.wikipedia.org/wiki/Cathode-ray_tube#High-frequency_audible_noise).

    [This puzzle](https://adventofcode.com/2022/day/10) involved calculating
    the value of a signal at specific intervals in a sequence of clock "ticks"
    or cycles.

    Both
    [This solution by Joe Harrison](https://share.unison-lang.org/@sigwinch28/p/code/latest/namespaces/public/aoc/;/terms/day10/README)
    and
    [this solution by Calvin Sauer](https://share.unison-lang.org/@cjsauer/p/code/latest/namespaces/public/advent_of_code_2022/day10)
    are great examples of understanding the constraints of the domain being
    modeled and simplifying it to make subsequent computations more
    straightforward. Check them out, they are very clever!
    }}

blog.adventOfCodeHighlights2022._day11 : Doc
blog.adventOfCodeHighlights2022._day11 =
  _foldDoc
    {{
    Day 11: Monkey in the Middle with ChatGPT 🐵
    }}
    {{
    What were these monkeys doing?
    [Day 11's](https://adventofcode.com/2022/day/11) instructions were
    **wild**.

    The real galaxy-brained problem solving innovation from the Unison
    community is that Rúnar fed the instructions into ChatGPT. 🤖 The puzzles
    for [Day 11](https://adventofcode.com/2022/day/11) became much more
    intelligible afterwards.

    Here's what part 1 of the problem is in plain English:

    "Four lists are given, each with a set of starting items and an operation
    that changes the item’s value. After the operation is applied, the item is
    tested based on a specified value. If the test is true, the item is
    appended to a specified list. If the test is false, the item is appended to
    a different specified list. The process repeats until all lists have had an
    iteration. Each time an item is inspected, its value is divided by three
    and rounded down before the next operation is applied.

    The above process repeats for 20 iterations. After 20 iterations, the total
    number of items that were processed by each list are tallied. The number of
    items processed by the two most active lists are multiplied together, and
    this number is the answer."

    Thank you, ChatGPT. 🙏
    }}

blog.adventOfCodeHighlights2022._day12 : Doc
blog.adventOfCodeHighlights2022._day12 =
  _foldDoc
    {{
    Day 12: Hill climbing with Dijkstra and company 🌄
    }}
    {{
    We did not expect anyone to implement graph traversal algorithms for us as
    a result of Advent of Code! (Or maybe we did, and Advent of Code is a ruse
    to generate more useful code examples for everyone. 🥸)

    [Day 12](https://adventofcode.com/2022/day/11) involved finding the
    shortest path between two points on a hilly terrain.

    This set of puzzles inspired a variety of approaches, some of which we've
    highlighted below.

    [This solution by Calvin Sauer](https://share.unison-lang.org/@cjsauer/p/code/latest/namespaces/public/advent_of_code_2022/day12/;/terms/README)
    is an implementation of the
    [A* search algorithm](https://en.wikipedia.org/wiki/A*_search_algorithm).
    Thanks Calvin! That's sure to come in handy in the future!

    Another solution used
    [Breadth First Search](https://en.wikipedia.org/wiki/Breadth-first_search)
    to solve the problem. You can read a fantastic walk through of the
    algorithm and solution
    [here in Joe Harrison's day 12 README](https://share.unison-lang.org/@sigwinch28/p/code/latest/namespaces/public/aoc/;/terms/day12/README).

    Saif Elokour wrote
    [a brain melting hill-climbing approach](https://share.unison-lang.org/@saifelokour/p/code/latest/namespaces/public/advent_of_code/day12)
    that you should check out as well.

    And finally, what would Advent of Code be without a solution that uses
    [Dijkstra's algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)?
    [Check out this implementation by Rúnar Bjarnason](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/advent/code2022/day12/;/terms/dijkstra)
    to see what that looks like in Unison.
    }}

blog.adventOfCodeHighlights2022._day13 : Doc
blog.adventOfCodeHighlights2022._day13 =
  _foldDoc
    {{
    Day 13: Distress signal with Eduard Nicodei 🗼
    }}
    {{
    We really enjoyed
    [this solution by Eduard Nicodei](https://share.unison-lang.org/@neduard/p/code/latest/namespaces/public/advent_of_code_2022/;/terms/day13/README)
    to [Day 13's puzzles](https://adventofcode.com/2022/day/13) because it
    truly embodies the spirit of Unison's Advent of Code. To learn more about
    Unison ability-based parsers, Eduard
    **wrote a whole mini parser combinator library** based on an existing
    library in Unison. In addition to explaining the puzzle solutions,
    [the README](https://share.unison-lang.org/@neduard/p/code/latest/namespaces/public/advent_of_code_2022/;/terms/day13/README)
    contains a full explanation of how the `Parse` ability works so that others
    can learn about it. Amazing! 🥲
    }}

blog.adventOfCodeHighlights2022._day14 : Doc
blog.adventOfCodeHighlights2022._day14 =
  _foldDoc
    {{
    Day 14: In the Regolith Reservoir with the Unison community ⏳
    }}
    {{
    [Day 14 of Advent of Code](https://adventofcode.com/2022/day/14) involved
    calculating the number of falling sand units in a cave filled with rocky
    obstacles.

    A number of solutions modeled the cave with a `Map (Nat, Nat) Cell` data
    structure where the `Cell` was either a `Rock`, `Sand`, or `Empty`. Check
    out
    [this amazing writeup](https://share.unison-lang.org/@neduard/p/code/latest/terms/public/advent_of_code_2022/day14/doc)
    for a map-backed implementation by Unison community member
    [Eduard](https://share.unison-lang.org/@neduard/p/code/latest) who also
    wrote a custom "cave viewer" function.

    We also live-coded this one together in a Community day stream.

    {{
    (Special
      (Embed
        (Any
          (Video
            [ MediaSource
                "https://www.youtube.com/embed/Lvw7m_6uyUE" (Some "youtube")
            ]
            [])))) }}

    A notably different implementation was
    [Rúnar's cave algorithm](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/advent/code2022/;/terms/day14/solution),
    which used a
    [mutable ByteArray data type](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/base/latest/;/types/mutable/ByteArray)
    and a runloop to track the units of fallen sand.

    This implementation has a number of performance optimizations. First,
    storage of the "cell" value is made more compact by using a ByteArray
    rather than a data type like `List a` where it's possible to store any
    type. Second, usage of a flat array allows for fast random access and array
    element updates. It might seem non-intuitive to map a 2D grid into a
    list-like data structure, but to do this you can use an indexing scheme
    based on the row length and the desired (x,y) coordinates. Your array index
    from coordinates can be calculated as `index = x * rowLength + y`. Very
    cool, Rúnar! 🤩
    }}

blog.adventOfCodeHighlights2022._day15 : Doc
blog.adventOfCodeHighlights2022._day15 =
  _foldDoc
    {{
    Day 15: Advent of Code Day 15: Beacon Exclusion Zone with Joe Harrison
    }}
    {{
    For [Day 15](https://adventofcode.com/2022/day/15) we were given a grid of
    beacons and signals and tasked to find the locations where the beacons
    could not be located for a certain row.

    We are in awe of the curiosity and care evident in these explanations of
    your work. Take a look at Joe Harrison's
    [day 15 README](https://share.unison-lang.org/@sigwinch28/p/code/latest/namespaces/public/aoc/day15)
    it's replete with diagrams, examples, and links to other resources.
    }}

blog.adventOfCodeHighlights2022._day17 : Doc
blog.adventOfCodeHighlights2022._day17 =
  _foldDoc
    {{
    Day 17: Pyroclastic Flow - Rúnar shares some bitwisdom 🪨
    }}
    {{
    [Day 17's puzzle](https://adventofcode.com/2022/day/17) looked a bit like
    Tetris; rocks were stacking on top of one another in a long tunnel whilst
    being buffeted back and forth by jet streams.

    It sounds like Rúnar worked hard to develop
    [his solution](https://share.unison-lang.org/@runarorama/p/code/latest/terms/public/advent/code2022/day17/part1)
    solution and offered this hint: "this solution is completely insane, I
    decided to represent each 8x8 block of the tunnel as a Nat. This was my
    first mistake"

    Duly noted, Rúnar.
    }}

blog.adventOfCodeHighlights2022._day18 : Doc
blog.adventOfCodeHighlights2022._day18 =
  _foldDoc
    {{
    Day 18: Boiling Boulders with Joe Harrison 🌋
    }}
    {{
    For [Day 18](https://adventofcode.com/2022/day/18), we needed to calculate
    the surface area of lava cubes in a 3D grid given x, y, and z coordinates.
    If, like me, you think imagining lava voids in three dimensional space is a
    little mind melting, you might find
    [this solution and thorough write-up by Unison community member Joe
    Harrison](https://share.unison-lang.org/@sigwinch28/p/code/latest/namespaces/public/aoc/;/terms/day18/README)
    especially refreshing.

    This solution collects the coordinates of the lava cubes in a {type Set}
    and then finds their
    [Von Neumann neighborhood](https://en.wikipedia.org/wiki/Von_Neumann_neighborhood)
    along the three axes. We won't spoil everything here,
    [This solution writeup is 🤌. Really, you should read it](https://share.unison-lang.org/@sigwinch28/p/code/latest/namespaces/public/aoc/;/terms/day18/README),
    but suffice to say we're impressed with the elegance of this solution.
    }}

blog.adventOfCodeHighlights2022._day2 : Doc
blog.adventOfCodeHighlights2022._day2 =
  _foldDoc
    {{
    Day 2: Rock Paper Scissors with Rebecca Mark 📃
    }}
    {{
    Advent of Code [Day 2](https://adventofcode.com/2022/day/2) is a game of
    Rock Paper Scissors with a twist. The twist is that the rules of the game
    are encoded in a text file and you're given varying strategy guides to
    determine your response.

    Often, half of challenge of Advent of Code is parsing the input. This month
    offered a timely opportunity to update
    [this abilities based parser library](https://share.unison-lang.org/@rlmark/p/code/latest/namespaces/public/parsing/latest)
    hosted on Unison Share. With this parser, we can do things like parse a
    line of input directly into datatypes that model the game play for easy
    scoring. That's what
    [this solution](https://share.unison-lang.org/@rlmark/p/code/latest/namespaces/public/;/terms/projects/aoc2022/day02/part1),
    written by yours truly does for parts 1 and 2.
    }}

blog.adventOfCodeHighlights2022._day3 : Doc
blog.adventOfCodeHighlights2022._day3 =
  _foldDoc
    {{
    Day 3: Rucksack Reorganization with Chris Penner and company 🎒
    }}
    {{
    [Day 3](https://adventofcode.com/2022/day/3) we did as part of community
    coding livestream with Unison team member
    [Chris Penner](https://share.unison-lang.org/@chrispenner/p/code/latest/namespaces/public)!
    We had a lot of fun solving this one together! You can watch the recording
    below.

    {{
    (Special
      (Embed
        (Any
          (Video
            [ MediaSource
                "https://www.youtube.com/embed/CLQEQUnMa5I" (Some "youtube")
            ]
            [])))) }}
    }}

blog.adventOfCodeHighlights2022._day4 : Doc
blog.adventOfCodeHighlights2022._day4 =
  _foldDoc
    {{
    Day 4: Camp Cleanup with Calvin Sauer 🏕
    }}
    {{
    We love this solution to [Day 4](https://adventofcode.com/2022/day/4) by
    [Calvin Sauer](https://share.unison-lang.org/@cjsauer/p/code/latest/namespaces/public/advent_of_code_2022/day04/;/terms/README).
    It's a wonderful example of how to use the newly added
    [NatSet data type](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/base/latest/;/types/data/NatSet)
    to solve the problem of identifying whether a range of values fully
    contains another. A NatSet is a Set which is optimized for containing
    {type Nat} elements, so you might reach for this datatype instead of the
    generic {type Set} next time your code requires storing {type Nat} elements
    or things that can be encoded as {type Nat} elements.
    }}

blog.adventOfCodeHighlights2022._day5 : Doc
blog.adventOfCodeHighlights2022._day5 =
  _foldDoc
    {{
    Day 5: Crates with Jemma Nelson 📦
    }}
    {{
    Advent of Code [Day 5](https://adventofcode.com/2022/day/5) is a puzzle
    about moving groups of crates around using cranes.

    This solution and documentation by
    [Jemma Nelson](https://share.unison-lang.org/@fwip) is one of our
    favorites. Highlights include finding and using the
    {jsonschema.lib.base.data.List.transpose} function for rotating the crates
    and a handy recursive function for moving the crates around. We love that
    others can follow along using
    [the writeup](https://share.unison-lang.org/@fwip/p/code/latest/namespaces/public/advent_of_code_2022/day05/;/terms/doc),
    or shall we say, we are very... crateful for it! 🎁

    (I'm sorry, I will see myself out.)
    }}

blog.adventOfCodeHighlights2022._day6 : Doc
blog.adventOfCodeHighlights2022._day6 =
  _foldDoc
    {{
    Day 6: Tuning Trouble with Calvin Sauer and Rúnar Bjarnason 🤳
    }}
    {{
    [Day 6's Advent of Code](https://adventofcode.com/2022/day/6) puzzle
    involved finding characters in an input string that did not repeat in a
    given window.

    Rúnar's solution used the {type Stream} ability to inspect the input, also
    prompting some new functions in the standard library.
    [His day 6 README](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/advent/code2022/;/terms/day06/README)
    goes into depth to explain the new window function.

    For a creative optimized O(n) solution,
    [Calvin Sauer's solution](https://share.unison-lang.org/@cjsauer/p/code/latest/namespaces/public/advent_of_code_2022/day06)
    walks the character input with a {type Map}, incrementing and decrementing
    a count of characters until a duplicate is found.
    }}

blog.adventOfCodeHighlights2022._day7 : Doc
blog.adventOfCodeHighlights2022._day7 =
  _foldDoc
    {{
    Day 7: No Space Left with Rúnar Bjarnason and Stew O'Connor 🗄
    }}
    {{
    For [Day 7's puzzles](https://adventofcode.com/2022/day/7) We needed to
    model a file system, with information about files, sub-directories, and
    file sizes provided by a log of commands as our textual input.

    [This solution by Rúnar Bjarnason](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/advent/code2022/;/terms/day07/README)
    uses a Zipper to traverse the directory tree structure as its being parsed!
    Zippers are data structures that consist of a focus and some surrounding
    context. The focus is the current node in the tree, and the context is the
    rest of the tree. With a zipper over the directory tree, you can do things
    like move up and down the file system, add information as it's revealed,
    and keep track of what directory nodes you've visited. Check out
    [Rúnar's day 7 README](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/advent/code2022/;/terms/day07/README)
    for more about the `TreeZipper` data type he used.

    As a result of this puzzle, we even have a new data structure library for
    you all to enjoy:
    [Rose Trees and Zippers](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/rose/;/terms/latest/README).
    🌹

    If zippers aren't your thing.
    [Stew's solution](https://share.unison-lang.org/@stew/p/code/latest/namespaces/public/advent_of_code_2022/day07/;/terms/README)
    uses a {type Map} as the data backing for the directory tree structure.
    After the input is parsed, the {type Map} is updated with new information
    about the file system. If you're ever curious about the {type Pattern} API
    for parsing text, this README contains a fantastic example.
    }}

blog.adventOfCodeHighlights2022._day8 : Doc
blog.adventOfCodeHighlights2022._day8 =
  _foldDoc
    {{
    Day 8: Treetop Tree House with Cody Allen 🌲
    }}
    {{
    [Day 8](https://adventofcode.com/2022/day/8) gave us the hights of a forest
    of trees in a grid. We needed to identify which trees in the forest were
    visible from north south east and west given their height.

    Cody's ingenious solution to Day 8 features
    [a **glorious** writeup](https://share.unison-lang.org/@ceedubs/p/code/latest/namespaces/public/advent_of_code_2022/;/terms/day08/README).
    Chief among the innovations here is that rather than writing separate
    functions to identify visible trees in each direction, Cody
    __rotated the whole forest 90 degrees__. Herculean! 🏆
    }}

blog.adventOfCodeHighlights2022._day9 : Doc
blog.adventOfCodeHighlights2022._day9 =
  _foldDoc
    {{
    Day 9: Rope physics with Saif, Rúnar, Cody, Calvin, Jan, and Joe 🪢
    }}
    {{
    A number of folks came up with similar solutions to
    [Day 9's puzzles](https://adventofcode.com/2022/day/9) by writing functions
    that move the head of the rope one step and subsequently update the tail,
    you can read
    [Rúnar's solution writeup](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/advent/code2022/;/terms/day09/README),
    [Cody's solution writeup](https://share.unison-lang.org/@ceedubs/p/code/latest/namespaces/public/advent_of_code_2022/;/terms/day09/README),
    [Saif's solution writeup](https://share.unison-lang.org/@saifelokour/p/code/latest/namespaces/public/advent_of_code/day09),
    [Jan's solution writeup](https://share.unison-lang.org/@fride/p/code/latest/terms/public/advent_of_code_2022/day09/README)
    and
    [Joe's solution writeup](https://share.unison-lang.org/@sigwinch28/p/code/latest/namespaces/public/aoc/;/terms/day09/README)
    for their generous explanations. For a slight variation,
    [Calvin's solution to the rope physics puzzle](https://share.unison-lang.org/@cjsauer/p/code/latest/namespaces/public/advent_of_code_2022/day09)
    simplifies the calculation of the location of the rope by parsing the input
    as a delta representing the direction of the rope's movement.

    😆 This puzzle inspired some real gems:

    * "Assume a spherical rope in an ideal vacuum" - Joe Harrison
    * "I'm revising history and writing this as though I used Int from the
      beginning" - Cody Allen
    * "The only difference with part 2 is that we need to calculate the tail of
      the tail of the tail... ten times" - Saif Elokour
    * "Rope physics. Yay." - Calvin Sauer
    }}

blog.adventOfCodeHighlights2022._foldDoc : Doc -> Doc -> Doc
blog.adventOfCodeHighlights2022._foldDoc title body =
  Folded
    true {{
    # {{ title }}


    }} body

blog.adventOfCodeTooling2022.index : Doc
blog.adventOfCodeTooling2022.index =
  use Debug trace
  use base bug
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison provides tooling to make it easy to try this year's Advent of Code. If you fall off the proverbial sleigh mid-way through the month of December, don't worry, the real advent is the friends you made along the way. 🎅🏻"
      )
    , ("date", "2022-12-02")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/aoc-2022.svg")
    , ("status", "published")
    ] }}

  # Feeding the reindeer with Unison's Advent of Code tooling ⭐️

    This year's Advent of Code is all about feeding the reindeer. Or rather, it
    should be, but before you tackle the Advent of Code you might have to set
    up helper functions for doing file I/O, translating bytes into UTF-8 text,
    and then there's the separate business of downloading your personalized
    puzzle input and submitting your answer for validation. Those precious
    nanoseconds add up when you're attempting to make it on the leaderboard! Or
    maybe you just want to focus on the puzzle at hand. Wouldn't it be nice to
    run everything in the UCM? Thanks to Unison teammate Cody Allen,
    [Unison has a library to support that](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/advent_of_code).

    Unison has set up a template project for the Advent of Code with the goal
    of getting folks solving puzzles with minimal friction. It takes care of
    downloading your unique puzzle input, submitting your answer, and will let
    you know if your submission was correct! You won't have to copy a text blob
    to a file or input a value into the web form.

    ## Here's how it works

       {{
       docAside
         {{
         The download button given on Unison share will try to put the advent
         of code template project into a `lib` namespace because of library
         conventions, but this project should be pulled into the top level of
         your codebase.
         }} }}

       First, pull the
       [advent of code project](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/advent_of_code)
       with the following command:

       ``` ucm
       pull unison.public.advent_of_code .advent_of_code
       ```

       Next you should log in to the the
       [Advent of Code website](https://adventofcode.com/) to let the Advent of
       Code know who you are. The Advent of Code client will need to submit
       your puzzle as **you** with a session cookie. This involves a bit of
       browser tooling spelunking so fortunately the marvelous Chris Penner has
       provided a walk through video for getting the token you need for
       authentication.

       {{
       Special
         (Embed
           (Any
             (Video
               [ MediaSource
                   "https://www.youtube.com/embed/tUd33_CXCzE" (Some "youtube")
               ]
               []))) }}

       Use that session cookie in one of the ways specified by
       [the project readme](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/advent_of_code)
       and you are set up to download and submit.

       In this project, each day is in a namespace which contains two functions
       corresponding to parts one and two of the challenge.

       ``` unison
       day01.part1 : '{IO, Exception} ()
       day01.part1 = do
         solve input = todo "implement solution for day 1 part 1"
         submitSolution (Day 1) (Part 1) solve
       ```

       {{
       docAside
         {{
         Functions like {Nat.toText} and {fromTextOrFail} may be helpful as
         many of the puzzles will be expressed in numbers.
         }} }}

       The part **you** need to implement is the function called "solve". It
       takes in a value of {type Text} which represents the input, and returns
       a value of {type Text} which is the value that would otherwise be
       entered into the Advent of Code website as your answer. Run
       `edit day01.part1` to bring the function into a local scratch file.

       When you want to submit your answer you will run something like
       `run day01.part1` in the UCM to see if your answer was correct.

    ## Debugging tips from the team

       **How do I see the input text before I start my implementation?**

       You can use the {trace} function for quick "printLine" style debugging.
       This call to {trace} will split the input on newlines and take the first
       100 lines:

       ``` unison
       day01.part1 : '{IO, Exception} ()
       day01.part1 = do
         solve input =
           Debug.trace "puzzleInput" (Text.split ?\n input |> take 100)
           todo "implement solution for day 1 part 1"
         submitSolution (Day 1) (Part 1) solve
       ```

       **How do I see my answer before I submit to the api?**

       A fastest way to do this is to redirect the results of the stub function
       with a call to {bug}. {bug} will abort the program and print the result
       of `solve` to the UCM console.

       `submitSolution (Day 1)(Part 1)(solve >> bug)`

       **I'm in the `adventOfCode.dayN` namespace, why can't Unison find the
       standard lib?**

       Unison namespaces are "scoped" in what they can reference in the
       codebase so it's common to work with your UCM console at the project
       "root" ("adventOfCode" in this case). If you've `cd`-ed into a namespace
       called `adventOfCode.day01` you're one level too far down the namespace
       tree to reference the `lib` directory in the project. `cd ..` to go back
       up one level and `edit` the puzzle function from there.

    ## Community

       If you haven't joined us in [Slack](https://unisonweb.org/slack), come
       by, we're friendly! There's a channel called `#adventOfCode`, where you
       can get help with puzzle solving and check out others solutions. A few
       of the Unison team members have been helpfully documenting their
       solutions to help others follow along or learn new approaches.

       🎄 We hope you're having a very happy Advent of Code!
  }}

blog.aocInUnison2023.index : Doc
blog.aocInUnison2023.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "This year Unison warmly invites you to participate in the Advent of Code! Here are some of the ways you can get started."
      )
    , ("date", "2023-11-27")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/aoc-2022.svg")
    , ("status", "published")
    ] }}

  # Join Unison for the Advent of Code 2023

    Season's greetings! We’d like to warmly invite all programming enthusiasts
    to join us in tackling this year's Advent of Code in the Unison programming
    language. Here are some of the ways you can participate in the festivities.
    🎁

    **1. Download the Advent of Code template project**

    Unison comes equipped with its very own template project for completing the
    Advent of Code. You can use this project to download your puzzle inputs and
    submit your solutions, all without having to leave the Unison Codebase
    Manager. No need to juggle between multiple tools or text files; Unison
    streamlines the entire process for you!
    [Read more about how to use this library here](https://share.unison-lang.org/@unison/advent-of-code).

    **2. Learn and share with others**

    Past participants have generously documented their puzzle-solving thought
    processes, providing explainers for many of the challenges written in the
    Unison Doc format. We collected a few of our favorites in
    [last year’s Advent of Code writeup](https://www.unison-lang.org/whats-new/advent-of-code-highlights2022/).
    We hope this is a tradition that we’ll carry forward to this year.

    **3. Collaborate in real time**

    There are a few active community channels dedicated to the Advent of Code.
    Members of our #advent-of-code
    [Slack channel](https://unison-lang.org/slack) have created daily threads
    for their questions and solutions in the past. You can also join our
    [Advent-of-Code Discord channel](https://discord.gg/3jKgztWDAW) for
    streaming or screen sharing.

    **4. Climb the leaderboard**

    Team up with fellow programmers and collect your stars on our community
    leaderboard. To sign up, head to
    [https://adventofcode.com/2023/leaderboard/private](https://adventofcode.com/2023/leaderboard/private)
    and enter the code `96155-309fe9eb`.

    🎄 We’re excited for the month to come! Head over to our community spaces,
    start practicing your puzzle solving skills, and may your Advent-of-Code be
    filled with joy!
  }}

blog.april_2020Update.index : Doc
blog.april_2020Update.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "We've just released milestone M1l of the the Unison Codebase Manager, which focused on essentials for ecosystem growth, specifically: guidance and tools for structuring and licensing your own libraries, and contributing to others."
      )
    , ("date", "2020-04-25")
    , ("authors", "arya-irani")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing4.svg")
    ] }}

  # Get set up for publishing Unison libraries with milestone M1l

    Hi folks! We've just released milestone M1l of the the Unison Codebase
    Manager (the [quickstart guide](/docs/quickstart) has install
    instructions), which focused on essentials for ecosystem growth,
    specifically: guidance and tools for structuring your own libraries and
    contributing to others.

  # A Slack channel to talk about Unison libraries you're working on

    Rúnar has started
    [#hackathon](https://slack.com/app_redirect?channel=C011CJFTQP9&team=TLL09QC85)
    on the [Unison Slack](/slack), as a place to talk about Unison libraries
    you're working on, find collaborators, and compare notes. He's also started
    streaming Unison live-coding sessions! Check out reruns
    [on Twitch](https://twitch.tv/runarorama), or join
    [#hackathon](https://slack.com/app_redirect?channel=C011CJFTQP9&team=TLL09QC85)
    to chat about the next one.

  # Organizing your codebase

    We've had our first few PRs to `unisonweb/base`, which has been been
    rewarding, and also forced us to sit down and figure out what a nice
    process in Unison might look like. So check out the draft docs on
    [how to organize your codebase](/docs/codebase-organization). It gives some
    guidance on how to install new Unison libraries (both "released" and
    pre-released), doing the day-to-day work of creating, or reviewing and
    merging pull requests, and how to publish a release of your own.

  # Publishing a library

    Speaking of publishing your own libraries, we are now hosting a
    [Unison code catalog](/docs/libraries) to show off what projects people are
    working on, or maybe accepting contributions for. As of this writing, we've
    only listed `unisonweb/base`, so please submit your new libraries to the
    list via PR (until we have an automated solution)! 🙂

    You can use the new `create.author` command to create `Author` and
    `CopyrightHolder` values to attach, along with your library's `License`, as
    metadata to your published definitions.

    As of M1l, you can
    [configure the Unison Codebase Manager](/docs/configuration) with some
    default metadata to attach to all of your work. You can also associate a
    default Git url to a given namespace, meaning that with some configuration,

    ``` ucm
    ._coolproject> push git@github.com:myorg/coolproject
    ```

    can become simply:

    ``` ucm
    ._coolproject> push
    ```

    and similarly for `pull`.

  # UCM improvements

    Speaking of `push` and `pull`, these commands have been updated to be a bit
    snappier. The `view` and `display` commands now support suffix-based
    lookups (we're tracking down all the stragglers that don't!). The runtime
    now supports more operations on `Int` and `Nat`, and we've fixed a few
    other whoopsies. (Thanks to @pete-ts, @noahhaasis, @stew, and @atacratic
    for their PRs!)

  # What's next?

    Work on the faster new runtime has been humming along, and we plan to
    release it soon in milestone M2. We'll add better support for the
    abovementioned proposed codebase organization format to UCM, e.g. good
    project scoping for commands where it matters, and we're also about to
    start devoting more resources to the distributed computing libraries. 🚀

    Are we forgetting anything? Tweet
    [@unisonweb](https://twitter.com/unisonweb) or come tell us
    [on Slack](https://unisonweb.org/slack)!
  }}

blog.autocomplete.index : Doc
blog.autocomplete.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The Unison Language Server adds autocompletion support for Unison terms. If only the LSP integration could autocomplete all our non-Unison work. 🤔"
      )
    , ("date", "2022-11-28")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/lsp.svg")
    , ("status", "published")
    ] }}

  # Dear Unison Language Server, you autocomplete us 💌

    The M4d release added term autocompletion to the Unison Language Server.
    This means that if you have
    [the Unison LSP installed](https://github.com/unisonweb/unison/blob/trunk/docs/language-server.markdown),
    you'll get suggestions for possible Unison terms based on the prefix of the
    term that you've started.

    **Check it out:**

    {{
    Image
      {{
      gif autocomplete suggesting a function from the Map namespace
      }}
      {{
      /assets/feed/autocomplete/autocomplete-demo.gif
      }}
      Optional.None }}

    Unison teammate Chris Penner has been hard at work adding LSP tooling
    improvements. This feature is the latest addition to others like viewing
    the type of a term on hovering, and in-editor error rendering. Thank you,
    Chris, for making our developer experience more complete! 💐
  }}

blog.batchStorageApi.index : Doc
blog.batchStorageApi.index =
  use Storage write
  use Table Table
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The 20.1.0 release of the Cloud client introduces Storage.Batch, a new API for bulk database reads. The design of the Batch ability involved balancing the need for type-safety and the ability to query across multiple tables of different types. Here's where we landed with it."
      )
    , ("date", "2024-12-06")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    , ("featuredImage", "/assets/thing4.svg")
    ] }}

  # Designing a typed batch storage API

    In the
    [20.1.0 release of the Unison Cloud client](https://share.unison-lang.org/@unison/cloud/releases/20.1.0),
    there's a new Ability related to Storage, {type Batch}, which performs a
    bulk read from the database, returning values in one round-trip. At a high
    level, Cloud users can expect faster database queries since some reads
    internal to `OrderedTable` can happen in bulk. For the curious, the design
    process for an ability that interacts with arbitrarily typed Storage has
    some interesting considerations worth learning.

    It's tempting to write `Batch.read: Table k v -> [k] -> [v]` and be done
    with it. But we needed a bulk read API that can span **multiple tables**
    that store **arbitrary Unison types** to enable the fewest database round
    trips possible. A batched read API that doesn't support heterogeneous types
    has limited value to us.

    How then can we model a "batch" of mixed key and value types, while still
    keeping true to the Unison promise of typed schemas? Modeling a “batch” as
    `read : [Any] → [Any]` doesn't cut it here. Instead, you can think of a
    "batch" as something you build with a fork-await pattern.

        @source{type Batch}

    Build a batch by issuing multiple `Batch.forkRead` requests, each of which
    preserves the type of its desired value. Then `Batch.tryAwaitRead` the
    requests in the batch, extracting the arbitrary Unison type.

    This API is type-safe on the level of individual tables, but flexible
    enough to perform a bulk database request across tables of multiple types:

    ```
    Storage.doc.example do
      db = Database (Database.Id.Id "id") "db"
      table1 = Table "table1"
      table2 = Table "table2"
      write db table1 1 "🌹"
      write db table2 "abc" false
      batchRead db do
        read1 : Read Text
        read1 = forkRead table1 1
        read2 : Read Boolean
        read2 = forkRead table2 "abc"
        (awaitRead read1, awaitRead read2)
    ```

    ## Batch fork/await drawbacks:

       The arguable drawback to this API is that it is harder to see what
       requests are being executed in what batch, since the semantics of when a
       batch is actually flushed depends on the first call to `tryAwaitRead`
       after a batch has been built.

       [You can read more about those semantics in the API docs.](https://share.unison-lang.org/@unison/cloud/code/main/latest/types/Storage/Batch)

       We felt this tradeoff was ultimately worth it. First, the type safety
       provided by this API is more in keeping with the spirit of Cloud
       storage. (Imagine trying to pair `[Any]` reads with `[Any]` responses!)
       Second, the performance improvements gained by running bulk database
       requests across tables in a single operation were too significant to
       overlook. This approach ensures that applications using typed Storage
       can handle large read workloads more effectively.
  }}

blog.benefitCorpReport.index : Doc
blog.benefitCorpReport.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison Computing is a public benefit corp (PBC), cofounded by Paul Chiusano, Rúnar Bjarnason, and Arya Irani. We work alongside other amazing open source contributors on the Unison language. 💜 This post talks about why Unison Computing is a PBC and also includes our first annual report."
      )
    , ("date", "2020-03-30")
    , ("authors", "paul-chiusano")
    , ("authors", "runar-bjarnason")
    , ("authors", "arya-irani")
    , ("categories", "announcements")
    , ("featuredImage", "/assets/thing11.svg")
    ] }}

  # Why Unison Computing is a public benefit corporation

    Unison Computing is a
    [public benefit corp](https://en.wikipedia.org/wiki/Public-benefit_corporation)
    (PBC), cofounded by Paul Chiusano, Rúnar Bjarnason, and Arya Irani. We work
    alongside other
    [amazing open source contributors](https://github.com/unisonweb/unison/blob/trunk/CONTRIBUTORS.markdown)
    on the Unison language. 💜 This post talks about why Unison Computing is a
    PBC and also includes our first annual report.

    {{
    docCallout
      (Some {{ 📕 }})
      {{
      If you're new to the Unison language and would like an overview of the
      project and its core ideas, we recommend this
      [40 minute Strange Loop talk](https://www.youtube.com/watch?v=gCWtkvDQ2ZI).
      }} }}

    Our company's overall mission: advance what's possible with software and
    work to make software creation simpler and more accessible to all.
    Underlying this pursuit is a belief that the medium of computation is an
    important and powerful means of human expression, one capable of both
    beauty and utility, and that advancing software technology and making it
    more accessible will be a force for good. We pursue our mission through
    applied research and development of new, free, open source software
    technologies like Unison, and by building useful products (like
    [the Unison Cloud Platform](http://unison.cloud/)) that make money atop
    these technologies. As a public benefit corp, we view the business side of
    our work as a means of capitalizing our larger mission.

    This post talks about why Unison Computing is a PBC and also includes our
    first annual report.

    ## How did we get here?

       Way back in 2013, I (Paul Chiusano) quit a cushy full-time job to start
       research on what would eventually become Unison. Like many other
       developers, I was unhappy with the tools we had available for building
       software and thought it was possible to do much better. It felt the
       software industry was perpetually trying to get to the moon by piling up
       chairs, and I knew if I didn’t at least try doing something about it I’d
       become embittered or detached from a field I still really love. To
       support myself and my family, I did consulting work and used the time
       between gigs to do research on Unison.

       The foundational ideas of Unison—combining functional programming with
       an append-only codebase—had
       [many fantastic and surprising implications](https://www.youtube.com/watch?v=gCWtkvDQ2ZI):
       no builds, easy persistence, robust distributed execution with
       on-the-fly code deployment, and more. I felt like I was discovering an
       alternate reality of programming where new things were possible and hard
       things were easy. I found I wasn't the only person who thought these
       ideas were exciting: the more I collaborated on Unison with other
       people, including my friends Arya and Rúnar who later cofounded Unison
       Computing with me, the more it felt like Unison was tapping into big
       ideas whose time had come. It also became clear that Unison wasn't going
       to get far just on unpaid part-time labor. This was a massive project
       with lots of potential that needed dedicated professionals working on it
       full-time.

       Unison was a mix of engineering, novel applied research, and drawing on
       existing academic research to assemble a cohesive, practical system. It
       wasn't clear how to fund it, and I explored a few different options:

       * For a while, I ran a Patreon. While I truly appreciated the support,
         this only ever managed to bring in a few hundred dollars per month.
       * I applied for an [SBIR grant](https://www.sbir.gov/), which is a
         program that certainly talks a lot about bridging the gap between
         academia and industry. The proposal I spent weeks putting together was
         unceremoniously rejected. One of the reviewers noted: "This proposed
         project is totally unrealistic and lacks any sound technology
         foundation." 😬

       I also considered growing a consulting group that worked on Unison part
       time, or entering academia, but neither of these options seemed like a
       good fit either. While I worked on Unison I would read regular reports
       of tech startups building on much worse ideas, but somehow raising
       millions of dollars. That got me wondering what a business around Unison
       would look like.

    ## Funding innovative OSS like Unison by crafting a business around it from
    the beginning

       Companies like Unison Computing that are based around open source
       software usually form and raise money **after** the core technology has
       already been incubated elsewhere and reached a critical mass of users.
       In fact, most investors, even those comfortable with open source
       businesses, won't even take you seriously until
       **somehow, miraculously**, there's a wildly popular open source
       technology for you to commercialize. But this typical approach of
       waiting for innovative OSS to be __incubated by someone else__ has
       serious limitations:

       * Technology that's incubated within a big company tends to be pretty
         conservative and related only to the immediate needs of the business.
         So Google funds open-source work on Go and Kubernetes, tech that lets
         them more efficiently do the things Google is already doing. More
         generally, big companies that can afford to fund this work often have
         different ideas about what's pressing and worth solving than the rest
         of us. Who will build the technology that empowers tiny teams to build
         "the next Google"?
       * If the tech is incubated within academia, it is often is more
         innovative but undercapitalized. And incentives in academia prevent
         the necessary level of engineering polish, since the emphasis is more
         on proving concepts in peer-reviewed publications, rather than
         releasing a practical piece of technology.
       * And if the tech is incubated by individuals working nights and
         weekends, it's __way__ undercapitalized. This is roughly the position
         Unison was in before we raised money.

       Rather than forming a commercial entity after the technology exists,
       it's possible to fund the __creation__ of OSS by identifying a business
       model that fits the technology, raising initial funding from investors
       on this basis, and eventually supporting continued OSS development with
       the proceeds of the successful business. This is the idea behind Unison
       Computing: use the business side of the company to capitalize truly
       innovative work on better programming technology.

       We adopted the structure of a public benefit corp to make it clear to
       everyone involved that we have a mission we care about and that we're
       not just building a soulless profit-maximizing machine. Though we had
       some concerns that investors might be frightened off by the benefit corp
       structure, so far it's turned out not to be an issue, and we are now a
       well-funded startup. One of our investors told us that anyone frightened
       off by the benefit corp structure is probably not an investor we'd want
       to have anyway. 😀

       There are lots of ways for companies to be financially successful, but
       we think the best companies (benefit corp or not) are not solely or even
       primarily about the pursuit of profit—they start with a group of people
       who commit to pursuing something they think is worthwhile. And when that
       thing is something the world needs, profit emerges as a byproduct. Apple
       doesn't make beautiful, delightful and humane technology because that's
       the best path to profit (though they certainly are profitable). They do
       it because they think those products ought to exist and that that is how
       technology should be designed. SpaceX was founded on dreams of humans
       becoming a spacefaring species, but they've designed a business
       structure that makes money as they work towards this longer-term goal.
       This is the sort of thing we designed Unison Computing to be: a
       carefully designed business that helps capitalize a mission we care
       about.

       Unlike a lot of open source software, where there's a struggle to figure
       out what the product even is, there's an obvious one for Unison: a cloud
       computing platform. Since Unison programs can describe whole distributed
       elastic computations, a managed service that lets you run your Unison
       programs on "the cloud computer" sounds pretty great. It's hard to
       build, but it will make cloud computing simple and accessible—something
       even kids who just learned programming could do, but also something
       experts can appreciate. It's the product we all wish existed and would
       have gladly used for systems we've built before.

       Moreover, since the cloud market is absolutely enormous and continues to
       grow, the honest pitch to our investors was simply that we are building
       radical new technology that will provide "a better way to cloud" and
       that can turn into a big business as Unison matures and becomes more
       widely adopted.

       Our initial funding was led by Amplify Partners, Project 11 Ventures,
       Good Growth Capital, and Hyperplane Venture Capital. All of our
       investors are good people who are supportive of what we're trying to do
       and we're happy to be working with them. Being a well-funded company
       means we get to develop Unison and [Unison.Cloud](http://unison.cloud/)
       full-time, and it also means we can
       [hire talented people](https://www.unison-lang.org/jobs/).

    ## How are we doing?

       We said our overall mission is to advance what's possible with software,
       and to make software creation simpler and more accessible to all. The
       foundational work needed to pursue this mission is to build the open
       source Unison language, ensuring it is useful enough to become widely
       adopted.

       Over 10,000 hours have been put into open source Unison development
       since we became a benefit corp, amounting to about 80% of our total
       developer hours. This is highly unusual: most software businesses
       (including those built on open source technology!), actually devote a
       small fraction of their development resources to OSS. We do expect that
       over time we'll start to shift more of our resources to building out
       products like [Unison.Cloud](http://unison.cloud/) on top of Unison, but
       developing and supporting Unison and its open source ecosystem will
       remain a large portion of what the company devotes resources to.

       The outcome of all this effort is that Unison has evolved from a
       research protoype to a real language that will leave alpha testing and
       enter general availability this year. Some identifiable technical
       results:

       * We worked out in detail the implications of Unison's
         __append-only codebase__, where definitions are never modified
         in-place. This concept, familiar from the world of
         [purely functional data structures](https://en.wikipedia.org/wiki/Purely_functional_data_structure),
         yields surprising benefits: no builds, perfect test caching, instant
         non-breaking renames, elimination of dependency conflicts, trivial
         persistence, and a simple approach to distributed execution with
         runtime code deployment. These results are covered in
         [the Strange Loop talk](https://www.youtube.com/watch?v=gCWtkvDQ2ZI).
       * We identified a novel approach to refactoring append-only codebases,
         where the codebase is never in a broken state, even midway through the
         refactoring. These results are covered in our
         [Scale By The Bay talk](https://www.youtube.com/watch?v=IvENPX0MAZ4)
         and also
         [this page on the documentation site](https://www.unison-lang.org/docs/usage-topics/workflow-how-tos/update-code/).
       * We incorporated recent excellent research in programming language
         theory and type systems (see
         [our bibliography](https://www.unison-lang.org/learn/usage-topics/bibliography))
         into the core Unison language. See for instance our
         [documentation on abilities](https://www.unison-lang.org/docs/fundamentals/abilities/),
         a simple-to-use but powerful language feature that subsumes many other
         more specific language features: exceptions, asynchronous I/O,
         generators, coroutines, logic programming, and more.

       We think the ideas behind Unison are exciting and fascinating, but
       besides just developing the ideas, we have assembled these ideas into
       real, usable software.

       As we make Unison generally available, we can start to quantify our
       success in terms of the number of users and the size of the Unison
       ecosystem, as measured by metrics like the total number of public Unison
       repositories and the total number of Unison definitions. This is how
       we'll measure the impact of the technology we build—we want to create
       technology that actually gets **used**. We will start reporting on these
       metrics for our next annual report.

       Overall, we are happy with the work we've done so far. This year, we're
       looking forward to seeing what people create with Unison!

    ## Current status and future plans

       We released a public alpha version of Unison in August 2019 and have
       been incorporating feedback from alpha testers since then (the
       [docs site](https://www.unison-lang.org/docs/) has information on
       participating in alpha testing). We'll make Unison generally available
       this year and then help to build out the Unison open source ecosystem
       alongside other contributors. Our stretch goal is to release an alpha
       version of our first cloud product this year.

       We also have a few areas we're looking at for the future:

       * Create or curate free documentation, tutorials, and educational
         materials that enable anyone to learn how to build distributed systems
         starting from first principles. Great learning materials should be
         available for anyone or any team.
       * Create simpler, more accessible **interfaces** to programming in
         Unison. When you remove the possibility of syntax and type errors from
         programming (as is done in
         [Scratch](https://www.media.mit.edu/projects/scratch/overview/) or
         spreadsheets), the barrier to entry drops dramatically, enabling kids
         and non-programmers to become productive at building programs. We want
         that same level of approachability but for a powerful, general purpose
         language. This was an area of research early on in the development of
         Unison, but we set it aside to focus more on the core language and
         tooling. It's still an area we are enthusiastic about and are planning
         to pick back up later this year or next. It's also an area where other
         groups have been doing a lot of interesting active research (for
         instance, [Hazel](https://hazel.org/)).

       Thanks so much for reading. If you have questions about this report,
       feel free to come visit us
       [on Discord](https://www.unison-lang.org/discord).

       😀 **Paul, Rúnar, Arya**
  }}

blog.birthdayKata.index : Doc
blog.birthdayKata.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Thank you Tavish Pegram for being the first in our community blogpost series! In this post, Tavish walks through a popular 'kata' for practicing test driven development and hexagonal architecture. Along the way, he explores Unison's type system, abilities, and testing conventions."
      )
    , ("date", "2021-08-20")
    , ("authors", "tavish-pegram")
    , ("categories", "community")
    , ("featuredImage", "/assets/thing7.svg")
    ] }}

  # Practical Example - Modeling a Birthday Message Service

    ## Community Series

       Hi folks, Rebecca Mark here, kicking off the new Unison community
       focused blogpost series. In this series, we're going to be featuring
       different contributors' work in addition to the usual release notes and
       company news. We want the blog to highlight Unison community voices and
       projects because we know that no programming language exists without the
       people who write in it and the problems they're interested in solving.
       We hope to feature more community generated content in the future! If
       you have an engineering topic or Unison project you'd like to write
       about, email [community@unison.cloud](mailto:community@unison.cloud) and
       get in touch.

       With that in mind, we'll turn it over to the author of this post: Tavish
       Pegram. Tavish is a Software Engineer at Peloton. His interests include
       DDD, FP, TDD, XP, and other letters as well.

    ## The Kata

       [Source: Matteo Vaccari](http://matteo.vaccari.name/blog/archives/154)

       ### Goals

           This kata is normally used to practice TDD, dependency injection,
           and ports and adapters architectures in an Object Oriented style.
           Instead, we will tackle the same problem in Unison and explore TDD,
           dependency rejection, and how pure FP languages naturally encourage
           ports and adapters like architectures (through seperation of pure
           and impure functions).

           If you aren't familiar with "ports and adapters" (also called
           "Hexagonal Architecture", "The Clean Architecture", and "The Onion
           Architecture") the idea is to invert dependencies between pure
           business logic and infrastructure code, usually using interfaces, so
           that implementation details like the DB, transfer protocols, etc. is
           fully decoupled from the actual business logic -- making it easier
           to extend, update, maintain, and test!

           At a more technical level, we will explore how to do domain modeling
           with the Unison type system, how to use abilities, and how to write
           tests.

       ### The Prompt

           As the HR department, I want to send an email to every employee on
           their birthday so that they feel appreciated and company morale is
           kept high.

           Technical Notes:

           1. Loads a set of employees from somewhere (we haven't decided yet
              if its a database, or a flat file, or just in memory)
           2. Sends an email to all employees whose birthday is today.

           Platform Goals:

           1. Testable: we should be able to test the internal application
              logic with no need to ever send a real email.
           2. Flexible: we anticipate that the data source in the future could
              change from a flat file to a relational database, or perhaps a
              web service. We also anticipate that the email service could soon
              be replaced with a service that sends greetings through Facebook
              or some other social network.
           3. Well-designed: clearly separate the business logic from the
              infrastructure.

           For further information about this kata please checkout the original
           post [here](http://matteo.vaccari.name/blog/archives/154).

       ### Our Approach

           First, we will come up with a rich domain model and discuss
           different ways we can model the system to take advantage of the
           compiler and what the resulting tradeoffs are.

           Second, we will talk about Abilities, dependency injection /
           rejection, and how we can decouple possibly impure infrastructure
           from pure decision making logic.

           Third, we will apply TDD to implement our behavior.

    ## Modeling

       Unison provides us with all the algebraic data types we need to build
       and compose types. In lieu of discussing them up front, we will just
       jump into modeling and discuss syntax and decisions as we go!

       From skimming over the prompt, it seems pretty clear that top level
       types we need are `Employee` and `Email`. Let's start with `Employee`.

       ### Employee

           So what is an employee to us? For one, they are an entity and
           therefore should have a unique `id`. Some other fields we probably
           care about include the employee's `name`, and importantly, their
           `birthday`.

           Obviously, there are millions of other fields we could choose to
           include in our model, but we would also like to only include what we
           care about. In a larger more complex system, the Employee model may
           have many other fields we don't care about but make sense to include
           in the broader modelling context (see "bounded context", Domain
           Driven Design).

           So lets start with:

           ``` unison
           unique type EmployeeId = EmployeeId Text
           unique type FirstName = FirstName Text
           unique type LastName = LastName Text
           unique type Name =
             { first: FirstName
             , last: LastName
             }
           unique type Date =
             { day: Nat
             , month: Nat
             , year: Nat
             }
           unique type Employee =
             { id: EmployeeId
             , name: Name
             , birthday: Date
             }
           ```

           #### Decision 1 - Record Types

                Our employee is a record type consisting of an `id`, `name`,
                and a `birthday`. In Unison, the record type syntax is actually
                equivalent to a normal data type like

                ``` unison
                type Employee = Employee EmployeeId Name Date
                ```

                except the compiler will automatically generate a collection of
                functions that allow for easy access and updates of this
                immutable data structure, which will be a big help later. You
                can see this in the output in `ucm`:

                ``` ucm
                I found and typechecked these definitions in ~/projects/scratch.u. If you do an `add` or
                  `update`, here's how your codebase would change:

                    ⍟ These new definitions are ok to `add`:

                      unique type Date
                      unique type Employee
                      unique type EmployeeId
                      unique type FirstName
                      unique type LastName
                      unique type Name
                      Date.day                 : Date -> Nat
                      Date.day.modify          : (Nat ->{g} Nat) -> Date ->{g} Date
                      Date.day.set             : Nat -> Date -> Date
                      Date.month               : Date -> Nat
                      Date.month.modify        : (Nat ->{g} Nat) -> Date ->{g} Date
                      Date.month.set           : Nat -> Date -> Date
                      Date.year                : Date -> Nat
                      Date.year.modify         : (Nat ->{g} Nat) -> Date ->{g} Date
                      Date.year.set            : Nat -> Date -> Date
                      Employee.birthday        : Employee -> Date
                      Employee.birthday.modify : (Date ->{g} Date) -> Employee ->{g} Employee
                      Employee.birthday.set    : Date -> Employee -> Employee
                      Employee.id              : Employee -> EmployeeId
                      Employee.id.modify       : (EmployeeId ->{g} EmployeeId) -> Employee ->{g} Employee
                      Employee.id.set          : EmployeeId -> Employee -> Employee
                      Employee.name            : Employee -> Name
                      Employee.name.modify     : (Name ->{g} Name) -> Employee ->{g} Employee
                      Employee.name.set        : Name -> Employee -> Employee
                      Name.first               : Name -> FirstName
                      Name.first.modify        : (FirstName ->{g} FirstName) -> Name ->{g} Name
                      Name.first.set           : FirstName -> Name -> Name
                      Name.last                : Name -> LastName
                      Name.last.modify         : (LastName ->{g} LastName) -> Name ->{g} Name
                      Name.last.set            : LastName -> Name -> Name
                ```

                `Name` and `Date` are record types as well.

           #### Decision 2 - Nominal vs Structural Typing

                Also note that we have opted in to using nominal typing (with
                the `unique` keyword) instead of structural typing. If we had
                left out `unique` the compiler would consider `EmployeeId`,
                `FirstName`, and `LastName` all to be the same type (with all
                names being interchangeable). For our current use case, we want
                to make sure that the compiler considers all of these different
                types, so we can prevent mistakes like accidentally passing in
                a `LastName` where an `EmployeeId` should go.

           #### Decision 3 - Avoiding Primitives

                We could have also modeled the Employee like this (or any other
                similar way)

                ``` unison
                unique type Employee =
                  { id: Text
                  , name: Name
                  , birthday: Date
                  }

                unique type Name =
                  { first: Text
                  , last: Text
                  }

                unique type Date =
                  { day: Nat
                  , month: Nat
                  , year: Nat
                  }
                ```

                When deciding whether to use primitives or to wrap them in more
                rich domain types we should consider some tradeoffs:

                1. Using primitive types gives the compiler less context on
                   what you are attempting to model. For example, using `Text`
                   for the id, the first name, and the last name, means the
                   compiler wouldn't catch an easy mistake like

                ``` unison
                foo =
                    id = "12345"
                    firstName = "John"
                    lastName = "Lennon"
                    employee = Employee id (Name lastName firstName) (Date 1 1 1991)
                ```

                (We've transposed the employees name!) Or even worse, maybe we
                accidentally swap the id and last name! However, the compiler
                would catch this problem.

                ``` unison
                foo =
                    id = EmployeeId "12345"
                    firstName = FirstName "John"
                    lastName = LastName "Lennon"
                    employee = Employee id (Name lastName firstName) (Date 1 1 1991)
                    ()
                ```

                ``` ucm
                The 1st argument to `Name`

                            has type:  LastName
                      but I expected:  FirstName

                      9 | unique type LastName = LastName Text
                     10 | unique type Name =
                     11 |   { first: FirstName
                      .
                     23 |     employee = Employee id (Name lastName firstName) (Date 1 1 1991)
                ```

                Of course, you can still make a mistake like

                ``` unison
                firstName = LastName "Lennon"
                ```

                But it's much harder to make this mistake. If we are ok with
                the extra types and the overhead of deconstructing them, we can
                catch many more typos/bugs at compile time, which means fewer
                tests are necessary to ensure correctness!

                2. In the future, Unison may introduce the ability to make to
                   make data constructors private and/or refined types. Doing
                   so would allow us to to avoid another huge source of bugs
                   when using primitive types directly, which is that the set
                   of possible values is much larger than what we are
                   attempting to model. You can see this in our model for
                   `Date`:

                ``` unison
                unique type Date =
                  { day: Nat
                  , month: Nat
                  , year: Nat
                  }
                ```

                By modeling day/month/year all as `Nat` we have introduced the
                possibility of an illegal state into our system. For example,
                in this model, we could have illegal dates like
                `0/500/99999999999999`. In fact, lets try to restrict the
                possible values a bit, to reduce the surface area for future
                bugs. This means more tests and more runtime validation (and
                runtime validation failures).

                Lets try to contrain the possible values a bit.

                ``` unison
                unique type Date =
                  { day: Day
                  , month: Month
                  , year: Year
                  }
                unique type Month
                  = January
                  | February
                  | March
                  | April
                  | May
                  | June
                  | July
                  | August
                  | September
                  | October
                  | November
                  | December
                unique type Day = Day Nat
                unique type Year = Year Nat
                ```

                It is really easy for us to enumerate all of the possible
                months. We have eliminated the possiblity of an invalid month
                appearing in our system! Now we have to decide how far we want
                to go to make illegal state unrepresentable. Maybe `Nat` is ok
                for representing a year if we don't care about `BCE` and we are
                ok with possibly talking about birthdays millions of years in
                the future (not ideal). But it would be nice to disallow days
                of months that don't exist, and this is where refined types,
                dependent types, or private constructors could be leveraged.
                Hopefully, we will have those one day!

       ### Email

           Let's apply some similar decision making to get an Email.

           ``` unison
           unique type Email =
             { to: EmailAddress
             , subject: Subject
             , body: Body
             }

           unique type EmailAddress = EmailAddress Text
           unique type Subject = Subject Text
           unique type Body = Body Text
           ```

           Let's also update `Employee` to have an email address

           ``` unison
           unique type Employee =
             { id: EmployeeId
             , name: Name
             , birthday: Date
             , email: EmailAddress
             }
           ```

           But maybe we can build a little bit toward the future here. The
           prompt told us the future will likely include sending birthday
           messages via other platforms, like SMS or robocalls.

           Maybe our model should actually be about a `Message` of which there
           is some relationship with an `Email`. One possible way to model this
           would be

           ``` unison
           unique type Message
             = Email EmailAddress Subject Body
           ```

           which would give us the option of extending it in the future as
           needed

           ``` unison
           unique type Message
             = Email EmailAddress Subject Body
             | SMS PhoneNumber Body
             | TwitterDM TwitterHandle Body
           ```

       ### Summary

           There isn't one "best" way to model this, but this is one possible
           way:

           ``` unison
           unique type Employee =
             { id: EmployeeId
             , name: Name
             , birthday: Date
             }

           unique type EmployeeId = EmployeeId Text
           unique type FirstName = FirstName Text
           unique type LastName = LastName Text
           unique type Name =
             { first: FirstName
             , last: LastName
             }

           unique type Date =
             { day: Day
             , month: Month
             , year: Year
             }
           unique type Month
             = January
             | February
             | March
             | April
             | May
             | June
             | July
             | August
             | September
             | October
             | November
             | December
           unique type Day = Day Nat
           unique type Year = Year Nat

           unique type Message
             = Email EmailAddress Subject Body

           unique type EmailAddress = EmailAddress Text
           unique type Subject = Subject Text
           unique type Body = Body Text
           ```

    ## Abilities

       Now that we have our model, let's quickly talk about the
       effects/infrastructure we know we will need.

       One of the goals of this exercise (and generally working as a software
       engineer) is to decouple infrastructure from our business logic (which
       is often approximately the same thing as separating pure and impure
       code). In OO we would use interfaces to define contracts and dependency
       inject in whatever implementations we need (be it Postgres, AWS, an
       in-memory store, mocks, etc).

       In Unison, we leverage Abilities (also called Algebraic Effects) to
       accomplish something similar. See
       [the abilities documentation](https://www.unison-lang.org/learn/fundamentals/abilities/)
       for a more detailed overview of Abilities.

       In our case, let's limit ourselves to the following effects: sending a
       message, fetching employees from somewhere (a flat file, a db, an api,
       anything), and fetching the current date. For the sake of simplicity
       let's ignore an exception throwing ability (and failures in general) or
       any other abilities that may make sense to add in a real production
       system.

       ``` unison
       unique ability MessageService where
         send: Message -> Message

       unique ability EmployeeRepository where
         fetchAllByBirthday: (Day, Month) -> [Employee]

       unique ability Calendar where
         today: Date
       ```

       Let's walk through what these abilities are doing:

       1. `MessageService` is an ability that provides the interface for a
          single command `send`. `send`s type signature can be read as "a
          function that takes a message and returns a (same) message, requiring
          the `MessageService` ability."
       2. `EmployeeRepository` provides the interface `fetchAllByBirthday`
          which takes a `Day` and a `Month` pair and returns a list of
          `Employees`, requiring the `EmployeeRepository` ability.
       3. `Calendar` provides the interface `today` which is a function that
          takes no arguments and returns a `Date`, requiring the `Calendar`
          ability.

       Note that abilities

       1. can provide multiple interfaces if we wanted

       ``` unison
       unique ability EmployeeRepository where
         fetchAllByBirthday: (Day, Month) -> [Employee]
         fetchAll: [Employee]
         findById: EmployeeId -> {Employee}
       ```

       2. have their behavior defined elsewhere (using handler syntax we will
          get to later)
       3. are composable (hence "algebraic effects")
       4. require that any calling function provide the ability in their type
          signature, which bubbles all the way to the top of the call stack
          (until it finds a handler).

       So let's scaffold our main function for this exercise and see this stuff
       in action.

       ``` unison
       sendBirthdayEmails : [Message]
       sendBirthdayEmails =
         todo "get the current date"
         todo "fetch all the employees with birthdays today"
         todo "create happy birthday messages"
         todo "send and return the messages"
       ```

       Let's say we want a function we can call that will find all the
       employees whose birthday is today, create emails for them, send those
       emails, and then return those emails so we can see what was created and
       sent.

       As an aside, let's avoid modeling failures simply because it will
       clutter this exercise a bit. In real life, many of our effects would
       have type signatures with `Either` so we could model possible failures,
       but let's just naively pretend everything always works.

       So let's do some more scaffolding!

       ``` unison
       sendBirthdayEmails : [Message]
       sendBirthdayEmails =
         today' = today
         employees = fetchAllByBirthday (Date.day today', Date.month today')
         messages = map (Employee.toBirthdayMessage) employees
         map (send) messages

       Employee.toBirthdayMessage : Employee -> Message
       Employee.toBirthdayMessage _ = todo "toBirthdayMessage"
       ```

       So we will grab the date, use that to fetch all the employees with
       birthdays today, map those employees to messages, and then send out (and
       return) those messages.

       Uh oh! The compiler is mad!

       ``` ucm
       The expression in red needs the {Calendar} ability, but this location does not have access to any abilities.

           136 |   today' = today)
       ```

       Ah, turns out that any function with an ability in its signature can
       only be called by another function with that ability available in its
       signature. So we need to add all our abilities to the function
       signature. So let's just go ahead and add all three.

       ``` unison
       sendBirthdayEmails : {MessageService, EmployeeRepository, Calendar} [Message]
       ```

       But we are stil getting the same error. 🙁

       Well, it turns out that these effects can actually only be run in the
       context of a handler and they have to be in a function body. We should
       defer the computation with a thunk (so all effects become deferred) and
       then wire our handler up.

       ``` unison
       sendBirthdayEmails : '{MessageService, EmployeeRepository, Calendar} [Message]
       sendBirthdayEmails =  'let
         today' = today
         employees = fetchAllByBirthday (Date.day today', Date.month today')
         messages = map (Employee.toBirthdayMessage) employees
         map (send) messages

       Employee.toBirthdayMessage : Employee -> Message
       Employee.toBirthdayMessage _ = todo "toBirthdayMessage"
       ```

       And the compiler seems happy so far! Note that we just deferred the
       entire computation by putting the {{ Code (Word "'let") }} at the
       beginning.

       Let's move on applying TDD in order to implement the remaining code.

    ## Implementation!

       Let's write a first failing test!

       ``` unison
       test> sendBirthdayEmails.tests.noBirthdaysToday =
         check let
           actual = !sendBirthdayEmails
           expected = []
           if expected === actual
           then true
           else bug (exected, actual)
       ```

       ``` ucm
       The expression in red  needs these abilities: {Calendar, EmployeeRepository, MessageService}, but this location does not have access to any abilities.

            70 |     actual = !sendBirthdayEmails
       ```

       Well we can't defer this call any more, this is the boundary of the
       system! So it's time to implement handlers for our abilities!

       ``` unison
       test> sendBirthdayEmails.tests.noBirthdaysToday =
         check let
           actual =
             handle
               handle
                 handle
                   !sendBirthdayEmails
                 with (Calendar.handler.mock (Date (Day 1) January (Year 1991)))
               with (EmployeeRepository.handler.mock [])
             with MessageService.handler.mock
           expected = []
           if expected === actual
           then true
           else bug (expected, actual)

       Calendar.handler.mock : Date -> {Calendar} k -> k
       Calendar.handler.mock date k =
         h : Request {Calendar} k -> k
         h = cases
           {today -> resume} -> handle resume date with h
           { resume } -> resume
         handle k with h

       EmployeeRepository.handler.mock : [Employee] -> {EmployeeRepository} k -> k
       EmployeeRepository.handler.mock employees k =
         h : Request {EmployeeRepository} k -> k
         h = cases
           { fetchAllByBirthday birthday -> resume } ->
             birthdays = filter (employee -> (Date.day (Employee.birthday employee), Date.month (Employee.birthday employee)) === birthday) employees
             handle resume birthdays with h
           { resume } -> resume
         handle k with h

       MessageService.handler.mock : {MessageService} k -> k
       MessageService.handler.mock k =
         h : Request {MessageService} k -> k
         h = cases
           { send message -> resume } -> handle resume message with h
           { resume } -> resume
         handle k with h
       ```

       This is a lot so lets dig into it a bit!

       The syntax for a handler is `handle <fn> with <handler>`. I've wrapped
       our call to `!sendBirthdayEmails` in three nested handle blocks (we can
       make this cleaner later).

       When you write a handler, your goal is to pattern match on the possible
       ability function signatures, and then "resume" the computation (or not)
       along with providing the expected value for the ability. Let's dig in to
       our mock Calendar handler:

       ``` unison
       Calendar.handler.mock : Date -> {Calendar} k -> k
       Calendar.handler.mock date k =
         h : Request {Calendar} k -> k
         h = cases
           {today -> resume} -> handle resume date with h
           { resume } -> resume
         handle k with h
       ```

       1. our mock calendar handler dates a `Date` as input. This is so we can
          specify the return value of `today`, so we can "mock" it in our
          tests.
       2. the `k` is the "continuation", our handler is being consulted to try
          to handle an ability, and then we call k to "continue" the existing
          computation.
       3. we define some handler `h` locally which does the actual bulk of the
          work. It pattern matches on any ability operations we care about.
          Note that its signature has access to the `Calendar` ability.
       4. we pattern match on two cases. The first is the `today` case. If we
          are handling the `today` method, all we are doing is handling the
          continuation (by calling resume) and providing the value for `today`
          which is the provided `date` since are just "mocking" the date in
          this handler. The continuation is called and handled recursively.
       5. we have a base `resume` pattern where we are basically saying "if
          this handler encounters behavior which __doesn't__ call the ability
          operations, just bubble this result up to the caller."

       In summary, `Calendar.handler.mock` takes a `Date`, and any function it
       handles that calls `today` will return that date.

       Now let's look at the `EmployeeRepository`:

       ``` unison
       EmployeeRepository.handler.mock : [Employee] -> {EmployeeRepository} k -> k
       EmployeeRepository.handler.mock employees k =
         h : Request {EmployeeRepository} k -> k
         h = cases
           { fetchAllByBirthday birthday -> resume } ->
             birthdays = filter (employee -> (Date.day (Employee.birthday employee), Date.month (Employee.birthday employee)) === birthday) employees
             handle resume birthdays with h
           { resume } -> resume
         handle k with h
       ```

       This is another mock to make it easy to test our program.

       1. This handler takes a list of employees, which it uses to generate the
          return value for `fetchAllByBirthday`.
       2. Our `h` take a request with the `EmployeeRepository` ability.
       3. We match on the `fetchAllByBirthday` method and it's argument
          `birthday`.
       4. When we match on that method, we filter the provided list of
          employees based on the `birthday` arg, and resume the computation
          with those employees as the return value.
       5. In real life, we might read from a DB here.
       6. Otherwise we bubble up the function in case other handlers know how
          to handle it.

       And finally

       ``` unison
       MessageService.handler.mock : {MessageService} k -> k
       MessageService.handler.mock k =
         h : Request {MessageService} k -> k
         h = cases
           { send message -> resume } -> handle resume message with h
           { resume } -> resume
         handle k with h
       ```

       1. This handler does not take any args because it doesn't need any
          outside info to handle the `send` function.
       2. We match on the `send` function and its message argument and resume
          the computation with that same message as a return value
       3. A real version of this might instead reach out to Twilio or some
          external service to perform an effect before continuing.
       4. And we bubble up any functions we don't care about.

       Great! And then we just wrap all these handlers around our birthday
       function.

       ``` unison
       test> sendBirthdayEmails.tests.noBirthdaysToday =
         check let
           actual =
             handle
               handle
                 handle
                   !sendBirthdayEmails
                 with (Calendar.handler.mock (Date (Day 1) January (Year 1991)))
               with (EmployeeRepository.handler.mock [])
             with MessageService.handler.mock
           expected = []
           if expected === actual
           then true
           else bug (expected, actual)
       ```

       And thats how we do "dependency injection" in unison! We can easily swap
       out these handlers with other behaviors at the boundary of our system!

       Now that we have a passing test, let's take a minute to refactor a bit
       before we add some more interesting test cases.

       All these nested handlers are kind of gross. Let's combine them into a
       single "multihandler".

       ``` unison
       sendBirthdayEmails.handlers.mock : Date -> [Employee] -> '{Calendar, EmployeeRepository, MessageService} k -> k
       sendBirthdayEmails.handlers.mock date employees k =
         h : Request {Calendar, EmployeeRepository, MessageService} k -> k
         h = cases
           {today -> resume} -> handle resume date with h
           { send message -> resume } -> handle resume message with h
           { fetchAllByBirthday birthday -> resume } ->
             birthdays = filter (employee -> (Date.day (Employee.birthday employee), Date.month (Employee.birthday employee)) === birthday) employees
             handle resume birthdays with h
           { resume } -> resume
         handle !k with h

       test> sendBirthdayEmails.tests.noBirthdaysToday =
         check let
           today = Date (Day 1) January (Year 2021)
           actual = sendBirthdayEmails |> sendBirthdayEmails.handlers.mock today []
           expected = []
           if expected === actual
           then true
           else bug (expected, actual)
       ```

       Note that we have changed how we use the handlers to something slightly
       more idiomatic: a normal function call! I've chosen to pipe in the
       function as the last argument because I think it puts the "important"
       bit at the beginning of the line.

       Note (again) that we updated the handler's signature to defer the first
       `k` so we no longer need to add `!` to the top level test since it is
       done inside the handler.

       Alright let's test with the next test case, a single birthday today!

       ``` unison
       test> sendBirthdayEmails.tests.oneBirthdayToday =
         check let
           employees =
             [
               Employee
               (EmployeeId "1")
               (Name (FirstName "John") (LastName "Smith"))
               (Date (Day 1) January (Year 1991))
               (EmailAddress "john@smith.com")
             , Employee
               (EmployeeId "2")
               (Name (FirstName "Fred") (LastName "Smith"))
               (Date (Day 2) March (Year 1991))
               (EmailAddress "fred@smith.com")
             ]
           today = Date (Day 1) January (Year 2021)
           actual = sendBirthdayEmails |> sendBirthdayEmails.handlers.mock today employees

           expected =
             [
               Email
               (EmailAddress "john@smith.com")
               (Subject "Happy Birthday!")
               (Body "Congrats! Love, HR.")
             ]
           if expected === actual
           then true
           else bug (expected, actual)
       ```

       ``` ucm
       💔💥

         I've encountered a call to builtin.todo with the following value:

           "toBirthdayMessage"
       ```

       That's a good failure! Let's fix it!

       ``` unison
       Employee.toBirthdayMessage : Employee -> Message
       Employee.toBirthdayMessage employee =
         Email (Employee.email employee) (Subject "Happy Birthday!") (Body "Congrats! Love, HR.")
       ```

       ``` ucm
       70 |   check let

           ✅ Passed : Proved.

           81 |   check let

           ✅ Passed : Proved.
       ```

       It's working! Let's do one more test case just to be sure.

       ``` unison
       test> sendBirthdayEmails.tests.twoBirthdaysToday =
         check let
           employees =
             [
               Employee
               (EmployeeId "1")
               (Name (FirstName "John") (LastName "Smith"))
               (Date (Day 1) January (Year 1991))
               (EmailAddress "john@smith.com")
             , Employee
               (EmployeeId "2")
               (Name (FirstName "Fred") (LastName "Smith"))
               (Date (Day 2) March (Year 1991))
               (EmailAddress "fred@smith.com")
             , Employee
               (EmployeeId "3")
               (Name (FirstName "Abe") (LastName "Lincoln"))
               (Date (Day 2) March (Year 1776))
               (EmailAddress "abe@lincoln.com")
             ]
           today = Date (Day 2) March (Year 2021)
           actual = sendBirthdayEmails |> sendBirthdayEmails.handlers.mock today employees

           expected =
             [
               Email
               (EmailAddress "fred@smith.com")
               (Subject "Happy Birthday!")
               (Body "Congrats! Love, HR.")
             , Email
               (EmailAddress "abe@lincoln.com")
               (Subject "Happy Birthday!")
               (Body "Congrats! Love, HR.")
             ]
           if expected === actual
           then true
           else bug (expected, actual)
       ```

       ``` ucm
       70 |   check let

           ✅ Passed : Proved.

           81 |   check let

           ✅ Passed : Proved.

           113 |   check let

           ✅ Passed : Proved.
       ```

       Great! And of course there many more tests you can add to make sure this
       is working for various corner cases, but this seems pretty good for now!

       So let's go back and refactor our main function a bit now that we have
       the stability of some tests.

       ``` unison
       sendBirthdayEmails : '{Calendar, EmployeeRepository, MessageService} [Message]
       sendBirthdayEmails =  'let
         today
           |> toDayMonthPair
           |> fetchAllByBirthday
           |> toBDayMessages
           |> sendAll

       toDayMonthPair : Date -> (Day, Month)
       toDayMonthPair = cases
         Date day month _ -> (day, month)

       toBDayMessages : [Employee] -> [Message]
       toBDayMessages employees =
         map (Employee.toBirthdayMessage) employees

       sendAll : [Message] ->{MessageService} [Message]
       sendAll messages =
         map (send) message
       ```

       Looks a lot cleaner, its easier to read, and its composed of a bunch of
       small modular easy to understand functions!

    ## Conclusion

       Let's see it all together!

       ``` unison
       unique type Employee =
         { id: EmployeeId
         , name: Name
         , birthday: Date
         , email: EmailAddress
         }

       unique type EmployeeId = EmployeeId Text
       unique type FirstName = FirstName Text
       unique type LastName = LastName Text
       unique type Name =
         { first: FirstName
         , last: LastName
         }

       unique type Date =
         { day: Day
         , month: Month
         , year: Year
         }
       unique type Month
         = January
         | February
         | March
         | April
         | May
         | June
         | July
         | August
         | September
         | October
         | November
         | December
       unique type Day = Day Nat
       unique type Year = Year Nat

       unique type Message
         = Email EmailAddress Subject Body

       unique type EmailAddress = EmailAddress Text
       unique type Subject = Subject Text
       unique type Body = Body Text

       unique ability MessageService where
         send: Message -> Message

       unique ability EmployeeRepository where
         fetchAllByBirthday: (Day, Month) -> [Employee]

       unique ability Calendar where
         today: Date

       sendBirthdayEmails : '{Calendar, EmployeeRepository, MessageService} [Message]
       sendBirthdayEmails =  'let
         today
           |> toDayMonthPair
           |> fetchAllByBirthday
           |> toBDayMessages
           |> sendAll

       toDayMonthPair : Date -> (Day, Month)
       toDayMonthPair = cases
         Date day month _ -> (day, month)

       toBDayMessages : [Employee] -> [Message]
       toBDayMessages employees =
         map Employee.toBirthdayMessage employees

       sendAll : [Message] ->{MessageService} [Message]
       sendAll messages =
         map send messages

       Employee.toBirthdayMessage : Employee -> Message
       Employee.toBirthdayMessage employee =
         Email (Employee.email employee) (Subject "Happy Birthday!") (Body "Congrats! Love, HR.")

       sendBirthdayEmails.handlers.mock : Date -> [Employee] -> '{Calendar, EmployeeRepository, MessageService} k -> k
       sendBirthdayEmails.handlers.mock date employees k =
         h : Request {Calendar, EmployeeRepository, MessageService} k -> k
         h = cases
           {today -> resume} -> handle resume date with h
           { send message -> resume } -> handle resume message with h
           { fetchAllByBirthday birthday -> resume } ->
             birthdays = filter (employee -> (Date.day (Employee.birthday employee), Date.month (Employee.birthday employee)) === birthday) employees
             handle resume birthdays with h
           { resume } -> resume
         handle !k with h

       test> sendBirthdayEmails.tests.noBirthdaysToday =
         check let
           today = Date (Day 1) January (Year 2021)
           actual = sendBirthdayEmails |> sendBirthdayEmails.handlers.mock today []
           expected = []
           if expected === actual
           then true
           else bug (expected, actual)

       test> sendBirthdayEmails.tests.oneBirthdayToday =
         check let
           employees =
             [
               Employee
               (EmployeeId "1")
               (Name (FirstName "John") (LastName "Smith"))
               (Date (Day 1) January (Year 1991))
               (EmailAddress "john@smith.com")
             , Employee
               (EmployeeId "2")
               (Name (FirstName "Fred") (LastName "Smith"))
               (Date (Day 2) March (Year 1991))
               (EmailAddress "fred@smith.com")
             ]
           today = Date (Day 1) January (Year 2021))
           actual = sendBirthdayEmails |> sendBirthdayEmails.handlers.mock today employees

           expected =
             [
               Email
               (EmailAddress "john@smith.com")
               (Subject "Happy Birthday!")
               (Body "Congrats! Love, HR.")
             ]
           if expected === actual
           then true
           else bug (expected, actual)

       test> sendBirthdayEmails.tests.twoBirthdaysToday =
         check let
           employees =
             [
               Employee
               (EmployeeId "1")
               (Name (FirstName "John") (LastName "Smith"))
               (Date (Day 1) January (Year 1991))
               (EmailAddress "john@smith.com")
             , Employee
               (EmployeeId "2")
               (Name (FirstName "Fred") (LastName "Smith"))
               (Date (Day 2) March (Year 1991))
               (EmailAddress "fred@smith.com")
             , Employee
               (EmployeeId "3")
               (Name (FirstName "Abe") (LastName "Lincoln"))
               (Date (Day 2) March (Year 1776))
               (EmailAddress "abe@lincoln.com")
             ]
           today = Date (Day 2) March (Year 2021)
           actual = sendBirthdayEmails |> sendBirthdayEmails.handlers.mock today employees

           expected =
             [
               Email
               (EmailAddress "fred@smith.com")
               (Subject "Happy Birthday!")
               (Body "Congrats! Love, HR.")
             , Email
               (EmailAddress "abe@lincoln.com")
               (Subject "Happy Birthday!")
               (Body "Congrats! Love, HR.")
             ]
           if expected === actual
           then true
           else bug (expected, actual)
       ```

    ## References

       [Scott Wlaschin - Domain Modeling Made Functional](https://www.youtube.com/watch?v=Up7LcbGZFuo&ab_channel=NDCConferences)

       [Mark Seemann - Dependency Injection to Dependency Rejection](https://www.youtube.com/watch?v=cxs7oLGrxQ4)

       [Mark Seemann - Pits of Success](https://www.youtube.com/watch?v=US8QG9I1XW0&ab_channel=NDCConferences)

       [Unison slack thread that contributed a lot of code examples](https://unisonlanguage.slack.com/archives/CLKV43YE4/p1624391625329100?thread_ts=1624385627.328200&cid=CLKV43YE4)

    ## Get In Touch

       If you've been working on a Unison project or have a programming topic
       you'd like to explore in Unison, we want to hear from you! Email
       [community@unison.cloud](mailto:community@unison.cloud) and we'll help
       you get published here.
  }}

blog.blogEngine.index : Doc
blog.blogEngine.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison's new blog engine library embeds evaluated code, renders LaTeX markup and mermaid diagrams, emails your followers, and publishes RSS feeds. Who among us isn't sitting on a pile of half-written technical blog posts? Take this as a sign that you should finish them up. 👀"
      )
    , ("date", "2024-04-11")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # A spotlight on the Unison Blog Engine library

    As part of our ongoing work highlighting what you can do with the
    [Unison Cloud platform](https://www.unison.cloud/), we're excited to
    announce the
    [Unison Blog Engine](https://share.unison-lang.org/@unison/blog-engine/)
    library. This library makes it incredibly easy to create and deploy a
    professional-looking blog, with a particular focus on supporting developers
    writing about technical concepts. The blog engine ships with an RSS/Atom
    feed, and supports email notifications out of the box.

    {{
    Image
      {{
      An example blog post showing how different doc features are rendered
      }}
      {{
      /assets/feed/blogEngine/blogExample.png
      }}
      (Some
        {{
        Look familiar? This blog post was generated from the Unison doc format
        as well.
        }}) }}

    The Unison Blog Engine uses Unison's powerful {type Doc} format. Unlike
    traditional markdown, Unison docs allow you to embed typechecked and
    evaluated Unison code snippets directly into your blog posts. The blog also
    supports syntax highlighting for other programming languages and other
    forms of rich content, like [mermaid diagrams](https://mermaid.js.org/) and
    LaTeX markup rendering. This makes it an especially useful tool for sharing
    code examples and other technical details with your readers.

    We designed the blog engine so your content can be authored, deployed, and
    edited entirely from your text editor and terminal. No more fiddling with
    website builders, hosting providers, or content management systems—your
    blog is just a Unison program that you manage with the Unison Codebase
    Manager.

    {{
    docCallout
      None
      {{
      Check out the
      [Unison Blog Engine README](https://share.unison-lang.org/@unison/blog-engine/code/releases/2.0.0/latest)
      for detailed instructions on getting started.
      }} }}

    ## An overview of how it works

       **Your blog is a type which indexes Unison Share**

       You create your blog as an instance of the `Blog` type which includes
       settings like the blog's title, slug, and the Unison Share project where
       your posts are stored. While your blog is __hosted and deployed__ on the
       Unison Cloud, posts are loaded from your Unison Share project.

       {{
       docCallout
         (Some {{ 💡 }})
         {{
         Building on top of the existing Unison Share infrastructure offers a
         huge benefit to authors: it means that the Unison code snippets
         transcluded in your posts support click-through-to-source linking for
         individual definitions in your code. This means that readers can
         explore the implementation of your code snippets directly, without
         needing to click on a static image and find their bearings in a huge
         file view of the code.
         }} }}

       {{
       Image
         {{
         Clicking through to source definitions in a blog post
         }}
         {{
         /assets/feed/blogEngine/clickThroughBlog.gif
         }}
         None }}

       **The hard part—you have to write stuff**

       😅 We can't tell you what to write, but once you've figured that out,
       author your blog posts as {type Doc} values.
       [You can read a quick primer on using the Doc format here.](https://www.unison-lang.org/docs/usage-topics/documentation/)

       Be sure to `push` your posts to a Unison Share project and set the
       project's visibility to "public" so that the blog engine can find them.

       **Deploy your blog with one function**

       When you're ready to publish your blog, you'll write a function that
       links your posts to your blog and provides some additional metadata:

       ``` unison
       deploy =
         Cloud.main do
           _ = withBlog !myBlog do
             publish
               BlogEnv.post
                 "Hello World"
                 sampleAuthor
                 (NamespacePath ["posts", "firstPostEver"])
                 |> withSummary "My first post"
           Blog.deploy !myBlog
       ```

       Entering `run deploy` in your terminal will deploy your blog to the
       Unison Cloud. You can then share the URL with your readers! 🚀

       Happy blogging! 📝
  }}

blog.cloudLearningKickoff.index : Doc
blog.cloudLearningKickoff.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "If you head to the Unison Cloud website, there's a new way to learn how to write Unison services. Cloud learning modules offer a more structured, step-by-step approach to learning. They're also written in Unison as a Unison Service!"
      )
    , ("date", "2024-05-24")
    , ("authors", "rebecca-mark")
    , ("categories", "news")
    , ("status", "published")
    , ( "featuredImage"
      , "/assets/feed/cloud-learning-kickoff/learnUnisonCloud.png"
      )
    ] }}

  # Kicking off new ways to learn Unison Cloud

    If you head to the [Unison Cloud](https://unison.cloud) website, there's a
    new way of learning how to write Unison services.
    [Cloud exercises offer a more structured, step-by-step approach to
    learning.](https://www.unison.cloud/learn/)

    In pursuit of the goal of teaching folks Unison through various projects,
    we wrote an application that deploys and tests services, is backed by a
    Unison native application, and uses Cloud data storage. We think using
    Unison as a platform to teach Unison is pretty rad. 🤘

    The gist of the workflow is that a user who signs up for the Cloud and
    installs our cloud-start template project can follow along with the steps
    and guidance given in the exercises.

    {{
    Image
      {{
      Some language from a lesson instructing the user to create client models
      and not store them directly in the database
      }}
      {{
      /assets/feed/cloud-learning-kickoff/sampleLesson.png
      }}
      None }}

    Using the tips, code snippets, and samples provided, users can `edit` the
    exercise stubs in their local environment, and then submit their solution
    for validation.

    {{
    Image
      {{
      The UCM console being used to submit a solution to an exercise with the
      command `run`
      }}
      {{
      /assets/feed/cloud-learning-kickoff/consoleSubmit.png
      }}
      None }}

    Because service deployments can be **described** with regular function
    calls in Unison, they can also be **tested** with regular function calls.
    When a user issues `run submit.exerciseName` in the UCM, they're actually
    kicking off a program that deploys the service and issues a series of test
    requests to that service once it starts up.

    {{
    Image
      {{
      The UCM console after a passing solution has been submitted. Displaying
      the passing test and some info about the learning track.
      }}
      {{
      /assets/feed/cloud-learning-kickoff/consoleSuccess.png
      }}
      None }}

    As a user successfully completes different modules, we print a nice record
    of their progress to the console. ⭐️

    A sense of progress and direction was something we wanted to surface to
    folks learning about the Cloud, so a simple record of previous successes or
    errors is recorded in a Unison native service. That means, when you submit
    an exercise, you're also performing a typed remote function call behind the
    scenes to save the submission's test result.

    ## 🍎 Why is this stuff important to us?

       We realize there can be a bit of a "blank page effect" when encountering
       a new platform or technology. Unison might seem… cool… but what should
       you do with it if you're not a library author beyond the regular “hello
       world” deployment? We think providing some direction while exploring the
       language and ecosystem will help folks find their creative footing.

       Unison is a new language, and that means we're a community of
       autodidacts, fighting against a tide of
       [pretty bad pedagogy in tech](https://faculty.washington.edu/ajko/papers/Kim2017CodingTutorialEvaluation.pdf).
       We want to provide experiences and build a community that meets people
       where they're at in their learning, and builds competencies from there.

       The modules are open source, so we hope to incorporate community
       contributed feedback and projects too! Over time, we'll be adding more
       variety so you can keep learning and building things with Unison. 🎨
  }}

blog.cloudTeaser.index : Doc
blog.cloudTeaser.index =
  use Services call
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The Unison team has been hard at work building our cloud computing platform. Here's a teaser for what's to come!"
      )
    , ("date", "2023-10-12")
    , ("authors", "rebecca-mark")
    , ("categories", "news")
    , ("featuredImage", "/assets/unison-services-preview.svg")
    , ("status", "published")
    ] }}

  # Unison Cloud - our month in testing

    Since our earlier
    [preview of what Cloud services might look like]({unisonServicesPreview.index}),
    we've made many of the speculative goals of cloud computing in Unison a
    reality. Over the past month,
    [the Unison Cloud platform](https://unison.cloud) has been in testing with
    a small group of trailblazers.

    Let's take a look at what you can expect when Unison Cloud enters general
    availability later this year:

    **Long-running http service support**

    With other platforms, the typical experience of deploying an HTTP service
    generally involves some out-of-band steps to get your code and its
    dependencies running "somewhere in the cloud". In Unison, you just call a
    function:

    {{
    docAside
      {{
      These examples are clickable! You can read the docs on Unison Share.
      }} }}

    ```
    httpMain : '{IO, Exception} ServiceHash HttpRequest HttpResponse
    httpMain = Cloud.main do
      helloService : HttpRequest -> HttpResponse
      helloService request = HttpResponse.ok (Body (Text.toUtf8 "Hello world"))
      deployHttp Environment.default() helloService
    ()
    ```

    Notice the `deployHttp` call. This uploads the code and any missing
    dependencies to Unison Cloud and starts the service running on our managed
    infrastructure. Services by default get assigned a unique content-addressed
    hash, but you can have service names which are assigned to these hashes,
    and this can be used for easy rollback or conditional "promote to
    production".

    Unlike other platforms, there's no separate packaging step, no building
    containers or uploading them somewhere or other, no YAML files or weird
    configuration languages to specify how deployment should happen. Deployment
    of services and other management tasks are done with ordinary typed Unison
    code which you can factor however you like.

    When using Unison Cloud, you get to focus on the actual business logic of
    your services, not a mess of plumbing and cloud infra management.

    How is it so simple? In Unison, arbitrary values (including functions and
    code) may be serialized and sent over the network, and Unison has an
    approach to dynamic code loading that avoids the possibility of dependency
    conflicts. We build on these features to make Unison Cloud work.

    **Durable transactional storage**

    {{
    docAside
      {{
      You can still use external datastores in your application if you like,
      same as in any other language.
      }} }}

    Rather than needing a tedious layer of boilerplate between your application
    and the storage layer, you can persist arbitrary Unison values to typed
    Unison-native storage:

        @source{simpleStorage}

    The storage layer has typed tables and transactions that operate on these
    tables. Tables can be used directly, or as building blocks for all more
    interesting durable data structures: queues, sorted maps, search indexes,
    and more.

    This works via the same magic that powers the dynamic code deployment.
    Since arbitrary Unison values may be persisted and then unpersisted without
    dependency conflicts, we can eliminate the layer of manual encoding and
    decoding to SQL or whatever other storage layer and just store values
    directly.

    **Typed inter-service communication**

    Calls between services often involve boilerplate for serializing and
    deserializing data models, and it can be a pain to verify schemas or keep
    multiple service versions in sync with each other. In Unison,
    service-to-service communication can be expressed as regular function calls
    whose arguments and return values are checked at compile time. Check out
    the signature of the {call} function:

        @signature{call}

    The {call} function's argument must match the input type represented in the
    {type ServiceHash}. Moreover, because Unison types are identified by their
    hash, not just their name, we’re assured that the `UserModel` used by the
    caller and the service are the exact same version.

    Say you don't have or care about the unique {type ServiceHash} of the
    service you're calling, but like most clients, you know the overall service
    name. {callName} lets you perform typed service calls by their name because
    the Unison Cloud handles resolving the service name to the particular
    {type ServiceHash} which is currently registered to it.

        @signature{callName}

    **Logging and log viewing**

    While this isn't the most earth-shattering feature, service logs are easily
    viewable in the Unison Cloud UI. You can also you can tail logs to your
    local terminal with a single function call.

    Log messages are arbitrary JSON and we include a number of convenience
    functions for logging messages for instance:

        @signatures{warn, warn.json, customLevel.json}

    The use of [abilities](/learn/abilities) here also makes it easy to
    intercept and send log messages to whatever external log aggregator you
    like.

    **Secrets and config management**

    Services and jobs have access to config environments via the
    [`Config`]({type Environment.Config}) ability. Config values are encrypted
    and your program can only access them if it has the appropriate
    permissions.

        @source{setConfig}

    ## ... and we're just getting started

       In the coming months, we have a series of additions planned, including:

       * A entire suite of durable data structures for use in your applications
       * WebSocket-based services
       * Scheduled jobs
       * Asset management support for full-stack web applications
       * ... and more

    ## Curious? Connect with us!

       If you like the sound of this, head over to the newly revamped
       [Unison Cloud website](https://www.unison.cloud/) and sign up to request
       early access or be notified of launch.

       In the meantime you can also brush up on your Unison programming skills
       or ask us your questions in our welcoming
       [Slack community](https://unison-lang.org/slack).

       We'll also be at [Scale by the Bay](https://www.scale.bythebay.io/)
       showing a live demo of all this.

       The Cloud is coming soon and we can't wait to share it with you!

       {{
       docCallout
         (Some {{ 🙏 }})
         {{
         **Thank you to our Cloud Trailblazers** who have helped test out the
         platform, reported bugs, given feedback, and discovered new practices
         and usage patters while writing their applications. We really
         appreciate it!
         }} }}
  }}

blog.cloudTeaser.setConfig : Text ->{IO, Exception} Text
blog.cloudTeaser.setConfig apiKeyValue = Cloud.run do
  cloudEnv = Environment.default()
  setValue cloudEnv "api-key" apiKeyValue
  Cloud.submit cloudEnv do Config.expect "api-key"

blog.cloudTeaser.simpleStorage :
  Database -> Table Text Nat -> '{Exception, Cloud, cloud.Storage} ()
blog.cloudTeaser.simpleStorage db table = do
  use Nat +
  use Transaction write.tx
  key = "myKey"
  transact db do match Transaction.tryRead.tx table key with
    Optional.None -> write.tx table key 1
    Some count    -> write.tx table key (count + 1)

blog.contributingToUnison.index : Doc
blog.contributingToUnison.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Contributing to Unison, a walk-through of adding a feature to the UCM."
      )
    , ("date", "2023-02-21")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "draft")
    ] }}

  # Adding the delete-many feature to the UCM

    Hello future Unison contributors! We'll be walking through the process of
    contributing a small feature to the Unison Codebase Manager in this post.

    We'll be updating the `delete` command in the UCM to support deleting
    multiple definitions at once. This has been an ergonomic papercut for
    users: say you've added several functions and types but realize they aren't
    necessary, if you can't delete the entire namespace they reside in, you
    issue `delete` once for every entity! 😩 It's a pretty simple command, but
    it's a good place to start because it's a command that involves simple
    changes to both inputs and outputs in the CLI and touches how terms are
    stored in the codebase.

    Currently, you can delete a single definition at a time, but most commands
    in the UCM allow you to interact with multiple terms, either by specifying
    a list of names or by using ranges of numbered arguments. By the end of our
    work we should be able to write variations of the following:

    ``` ucm
    .> delete myTerm myOtherTerm MyType
    .> delete 1-3
    .> delete 1,5,7
    ```

    {{
    docAside
      {{
      Standard caveats apply that this post represents a snapshot in time and
      the information and processes described may change over time.
      }} }}

    Here's what we'll do in this post:

    * We'll start by setting up our environment for local development
    * We'll talk through the technical considerations that go into implementing
      this feature
    * We'll highlight some of the code changes involved next, putting those
      technical considerations into action.
    * And finally we'll test and submit the PR!

  # 🏗 UCM development environment setup

    Start by cloning the
    [Unison repository from github](https://github.com/unisonweb/unison/) and
    ensuring that you can build Unison from source with Haskell. {{
    docAside
      {{
      If you're using a Mac M1 workstation, check out
      [this document](https://github.com/unisonweb/unison/blob/trunk/docs/m1-mac-setup-tips.markdown)
      for some additional pointers.
      }} }}

    We'll be using Stack to build the UCM artifact.

    ``` bash
    $ stack build --fast && stack exec unison
    ```

    While this is building make sure to read the
    [development.md](https://github.com/unisonweb/unison/blob/trunk/development.markdown)
    file in the repository. It contains useful commands that you'll need to
    know to work in this project. When the `stack` command finishes, it should
    open up the UCM console, meaning that you've successfully built the Unison
    executable from source!

    {{
    docAside
      {{
      If you're working in the Unison project and want to quickly check if your
      project builds, the `fast` flag will save you a lot of time, at the
      expense of building Unison without optimizations. Otherwise,
      `stack build` can be very slow.
      }} }}

    ## Check that your testing environment is set up

       Unit tests for the Haskell code are run with `stack test`, but this
       project primarily uses
       [Unison transcripts](https://www.unison-lang.org/learn/tooling/transcripts/)
       to test interactions between Unison code, a codebase, and the UCM CLI.
       Run `stack exec transcripts` to see these run as well. In particular
       we'll be running `stack exec transcripts -- delete.md` to run the single
       transcript that we care about most.

    ## Other tooling

       The Haskell Language Server will help us out with features like
       autocompletion and type signatures on hover. I've found it invaluable
       for working in Haskell.

       The UCM uses [ormolu](https://www.tweag.io/blog/2019-05-27-ormolu/)
       version 0.5.3.0 for formatting. This is important for the PR process as
       the CI will fail if your PR is not formatted correctly.

  # 🧐 Technical considerations and scope

    We should ask ourselves a few technical questions before we start coding
    the "delete many" story. We want to make sure we understand the scope and
    context that this story involves.

    **How is a "deletion" currently represented given that codebases are
    immutable?**

    A Unison codebase is a log of changes, so we're not going to "hard delete"
    a term and fully remove all record of it from the codebase. Deletion is
    more akin to the process of "un-naming". A deleted term can be referenced
    by its hash still, but the namespace mapping from human-readable name to
    hash is removed. If you rely on a term that has been deleted, your code
    will still __work__, but it will show up as its hash (for now) rather than
    a nice human-readable name.

    **Should we be able to delete different entities in the codebase in one
    deletion command, for example, deleting terms, patches, and namespaces all
    in one invocation of `delete`?**

    Deleting namespaces and patches are a little different. Let's focus on
    supporting the multi-delete experience for just terms and types. So
    `delete termA TypeB` would be valid but `delete termA patch` would not. The
    two commands for deleting just terms and types are implemented in terms of
    shared logic, so we'll get the multi-delete experience for `delete.term`
    and `delete.type` for free.

    **Given that this story enables multi-deletion, should we support partially
    successful deletions or roll back the deletion command if any fail?**

    This could happen if a user wants to delete term1 and term2 and term1 can
    be deleted safely but term2 is called by other code in the codebase.

    For now, let's assume that we want to run the deletions in a single
    transaction, and if any of the deletions fail, we should roll back the
    entire transaction. We can always ask the friendly core team in the
    #development slack channel for their suggestions.

    **How do we currently prevent the deletion of a term that is referenced by
    other terms?**

    The last thing we want to do in our deletion story is to accidentally leave
    codebases in an unexpected state. There's `delete.force` for cases where
    the user really wants to delete something. The current `deletion` process
    checks for "endangered dependents": terms that reference the prospective
    deletion.

    **How should we support the new experience of deleting a cycle of terms
    that depend on each other, all at once?**

    This use case is a common one, we often want to delete a chain of terms
    which depend on each other, from the leaf terms to the root term. We'll
    solve this by modifying the existing check for dependents that the UCM
    currently performs upon deletion.

  # 💻 Where to start coding

    In this story, types will be our guide. We're going to be turning a single
    term or type to delete into a `List` of terms or types to delete. Prepare
    yourselves for a lot of calls to
    [`traverse`](https://en.wikibooks.org/wiki/Haskell/Traversable). We'll
    mainly outline the steps we're taking in pseudocode, with a few type
    signatures sprinkled in for clarity.

    ## Entry points to the CLI

       While the UCM is running, interactions with the Unison codebase are
       either `Events`, like when you save a `.u` file, or `Inputs`, like when
       you type a command into the UCM CLI. Check out the
       [HandleInput.hs](https://github.com/unisonweb/unison/blob/b5fca58162798dc8635bedd200eb735a707a7fe8/unison-cli/src/Unison/Codebase/Editor/HandleInput.hs)
       file to see the loop function. The run loop pattern matches on an
       `Input` data type to determine its behavior and responds to the user
       with an
       [`Output`](https://github.com/unisonweb/unison/blob/b5fca58162798dc8635bedd200eb735a707a7fe8/unison-cli/src/Unison/Codebase/Editor/Output.hs)
       data type in the context of a CLI interaction. Predictably, both Input
       and Output data types were changed to accept lists instead of singular
       items.

       The case we care about is `DeleteI`; its argument is a type
       `DeleteTarget` representing the entities in the codebase which can be
       deleted, like terms, types, patches, and namespaces. We decided we are
       only going to focus on the types and terms for our story.

       ``` haskell
       [... giant pattern match representing other UCM commands ...]
         DeleteI dtarget -> case dtarget of
           DeleteTarget'TermOrType doutput hq -> delete doutput Cli.getTermsAt Cli.getTypesAt hq
           DeleteTarget'Type doutput hq -> delete doutput (const (pure Set.empty)) Cli.getTypesAt hq
           DeleteTarget'Term doutput hq -> delete doutput Cli.getTermsAt (const (pure Set.empty)) hq
       [... continued pattern match ...]
       ```

       As a starting point we should change the `DeleteTarget` type to accept
       lists of arguments instead of a single query. From the single "hash
       qualified path" in the constructor, `Path.HQSplit`, we want to get to
       `[Path.HQSplit]`.

       {{
       docAside
         {{
         `Path.HQSpit` is a hash qualified path, split into namespace segments
         and a final hash qualified name segment. All Unison terms receive a
         hash, which you can see by typing `names some.term.here` in the UCM.
         }} }}

       ``` haskell
       data DeleteTarget
       = DeleteTarget'TermOrType DeleteOutput [Path.HQSplit']
       | DeleteTarget'Term DeleteOutput [Path.HQSplit']
       | DeleteTarget'Type DeleteOutput [Path.HQSplit']
       | DeleteTarget'Branch Insistence (Maybe Path.Split')
       | DeleteTarget'Patch Path.Split'
       ```

       From there we'll change the signature of the `delete` helper function
       which is responsible for the actual deletion of the term or type to
       accept a list.

       ``` haskell
       delete ::
         Input ->
         DeleteOutput ->
         ((Path.Absolute, HQ'.HQSegment) -> Cli (Set Referent)) -> -- compute matching terms
         ((Path.Absolute, HQ'.HQSegment) -> Cli (Set Reference)) -> -- compute matching types
         [Path.HQSplit'] -> -- NEW: This now takes a collection
         Cli ()
       delete input doutput getTerms getTypes hqs' = do
       ```

       The `delete` function is going to involve some more significant changes.
       Its current core responsibilities are threefold:

       1. It checks if the target to delete is actually present in the
          codebase. So if I try to delete "foot" but that is a typo for "foo",
          this function handles the logic for reporting back the error.
       2. If the target for deletion is present, it looks up its dependents
          (other terms that reference the prospective deletion) in the
          codebase. We run a check for "endangered dependents" so we can report
          if a deletion would impact other terms.
       3. If the target for deletion has nothing that references it, it's safe
          to remove, so it un-names the target and thus term or type won't show
          up in the user's namespace anymore.

       Now that we're permiting multiple terms or types for deletion, our
       failure conditions are going to be slightly more complex.

       For the first step, checking if the targets for deletion exist, we want
       to report __all__ of the terms that the user may have mis-typed at once,
       so that they don't have to run the command multiple times to get all of
       the errors.

       For this check we are doing the following:

       * Traversing over the list of deletion targets from the user, and for
         each of them
         * Collecting the terms and types that match the deletion target in the
           codebase
         * Filtering the list of results for things that don't, in fact, have
           terms or types to delete
         * Reporting the names back to the user if any of the things they
           wanted to delete are missing

       Our second step, checking if a term is safe to delete, draws on a unique
       feature of Unison code. A Unison term or type is stored in such a way
       that the things that depend upon it (its "dependents") are
       programmatically known. Fortunately, there's a function that already
       checks if a term or type would "endanger" other things in the codebase
       if it no longer exists in a namespace. We'll change the existing
       `getEndangeredDependents` function to take in the full set of targets
       for deletion, in light of our desire to support deleting full cycles of
       dependencies in one command. With this we can "subtract" the set of the
       user's desired deletions from the dependents of each term to delete, so
       the `getEndangeredDependents` check will pass. The logic is now:

       * For every entity the user wants to delete...
         * Look up the types and terms that depend upon it in the codebase
         * Get the full set of codebase entities and subtract the other
           deletion targets
         * Return the "endangered" dependents of the target for deletion which
           are still present in codebase

       {{
       docAside
         {{
         You can use the `dependents` UCM command to see the terms which depend
         on the given argument. Likewise, use the `dependencies` UCM command to
         see the terms that the given argument relies upon.
         }} }}

       We decided earlier that if any of the types or terms for deletion can't
       be safely deleted, we're going to abort the command.

       For that we'll do the following:

       * Perform a filter on the list of dependents to see if any of the
         targets for deletion are still being used in the codebase
       * We report them back to the user as unsafe to delete if present.
       * Otherwise we run the set of deletions in a database transaction,
         removing them from the namespace.

    ## The hard part

       We've elided over the details of the implementation, but it's worth
       noting what the most difficult part of this change was. Working in the
       UCM, the challenge is in knowing the domain models and what they do. Is
       a `HQSplit` what we need or a `Path`? Both might loosely represent some
       notion of a "term" in the codebase, but might present the data in
       non-interoperable ways.

       TODO - What to do about this??? Glossary? Just... apologize???

  # ✅ Testing and submitting the PR

    ## Setting up the transcript test

       In testing our story we're going to rely heavily on the UCM's transcript
       testing framework. Rather than mocking the various interactions between
       the CLI and the codebase, this allows us to run the UCM in a real
       codebase and test the behavior of our change. If you are contributing
       stories which primarily involve interactions between the user, the CLI,
       and the codebase, these will be your "unit tests".

       It looks like there's a basic test for the "delete" functionality in
       `unison-src/transcripts/delete.md`. We'll start by adding transcript
       stanzas that test the cases that we care about. The stipulations we made
       earlier when thinking about the scope and impact of the story can help
       guide these tests, For example, we might add a deletion workflow that
       adds a type to the codebase and tests that we can delete both the type
       `structural type Foo = Foo ()` and a term that depends upon it in one
       `delete` command.

       ```` markdown
       ``` unison :hide
         structural type Foo = Foo Nat

         incrementFoo : Foo -> Nat
         incrementFoo = cases
           (Foo n) -> n + 1
         ```
       ````

       ```` markdown
       ``` ucm
         .> add
         .> delete.verbose Foo Foo.Foo incrementFoo
         .> ls
         ```
       ````

       We expect the UCM to allow the delete command to succeed, and can check
       that the terms have been removed with an `ls` command.

       {{
       docCallout
         (Some {{ ⭐️ }})
         {{
         Often, your transcript tests need to express that something should
         fail. For example, in our case, if you try to delete a term that is
         referenced by another term, we want the UCM to return an error. You
         can communicate that this is an expected failure by adding the
         ''``` ucm :error'' tag to the transcript stanza.
         }} }}

       The transcript based testing framework for the UCM works by comparing
       the the expected output.md file to the actual output file that's
       produced from running the transcript command. This means after we've run
       `stack exec transcripts` and inspected the `delete.output.md` file to
       make sure it exhibits the behavior we expect, the output file will be
       checked into the repository. These tests help guard against regressions
       in the UCM behavior, but in some circumstances, like when you're
       changing output error messages, you may need to update multiple output
       files.

       After your tests are all passing, you'll want to check the formatting of
       your code for consistency. There are a few helpful scripts and commands
       for formatting your code in the
       [`development.markdown`](https://github.com/unisonweb/unison/blob/cf278f9fb66ccb9436bf8a2eb4ab03fc7a92021d/development.markdown#autoformatting-your-code-with-ormolu)
       file. {{
       docAside
         {{
         If your code has been formatted by ormolu, but eventually fails the CI
         pipeline, check the version of your ormolu installation.
         }} }}

       Once you are satisfied with your implementation, open a PR! We'll review
       your code and help you get it merged into the Unison codebase. 🎉

  # 💪 Want to help out?

    If you're interested in contributing to the UCM, join is un the
    #development channel in Slack.

    The kinds of issues that might be good for a first time contributor are
    marked with the `good first issue` label. Changes like "improvements to
    error messaging" or small ergonomic changes to commands, like this one, are
    good candidates for a first contribution.
  }}

blog.decLibraryUpdates2022.index : Doc
blog.decLibraryUpdates2022.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The Unison ecosystem is growing! Here are a few of our November to December highlights."
      )
    , ("date", "2022-12-08")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # December library ecosystem updates

    ## New(ish) libraries:

       ### [Exists library](https://share.unison-lang.org/@ceedubs/p/code/latest/namespaces/public/exists/latest)

           Maintained by [@ceedubs](https://share.unison-lang.org/@ceedubs)

           Has programming been feeling like you're pushing a rock up a hill?
           Maybe the lack of existential types in Unison has been causing you…
           **angst**? While you can't directly represent an existential type in
           Unison, you __can__ emulate them, and as it turns out there "exists"
           [a mini library demoing that](https://share.unison-lang.org/@ceedubs/p/code/latest/namespaces/public/exists/latest).

           {{
           Image
             {{
             Gregor Samsa turned into a giant bug, stuck in bed with the words
             "Yeah! Existential types!" floating on top.
             }}
             {{
             /assets/feed/decLibraryUpdates2022/gregor.jpg
             }}
             (Some
               {{
               Gregor Samsa awoke one morning to find himself
               [in need of a `Remote` test handler capable of verifying
               functions which return different types.](https://share.unison-lang.org/@ceedubs/p/code/latest/namespaces/public/exists/releases/v1_1)
               }}) }}

           The project readme breaks down a datatype which can represent an
           existential type, but if you want more information about existential
           types in general, the
           [Basics section of this Haskell wiki](https://wiki.haskell.org/Existential_type#Overview)
           does a good job at explaining them.

       ### [Google Places API](https://share.unison-lang.org/@tapegram/p/code/latest/namespaces/public/project/googleplaces/;/terms/main/README)

           Maintained by [@tapegram](https://share.unison-lang.org/@tapegram)

           This library currently supports a subset of the Google Places API.
           For example, I used it to search for "Dinner" at the the Mount
           Everest Basecamp in an imagined future where I am capable of
           climbing a mountain. I got quite a few restaurants in response!

           ``` json
           ...
           {
             place_id: ChIJT-phrtoI6TkRybyBNFC4-WQ
             name: Himalayan Lodge Restaurant
           },{
             place_id: ChIJdQYGNtQJ6TkRhOX1KvC7Lak
             name: The Hungry Yak Live Music Bar Pvt Ltd
           },{
             place_id: ChIJ576ljNoI6TkRMi00fxQVj-w
             name: Hotel khangri
           },{
             place_id: ChIJ9celvckP6TkRkzz9XydzCcM
             name: Rokpa guest house
           }
           ...
           ```

           "The Hungry Yak" speaks to me, so I can use the information from the
           previous query to see what it looks like using the library. Here's
           where we're eating:

           {{
           Image
             {{
             An exterior photo of The Hungy Yak restaurant, showing signage and
             a facade and staircase painted with red and blue.
             }}
             {{
             /assets/feed/decLibraryUpdates2022/TheHungryYak.jpeg
             }}
             Optional.None }}

       ### [Midi library](https://share.unison-lang.org/@alvaroc1/p/code/latest/namespaces/public/midi/main)

           Maintained by [@alvaroc1](https://share.unison-lang.org/@alvaroc1)

           "Why not?" asks the project's readme, and we agree! Why not! If you
           need to parse a Midi file, you should be able to do it in Unison.
           [Once the UCM supports UDP](https://github.com/unisonweb/unison/issues/3283),
           the library should be able to play music, and perhaps a Unison
           concert is in order. 🎸

    ## Version updates:

       ### [Dhall parsing library](https://share.unison-lang.org/@hagl/p/code/latest/namespaces/public/dhall/latest)

           Maintained by [@hagl](https://share.unison-lang.org/@hagl)

           Having misconfigured quite a few YAML configs in our day, we are
           very thrilled that Unison has a library to support parsing the Dhall
           language. If you haven't heard, Dhall is the coolest configuration
           language on the block. The
           [Dhall language homepage](https://dhall-lang.org/#) includes a
           helpful tutorial which showcases its expressiveness and utility and
           the readme of the Dhall library on Share brings that content to
           Unison.

       ### [Ability-based parsing library](https://share.unison-lang.org/@rlmark/p/code/latest/namespaces/public/parsing/latest)

           Maintained by [@rlmark](https://share.unison-lang.org/@rlmark)

           Version two of this parsing library includes a rewrite of the
           `Parse` ability to make use of the more efficient {type Pattern}
           utilities included in the base library. The
           [CHANGELOG](https://share.unison-lang.org/@rlmark/p/code/latest/namespaces/public/parsing/latest/;/terms/CHANGELOG)
           for this version contains information about the update.

           That's all for now! If you have a library you'd like featured in a
           post, get in touch with us in the #libraries channel in the
           [Unison slack](https://unisonweb.org/slack)!
  }}

blog.developerProductivityReallyMatters.index : Doc
blog.developerProductivityReallyMatters.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Most companies spend far more on developer compensation than on their cloud bill. So why isn't there more focus on improving developer productivity for cloud platforms and tools?"
      )
    , ("date", "2024-02-07")
    , ("authors", "paul-chiusano")
    , ("categories", "cloud")
    , ("featuredImage", "/assets/unison-services-preview.svg")
    , ("status", "published")
    ] }}

  # Developer productivity is what really matters for a cloud platform

    {{
    docAside
      {{
      ¹
      [$80b in revenue](https://www.statista.com/statistics/233725/development-of-amazon-web-services-revenue/)
      / [1 million accounts](https://www.contino.io/insights/whos-using-aws)
      }} }} Here's a startling fact: the average AWS bill per account is only
    about $80k per year.¹ The median bill is likely even less, since outliers
    like Netflix skew the average, spending
    [upwards of $300 million per year](https://www.cloudzero.com/blog/netflix-aws)
    in the cloud, while small and medium-sized businesses spend nowhere near
    that.

    {{
    docAside
      {{
      ² The median developer salary is
      [at least $120k](https://money.usnews.com/careers/best-jobs/software-developer/salary),
      perhaps $150k fully loaded with salary, benefits, etc.
      }} }} What most businesses spend a lot more on is paying developers:
    $80k/yr is not even a single developer's salary² Even a 12 person team of
    developers might cost $1.8 million dollars all in, nearly 20x the average
    cloud bill.

    Put another way,
    **most businesses are better off focusing on improving developer
    productivity than on shaving percentage points off their cloud bill.**
    Arguably even Netflix could benefit from this advice:
    [they employ over 2k engineers](https://blog.pragmaticengineer.com/netflix-levels/),
    at
    [upwards of $225k per person](https://www.levels.fyi/companies/netflix/salaries/software-engineer),
    so at least $450 million in annual compensation, well exceeding their cloud
    spend.

    So why **do** we see such perseveration about cloud spending and such
    little discussion of what makes developers more productive? Several
    reasons:

    * **Developer productivity is hard to measure, while cloud spending is not.**
      It's easy to point to an AWS bill and say "oh, we can reduce this
      number", but how do you know if switching to another language or using
      some new developer tool makes the team more effective? Of course, it
      doesn't make sense to optimize unimportant factors like spending on
      snacks and office chairs just because they're easy to measure, while
      ignoring the important yet harder-to-measure. But many organizations end
      up doing just that. In part this is a general phenomenon: people want an
      objective measure to guide improvements, and developer productivity has
      no agreed-upon measure, so it gets mostly ignored. That's not great, but
      there's something even more insidious going on…
    * **Default cynicism about claimed improvements in developer productivity.**
      We live in a hype-driven world where a multitude of devtool startups and
      projects all claim to make the work drastically easier. Given the amount
      of noise, people understandably become inured to these claims, adopting a
      default position of skepticism. It makes sense as a heuristic, yet this
      has been taken too far, with a default assumption that all programming
      languages and technologies "more or less the same" and that developers
      are equally productive no matter what tools they're using. They're not.
      Software creation technology **has** seen huge advances over the course
      of its history (imagine trying to build Netflix in assembly language!),
      and we're not close to done yet. Paradigm shifts that bring about huge
      increases in capability are real, have happened many times before, and
      will again.
    * **Developer productivity isn't even the focus of the conversation.** Most
      people will admit that developing for the cloud is more complicated and
      less productive than building a single-machine monolithic app. The
      cloud's selling points are elsewhere, like in not having to buy and
      manage hardware, scalability via software knobs, and greater system
      resilience if you know what you're doing. These benefits are big enough
      that organizations have been willing to trade off developer productivity.
      But even though that tradeoff has been made historically, it doesn't mean
      developer productivity is unimportant. Far from it. We ought to strive
      for both: the benefits of the cloud, and excellent developer
      productivity.

    The worse productivity of the cloud compared to single-machine apps is also
    part of why developers will gripe about costs and make noise about moving
    away from using cloud services. Such moves may be justified in terms of
    cost savings, and that can be real (especially for companies heavily using
    various higher margin "value-add" services offered by cloud providers), but
    saving developer time and energy is often the bigger win.

    ## What we're doing instead

       For [Unison Cloud](https://unison.cloud), we're doing something
       different. We're focused on building a more productive cloud platform
       which is a joy to use (and with
       [simple and predictable pricing](./its-time-to-rethink-cloud-pricing/)).

       By building on the [Unison language](https://unison-lang.org),
       [we get to completely eliminate entire classes of time-consuming work](https://unison.cloud/our-approach).
       Deployment is done with a single function call (no packaging or building
       containers), inter-service calls are as easy as local calls (and they're
       typechecked), storage is as easy to access as in-memory data structures
       (and it's typechecked), and lots more. We think the cloud should be
       simple and delightful to use, and we're making it happen.

       Sound good? [Join us.](https://unison.cloud)
  }}

blog.dutchUnisonMeetup.index : Doc
blog.dutchUnisonMeetup.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Did you know that the Dutch Unison community is thriving? We're excited to announce the first Dutch Unison Meetup, where we'll be discussing all things Unison."
      )
    , ("date", "2024-09-23")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # Join the Dutch Unison Meetup

    You might associate many things with the Netherlands:

    * Tulips
    * Windmills
    * Bicycles

    And now... the Unison programming langauge! By happenstance, many Unison
    developers call the Netherlands their home. The Dutch Unison community is
    thriving and they're excited to announce the first Dutch Unison Meetup.
    Join us for pizza and lively discussions about all things Unison.

    ## 📆 Event details

       **Who**

       Anyone interested in Unison!

       **When**

       Wednesday, September 25 · 5:30 - 8:30pm CEST

       **Where**

       The offices of YipYip in Rotterdam, see event page below for details.

       [RSVP to the event here!](https://www.eventbrite.com/e/dutch-unison-meetup-tickets-950854821367)

       See you there! 🌷
  }}

blog.experienceReportUnisonInProduction.index : Doc
blog.experienceReportUnisonInProduction.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The Unison ecosystem, tooling, and core language experience is currently mature enough that we're using Unison in production—on mission-critical applications. But along the way, we encountered a number of stumbling blocks that required careful developer investment. This post is our candid experience report on what we ran into, what we fixed, and what we're excited about tackling next."
      )
    , ("date", "2024-03-11")
    , ("authors", "paul-chiusano")
    , ("categories", "viewpoints")
    , ("categories", "experience-report")
    , ("featuredImage", "/assets/thing15.svg")
    , ("status", "published")
    ] }}

  # Unison in production at Unison Computing

    Unison Computing is the company behind the open source
    [Unison programming language](https://unison-lang.org/) and the
    [Unison Cloud Platform](https://www.unison.cloud/). This post has our
    candid experience report on using Unison over the years.

    What do we use Unison for at our company? Several mission-critical
    applications:

    * **Unison Cloud's basic compute fabric**, an elastic pool of nodes that
      runs arbitrary distributed Unison code. This is the basis for our cloud
      platform. It handles moving computations between nodes, on-the-fly
      loading of dependencies, and code syncing.
    * **Unison Cloud's scalable transactional storage layer**. This is backed
      by DynamoDB, but significant engineering went into building the
      capabilities we wanted. (For instance, we support arbitrary transactions,
      storage of arbitrary typed Unison values, and defining new durable data
      structures besides just key-value tables.)

    We're also currently working on a few other important projects in Unison:
    code and documentation search for
    [Unison Share](https://share.unison-lang.org/), powered by a scalable
    distributed search index, and a programmer blog engine (with posts rendered
    from the excellent Unison documentation format).

    In addition to these more serious applications, most of us have little side
    projects or libraries written in Unison just for fun. 😀 Suffice to say,
    we've been using Unison heavily.

    So how has it gone? Well, we're quite happy with Unison today, but it's
    been a journey to get here.

    ## What we struggled with

       On the one hand, Unison makes new things possible and it's been a thrill
       working with the language. But when we first started on Unison Cloud,
       the language, ecosystem, and tooling weren't nearly as mature as today,
       and we encountered all sorts of difficulties.
       **All in all, if you'd asked me even a year ago if Unison were a
       language I'd recommend for real stuff, I'd have said probably not!**

       Here's what we encountered, in increasing order of annoyance:

       * **Runtime bugs.** When Unison Cloud's basic compute fabric was first
         written, it was by far the most significant system written in Unison
         by anyone (likely it still is). It's also fairly intricate. Our
         implementation exposed several bugs in the Unison runtime which were
         not fun to minimize and track down. This at least stabilized pretty
         quickly and the runtime today is quite stable, though not super
         performant. We'll be shipping the JIT native compiler with much faster
         performance in the coming few weeks.
       * **Gaps in the ecosystem.** The ecosystem and core language weren't
         nearly as developed when we started using Unison for our cloud
         platform. Even very basic libraries did not exist (for TLS, HTTP, JSON
         encoding / decoding, various AWS libraries, etc) and we regularly
         needed to stop what we were doing and build them or add core language
         builtins. While this has improved greatly over the years, in the early
         days it was a major bottleneck.
       * **Issues with Unison's tooling.** Unison is a language built around
         [an amazing core idea](https://www.unison-lang.org/docs/the-big-idea/)
         with huge potential for vastly better tooling than other languages,
         but actually realizing all that potential has been a colossal amount
         of work, with a lot of little details and engineering to get right.
         More on this below.

       {{
       docAside
         {{
         🎉 Unison Share today hosts over 49,000 definitions spread across
         hundreds of projects, with more being added every week.

         Among many other things, the ecosystem now has library support for
         TLS, HTTP (including WebSockets), talking to AWS, JSON encoding /
         decoding, binary decoding, text parsing, and lots more!
         }} }}

       ### Issues with Unison's tooling in the early days

           The experience of developing Unison code today is quite lovely (more
           on that later), but in the early days it had all kinds of problems.
           Some were engineering issues, others were more conceptual.

           On the engineering side, before Unison's switch to SQLite for
           storing codebases (a huge effort that took us many months), Unison
           used the file system as a terrible database, which was both
           complicated and led to all sorts of performance problems. Even when
           we fixed that, [Unison Share](https://share.unison-lang.org/) didn't
           exist when we first started on Unison Cloud, so we didn't even have
           a great way of browsing and collaborating on Unison code. Instead we
           stashed large SQLite database files on GitHub and shared code that
           way, which was exactly as janky as it sounds.

           In addition, the Unison Codebase Manager formerly had annoying
           workflows and bugs we hit regularly when developing Unison Cloud,
           especially around basic things like updating code and library
           dependencies. The situation is now vastly improved
           ({{ docCode {{ update }} }} generally just works, as does `upgrade`
           for upgrading library dependencies).

           {{
           docAside
             {{
             One thing that's still left to do for basic workflow improvements
             is a better `merge` function for merging branches in a
             history-aware way—this should land in the coming weeks. It also
             mostly affects projects with multiple concurrent collaborators. If
             you're just working on projects on your own, you probably won't
             even notice.
             }} }}

           There were more conceptual issues, too. Unison was for a long time
           missing any real notion of "projects", "releases", and "merge
           requests", instead providing just a freeform “versioned namespace
           tree". This seemingly elegant abstraction was, in theory, capable of
           representing many things, **but not well or with good ergonomics**.
           We at one point published a ridiculously complicated document laying
           out certain conventions that could be followed to track a project
           with a bunch of releases, branches, and in-flight merge requests. I
           think maybe 2 people in the world actually read it and understood
           it. 😀

           {{
           docCallout
             Optional.None
             {{
             One of the design principles we've settled on from all this
             experience:
             **whenever possible, avoid giving users low-impact decisions.**
             }} }}

           Be opinionated if it helps to free people from needing to think
           about stuff that probably doesn't matter much for their work. (Also
           see: Unison's automatic formatting of code.) This both reduces
           burden of choice for users and lets us craft a more tailored UI with
           better ergonomics.

           We've since introduced first-class support for projects, releases,
           merge requests, and tickets, and we think the experience is much
           better overall. On the one hand, Unison's core model doesn't
           actually care about these things. Code is referenced by hash, and
           dependencies are tracked at the level of individual definitions. Any
           level of grouping or organization above the level of individual
           definitions is purely for the convenience of humans.

           But this "for humans" level of grouping is incredibly important! For
           authors, it's just easier to maintain a self-contained collection of
           definitions with sensible names. These definitions can all be
           updated together, with a common set of release notes, a README for
           the library as a whole, and so on. As a consumer of a library,
           relying on a curated bundle of definitions and documentation is also
           often easier. It's easier to learn ("an expert has documented and
           bundled together all these bits of functionality that I'm likely to
           need when working with this domain") and easier to maintain as a
           dependency due to less burden of choice. ("An expert in the domain
           of this library has made hundreds of related changes or additions
           that are all consistent with each other, and I'm just going to go
           with their recommendations.")

           While Unison doesn't prevent you from making decisions in a more
           fine-grained way—you can easily reference multiple versions of "the
           same" definition or library within your project—the most common use
           case should be easy and ergonomic and that's what we've settled on.

    ## What's been great

       Overall, the Unison language is very capable. The combination of basic
       functional programming support (data types, pattern matching, proper
       tail calls) plus [abilities](https://unison-lang.org/docs/abilities),
       along with Unison's fancy runtime which supports async I/O and green
       threads feels like a real sweet spot. While Unison is simpler than
       languages like Haskell or Scala, which many of us have used heavily, we
       haven't missed the additional features of these languages nearly as much
       we thought. There's always a way of accomplishing what you want in
       Unison.

       Besides the core language, there's much more about Unison that we
       appreciate every day:

       * Unison's fundamental superpower of being able to serialize arbitrary
         values, including functions, and ship them to a different location
         without dependency conflicts. We obviously use this heavily in Unison
         Cloud.
       * Almost never waiting around for code to compile, since the Unison
         codebase is a "perfect" shared compilation cache that invalidates as
         little as possible on updates. We get the low build times of a
         dynamically typed language, but without having to give up static
         types!
       * The code browsing experience on Share is amazing, with all code
         hyperlinked, docs right there, and the ability to pop open individual
         definitions rather than "files". Browsing code on GitHub feels archaic
         in comparison.
       * It's a joy to create and document libraries. The documentation
         experience (both viewing and authoring documentation) is nicer than
         any language ecosystem we've ever used, and there's no friction to it.
         With a single `push` command, everything shows up on Unison Share, the
         code fully hyperlinked, with live examples in the docs, and it looks
         awesome.
       * Cutting releases with a click of a button on Share is great.
       * The workflow of using scratch files with watch expressions is very
         freeing and pleasant. It's easy to get into a flow state. Just start
         coding without worrying too much about where things should live. Once
         definitions are added to the codebase, you can move them around later
         with a single command and without breaking anything.
       * It's nice to be able to reference multiple versions of the same
         library, without it being a "stop everything until this is fixed"
         dependency conflict. Our compute fabric is happily using multiple
         versions of libraries for backwards compatibility with older clients.
       * Packaging of Unison code for deployment is easy. A single `compile`
         command produces a bytecode bundle file with the minimal set of needed
         dependencies. This bytecode file can then be passed to `ucm` via
         `ucm run.compiled mything.uc` to start your application. We use this
         everywhere for packaging code used by Unison Cloud's implementation.
       * The Unison community is great, full of friendly, kind, and helpful
         people.

    ## Conclusions

       Despite all the problems we've encountered during the early days of
       using Unison for real work, we've stuck with it and continued making
       things better. We're actively using the language in production now and
       feel good about recommending that others do the same, with the following
       caveats:

       * Even today, Unison's ecosystem is not as well-developed as other
         languages. If you're thinking of using it for something, we recommend
         taking an inventory of the libraries you'll need and decide if you're
         comfortable writing whatever libraries are missing.
       * The current runtime performance isn't great, so if you're doing
         something performance sensitive, check that Unison is fast enough for
         your use case. But important note:
         **we're shipping the first version of the JIT native compiler in the
         next few weeks, which will make a huge difference here.**

       Besides just the niceties of Unison today, it's also highly motivating
       to use a technology that feels like it has huge potential, and which is
       getting better and better with each release.

       As much as I've enjoyed using other languages, the basic experience of
       building systems with these languages hasn't changed appreciably in a
       long time. Programs are still trapped in the tiny box of a single OS
       process despite most systems being distributed, we're still versioning
       and viewing code using lowest-common denominator tools that only
       understand text, and so on. Sure, languages introduce new features and
       tooling, but it's always within the existing narrow paradigms.

       Getting to use Unison is like stepping into an alternate programming
       universe where hard things are easy and new things are possible. It's
       fun, inspiring, and helps the work feel more joyful.
  }}

blog.heatherMiller.index : Doc
blog.heatherMiller.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Exciting news! Heather Miller, CMU professor and Scala Center founder, who does very cool research at the intersection of programming languages, FP, and distributed systems, will be a Visiting Researcher with us this summer. Like us, Heather is passionate about finding ways to make distributed programming more compositional. We'll be collaborating together on a library for distributed computing in Unison and some interesting demo application using that library."
      )
    , ("date", "2020-05-29")
    , ("authors", "paul-chiusano")
    , ("categories", "announcements")
    , ("featuredImage", "/assets/thing13.svg")
    ] }}

  # Summer collaboration with Heather Miller on Unison distributed programming
  library

    Exciting news! [Heather Miller](https://heather.miller.am/),
    [CMU professor](https://isr.scs.cmu.edu/people/core-faculty/miller-heather.html)
    and [Scala Center founder](https://scala.epfl.ch/), who does very cool
    research at the intersection of programming languages, FP, and distributed
    systems, will be a Visiting Researcher with us this summer. She starts next
    week. Like us, Heather is passionate about finding ways to make distributed
    programming more **compositional.** We'll be collaborating together on a
    library for distributed computing in Unison and some interesting demo
    application using that library.

    The focus of this library will be creating fundamental, reusable
    abstractions that can be used to assemble distributed systems of any size.
    We'll be using Unison's [abilities system](/docs/abilities) to keep the
    library high-level and portable: distributed algorithms and data structures
    can be implemented in terms of abstract abilities which are then handled
    into more concrete backend implementations. One backend might just do local
    execution (possibly with simulated faults injected for testing), another
    might delegate to a static on-premise cluster, and another might delegate
    to an elastic source of cloud compute.

    All the work will be open source and we'll be developing it out in the open
    and blogging as we go. We'll also be publishing some blog posts covering
    distributed systems from first principles, so anyone can follow along with
    the work without needing to be a distributed systems guru who's read every
    paper in the field going back 30 years.

    Heather's position is being jointly funded by
    [Unison Computing](/2020/03/30/benefit-corp-report/) and the early
    supporters of Unison on Patreon (when I closed down my Patreon for Unison,
    I wanted to put the funds toward open source Unison work, but wasn't sure
    how best to do that until now). This Visiting Researcher role is something
    we'll start doing regularly.

    Stay tuned for more updates on this. And welcome, Heather! 👋💜
  }}

blog.heresWhatsBeenHappeningWithUnison.index : Doc
blog.heresWhatsBeenHappeningWithUnison.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Since our last official update here, we started alpha testing a first release of Unison, gave a talk at Strange Loop, and have been working towards an M2 release with lots of new features, bugfixes, and polish."
      )
    , ("date", "2019-10-16")
    , ("categories", "news")
    , ("authors", "paul-chiusano")
    , ("featuredImage", "/assets/thing9.svg")
    ] }}

  # Here's what's been happening with Unison

    Since our last official update here, we started alpha testing a first
    release of Unison, gave
    [a talk on Unison at Strange Loop](https://www.youtube.com/watch?v=gCWtkvDQ2ZI),
    and have been working towards an M2 release with lots of new features,
    bugfixes, and polish. Our goal with M2 is to have the core language and
    tooling be "feature complete and totally usable." We have often used the
    metric of: "a user can write Unison libraries without hitting major gaps or
    bugs that cause undue frustration."

    ## Strange Loop was great!

       {{
       Special
         (Embed
           (Any
             (Video
               [ MediaSource
                   "https://www.youtube.com/embed/gCWtkvDQ2ZI" (Some "youtube")
               ]
               []))) }}

       The approach I took in explaining Unison in the The Strange Loop talk
       was to focus on how the core idea of content-addressed code (explained
       in the talk) leads to a host of nice benefits, almost for free:

       * No builds, easy renames, test caching, and an overall better
         experience for codebase management
       * No dependency conflicts
       * Typed durable storage
       * A better model for distributed execution and transparent code
         deployment
       * ... and I could have kept going! My favorite additional benefits that
         I didn't cover are having structured refactoring sessions rather than
         long lists of compile errors, and having a codebase that is always
         runnable - never broken.

       Content-addressed code is one of those essential, simple ideas that
       feels like it ought to become ubiquitous in languages of the future.
       Even though it might seem elementary, it's also a fundamental change
       that affects almost everything about the developer experience. When
       Unison started as a research project based on this core idea, there were
       so many questions - things like
       [if you can't ever modify a definition, only introduce new ones, how do
       you refactor or update a codebase?](https://twitter.com/unisonweb/status/1173942969726054401)
       What has been surprising and cool is that all the questions around "how
       do you do X in the Unison worldview" continue to have answers, and these
       answers often make MORE sense than what is being done currently. Just by
       thinking through things with an open mind you can uncover an entirely
       consistent alternate reality of how programming could work, and it has
       been there the whole time just waiting to be discovered. That's been a
       lot of fun!

    ## Working towards our next release

       In the months leading up to Strange Loop and following the conference,
       we've been focused on filling in some gaps in the developer experience.
       Some things we've already done:

       * You can view the history of your codebase (the `history` command).
       * You can move around in that history (''undo'', `reflog`, and
         `reset-root` commands).
       * You can run `IO` programs without needing to add definitions to the
         codebase first, and you can run scripts that do `IO`
       * Literate Unison transcripts, for producing tutorial style
         documentation. For instance, much of [the docs site](/docs) could be
         moved over to be generated via the transcript runner, and we're also
         using these transcripts internally for integration testing.

       Things we plan on getting done for our next major release:

       * Support for authoring API documentation
       * A workflow for pull requests and code reviews
       * A workflow for publishing and using Unison libraries
       * A much better algorithm for refactoring types, which avoids manual
         propagation of edits
       * Bugfixes and general polish - thank you to our alpha testers for
         uncovering and reporting issues, we will be cranking through those.

       At that point the developer experience of using Unison will hopefully be
       pretty good - without major gaps, and anyone will be able to write and
       share Unison code without issue.

    ## In progress: an ecosystem-wide code viewer with click-through to
    definition abilities

       There's a cool project in the works that I wanted to mention here.

       One downside of the Unison codebase not just being a collection of text
       files is that we don't get to use rudimentary text-based tools to view
       that code. I prefer to see this as a feature, though, in that it creates
       a bit of a vacuum which can be filled by something that is
       __way better__ than the text based tool.

       Mitchell Rosen, Elliot Wu,
       [and friends](https://github.com/unisonweb/elm-browser/graphs/contributors)
       have started on a
       [codebase browser for Unison](https://github.com/unisonweb/elm-browser)
       which we are planning on hosting here at unisonweb.org/browse when it's
       a little further along. The idea is that you can hyperlink to any Unison
       definition, in any Git repo, and render that definition nicely with
       hyperlinks to all its dependencies. And rather than this being a build
       artifact that every library author must maintain and keep up to date,
       it's something that Just Works for all publicly hosted Unison code,
       without any action needed by library authors! It works by reading the
       underlying codebase format which has all the semantic information needed
       for this to be possible.

       I am very excited for this to come online. Kudos to the team for putting
       this together.

    ## Wrapping up

       We will try to post updates more regularly than once every 6 months. 😀
       In addition to this blog, feel free to come by the
       [Unison Slack](/community), which is a friendly spot to ask questions if
       you’re trying out Unison. Besides
       [the project on GitHub](https://github.com/unisonweb/unison), the
       #contrib channel is a good spot to follow along with Unison's
       development.

       One more thing: Arya and I will be at
       [Scale By the Bay](https://sched.co/RoSk) in a month, giving a talk on
       Unison.

       That's all for now. 🌻

       __Thanks to all contributors to this post: Rebecca Mark, Noah Haasis,
       Rúnar Bjarnason, and Arya Irani__
  }}

blog.howToRefactorACodebaseWithoutEverBreakingIt.index : Doc
blog.howToRefactorACodebaseWithoutEverBreakingIt.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "At Scale By the Bay 2019 we gave a talk on Unison's unique approach to refactoring. This post gives a brief overview of how it works."
      )
    , ("date", "2019-11-26")
    , ("categories", "news")
    , ("authors", "paul-chiusano")
    , ("featuredImage", "/assets/thing10.svg")
    ] }}

  # How to refactor a codebase without ever breaking it

    At
    [Scale By the Bay this month](https://www.youtube.com/watch?v=IvENPX0MAZ4)
    we gave a talk on Unison's unique approach to refactoring. Unison takes a
    different approach to refactoring and updating code: rather than modifying
    definititons in place, which generates lots of (often misleading) compile
    errors and prevents you from running or writing other code, Unison
    refactoring is a structured process whereby a new, compiling version of the
    code is built up incrementally off to the side. We like this process much
    better and it has significant benefits:

    * A Unison codebase is always runnable and never broken, even when in the
      middle of a refactoring.
    * There's no need to "upgrade your whole codebase" just to be able to test
      out or play with a code change within some smaller context.

    If you're interested in learning more about this, see
    [the SBTB talk](https://www.youtube.com/watch?v=IvENPX0MAZ4) and also check
    out the newly added [docs on refactoring](/docs/refactoring). The
    documentation goes through a longer worked example.

    One very common refactoring which Unison makes quite easy is updating a
    pure function to one that uses abilities like `IO`. For those who have used
    Scala or Haskell, you might have bad memories of tedious refactoring
    converting pure code to monadic, which involves switching from pure to
    monadic syntax and updating a bunch of type signatures, often all along an
    entire dependency chain. It's not very fun. 😬 In Unison, this work just
    vanishes and ability requirement changes can be propagated automatically.
    See [the docs to learn more about this](/docs/refactoring).
  }}

blog.introducingContributions.index : Doc
blog.introducingContributions.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "We're excited to announce that \"pull requests\" are finally live! They are enabled for all projects across Unison Share. \"Contributions,\" as we've chosen to call them, serve as the main point of collaboration for Unison projects. They are how you'd present your work to project maintainers for review, approval, and merging."
      )
    , ("date", "2023-11-20")
    , ("authors", "hojberg")
    , ("categories", "announcements")
    , ( "featuredImage"
      , "/assets/feed/introducingContributions/contributions.svg"
      )
    , ("status", "published")
    ] }}

  # Introducing Contributions

    We're excited to announce that "pull requests" are finally live! They are
    enabled for all projects across Unison Share. "Contributions," as we've
    chosen to call them, serve as the main point of collaboration for Unison
    projects. They are how you'd present your work to project maintainers for
    review, approval, and merging.

    Clicking the "contributions" tab in the project navigation will show you
    all contributions. Here, you can view the details of a contribution or
    submit a new one.

    {{
    Image
      {{
      List of contributions for a project
      }}
      {{
      /assets/feed/introducingContributions/contributions-list.png
      }}
      None }}

    Submitting a contribution allows you to select your contributor branch
    (these are created when cloning a project and creating a branch for your
    new work) and a target branch.

    {{
    Image
      {{
      Contribution submission modal
      }}
      {{
      /assets/feed/introducingContributions/contributions-modal.png
      }}
      None }}

    {{
    docAside
      {{
      Checkout the
      [licensing docs](https://www.unison-lang.org/learn/tooling/author-license/)
      for how to add a license to your project.
      }} }}

    We've updated our
    [Terms of Service](https://share.unison-lang.org/terms-of-service) to
    include a note about the interplay of contributions and the project's
    license.

    The contribution feature set is in its nascency right now. We wanted to get
    something in users' hands quickly since there wasn't any natural way to
    interact on contributions. We're working hard to add support for comments,
    diffs, and merging—structural diffs are something we're incredibly excited
    to explore. Be on the lookout for these improvements shortly.

    We hope this alleviates some of the collaboration pain points. Go forth,
    contribute, and collaborate 🎉!
  }}

blog.itsTimeToRethinkCloudPricing.index : Doc
blog.itsTimeToRethinkCloudPricing.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Cloud pricing has gotten complicated, and this doesn't serve the needs of most users. What does? Platforms with simple, predictable pricing, and good developer productivity."
      )
    , ("date", "2024-02-07")
    , ("authors", "paul-chiusano")
    , ("categories", "cloud")
    , ("featuredImage", "/assets/unison-services-preview.svg")
    , ("status", "published")
    ] }}

  # It's time to rethink complicated cloud pricing

    **Cloud pricing has gotten complicated, and this doesn't serve the needs of
    most users. What does? Platforms with simple, predictable pricing, and good
    developer productivity.**

    Right now, if you're using any of the major cloud providers, you generally
    need a pricing calculator to attempt estimation of what your costs will be.
    But good luck with this exercise, because the pricing schemes are in terms
    of such oddly granular units that you often have little idea what numbers
    to punch in. ("How the heck am I supposed to know what my 'duration of peak
    read activity' will be?? I'm trying to get things done here, not predict
    the weather six weeks from now.")

    Making matters worse, the default billing relationship with providers like
    AWS is unfortunately that you write them a blank check and hope that a bug
    in your code or DDOS attempt on your service doesn't bankrupt your company
    or send you groveling for a discount on your bill. To work around this, a
    recommended practice when using any sort of elastic cloud resources is to
    set up "billing alerts" to notify you when you're in the process of racking
    up an unexpected mile high cloud bill. So that's… something?

    The setup doesn't serve the needs of most companies, for a couple reasons:

    * First,
      **[most companies spend far more on developer compensation than on their
      cloud bill]({developerProductivityReallyMatters.index}).** Hyper-granular
      pricing that in theory allows optimizing your costs to shave some
      percentage points off your bill just isn't worth it for many orgs. It's
      time-consuming and complicated (often requiring external consultants),
      and when the cloud bill is dwarfed by other factors, time and energy are
      better spent elsewhere.
    * Second, simplicity and predictability of costs are valuable. When the
      cloud bill and pricing is too complicated to predict and can fluctuate
      wildly based on access patterns and usage, an org has no choice but to
      reserve capital to cover such uncertainty. This is inefficient and makes
      planning and budgeting more difficult. Who wants that?

    On this second point, the cloud providers are in the best position to offer
    greater predictability, since their costs are aggregated over all their
    customers and they can select prices that reflect these average costs. So
    why **don't** AWS and friends offer more reasonable pricing? They certainly
    could, but they also have so much market power that they aren't really
    forced to innovate here. Many customers don't like this status quo, but
    they grudgingly accept it.

    ## What we're doing

       For Unison Cloud, we have simple prices
       [that fit on a notecard](https://unison.cloud#pricing). We don't pass
       the bizarrely complicated pricing structure of infra providers on to our
       customers, since most companies don't want or need that. They want
       simple and predictable pricing, and good productivity. For a larger
       enterprise deal, we're of course happy to negotiate a more granular
       pricing scheme (and we can suggest some options), as long as you aren't
       asking us to sell you $1 at a 20% discount. If you do need something
       custom, please get in touch.

       To keep our costs under control, we make use of rate limiting so one
       user can't monopolize our resources or render an entire service
       unprofitable. But there are a range of limits which still allow us to
       operate profitably, and for bigger customers looking to optimize their
       spending, we're again happy to work out some custom deal.

       This makes a lot more sense to us than having a complicated default
       pricing scheme that only serves the needs of the 1%. Big accounts are
       likely to want a custom deal anyway for their unique needs, so why not
       keep the default prices simple and leave the complexity for custom
       deals? Everybody wins.

       Besides keeping pricing simple, we are actually
       [serious about improving developer productivity](https://unison.cloud/our-approach).
       On Unison Cloud, there's no packaging or building containers, no
       boilerplate talking between services, no tedious code getting data
       stashed in durable storage and read back later, and lots more. We think
       the cloud should be simple and delightful to use, and we're making it
       happen.

       Sound good? [Join us.](https://unison.cloud)
  }}

blog.jitAnnounce.index : Doc
blog.jitAnnounce.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Dan Doel summarizes the decision making process and progress towards native code compilation for Unison."
      )
    , ("date", "2022-03-28")
    , ("authors", "Dan Doel")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing15.svg")
    ] }}

  # JIT compilation is coming to Unison: an early progress report

    In the past couple weeks, I've been working on a new method of compiling
    unison programs to native code. Unison already has a way of
    [packaging a standalone program](https://www.unison-lang.org/learn/at-a-glance/#hello-world)
    into a binary file that starts up very quickly, but that still uses the
    same interpreter written in Haskell. While the interpreter is written to be
    reasonably efficient given optimized intermediate code, unfortunately there
    hasn't been an opportunity to spend a significant amount of time on
    optimizations that would realize its full potential. Also, even in the best
    case, an interpreter will always have significant overhead compared to
    native code.

    Thus, compiling to native code seems like an inevitable step. There are
    several considerations that would make a target more or less
    suitable/convenient:

    1. The compilation has to have the ability to work just-in-time. It's okay
       to be able to precompile binaries from known code, but one of the
       primary uses we have for the standalone binaries right now is to
       implement a server that evaluates unison code sent to it from another
       environment. That code is not known ahead of time; it is serialized and
       sent from the client, and needs to be deserialized, compiled and
       executed on the server.
    2. Tail calls need to be handled properly. They’re
       [a useful feature in any language](https://eighty-twenty.org/2011/10/01/oo-tail-calls)
       but in Unison they’re also the only mechanism for writing loops.
    3. Ideally, the target would support delimited continuations as an
       implementation of abilities. There are ways of implementing algebraic
       effects without delimited continuations, but continuations are a better
       match (I'll explain further on).
    4. It would be advantageous if the target already had a reasonable
       implementation of various low level compilation details. Unison isn't
       really novel in ways that would require a specialized garbage collector
       or native code generator, so it would be good if we can avoid needing to
       implement these things from scratch.
    5. The runtime should be capable of doing some relatively sophisticated
       things. Right now Unison wraps features of GHC's runtime, like
       lightweight threads with asynchronous I/O, and software transactional
       memory. Ideally it wouldn't be necessary to completely reimplement these
       features.

    Based on these considerations, we decided that a
    [Chez Scheme](https://cisco.github.io/ChezScheme/) backend was a promising
    direction. Scheme and Lisp in general are well known for supporting dynamic
    code loading features, and well behaved tail calls are one of the defining
    features of Scheme. Continuations are also heavily associated with scheme,
    so it's likely that most implementations would be well equipped in that
    area, too. Since it's meant to be usable as a functional language in its
    own right, it has garbage collection and reasonable library capabilities.
    Moreover it seems to be fairly well equipped as far as generating code for
    functional languages goes.

    [Jared Forsyth](https://jaredforsyth.com/) did some early prototyping of a
    compilation to Scheme pipeline and was getting some nice results compiling
    pure code, and that really inspired us to look more closely at Scheme as a
    serious target. We also knew that the rewrite of
    [the Idris language](https://www.idris-lang.org/) had initially based its
    backend on Chez (although I think it has several backends again at this
    point). But when researching, I also discovered that
    [Racket](https://racket-lang.org/) has been moving toward
    [replacing its backend](https://www.cs.utah.edu/plt/publications/icfp19-rddkmstz.pdf)
    with Chez as well. The Racket report specifically suggests that Chez could
    be a better target for functional languages than a lot of other common
    compiler backends, since many of the latter have limitations based around
    the needs of more traditional imperative languages.

    {{
    docCallout
      (Some {{ 🤔 }})
      {{
      **What about LLVM?**

      For a high-level functional language like Unison, LLVM is pretty
      low-level as a compilation target. It provides something like a platform
      independent assembly language, saving you from needing to write a
      register allocator and native code generator. LLVM can also support tail
      calls provided you use one of the
      [right calling conventions](https://llvm.org/docs/CodeGenerator.html#tail-call-optimization).

      It doesn't provide any runtime services out of the box, such as a garbage
      collector, continuations and/or delimited continuations, lightweight
      threads, async I/O, etc, which means it can be a considerable amount of
      work to build a serious LLVM-based JIT with these features.
      }} }}

    Probably the most significant gap in the capabilities of the Chez runtime
    is software transactional memory. Unsurprisingly (since it's very difficult
    to use correctly without an effect checking system), Chez doesn't implement
    it. Glancing at
    [the original STM paper for GHC](https://www.microsoft.com/en-us/research/publication/composable-memory-transactions/),
    the implementation they describe doesn't sound __too__ difficult, and looks
    doable using the concurrency primitives present in Chez.

    ## What's working so far

       So far, I've written (part of) a compiler from one of the existing
       intermediate code representations to Scheme code. The intermediate
       representation uses
       [A-normal form](https://en.wikipedia.org/wiki/A-normal_form) with nested
       pattern matching desugared to single level matching and all local
       function definitions floated to an outer-most recursive let block for
       each top level definition. This level of normalization is not all
       completely necessary for compilation to Scheme, but it is the format
       we're already using to send code between Unison instances, so it would
       need to be handled anyway.

       I started by writing the Scheme emitter in Haskell using the existing
       data structures there. But after some discussion, Paul and I realized
       that in order for the dynamic loading of Unison code to work in a
       program compiled to Scheme, it'd be necessary to have the compilation
       from Unison to Scheme available in Scheme itself. One option is to just
       write it directly in Scheme, but another option is to write it in
       Unison, which is then compiled to Scheme. This is what I've done most
       recently: I have a version of the intermediate data structures defined
       as Unison data types, along with ways of parsing the binary format for
       code interchange into those Unison types, and a compiler that emits
       Scheme definitions from those. Right now it is rather limited, only
       supporting pure code and a few arithmetic builtins, but it is possible
       to compile those Unison definitions to Scheme just by running a Unison
       program. For instance, if we define:

       ``` unison
       codeTest : '{IO,Exception} ()
       codeTest _ = printScheme (termLink addMain)
       ```

       And execute `run codeTest` at the prompt, we get output ending with:

       ``` scheme
       (define-unison
         (ref-3YXYAR7AJAIUWLOQDTCM4VL3FYDCHJ x1)
         (letrec-unison
           ([(x0 x1)
             (let* ([x2 10000000]
                    [x3 (identity x2)])
               (ref-M5Y65PHZ3GWHMCUMIJ3LGLBLKPSYMA x3))])
           (let* ([x2 100]
                  [x3 (identity x2)]
                  [x4 (x0)])
             (ref-ZQRWH24DGQ437B72KCOZXGRZAJJW2U x3 x4))))

       (ref-3YXYAR7AJAIUWLOQDTCM4VL3FYDCHJ #f)
       ```

       The full Unison API for code loading requires a fair bit more than just
       this sort of code generation, but it's an important component.
       Unfortunately I haven't yet filled in enough primitive operations to be
       able to compile the compiler itself to Scheme. The above code comes from
       a nested loop that prints the sum of the numbers from 0 to 10 million
       100 times. Using the compiled scheme code is around **470x faster** than
       our current interpreter, at least for this simple arithmetic loop.

       While we could produce much better intermediate code for our interpreter
       by applying standard optimizations (such as worker/wrapper
       transformations, inlining, etc), Scheme is providing great performance
       with our more naive intermediate code, presumably because
       [it already does](https://twitter.com/edwinbrady/status/1389212471513190401)
       many of these optimizations itself.

    ## Implementing abilities

       One major piece currently missing is the implementation of the
       primitives for abilities. As alluded to above, the way abilities work in
       the intermediate code and interpreter is based on delimited
       continuations. This section walks through some of the technical details
       of this but feel free to skip ahead.

       Scheme is well known for its support of continuations. However, the sort
       in the (R6RS) Scheme standard are not the ones we want. They are based
       around the operation `call-with-current-continuation`, which I'll
       abbreviate to `call/cc` going forward. The idea is that if we write:

       ``` scheme
       (call/cc (lambda (k) ...))
       ```

       Then the lambda expression gets called with a special function that has
       captured the control flow context leading up to that point in the
       program. The lambda expression may return normally, in which case its
       result is supplied to that context. However, calling `k` __also__ causes
       the program to act like the argument to `k` was returned from the lambda
       expression. This is true even if `k` escapes the scope of the `call/cc`
       block, which means that it has the power to __replace__ the entire
       remaining control flow context anywhere in the program.

       An ability handler clearly involves a continuation as well. A pattern
       match implementing one looks something like:

       ``` unison
       { E x y z -> k } -> ...
       ```

       `k` being the continuation again. However, these continuations behave
       much more like functions. Calling `k` does not completely replace the
       execution context, but adds to it like a normal function. It's possible
       that `k` would have captured some `Exception` effects that __would__
       jump to a top-level handler, but this is also no different from
       functions, and those effects can be handled so that they don't escape.

       This is where __delimited__ continuations come in. They are instead
       based around a __pair__ of operations, the simplest of which are `shift`
       and `reset`. `shift` is similar to `call/cc`, and a use would look
       something like:

       ``` scheme
       (shift (lambda (k) ...))
       ```

       There are three primary differences:

       1. `shift` only captures into `k` a portion of the control flow context,
          limited by the nearest enclosing `reset`.
       2. `k` actually behaves like a function. To know what `(k x)` does,
          imagine if `x` were returned from the original `(shift ...)`
          expression, and trace the execution until you find the value `y` that
          would be returned from the enclosing `(reset ...)` expression. Then
          `(k x)` evaluates to `y`. {{ Folded true _aside1desc _aside1 }}

       3. `shift` actually removes the captured portion in `k` from the control
          flow context. So, returning directly from the lambda expression
          yields a value directly to the enclosing `reset`.

       This is essentially how ability handlers work, too. The continuation
       captured in an ability match only captures a portion of the computation
       delimited by the associated `handle` block. So, `handle` blocks
       correspond to the `reset` operation. The big difference is that we also
       associate the ability matching, and thus the uses of `shift` with the
       `handle` block.

       However, the intermediate code actually converts this to something more
       like the Scheme presentation. Ability matching is compiled to code that
       uses an operation like `shift`, so that handled ability requests can
       actually be implemented by calls to the appropriate generated code. Then
       references to the implementation are threaded around, and requests are
       just function calls. So the intermediate code is already ideally suited
       for a runtime that directly supports delimited continuations.

       There are theoretical results about implementing delimited continuations
       using `call/cc` and a global mutable variable. I believe the original is
       in Filinski's
       [Representing Monads](https://dl.acm.org/doi/10.1145/174675.178047).
       Essentially the Scheme implementation there is:

       ``` scheme
       (define mk (lambda (x) (raise "fell off end")))

       (define-syntax reset
         (syntax-rules ()
           [(reset e ...)
            (call/cc
              (lambda (k)
                (let ([ok mk])
                  (set! mk (lambda (r) (set! mk ok) (k r)))
                  (let ([v (begin e ...)]) (mk v)))))]))

       (define-syntax shift
         (syntax-rules ()
           [(shift f)
            (call/cc
              (lambda (sk)
                (let* ([k (lambda (x) (reset (sk x)))]
                       [v (f k)])
                  (mk v))))]))
       ```

       However, there seem to be some issues with doing this.
       [Oleg Kiselyov's](https://okmij.org/ftp/continuations/against-callcc.html)
       page on the downsides of `call/cc` lists some. The most significant
       problem seems to be that the correctness of the result hinges on every
       other side effect being subsequently implemented by reduction to `shift`
       and `reset`. However, this ranges from expensive to impossible. Even in
       Unison, where declared abilities would reduce somehow to the delimited
       continuations, it is desirable to have some wired in pseudo abilities
       that implement things more efficiently. Encoding every mutable reference
       cell using `shift` and `reset`, which are themselves encoded using
       `call/cc` and a single global variable using closures is a very
       expensive strategy. And there are also built-in side effects like I/O
       and threading that are important for us to use.

       {{ docTooltip _aside2desc _aside2 }} But it seems like what is really
       needed is a careful, system-specific implementation of delimited
       continuations that definitely interacts well with other parts of the
       system. Luckily, it should be possible to get this for Chez. As
       mentioned, Racket now has a Chez backend, and the former has built-in
       support for delimited continuations.

       Technically, Racket uses its own forked copy of Chez, and the upstream
       version does not have all the features used for Racket's continuations
       implementation. There is a pull request against the upstream to add the
       feature, but it seems to be missing someone to fix some conflicts. I'm
       uncertain how necessary the feature is just for implementing delimited
       continuations (Racket uses it for other features as well). We might have
       to help get the pull request merged, or try using the Racket fork of
       Chez for our compilation in the end.

    ## Conclusion

       There's still quite a bit of work to be done, but I think even some of
       the early results so far are promising. The arithmetic examples
       mentioned above are much faster than the existing system, and that is on
       code actually generated from Unison definitions, not hand-crafted output
       that we could hypothetically generate given enough optimizations.

       I think the data structures I've ported to Unison may also have other
       uses than this compiler, as well.
       [Paul recently demoed a debugging ability](https://twitter.com/pchiusano/status/1502760429466042368)
       he wrote completely in Unison. While discussing it with him, it occurred
       to me that a lot of the runtime introspection capabilities I've
       implemented as part of the JIT pipeline could also be useful for
       providing an even richer debugging experience, with access to all local
       variables and other niceties. That's something to investigate another
       time, though.

       Stay tuned for more progress updates on this in the future!
  }}

blog.jitAnnounce.prompt : '{e, Control r} r ->{e} r
blog.jitAnnounce.prompt e =
  handle e()
  with cases
    { x }                      -> x
    { Control.control e -> k } -> e k

blog.jitAnnounce.reset : '{e, Shift r} r ->{e} r
blog.jitAnnounce.reset e =
  h = cases
    { x }            -> x
    { shift e -> k } -> e (x -> (handle k x with h))
  handle e() with h

blog.jitAnnounce._aside1 : Doc
blog.jitAnnounce._aside1 =
  use Nat +
  use jitAnnounce reset
  {{
  Consider the expression:

  '''
        (+ 1 2
          (reset
            (+ 1
               2
               (shift (lambda (k) (k (k 5))))
               3)))

  '''

  This evaluates to `20`, because the `k` captured is essentially the inner
  addition, meaning it's equivalent to:

  '''
        (let ((f (lambda (x) (+ 1 2 x 3))))
          (+ 1 2 (f (f 5))))

  '''

  If the `shift` is replaced with `call/cc` (removing the redundant `reset`),
  then the result is `14`, because it is equivalent to:

  '''
        (+ 1 2 (+ 1 2 5 3))

  '''

  If you want, you can also try using delimited continuations in Unison.
  `shift` is the effect part, introduced by the ability:

      @source{type Shift}

  `reset` is the handler part, definable via:

      @source{reset}

  Then we can try the above example:

  ```
  v = 1 + 2 + (reset do 1 + 2 + shift (k -> k (k 5)) + 3)
  v
  ```

  One thing to notice is that these operations use a "deep" handler. Shallow
  handlers actually correspond more closely to another pair of operations known
  as `control` (similar to `shift`) and `prompt` (similar to `reset`). A Unison
  version of these might be defined something like:

      @source{type Control}

      @source{prompt}

  Although I haven't experimented much with them, so I'm not sure how precisely
  they match the theoretical definitions.
  }}

blog.jitAnnounce._aside1desc : Doc
blog.jitAnnounce._aside1desc = {{ Here is a concrete example. }}

blog.jitAnnounce._aside2 : Doc
blog.jitAnnounce._aside2 =
  {{
  I've at least found
  [A robust implementation of delimited control](http://ix.cs.uoregon.edu/~ariola/tpdc11.pdf),
  which explains how to fix some of the space leaks with the `call/cc` version.
  However:

  1. The alternate implementation did not seem to fix the space leak from
     Oleg's example, at least when I ported it to Chez.
  2. It's not clear if it solves other problems with the `call/cc` encoding.
  }}

blog.jitAnnounce._aside2desc : Doc
blog.jitAnnounce._aside2desc =
  {{ There may be better 'portable' encodings than the one above. }}

blog.latexDocSupport.index : Doc
blog.latexDocSupport.index =
  use index _mermaid1
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The documentation experience in Unison just gained an extra dimension with support for mermaid diagrams and mathematical typesetting. Learn more about these new features and how to use them."
      )
    , ("date", "2022-12-16")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # Unison docs support enriched diagram rendering

    There are two new documentation features that have landed for
    [Unison Share](https://share.unison-lang.org/), support for
    [mermaid diagrams](https://mermaid-js.github.io/mermaid/intro/) and
    [LaTeX](https://www.latex-project.org/).

    {{
    docAside
      {{
      These features will be available for the
      [localUI](https://www.unison-lang.org/learn/tooling/local-codebase-u-i/)
      in a forthcoming release of the UCM.
      }} }}

    First, let's look at mermaid diagrams. Mermaid diagrams are textual
    representations for diagrams written in a markdown-inspired syntax. A
    variety of diagram types are supported, including sequence diagrams,
    flowcharts, state diagrams and gant charts. The following figure for the
    TCP 3-way handshake has been written in a ''``` mermaid'' block.

        @source{_mermaid1}

    The diagram type is indicated as the first line of the block. You can learn
    more about the
    [syntax for supported diagram types here](https://mermaid-js.github.io/mermaid/intro/).

    Unison Share will render this diagram as:

    {{ _mermaid1 }}

    {{
    docAside
      {{
      Alternatively, check out
      [Alvaro Carrasco's](https://share.unison-lang.org/@alvaroc1)
      abilities-based
      [mermaid library](https://share.unison-lang.org/@alvaroc1/p/code/latest/namespaces/public/mermaid/main)
      for writing diagrams using Unison syntax. 🧜‍♀️
      }} }}

    Next, something for the mathematicians in the room. The {type Doc} format
    will also render LaTeX, which is commonly used in the technical or
    scientific communities for typsetting content that would otherwise be
    frustrating to express in a regular word processor. Imagine opening up your
    rich text editor to write the following:

    {{ _ex1 }}

    That would be a nightmare! Instead, you can write the following in LaTeX,
    like so:

        @source{_ex1}

    ## What's going on here?

       When writing a Unison {type Doc}, much like when writing
       [standard markdown](https://www.markdownguide.org/extended-syntax/#fenced-code-blocks),
       the triple backtick codeblock optionally takes a language argument. If
       the UI sees `mermaid`, it will use the
       [mermaid.js](https://mermaid-js.github.io/mermaid/#/) library to render
       the diagram, and if it sees `latex`, it will use the
       [Katex](https://katex.org/) library to transform the given codeblock
       into its typeset form. The Katex library supports rendering the TeX
       dialect of LaTeX. A full summary of the supported symbols and functions
       [can be found here](https://katex.org/docs/support_table.html).

       We'd like to share our immense gratitude to Kento Okura and Simon
       Højberg for their work on this feature. Thanks for pushing the Doc
       format forward into new domains!

    ## Give it a try!

       Here's a challenge for you: given
       [Alvaro's Unison mermaid diagram library](https://share.unison-lang.org/@alvaroc1/p/code/latest/namespaces/public/mermaid/main),
       and the programmatic nature of Docs, can you write a program where the
       interactions between two entities in a Unison program are
       self-documenting? For example, you could render when a client calls a
       server or write a tool for showing how many times an algorithm passes
       through a basic collection. It's possible to programmatically create a
       fenced codeblock entity in native Unison with the {CodeBlock} data
       constructor. It looks something like
       ``CodeBlock "mermaid" (Word textualRepresentationOfDiagram)``. Check out
       this static example from Unison teammate Cody Allen
       [here on Unison Share](https://share.unison-lang.org/@ceedubs/p/code/latest/namespaces/public/tmp/mermaid_experiment/;/terms/examples/sequence/asDoc)
       for inspiration.

       As for the LaTeX functionality, while not everyone is looking for their
       Good Will Hunting moment, you might be interested in the basic
       commutative diagram support that the docs now provide. In anticipation
       of the many functional programming blogs written in the {type Doc}
       format, we've included a few useful symbols below!

           @source{_composition}

       {{ _composition }}

       {{
       docAside
         {{
         To use the following, you'll need to set the environment in the LaTeX
         codeblock with "{CD}" to get the right rendering.
         }} }}

       Basic arrows:

           @source{_arrows}

       {{ _arrows }}

       Labled arrows:

           @source{_labeledArrows}

       {{ _labeledArrows }}

       Adding vertical connections:

           @source{_vertical}

       {{ _vertical }}

       {{
       docAside
         {{
         Katex's support of commutative diagrams is currently limited to
         right-angles. Learn more about
         [the underlying specification here](https://www.jmilne.org/not/Mamscd.pdf).
         }} }}

       We hope to see your architecture diagrams, database schemas,
       mathematical proofs, physics notes, and other wild inventions on Unison
       Share soon!
  }}

blog.latexDocSupport.index._arrows : Doc
blog.latexDocSupport.index._arrows =
  {{
  ``` latex
  \begin{CD}
   @<<<

   @AAA

   @VVV

   @.

   @>>>

   @=

   @|
  \end{CD}
  ```
  }}

blog.latexDocSupport.index._composition : Doc
blog.latexDocSupport.index._composition =
  {{
  ``` latex
  (a \circ b)
  ```
  }}

blog.latexDocSupport.index._ex1 : Doc
blog.latexDocSupport.index._ex1 =
  {{
  ``` latex
  f(\relax{x}) = \int_{-\infty}^\infty
   \hat{f}(\xi)\,e^{2 \pi i \xi x}
   \,d\xi
  ```
  }}

blog.latexDocSupport.index._ex2 : Doc
blog.latexDocSupport.index._ex2 =
  {{
  ``` latex
  i \hbar \frac{\partial}{\partial t}\Psi(\mathbf{r},t) = \hat H \Psi(\mathbf{r},t)
  ```
  }}

blog.latexDocSupport.index._ex3 : Doc
blog.latexDocSupport.index._ex3 =
  {{
  ``` latex
  \input
  {commutative-diagrams}
  \codi

  \obj { A & B \\ };
  \mor A f:-> B;
  \mor B f:-> C;
  \mor A [f:-> dashed ] C;

  \endcodi
  \bye
  ```
  }}

blog.latexDocSupport.index._labeledArrows : Doc
blog.latexDocSupport.index._labeledArrows =
  {{
  ``` latex
  \begin{CD}
    \text{A} @>label>> \text{B}
  \end{CD}
  ```
  }}

blog.latexDocSupport.index._quantifiers : Doc
blog.latexDocSupport.index._quantifiers =
  {{
  ``` latex
  Exists: \exists a:a>0$
  For all: \forall a:a>0$
  ```
  }}

blog.latexDocSupport.index._vertical : Doc
blog.latexDocSupport.index._vertical =
  {{
  ``` latex
  \begin{CD}
  a @>F>> Fa \\
  @VgVV @VVFgV \\
  b @>F>> Fb
  \end{CD}
  ```
  }}

blog.longUpdateMergeProcess.index : Doc
blog.longUpdateMergeProcess.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "It's time for an update on our update process! We know it has been a challenging aspect of working in Unison, so here's a look at how we're improving the process for updating and merging code. Changes include kind-checking, automatic branch creation for sandboxed merges, and a much simpler workflow overall."
      )
    , ("date", "2023-10-18")
    , ("authors", "rebecca-mark")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing5.svg")
    , ("status", "draft")
    ] }}

  # A retrospective and look forward at the Unison update process

    The Unison team is improving a rough spot in the Unison workflow: the
    process for programmatically updating or merging your code. Based on
    Unison’s unique language properties, we designed some workflows to support
    developers when they wanted to apply changes to their types or terms. When
    a developer updated their code, Unison could either automatically apply the
    changes or prompt the user for more intervention.

    {{
    docAside
      {{
      Some context for the uninitiated: in Unison, terms and types are not just
      stored as plain text on the file system, instead they're stored as a
      hashed representation of their AST; that means when one function depends
      upon another, their relationship can be programmatically tracked in a
      Unison codebase.
      }} }}

    In the simple case, it was great! Internal changes in functions could
    auto-propagate to their dependents and you could rest assured that your
    codebase was kept in a non-broken and up-to-date state without hunting
    through your files for all the places where the function was called.
    However, most updates to a program of any size or complexity involve
    changing the implementation of types, adding or subtracting function
    parameters, or other non-type preserving changes. This kicked off an update
    process that was riddled with footguns, and frequently lead many a Unison
    dev to feel like this:

    {{
    Image
      {{
      A GIF of a person putting their computer in a dumpster
      }}
      {{
      /assets/feed/update-merge-process/frustration.gif
      }}
      (Some
        {{
        Actual footage of someone trying to edit a cycle of mutually recursive
        terms.
        }}) }}

    ## Some self-reflection on what was rough

       While the technical groundwork was there for performing operations like
       code merges, updates, or dependency upgrades in a guided, syntactically
       aware fashion; the experience left something to be desired. Yes, true to
       our promise, your code would “work” in that unresolved code conflicts
       could coexist or cryptically named hash references would resolve to
       their implementations, but the maintainability of your programs should
       be the priority, and we knew we could improve in that area. In
       redesigning the update and merge workflows, we first had to reflect on
       the question "what was going amiss?" Broadly, here are some of pain
       points we experienced:

       ### It contained non-intuitive, finicky steps

           * If you updated a type or term in place, you could accidentally
             cause hashes to appear instead of the user-friendly name. Our
             recommended workflow of creating a `fork` or `branch` before
             making non-type-preserving changes was an easy to miss extra step.
           * People were not sure when to run the `todo` command and we had no
             indication in the console that there were todo's to take care of.
             Many of us would happily work with our codebase containing
             conflicts and then wonder "huh, where did this hash suffixed term
             come from?"
           * The `todo` workflow would suggest an order for resolving conflicts
             that was sometimes mysterious. Sometimes your `todos` would lead
             you around in a circle! 😵‍💫

       ### It exposed unnecessary complicated technical details

           * Patches inspired confusion. They seemed like more of an
             implementation detail than something which should have been
             exposed to the user. Patches were meant to be a way to observe and
             potentially interact with how a function or type changes over
             time, so if you edited the implementation of a function, you'd see
             a patch entry mapping the old version to the new.

           {{
           docAside
             {{
             Some of us could see into the Matrix and manipulate patches, most
             of us could not and deleted or ignored them.
             }} }}

       ### It was missing some helpful features

           * There was no kind checking for types, so Unison would let you
             perform type substitutions that were, in fact, not valid. If you
             were in the middle of a migration from `Optional a` to
             `Either a b` and slipped up in a type signature with `Either a`,
             you could save code in a broken state.
           * We didn't have a simple experience for supporting dependencies in
             a first-class way. Users would use the `pull` and `merge` commands
             to manually perform library upgrades. We had the convention that
             the `lib` namespace was reserved, but a more specialized treatment
             of dependencies would enable tree shaking or other optimizations.

    ## Introducing the new update workflow

       The new version of the Unison programming language greatly simplifies
       things. We wanted development processes like “adding a constructor to a
       type” or “upgrading a library” to feel as easy as they are common. In
       light of this, we changed a number of things about the update process to
       address the pain points above:

       * The addition of kind checking
       * No one should have to think about patches again! Yay! They are not a
         part of the improved workflows.
       * A single, simple command for initiating a library dependency upgrade.
         (TODO check with team)

       {{
       docAside
         {{
         Thank you to the team responsible for these improvements: Arya, Chris,
         Mitchell, and Travis. We would forever be lost in the `edit frontier`
         without you! 🚀🌌
         }} }}

       {{
       docCallout
         Optional.None
         {{
         **The new workflow, at a glance**

         * User updates their codebase with changes containing
           non-type-preserving changes
         * Unison creates a branch for a sandboxed update process
         * Unison renders the impacted function's dependents and transitive
           dependents to the scratch file
         * User fixes conflicts and issues `update` command to apply changes
         * Unison merges the temporary branch back
         }} }}

       **An in depth walk-through**

       Let's walk through a sample change in this new workflow. Say we need to
       add a parameter to a function in our codebase. Our initial version is
       already saved and used elsewhere in the code so a subsequent `update`
       necessitates that its dependents do something to handle the new
       argument, for example, they can fill in a default value or continue to
       pass the argument up the call chain.

       ``` unison
       foo : Nat -> Text
       foo n =
       	Nat.toText n

       bar : Nat -> {IO, Exception}()
       bar n =
       	printLine (foo n)

       --foo changes to:

       foo : Nat -> Nat -> Text
       foo n1 n2 =
       	Nat.toText (n1 + n2)
       ```

       In the old workflow, we recommended that users create a branch or fork
       in their codebase to perform the update, but this was a detail that many
       folks simply didn't do. In the new workflow, the UCM will detect that
       this change cannot be propagated automatically and create a new branch
       for you in which the resolution will take place. This ensures that your
       updates happen in a sandboxed environment.

       ``` ucm
       myProject/main> update

       (COPY UCM MOCK OUTPUT HERE)

       myProject/updateBranch>

       (UCM MOCK OUTPUT ABOUT OPENING UP DEPENDENT TERMS HERE)
       ```

       Next, Unison will open up the dependent functions in a sensible order
       for tackling the upgrade. In your scratch file you'll see the immediate
       callers of `foo`, and then the transitive callers of `foo`, up until the
       top of the function call chain. You can make your decision about how to
       resolve the update with the additional context of the entire tree of
       possibly impacted terms. Compare this to the old workflow, in which
       you'd run `todo` after the update and then step through the changes,
       suggested by the UCM, entering `edit 1-n` for each batch.

       If your code contains mutually recursive terms, this workflow also
       ensures that you edit the components together as a cycle. Compiler
       errors and tips from the LSP integration are there to shepherd the
       process along.

       ``` unison
       foo : Nat -> Nat -> Text
       foo n1 n2 =
       	Nat.toText (n1 + n2)

       -- dependents to update

       bar : Nat -> {IO, Exception}()
       bar n =
       	printLine (foo n) -- red squiggly line appears here

       main : '{IO, Exception}()
       main = do
       	bar 5
       ```

       Once your code typechecks in the scratch file, you know your update has
       been safely managed with no surprises like hashes or more todo's. You
       can finish the process with the `update` command again and the branch
       will be merged back to its parent. (TODO confirm this with team)

       ``` ucm
       myProject/updateBranch> update
       (UCM MOCK OUTPUT)
       myProject/main>
       ```

       ### More improvements to come!

           Thank you to the Unison community members who stuck through this
           process and still
           [created an impressive suite of libraries and applications](https://share.unison-lang.org/).
           Your perseverance and feedback were instrumental in making this
           change happen. For new folks who've never written a Unison program,
           we think the improvements described here mean it's a great time to
           start. So give this new workflow a try and tell us how it goes! We
           hope to continue to build tooling and language features that bring
           more joy to the work of writing software. If that sounds like
           something you want to be a part of, come join our
           [friendly slack community](https://unison-lang.org/slack) and
           [write some Unison programs!](https://www.unison-lang.org/learn/quickstart/)

           Happy coding! 🌻
  }}

blog.m2Release.index : Doc
blog.m2Release.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "We've just put out a major new release of Unison. It includes a snazzy new UI for browsing Unison codebases, a new computable documentation format, a new faster runtime, and a new SQLite-based codebase format that substantially improves codebase performance."
      )
    , ("date", "2021-06-03")
    , ("authors", "paul-chiusano")
    , ("categories", "announcements")
    , ("featuredImage", "/assets/feed/m2-release/blog-m2.svg")
    ] }}

  # New milestone release of Unison

    Our last release was
    [M1m](https://github.com/unisonweb/unison/releases/tag/release%2FM1m) way
    back in May 2020 and a lot has been happening since then. Thanks to
    [all the contributors who helped make this release possible](https://github.com/unisonweb/unison/blob/trunk/CONTRIBUTORS.markdown).

    First, there's a snazzy new UI for browsing Unison codebases:

    {{
    Video.video
      "/assets/feed/m2-release/unison-share-demo-m2.mp4"
      "/assets/feed/m2-release/unison-share-demo-m2.png" }}

    This UI now comes embedded in UCM and a version is hosted at
    [share.unison-lang.org](http://share.unison-lang.org). If you have public
    Unison code you'd like to be browseable at
    [share.unison-lang.org](http://share.unison-lang.org), you can
    [open a PR for this file](https://github.com/unisonweb/shipwright/edit/trunk/files/initialize-codebase.sh).

    All the code shown in the UI is hyperlinked to support click through to
    definitions, and this interface will soon support find usages, rich
    rendering of documentation, and more. This excellent work was a joint
    effort by [@hojberg](https://github.com/hojberg) (designed and built the
    front end) and [@runarorama](https://github.com/runarorama) (wrote the back
    end server that provides an interface to the codebase over HTTP). There's
    still some ongoing work to improve the performance of this UI which
    [can be tracked here](https://github.com/unisonweb/unison/issues/2045).

    Besides the Codebase UI, here's what else is new:

    * There's a powerful new
      [computable documentation format](/docs/documentation) which makes it a
      joy to write deeply interlinked documentation with embedded live
      examples. Work by [@pchiusano](https://github.com/pchiusano). For now
      there's just a console renderer for docs within UCM, but the codebase UI
      will soon support doc viewing.
    * The M2 release uses a new
      [SQLite-based codebase format](https://github.com/unisonweb/unison/blob/trunk/docs/repoformats/v2.markdown)
      which is about 100x smaller on disk and uses up to 75x less RAM, with
      further performance improvements on the way. Work by
      [@aryairani](https://github.com/aryairani). Performance issues with the
      simplistic V1 codebase format were getting in the way of library
      development.
    * The Unison runtime has been rewritten: it's faster and comes with
      revamped I/O and concurrency primitives including software transactional
      memory and more. We'll be publishing docs on this soon. Work by
      [@dolio](https://github.com/dolio).
    * M2 has lots of new builtin functions, improvements to the base library,
      and various new syntax. Work by [@stew](https://github.com/stew),
      [@pchiusano](https://github.com/pchiusano),
      [@runarorama](https://github.com/runarorama) and
      [many others](https://github.com/unisonweb/unison/blob/trunk/CONTRIBUTORS.markdown).

    See [the release notes](https://github.com/unisonweb/unison/issues/1930)
    for the full details.

    You can head over to
    [unison-lang.org/learn](https://www.unison-lang.org/learn/) for
    instructions on getting started or upgrading. And come
    [say hello in the Slack](https://unisonweb.org/slack).

    ## What's next?

       There are a few events coming up: regular "office hours", a
       documentation day, and a Unison workshop at ZuriHac. See
       [the event calendar](/calendar).

       Following M2, the next major release will be a beta release which
       includes the distributed programming API and a number of improvements to
       UCM and the codebase UI. We'll be publishing a roadmap soon. After the
       beta release will be mostly bugfixes and polish before our first general
       availability release!

       🌻
  }}

blog.m4Codehosting.index : Doc
blog.m4Codehosting.index =
  use Pattern many run
  use patterns digit
  {{
  {{
  frontMatter
    [ ( "summary"
      , "We have just released a major milestone of Unison: version M4 with code hosting, self-contained namespaces, mutable and immutable arrays, and much, much more."
      )
    , ("date", "2022-07-14")
    , ("authors", "runar-bjarnason")
    , ("categories", "announcements")
    , ("featuredImage", "/assets/feed/m4-codehosting/m4-release.svg")
    ] }}

  # Announcing Unison Milestone Release 4

    We have just released a major milestone of Unison: version M4, and it's a
    big one. Here are the details on the most significant changes.

    ## Code hosting on Unison Share

       We built our own codebase hosting specifically designed for Unison, as a
       feature of [Unison Share](https://share.unison-lang.org).

       Before now, if you wanted to collaborate on a Unison codebase or share
       your code with others, you had to do so through binary files managed
       with Git. When viewing your code on e.g. GitHub, all you saw was a
       directory with a binary file in it.

       This all changes today. You can now push your Unison code directly to
       Share via the Codebase Manager, and then browse and share it in a
       beautiful interface, all gloriously hyperlinked.

       ### How to get started with Unison Share

           1. Create a new Share account at
              [share.unison-lang.org](https://share.unison-lang.org). You can
              use your GitHub account.

           2. Start `ucm` in your terminal, pointing to your Unison codebase.

           3. From `ucm`, issue `push myUsername.public.project mycode` where
              `mycode` is whatever namespace you want to push to Share, and
              `myUsername` is your Share user name (which is the same as your
              GitHub user name).

           You can now share your code with the world!

           Here's a short video of Simon pushing his code:

           {{
           docAside
             {{
             For more details on this, see
             [Simon's talk from Unison Forall in June](https://www.youtube.com/watch?v=aqLkcI_Yobc)
             }} }}

           {{
           Video.video
             "/assets/feed/m4-codehosting/m4-codehosting-demo.mov"
             "/assets/feed/m4-codehosting/m4-codehosting-demo.png" }}

       ### What will happen to the old Unison Share?

           The old Unison Share site is still available for now at
           [share-prev.unison-lang.org](share-prev.unison-lang.org), but it's
           deprecated. If you have Unison code on the old site, we encourage
           you to push it to the new Share as described above.

    ## Self-contained namespaces

       In past versions of Unison, name resolution was global for your whole
       codebase. That is, if you used a name like `foo`, Unison would look for
       things named `foo` everywhere in your codebase to figure out what hash
       you meant.

       This had a number of problems:

       1. Name lookup was slow for large codebases.
       2. If you had a lot forks of a namespace, you might end up with
          ambiguous names, and Unison would insist on overly long
          fully-qualified names to disambiguate.
       3. Namespaces implicitly depended on each other in a way that was hard
          to understand. As namespaces evolved separately, you might end up
          with code referencing hashes that no longer had names. If you pushed
          a namespace to share, but not its dependencies, you might end up with
          code on Share with hashes instead of names.

       Starting with version M4, Unison's namespaces are self-contained,
       meaning that name resolution is local to each namespace. This makes the
       Unison workflow slightly different, but it's a lot easier to understand
       in the end. Whereas before M4, you could do the following:

       1. Start up UCM.
       2. `cd` into a new namespace `foo`.
       3. Start coding with everything from your codebase in scope.

       Now you do this:

       1. Start up UCM.
       2. `cd` into a new namespace `foo`.
       3. `fork` any namespaces you want to use, and put them under `foo.lib`.
          For example, `fork .base foo.lib.base`. You can even have a namespace
          in your codebase that serves as a template, and `fork` that for each
          new project.
       4. Start coding with just the namespaces you want to use in scope.

       In future releases of Unison, we will add lots of quality-of-life
       features to make managing your namespaces and projects more ergonomic.

    ## Mutable and immutable arrays

       Unison M4 gets some new built-in types representing in-memory arrays:

       * {type mutable.Array} is a mutable boxed array.
       * {type mutable.ByteArray} is a mutable array of unboxed bytes.
       * {type data.Array} is an immutable boxed array.
       * {type data.ByteArray} is an immutable array of unboxed bytes.

       Arrays allow for efficient memory usage as well as fast random access,
       splitting, and slicing. What's more, mutable arrays are __scoped__ using
       the {type Scope} ability, which means mutable memory can't escape the
       scope in which it was allocated. For example, you cannot have a global
       mutable array, and the type system enforces this.

       See {arrays} for more information on how to use arrays.

    ## A date/time library

       There are new builtins for nanosecond-precision system clocks. For
       example:

       * {now} returns the current time, as an {type Instant}.
       * {Clock.monotonic} returns a monotonically increasing
         {type time.Duration} that is guaranteed to never go backwards (which
         can otherwise happen if the system clock is adjusted).

       The
       [`base.time`](https://share.unison-lang.org/users/unison/code/latest/namespaces/main/time)
       namespace contains a number of useful functions and data types for
       working with time and dates.

    ## Efficient regular expressions for text and binary data

       The Base library has a new type, {type Pattern}, which is a regular
       expression pattern. A {{ docExample 1 do p -> (p : Pattern Text) }} is a
       pattern that matches {type Text} input, and a {{
       docExample 1 do p -> (p : Pattern Bytes) }} is a pattern that matches
       {type Bytes}
       input.{{
       docAside
         {{
         Currently, only {type Text} patterns are supported. A future release
         will add {type Bytes} patterns.
         }}
       }}

       ```
       run (Pattern.capture (many digit)) "123abc"
       ```

       The `` ["123"] `` in the above output is a list of __captures__, and the
       `` "abc" `` is the remainder of the input after the {{
       docExample 0 do many digit }} successfully matches.

       A {type Pattern} is built up using functions like {many},
       {patterns.literal}, {charRange}, and so on, and run with either {run} or
       {isMatch}:

           @signatures{run, isMatch}

       For more information on patterns, see {type Pattern}.

    ## New keyword: do

       The `do` keyword is new syntactic sugar for {{ Code {{ 'let }} }}, which
       introduces an unevaluated block of code. For example, you can now write:

       @typecheck ```
       main : '{IO, Exception} ()
       main = do
         printLine "Greetings, earthling! 👽🪐"
         printLine "You can still use 'let if you really want."
       ```

       The pretty-printer uses `do` wherever it can, so all your existing code
       is already updated to use this new syntax.

    ## And lots more

       Those are the big changes, but there have also been a ton of bugfixes,
       performance enhancements, and various ergonomic improvements.

       Check out the release notes for the full list of changes.

       Head to the [Unison website](https://unison-lang.org) for
       download/upgrade instructions.

       Do create a Unison Share account and put all your amazing code there.

       Enjoy! 🚀
  }}

blog.m4hRelease.index : Doc
blog.m4hRelease.index =
  use Class or
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison releases version M4h of the Unison Codebase Manager and an updated base library."
      )
    , ("date", "2023-02-23")
    , ("authors", "rebecca-mark")
    , ("categories", "news")
    , ("status", "published")
    , ("featuredImage", "/assets/thing13.svg")
    ] }}

  # Unison Codebase Manager version M4h is here

    You may have noticed that Unison has been releasing new versions of our
    tooling with greater frequency. We're churning through the alphabet and
    have now released M4h.
    [Install and upgrade instructions are located here](https://www.unison-lang.org/learn/quickstart/#installation-options).

    This release is a product of the hard work of many contributors. Thank you
    all! A few of the release's changes and usage improvements are listed
    below.

    ## Character classes in the base library

       The newest version of `base`, which ships with the UCM executable,
       contains a new set of utilities for working with the {type Pattern} API
       and {type Char} type called {type Class}. {type Class} is a new type
       that represents a set of characters, for example, {whitespace} or
       {Class.alphanumeric}. Notably, the character classes, much like regular
       sets, can be combined with one another with functions like {Class.and}
       and {or}.

       This new type interfaces nicely with the existing {type Pattern} API for
       regex-like text matching and parsing.

       For example, if you wanted to match a string that contained either
       lowercase or whitespace characters, you could first define a class with
       both of them represented, translate it into a {type Char}, and then use
       it in a {type Pattern}. Here's what that looks like:

       ```
       lowerOrSpace = or whitespace Class.lower
       Pattern.run
         (Pattern.capture (Pattern.many (patterns.char lowerOrSpace)))
         "hi unison!"
       ```

       If you've already installed Unison, but are eager to try out the latest
       base version with this feature, check out this how-to for
       [updating your base library](https://www.unison-lang.org/learn/usage-topics/workflow-how-tos/update-dependency/).

    ## LSP improvements

       We're always looking for improvements to the Unison language for those
       cases when you've run into an error or need some additional prompting.

       The Unison language server will now tell you a specific error if you are
       matching on something that has the wrong number of arguments for the
       pattern match.

       ``` raw
       match eitherValue with
         Left _ -> "left"
         Right one tooMany -> "right"
       ```

       This code will now produce a friendly error in your editor!

       Type information on hover has also been vastly improved for the LSP!
       Check out the example provided by Chris Penner
       [in his PR notes here](https://github.com/unisonweb/unison/pull/3637).
       Thank you Chris! The LSP is a lifesaver! 🙏

    ## Better ergonomics when deleting types and terms

       Users of the UCM CLI might have noticed that while commands like `edit`
       or `display` will accept multiple arguments, the `delete` command only
       accepted one argument at a time. This could be a bit tedious. 💀

       In M4h, we've added the ability to delete multiple terms and types at
       once, including a full chain of dependent elements, from leaf to root.

       This means if you have a bunch of terms that are related to an
       implementation that is no longer needed, just remove them all:

       ``` ucm
       .myProject> delete function1 function2 Type3 function4
       ```

       🌻 Give the new version a try and let us know what you think!
  }}

blog.march2023LibraryUpdates.index : Doc
blog.march2023LibraryUpdates.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The Unison Codebase Manager releases version M4i. Unison contributors have authored libraries for XML, AWS, CNC and other acronyms."
      )
    , ("date", "2023-03-15")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # March 2023 Unison library and codebase manager updates

    Since our last ecosystem update in December, there have been a few new
    libraries and Unison tooling updates for you to check out.

    ## Unison codebase manager M4i release

       [Version M4i of Unison](https://github.com/unisonweb/unison/releases/tag/release%2FM4i)
       is now available for download.
       [Check out the upgrade or install directions to get this release.](https://www.unison-lang.org/learn/quickstart/#installation-options)

       We're very grateful to Unison teammate Travis Staton for implementing
       Unison's pattern match typechecker, which shipped with this version.

       No more will your program spuriously fail at runtime because you forgot
       one of your cases in a pattern match. Instead you'll get a nice
       compile-time error.

       ``` unison
       -- This will now fail to typecheck
         match (Some 5) with
           None -> 0
       ```

       Multi-line string literals have also landed with this release. They're
       introduced by triple quotation marks. Go ahead and enjamb those poems,
       or just write some nicely formatted long strings.

       ```
       _multiLine
       ```

       ### Syntax highlighting for Unison

           For your front-end Unison syntax highlighting needs, Runar has
           written a [highlight.js](https://highlightjs.org/) implementation
           for Unison code.
           [Check it out here](https://github.com/runarorama/highlightjs-unison).
           Instructions for including the package are in the README. Once
           loaded, your fenced codeblocks starting with ''``` unison'' will
           receive the appropriate highlighting. We hope to see your blog posts
           and websites using this package soon!

    ## Library updates

       ### XML parsing in Unison

           That's right, the early aughts called and they want their favorite
           data exchange format back! 😎

           We were writing a S3 Client in Unison (see below) when we realized
           it actually uses XML. Thus an XML library was born. 🐣 That's good
           news for all you folks writing SOAP apis! Thanks to Runar, Unison
           [has published this library for XML parsing](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/xml/latest).

           The docs for the library are fantastic, check out the Atom feed
           parsing example in
           [the docs for the Soup type.](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/xml/latest/;/types/Soup)

       ### Amazon Web Services SDK in Unison

           {{
           docAside
             {{
             Remember, with enterprise-grade power comes enterprise-grade
             responsibility.

             Say it with me, "I will not add my AWS credentials to my
             codebase." ✋📚
             }} }} Work is underway to create an
           [AWS SDK for Unison](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/aws/latest).
           The first AWS offering that we have targeted for integration is the
           backbone of the internet's data,
           [AWS S3](https://aws.amazon.com/s3/). For folks who have not had the
           pleasure of working with AWS, S3 is a simple object data store. Your
           data is stored as in versioned, time-stamped file-like "objects" in
           buckets for easy retrieval. In the library so far, you can put
           objects, get objects, and list buckets, but more is on the way.

       ### 3D printing and CNC machines

           Unison community member Alvaro Carrasco has written a library for
           parsing GCode for 3D printing and CNC machines.
           [It's hosted here on Unison Share](https://share.unison-lang.org/@alvaroc1/p/code/latest/namespaces/public/gcode/main).
           GCode is a simple language for controlling 3D printers and CNC
           machines. The readme contains a few example of the kinds of
           operations that machines that use this data format can perform, so
           if you'd like to, for example, 3D print a Unison logo widget with
           Unison code, give it a try and let us know how it goes. 🤖

       ### Visualizing remote computations

           [This library got a little write-up earlier this month in the Unison
           blog](https://www.unison-lang.org/whats-new/visualizing-remote/).
           You'll likely see more of these diagrams as we continue to explore
           the possibilities of Unison distributed programs.

       ### Have a library idea?

           Come talks to us in the #libraries channel in the
           [Unison slack](https://unison-lang.org/slack). We want to help you
           get started! 🌷
  }}

blog.march2023LibraryUpdates.index._multiLine : Text
blog.march2023LibraryUpdates.index._multiLine =
  """
      I write, erase, rewrite
      Erase again, and then
      A poppy blooms.

      - Katsushika Hokusai

  """

blog.march_2019Update.index : Doc
blog.march_2019Update.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Hi all — it's been 464 commits since our last update post, and I hardly know where to start..."
      )
    , ("date", "2019-03-29")
    , ("authors", "arya-irani")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing2.svg")
    ] }}

  # March update

    Hi all — it's been 464 commits since our last update post, and I hardly
    know where to start...

    So, in arbitrary order:

  # The first Unison Meetup

    ...went off without a hitch! Join the
    [Boston Unison meetup](https://www.meetup.com/Boston-Unison/) if you might
    like to come out to the next one. On Tuesday, about a dozen functional
    programming and future-of-computing enthusiasts gathered from around the
    greater Boston area to chat about their development experience, and let us
    show off our current progress, including:

  # Actually editing existing code 😅

    The `edit` command writes the text of the specified definition to disk for
    you to review or update.

    {{
    Image
      {{
      I added the definitions to the top of meetup3.u
      }}
      {{
      /assets/feed/march-2019-update/55251341-8fac5880-520d-11e9-9d74-9a6661e5f0bf.png
      }}
      None }}

    Once you're satisfied with your changes, you can use the `update` command
    to replace an existing definition. (The usual `add` command won't let you
    add a definition with an existing name.)

    {{
    Image
      {{
      I updated these definitions.
      }}
      {{
      /assets/feed/march-2019-update/55251578-2c6ef600-520e-11e9-81a4-4f09b40179d0.png
      }}
      None }}

    Boom.

  # Structured Refactors

    Gone are the days where changing a function signature produces a cascade of
    unhelpful error messages from across your entire project, where fixing one
    error causes seven more. Unison will support a number of structured
    refactorings, the first of which is simply: __definition replacement__.

    In this example, I've updated the original `sliding` function:

    ``` unison
    sliding : Text -> [Text]
    ```

    to take an extra `width` parameter, instead of hard-coding it:

    ``` unison
    sliding : Nat -> Text -> [Text]
    ```

    {{
    Image
      {{
      This branch has 3 transitive dependents left to upgrade.
      }}
      {{
      /assets/feed/march-2019-update/55250484-815d3d00-520b-11e9-9557-ef5d01eed85b.png
      }}
      None }}

    From this output, we can see that this update has __three__ transitive
    dependents. This is the maximum number of definitions that you could need
    to audit or update as a result of the change. More importantly, this number
    only goes down as you work!

    Unison will recommend an ordering to your remaining updates, to minimize
    repeat work. (e.g. You if you updated `foo`, and `bar` depends on `foo` and
    `baz`, and `baz` depends on `foo`, Unison knows to recommend that you
    finish up `baz` before updating `foo`.)

    In my example, I only had to update __one__ dependent to finish. Because I
    didn't change its type, there was no more manual work to do:

    {{
    Image
      {{
      No conflicts or edits in progress.
      }}
      {{
      /assets/feed/march-2019-update/55250768-355ec800-520c-11e9-8236-f82dfea8559a.png
      }}
      None }}

    If I had instead decided to pass the new parameter into `similarity` as
    well, Unison knows there's more work to do, and guides me through the rest
    of that refactor:

    {{
    Image
      {{
      This branch has 2 transitive dependents left to upgrade.
      }}
      {{
      /assets/feed/march-2019-update/55251059-dea5be00-520c-11e9-9cfb-b6a26c429865.png
      }}
      None }}

    For funsies, here are the replacements that Unison recorded:

    {{
    Image
      {{
      Edited terms.
      }}
      {{
      /assets/feed/march-2019-update/55251163-17de2e00-520d-11e9-8809-4f5993b57657.png
      }}
      None }}

  # A Shiny New Runtime

    We've jettisoned the Scala-based runtime and replaced it with a simpler,
    Haskell-based IR compiler and interpreter. As well as putting us in a
    better position for optimizations going forward (IR to LLVM, etc.), it's
    allowed us to incorporate the runtime into the codebase editor, simplifying
    installation and execution as well. (One build tool, one executable.)

    Here we can see it, pretty-printing the result of partially applying a
    function:

    {{
    Image
      {{
      Watch expression for a partially-applied function.
      }}
      {{
      /assets/feed/march-2019-update/55251780-92f41400-520e-11e9-86db-e092c6847f63.png
      }}
      None }}

  # An IO ability

    We've added a
    [preliminary `IO` ability](https://github.com/unisonweb/unison/blob/ed69a95128440f7976014d2826a0e0872662ba43/parser-typechecker/src/Unison/Runtime/IOSource.hs#L194-L281),
    and are in the process of implementing a native handler for it in the
    runtime.

    We have also added the `execute` command to the codebase editor, which will
    evaluate `IO` expressions, such as your application. Eventually, you'll be
    able to start your application from the shell as well, by passing
    command-line arguments.

    {{
    Image
      {{
      Hello, world!
      }}
      {{
      /assets/feed/march-2019-update/55258190-63013c80-521f-11e9-8853-ca10aaa8bd05.png
      }}
      None }}

  # A `Bytes` data type

    The `IO` functions will likely use this eventually!

    {{
    Image
      {{
      Bytes demo
      }}
      {{
      /assets/feed/march-2019-update/54630653-b968c100-4a50-11e9-9200-2a96e6ff6a03.png
      }}
      None }}

    ## Universal comparison

       ``` unison
       Universal.< : a -> a -> Boolean
       Universal.<= : a -> a -> Boolean
       Universal.== : a -> a -> Boolean
       Universal.> : a -> a -> Boolean
       Universal.>= : a -> a -> Boolean
       Universal.compare : a -> a -> Int
       ```

       The implementation works for all types, comparing values structurally.
       Even functions! We will probably do something in the future to give
       these a more constrained type and get our free theorems back.

       At any rate, given:

       ``` unison
       use Universal ==
       foo a b = a Nat.* b
       bar x y = x Nat.* y
       > 1 == 2
       > (5,5) == (5,5)
       > foo == bar
       > foo 1 == bar 1
       > foo 1 == bar 2
       > foo 1 < bar 2
       ```

       we get:

       {{
       Image
         {{
         Universal Eq/Ord demo
         }}
         {{
         /assets/feed/march-2019-update/55260307-4536d600-5225-11e9-818f-03d0876ae230.png
         }}
         None }}

       Not bad!

  # Bugfixes

    We've fixed a lot of bugs. 😅 Thank you to the masochistic handful who've
    been using the tool and reporting them, and special thanks to @noahaasis (
    [#328](https://github.com/unisonweb/unison/pull/328) ), @francisdb (
    [#333](https://github.com/unisonweb/unison/pull/333),
    [#392](https://github.com/unisonweb/unison/pull/392) ) , @mrziuban (
    [#382](https://github.com/unisonweb/unison/pull/382),
    [#385](https://github.com/unisonweb/unison/pull/385) ), @benfradet (
    [#418](https://github.com/unisonweb/unison/pull/418) ), for their fixes.

  # Unison-Related Projects

    Discovering new Unison projects in the wild has been super gratifying. Here
    are two:

    * [https://github.com/francisdb/unison-json](https://github.com/francisdb/unison-json)
      * JSON AST / parser / printer, written in Unison.
    * [https://github.com/BenFradet/vscode-unison](https://github.com/BenFradet/vscode-unison)
      * Unison syntax highlighting for VS Code.

  # What's up next?

    The most immediate next steps towards the M1 release of the codebase editor
    include:

    ## More I/O!

       File I/O! Network I/O! Concurrency! Universal `toString`? 🤔

    ## More types of types!

       Today, any two Unison types are the same if the (multi)set of their
       constructor types is the same. We'll be introducing new-types and opaque
       types.

    ## More Codebase Editor work!

       There are so many rough edges, but we'll get them one by one.

  # That's all for now.

    Thanks for reading, and keep the comments coming! Especially, let us know
    what you need to start your Unison-based project.
  }}

blog.march_2020Update.index : Doc
blog.march_2020Update.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "There have been more than 700 commits to Unison's master branch since we last did one of these update posts, so a lot has happened. We've made a lot of bug-fixes and improvements to the ergonomics of Unison--too many to list them all here. Here are some highlights."
      )
    , ("authors", "runar-bjarnason")
    , ("authors", "aryai-irani")
    , ("date", "2020-03-12")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing7.svg")
    ] }}

  # First class documentation with live examples, rethinking the pull request,
  a new runtime, and more

    There have been more than 700 commits to Unison's master branch since we
    last did one of these update posts, so a lot has happened. We've made a lot
    of bug-fixes and improvements to the ergonomics of Unison--too many to list
    them all here. Here are some highlights.

    ## Support for first-class API docs with live code examples

       You can now write documentation for your Unison libraries, and link the
       docs to the definitions in your codebase. What's more, documentation is
       first-class, so it's just Unison code! This means:

       * You can access documentation from Unison code and compute with it.
       * Code snippets and examples in your docs are not just text, but "live"
         code that typechecks.
       * Such code doesn't get out of date. When you refactor or update code
         that's referenced in documentation, the Unison Codebase Manager
         automatically updates the docs.

       For more information about this, see
       [Documenting Unison code](https://www.unison-lang.org/learn/usage-topics/documentation/).

    ## New documentation topics on Unison's abilities system and its testing
    library

       We added some new documentation topics! Firstly, we documented Unison's
       type system feature called [abilities](/docs/abilities) (often called
       __algebraic effects__ in the literature), a powerful yet easy-to-use
       feature that can express asynchronous programming, stream processing,
       coroutines, nondeterminism, and more. See
       [the docs on abilities](/docs/abilities). As a quick example, here's an
       implementation of Python-style generators in a few lines of Unison code:

       ``` unison
       ability Stream e where
         emit : e -> ()

       -- Emit all natural numbers starting from `n`
       Stream.from : Nat ->{Stream Nat} ()
       Stream.from n =
         emit n
         Stream.from (n + 1)
       ```

       See [the abilities tutorial](/docs/abilities) for more.

       We also added
       [better documentation on how to write tests in Unison](/docs/testing).
       For a while now, Unison's
       [base libraries](https://github.com/unisonweb/base) have come with a
       nice (but not well documented) library for testing, which supports
       traditional unit tests and programmatically generated test cases. Here's
       a quick example:

       ``` unison
       test> myTest = check (1 + 1 == 2)

       test> Nat.tests.addition = runs 1000 'let
         x = natIn 0 100
         y = natIn 100 200
         expect ((x+y) == (y+x))
       ```

       See [the documentation for how to write tests in Unison](/docs/testing)
       to learn more.

    ## A workflow for making pull requests against Unison repos

       This is still a work in progress, but we have a fairly straightforward
       workflow that you can use to make "pull requests" against Unison repos.
       The usual pull request review process involves navigating large textual
       diffs, using a tool that has little understanding of your code. Unison
       has a semantic understanding of changes that are made to a namespace,
       and can report things like "this function was changed" or "this
       definition was moved from here to there" rather than "these 46 lines in
       this file are now different, as are these other 74 lines in this other
       file". Also, by storing the Unison codebase as serialized abstract
       syntax trees, we avoid merge conflicts and diffs due to things like
       formatting.

       Because of this more semantic understanding, the PR review process can
       also be more random-access, where one can hop around through
       semantically meaningful parts of the change rather than scrolling
       through large textual diffs.

       Though we still call them "pull requests" and though Unison repos are
       hostable on GitHub, we cannot actually use the GitHub pull request
       mechanism. Or at least, that would not be a nice experience. Instead,
       Unison has its own kind of pull request.

       Let's say we've forked the
       [Unison Base library](https://github.com/unisonweb/base) to
       `https://github.com/me/mybase`, and we've added a new function
       `Char.toText` that we would like to have merged back to
       `unisonweb/base`. We can create a Unison pull request from the Unison
       Codebase Manager, with `pr.create`:

       ``` ucm
       .> pr.create https://github.com/unisonweb/base https://github.com/me/mybase

         The changes summarized below are available for you to review, using the
         following command:

           pr.load https://github.com/unisonweb/base https://github.com/me/mybase

         Added definitions:

            Char.toText                           : Char -> Text
       ```

       We take the output of this command and send it to the recipient of our
       pull request. In this case, we could for example paste it into a new
       GitHub issue opened against `unisonweb/base`. A maintainer of that repo
       can then run the `pr.load` command in their Codebase Manager:

       ``` ucm
       .> pr.load https://github.com/unisonweb/base https://github.com/me/mybase pr1

         I checked out https://github.com/unisonweb/base to pr1.base.
         I checked out https://github.com/me/mybase to pr1.head.

         The merged result is in pr1.merged.
         Use `diff.namespace pr1.base pr1.merged` to see what's been updated.
         Use `todo merged.patch pr1.merged` to see what work is remaining for the merge.
         Use `push https://github.com/unisonweb/base pr1.merged` to push the changes.
       ```

       Following the instructions in the output of `pr.load`, the maintainer of
       `unisonweb/base` can audit our changes and push them to their repo on
       GitHub.

       There will be a more detailed tutorial on this feature of UCM once it's
       a little bit more polished.

    ## An improved process for refactoring data types

       We've vastly improved the experience of updating or refactoring types.
       In Unison, when you make a modification to a data type, you actually
       create a new type and any existing code needs to be made to use your new
       type instead of the old one. With the improvements we've made, you just
       need to issue an `update` command in UCM, and it will try to update any
       code that depends on the changed data type.

       Sometimes this will result in code that doesn't typecheck, and Unison
       will let you know if that's the case so you can make the changes
       manually. To this end, we've also added commands that give you somewhat
       precise control of term and type replacements, `replace.term` and
       `replace.type`. These let you create patches that (when applied) replace
       all appearances of one term or type in a namespace with another.

    ## A number of syntax changes

       We've made some changes to Unison's surface syntax, hoping to make the
       language more ergonomic. Kudos go to Aaron Novstrup who contributed each
       of these improvements. 🙌 A cool thing about Unison is that we can change
       the syntax without breaking anyone's existing code! When you update to
       the latest version of Unison, it will simply start rendering your code
       using the new syntax.

       Here are three major syntax changes:

       ### Handler blocks

           Where you used to write `handle h in x`, such that `h` is an
           [ability handler](https://www.unison-lang.org/learn/fundamentals/abilities/writing-abilities/)
           and `x` is some code that needs the abilities handled by `h`, you
           now write `handle x with h`. We think this makes the code easier to
           read and write, since the logic (the `handle` block) comes before
           the implementation specifics (the handler). Now it looks rather like
           `try` / `catch` in other languages:

           ``` unison
           handle
             doOneThing
             doAnotherThing
           with
             theHandler
           ```

           As a bonus, we're able to get rid of the `in` keyword, freeing that
           name up for use as an ordinary identifier.

       ### Match-with instead of case-of

           Pattern matching gets a facelift as well. Where you used to write
           `case x of ...`, you now write `match x with ...`. For example:

           ``` unison
           match List.head xs with
             Some x -> "Hello, " ++ x
             None -> "Goodbye"
           ```

       ### Lambda-case syntax

           When writing a lambda literal that pattern matches on its argument,
           normally you would write:

           ``` unison
           x -> match x with ...
           ```

           But if you don't care to give the `x` argument a name, now you can
           instead just write:

           ``` unison
           cases ...
           ```

           This looks especially nice in ability handlers:

           ``` unison
           handle
             doOneThing
             doAnotherThing
           with cases
             { x } -> x
             { Store.get   -> k } -> ...
             { Store.put v -> k } -> ...
           ```

    ## Use any unambiguous name suffix to identify definitions

       This change massively cuts down on import boilerplate. For example, you
       can use `Optional` unqualified, without a `use` clause to import it, as
       long as there's no other `Optional` type in your tree.

       If you have two `Optional` types, `.foo.bar.Optional` and
       `.my.cool.Optional`, then `cool.Optional` is a suffix of name segments
       that uniquely identifies the latter type, and can be used without any
       imports.

       Notably, you no longer have to use patterns qualified with their data
       type. So whereas before you might have had this:

       ``` unison
       use .base Optional Text

       myFunction : Optional Text -> Text
       myFunction x = match x with
         Optional.Some x -> "Hello, " ++ x
         Optional.None -> "Goodbye"
       ```

       you can now just say:

       ``` unison
       myFunction : Optional Text -> Text
         Some x -> "Hello, " ++ x
         None -> "Goodbye"
       ```

       More generally, you can now refer to a type or term without imports
       using any suffix of name segments that has just one referent.

    ## Builtins for crashing Unison programs

       We added two builtins, `bug` and `todo`, which simply crash your program
       with an error. (A shoutout to Noah Haasis for contributing both of
       these! 🎉)

       The `todo` builtin is handy for when you've only partially implemented
       something but you want to try out the partial implementation anyway:

       ``` unison
       myFunction x = match x with
         Some x -> "Hello, " ++ x
         None -> todo "Handle the None case"
       ```

       The `bug` builtin is for implementing assertions and sanity checks, a
       way to quickly crash if you hit a case that should be impossible if your
       code were correct. For example:

       ``` unison
       ...
       tree' = rebalance tree
       if isBalanced tree' then
         tree'
       else
         bug ("Tree unbalanced after rebalancing!", tree')
       ```

       You can pass any value at all to `bug` or `todo` and it will be nicely
       formatted by Unison, using the pretty-printing code developed by
       contributor Chris Gibbs. A common idiom is just to give it a tuple with
       one element being the description and the other elements being a list of
       values that you want to be able to see if `bug` or `todo` call is ever
       hit in running code.

    ## What's next?

       We're going to keep polishing the pull-request workflow to make it nicer
       to use and will be opening up
       [the Unison base libraries](https://github.com/unisonweb/base) to new
       contributors very soon.

       Also exciting is that Dan Doel has started implementation on a new
       runtime for Unison which is going to be a lot faster than what we have
       now and sets us up to write a proper JIT for Unison. We'd like Unison to
       be both great to program in and also insanely fast. Unlike the current
       runtime, Dan's work is the start of a more traditional JIT compiler
       pipeline, where the code goes through several initial stages of
       transformations before being converted to an intermediate representation
       (IR) where various optimizations can be expressed before moving to code
       generation. The current code generation process Dan's working on goes to
       a low level representation that gets interpreted efficiently, but the
       endgame would be to go to something like LLVM.

       We might do a more in-depth technical post on the new runtime work. In
       particular, going to LLVM has interesting challenges due to Unison's
       [ability system](/docs/abilities) which needs to capture and manipulate
       continuations at runtime.

       The new runtime should land in the next couple of months, along with
       some new builtin functions we'll need to start building out Unison's
       distributed computing libraries.

       We still have a lot more work to do, but things are coming together!
  }}

blog.newUpdateProcess.index : Doc
blog.newUpdateProcess.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Our process for updating code was a rough spot in the Unison workflow, but it has so much potential! Here's a look at how we're fixing it."
      )
    , ("date", "2023-10-20")
    , ("authors", "rebecca-mark")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing11.svg")
    , ("status", "published")
    ] }}

  # A preview of Unison's improved update process

    Unison's process for updating code, merging code, and upgrading library
    dependencies is the roughest part of the experience right now. So we're
    fixing it. This post has preview of what you can expect in the next version
    of Unison.

    The original vision for Unison's update process always held promise.
    Imagine:

    * No conflicts due to semantically meaningless changes like differing
      whitespace, imports being reordered, or a definition being moved around
      in the file.
    * No breakage due to definitions being renamed.
    * A codebase that always typechecks, even partway through a complex
      refactoring.
    * Simple changes are easy to make, and complex refactorings are guided by a
      helpful copilot.

    … but in practice, the implementation of these ideas in the current Unison
    hasn't been as good as it needs to be. For instance:

    * It's easy to accidentally replace your human readable names with
      mysterious hashes.
    * There is no indication that conflicts are present unless you run `todo`.
    * The suggested order of edits sometimes leads you in a circle.
    * There's not a simple experience for upgrading dependencies in a
      first-class way.

    ## Introducing the new update workflow

       You'll primarily be using three commands, `edit`, `update`, and `merge`:

       ``` ucm
       myProj/main> edit foo
       myProj/main> update

         ⍟ I've updated these names to your new definition:

           foo : Nat -> Nat -> Text

         I couldn't automatically propagate your changes. I've created a branch for updates and added these definitions to your 'scratch.u' file to resolve:

       		bar : Nat -> {IO, Exception} ()

         Do `merge /update134 /main` when finished.

       myProj/update134> ... hack hack hack
       myProj/update134> update
       myProj/update134> merge /update134 /main
       myProj/update134> switch /main
       ```

       In the common case of a type-preserving edit, your change propagates
       automatically and doesn't create a branch. Otherwise Unison creates a
       branch for your changes and opens a scratch file with the terms that it
       couldn't automatically update. Once you fix the type errors in the file,
       you can run `update` again and `merge` the branch back. If you want to
       abandon the refactoring, you can just delete the branch in progress.

       The process for upgrading a library dependency is kicked off with the
       new `upgrade` command.

       ``` ucm
       myProj/main> upgrade lib.base_2_0_0 lib.base_3_2_1
       ```

       Simply specify the current library you want to upgrade and the new
       target version. If the library changes can be automatically applied,
       congratulations, you're done! Otherwise, you'll step through the same
       update process above.

       {{
       docAside
         {{
         Thank you to the team responsible for these improvements: Arya,
         Mitchell, and Travis. We would forever be lost in the `edit frontier`
         without you!
         }} }}

    ## More improvements to come!

       The new update process is shipping in the next version of Unison, so
       stay tuned for more news about this much anticipated feature. In the
       future, we may do a technical deep-dive into the update process, but we
       hope this preview of the workflow is cause for celebration. Thank you to
       the Unison community members who stuck through the old process and still
       [created an impressive suite of libraries](https://share.unison-lang.org/).
       Your perseverance and feedback were instrumental in making this change
       happen. Come join our
       [friendly slack community](https://unison-lang.org/slack) for news and
       conversations about the upcoming release.

       Happy coding! 🌻
  }}

blog.newYearsUpdate2019.index : Doc
blog.newYearsUpdate2019.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Hey everyone, Rúnar here. It's been a while since our last update. We've been busy."
      )
    , ("date", "2019-01-09")
    , ("authors", "runar-bjarnason")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing5.svg")
    ] }}

  # New Years Update 2019

    Hey everyone, Rúnar here. It's been a while since our last update. We've
    been busy.

    ## Spreading the word about Unison

       * The video of
         [my talk from Lambda World Seattle](https://www.youtube.com/watch?v=rp_Eild1aq8)
         has been published to YouTube.
       * Paul's talk
         [at Scale by the Bay](https://www.youtube.com/watch?v=v7L-5AQQkbM) is
         also up.
       * I gave a talk on Unison at Øredev in Malmö, and also at the Reykjavík
         Functional Programming meetup.
         [A video is available of the latter](https://www.facebook.com/enkidudidu/videos/10218046671060964/).
       * Arya did the hallway track at NeurIPS and got a sense of how
         researchers and industry are (or aren't) managing their distributed
         machine learning applications. This seems a good candidate for a
         Unison library.
       * We created a number of GitHub issues and marked some of them as "good
         first issue" and "help wanted". If you've been thinking about
         contributing to Unison, this might be a good place to start. We'll add
         to these issues as we think of more ways contributors can help. Go to
         [https://github.com/unisonweb/unison/issues](https://github.com/unisonweb/unison/issues)
         to look at the list.

    ## Codebase editor progress

       Meanwhile, we're making steady progress on the implementation, working
       mostly on the Unison codebase editor. Here's what you get now when you
       start up `unison`:

       {{
       Image
         {{
         Starting the codebase editor
         }}
         {{
         /assets/feed/new-years-update-2019/cbestart.png
         }}
         None }}

       From here, you can explore and manipulate your Unison codebase. You'll
       note that Unison first creates a __branch__ called "master". A branch is
       really two things:

       1. A collection of names for the hashes in your codebase.
       2. A collection of edits to the codebase.

       Right from the start, the master branch contains a number of predefined
       names for builtins. You can query the contents of the codebase using
       fuzzy matching:

       {{
       Image
         {{ ls drp }} {{ /assets/feed/new-years-update-2019/ls-drp.png }} None
       }}

       The codebase knows the type of every definition, and later on we'll add
       the ability to query by type.

       Oh, and we have tab completion already.

       ### Unison is watching

           Instead of having a REPL in the traditional sense, Unison is
           watching for changes to `*.u` files under the directory in which
           it's started. I'll open a file called `scratch.u` and type a Unison
           definition into it:

           {{
           Image
             {{
             replicate
             }}
             {{
             /assets/feed/new-years-update-2019/replicate.png
             }}
             None }}

           If I save the file, my Unison session immediately shows this:

           {{
           Image
             {{
             saved scratch.u
             }}
             {{
             /assets/feed/new-years-update-2019/scratchu.png
             }}
             None }}

           Note that it says it's "evaluating any watch expressions". I can add
           a watch expression just by adding a line that starts with `>` to my
           file.

           {{
           Image
             {{
             replicate 3 lambda
             }}
             {{
             /assets/feed/new-years-update-2019/replicatelambda.png
             }}
             None }}

           If I save again, Unison comes back with the evaluated result of this
           expression:

           {{
           Image
             {{
             eval replicate 3 lambda
             }}
             {{
             /assets/feed/new-years-update-2019/evalreplicatelambda.png
             }}
             None }}

       ### Adding and viewing definitions

           I'm happy with that, so I'll ask Unison to add `replicate` to my
           codebase:

           {{
           Image
             {{
             unison add
             }}
             {{
             /assets/feed/new-years-update-2019/unisonadd.png
             }}
             None }}

           If I had put more (well typed) definitions in my file, Unison would
           have happily added those too.

           Now that `replicate` is in my codebase, I can actually throw away
           the scratch file. If I need the definition of `replicate` again, I
           can always ask Unison for it:

           {{
           Image
             {{
             view replicate
             }}
             {{
             /assets/feed/new-years-update-2019/viewreplicate.png
             }}
             None }}

       ### Git-friendly codebase structure

           We really want to allow Unison developers to use good tools they're
           already familiar with like their favourite text editor, and Git. To
           that end, we've made it so that the codebase is just a bunch of
           (binary) files that can be versioned with Git.

           Under the bonnet, Unison creates a directory called `.unison` which
           contains the codebase. There are three subdirectories here
           (currently); one for branches, one for type declarations, and one
           for term definitions. Under `types` and `terms`, we have one
           directory per hash which contains the compiled definition as well as
           any metadata.

           {{
           Image
             {{
             Unison codebase structure
             }}
             {{
             /assets/feed/new-years-update-2019/codebasestructure.png
             }}
             None }}

           Since everything is indexed by hash, you'll never actually change
           any file, so Git merge conflicts should never happen.

           See
           [the Codebase Editor design document](https://github.com/unisonweb/unison/blob/trunk/docs/codebase-editor-design.markdown)
           for more information.

       ### More features

           We're currently adding more features to the Codebase Editor. Right
           now we're making it easier to edit existing definitions that have a
           lot of dependencies, through a kind of structured refactoring
           session.

           Here's the feature set we have so far:

           {{
           Image
             {{
             Unison help
             }}
             {{
             /assets/feed/new-years-update-2019/unisonhelp.png
             }}
             None }}
  }}

blog.ourSeedFunding.index : Doc
blog.ourSeedFunding.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "We've raised $9.75 million in seed funding and I'd like to say some nice things about the people financially supporting our work. This won't be your typical funding announcement; instead I'll talk candidly about some of the dynamics of VC and open source funding today and why the people investing in Unison are so rare, and so special. I hope you'll come away feeling the same."
      )
    , ("date", "2024-06-04")
    , ("authors", "paul-chiusano")
    , ("categories", "announcements")
    , ("status", "published")
    ] }}

  # Unison Computing's seed funding and why our investors are special

    I talked in
    [an earlier post](https://www.unison-lang.org/blog/benefit-corp-report/)
    about our company's pre-seed round. Since then,
    **we've raised $9.75 million** in seed funding and I'd like to say some
    nice things about the people financially supporting our work. This won't be
    your typical funding announcement; instead I'll talk candidly about some of
    the dynamics of VC and open source funding today and why the people
    investing in Unison are so rare, and so special. I hope you'll come away
    feeling the same.

    {{
    docCallout
      Optional.None
      {{
      The majority of this funding actually came through in late 2022 and we
      are still going strong. So far this year we
      [made Unison Cloud generally available](https://x.com/unisonweb/status/1755266140924784738),
      [open sourced Unison Share](https://www.unison-lang.org/blog/unison-share-is-open-source/),
      and
      [shipped the first version of our native compiler](https://fosstodon.org/@unison/112451476758872387).

      ➡️ **Check out**
      [**where Unison is headed next**](/blog/where-unison-is-headed/).
      }} }}

    A bit about our company: Unison Computing is a public benefit corporation,
    on a mission to advance what's possible with software and to make software
    creation simpler and more accessible to all. We build useful open source
    software (the Unison language and
    [Unison Share](https://www.unison-lang.org/blog/unison-share-is-open-source/)
    are open source) and plan to be sustainable as a business via our
    futuristic cloud platform, [Unison Cloud](https://unison.cloud/). Unison
    and Unison Cloud are both generally available and useful today and
    [we ourselves are using Unison in production](https://www.unison-lang.org/blog/experience-report-unison-in-production/).
    We'll continue to
    [innovate and improve on both](/blog/where-unison-is-headed/) in the coming
    months and years.

    Not every investor was a good fit for our company. Why not? Unison is a
    deep tech startup based around
    [a big idea](https://www.unison-lang.org/docs/the-big-idea/). The idea can
    be explained in minutes, and we knew it had huge potential to simplify
    distributed computing (and programming generally), but it's also an idea
    which is like "new physics" for computing. It touches many aspects of
    language design, developer tooling, and more. We knew it would take years
    to fully realize Unison's potential, however wasn't just about finding
    patient investors, there's a rare mentality that goes into funding a
    startup which is creating a new paradigm on radically different
    foundations.

    ## Most investors aren't interested in funding innovative OSS

       This is a hard truth. Companies like Unison Computing that are based
       around open source software usually form and raise money __after__ the
       core technology has already been incubated elsewhere and reached some
       critical mass. In fact, many investors, even those comfortable with open
       source businesses, won't even take you seriously until
       __somehow, miraculously,__ there's a popular open source technology for
       you to commercialize. But this typical approach of waiting for
       innovative OSS to be incubated by someone else has serious limitations:

       * Technology that's incubated within a big company tends to be pretty
         conservative and related only to the immediate needs of the business.
         So Google funds open-source work on Go and Kubernetes, tech that lets
         them more efficiently do the things Google is already doing. More
         generally, big companies that can afford to fund this work often have
         different ideas about what's pressing and worth solving than the rest
         of us. Who will build the technology that empowers tiny teams to build
         "the next Google"?
       * If the tech is incubated within academia, it is often is more
         innovative but undercapitalized. And incentives in academia prevent
         the necessary level of engineering polish, since the emphasis is more
         on proving concepts in peer-reviewed publications, rather than
         releasing a practical piece of technology.
       * And if the tech is incubated by individuals working nights and
         weekends, it's also undercapitalized and hard to produce something of
         significant scope. This is roughly the position Unison was in before
         we raised money, and it became clear that Unison was a project that
         needed dedicated professionals working on it full time.

       Rather than forming a commercial entity after the technology exists,
       it's possible to fund the creation of OSS by identifying a business
       model that fits the technology, raising initial funding from investors
       on this basis, and eventually supporting continued OSS development with
       the proceeds of the successful business. This was the idea behind Unison
       Computing: use the business side of the company to capitalize truly
       innovative work on better programming technology. (And to
       [open source anything that's not our core business model](https://www.unison-lang.org/blog/unison-share-is-open-source/).)

       We adopted the structure of a public benefit corp to make it clear to
       everyone involved that we have a mission we care about and that we're
       not just building a soulless profit-maximizing machine. Though we had
       some concerns that investors might be frightened off by the benefit corp
       structure, so far it's turned out not to be an issue. One of our
       investors told us that anyone frightened off by the benefit corp
       structure is probably not an investor we'd want to have anyway. 😀

    ## "Horse-betting" investors versus "gardener" investors

       At the risk of oversimplifying, there are two kinds of investors:
       "horse-betting" investors and "gardener" investors.

       The horse-betting investors tend to focus their energy on
       **identifying** companies that are obviously on a path to success. They
       treat their job a bit like betting on a horse race. Rather than helping
       to develop and train a winning horse and jockey, they instead show up
       with a check after it's more clear "we've got a winner on our hands".
       This mentality is incredibly common, even among early stage investors.

       At first I found this surprising. Isn't the whole point of seed stage
       investing to provide capital and support to nascent ideas with big
       potential, __before__ this is obvious to everyone? Isn't this the
       activity which is so inspiring and important about venture capital?
       You'd think so, but it isn't that simple. The horse-betting strategy of
       investing works, so plenty of people and firms employ it.

       Why __does__ it work though? It seems like a horse-betting VC is more of
       a commodity, at risk of competing with everybody else for the same
       obviously great startups and therefore not landing many deals, right?
       Not quite. Investors at every stage are competing with each other not
       __just__ on the basis of how well they can evaluate startups; they also
       compete on deal-flow. Even if you are 10x worse at evaluating the
       potential of startups, if you are 10x better at finding out about
       startups and convincing them to take your money when you offer
       investment, you can still come out ahead and run a very profitable fund.

       The most famous investors can get away with this strategy to an even
       greater extent. They tend to see more deals and their offers are
       accepted more often; if they want, they can "just" sit back and invest
       in the lowest-risk companies that already seem to be on the path to
       success. Name brand investors also tend to have stronger networks of
       connections (which is useful for startups) and more of a halo effect
       (your company can sound more legit if it's funded by some big names)
       which makes founders more inclined to accept their offers.

       To be clear, not all big name firms and not all partners at these firms
       operate this way; it's more that they __can__ employ this strategy more
       effectively. There's nothing wrong with the more conservative approach,
       but its pervasiveness even in early stage VC does mean it can be hard to
       find investors willing to take a chance on something as ambitious as
       Unison.

       Another factor that can get in the way of making investments in
       companies like Unison is the tendency to focus on investments that are
       "easy to justify". Just like "No one ever got fired for buying IBM", no
       VC ever got fired for picking investments based on the same signals used
       by all the other VCs. This is why you see odd dynamics like ex-Google or
       ex-UnicornStartup™️ engineers getting piles of money for their startup,
       or chasing the latest hype train. No one would credibly argue that only
       ex-UnicornStartup™️ founders are qualified to be startup founders, nor
       would they claim that only startups in hyped markets can be successful.
       But it's easier to justify such investments and it brings less scrutiny
       even if these investments don't pan out.

       {{
       docCallout
         (Some {{ 🤔 }})
         {{
         Unison is building a business in a pretty "boring" market: cloud
         computing. For whatever reason, there isn't much hype around cloud
         computing, even though it's a
         [$270 billion dollar market, growing 15-20% annually](https://www.statista.com/outlook/tmo/public-cloud/worldwide#revenue).
         Even though just about every hype train startup is dependent on the
         cloud in some way. We're solving problems that just about every
         company writing software faces today, but because these problems are
         "in the background" or "an implementation detail" of more hyped and
         visible user-facing applications, it just doesn't get the same
         attention.
         }} }}

       All this is to say: it can be hard to find investors who are willing to
       invest in nascent ideas in less hyped markets __before__ their potential
       is obvious.

    ## Our investors are gardeners.

       Our investors are special. I think of them a bit like gardeners. They
       looked at Unison in its early days or half-finished state, when it was
       at its most nascent and fragile, and they said, "It's worth planting
       these seeds and taking good care of them." They weren't horse-betting.
       They didn't assume the hard work was already done and they just had to
       pick the winner. They saw their role as helping to bring about a new
       thing in the world that would take years.

       I want to thank them now. And, if you like Unison and what we've built
       so far, I hope you'll join me in expressing gratitude for their support.
       While I won't list everyone on our cap table, here are our current major
       investors:

       * [Good Growth Capital](https://www.goodgrowthvc.com/), in particular
         Maureen Boyce and Carolyne LaSala, who helped advise us before the
         company even had a business model. Y'all are amazing!
       * [Uncork Capital](https://uncorkcapital.com/), in particular Andy
         McLoughlin. Andy is an all around good human, super supportive, and he
         also seems to know literally everybody.
       * [Amplify Partners](https://www.amplifypartners.com/), in particular
         Lenny Pruss, who took a leap of faith in leading our pre-seed round,
         back when Unison was just a science project. Thanks, Lenny!
       * [Bloomberg Beta](https://www.bloombergbeta.com/), in particular James
         Cham, an incredibly thoughtful and kind person who is always pushing
         our thinking.

       Thanks also to Bob Mason at
       [Project 11 Ventures](https://www.project11.com/),
       [Lime Street Ventures](https://limestreet.ventures/), and all our our
       angel investors and advisors.

       Building Unison has been a long journey with a lot of twists and turns.
       Being on that journey with good and supportive people who believe in
       what we're doing has meant a lot to us. And it's not just about good
       vibes and support; our investors are incredibly helpful in practical
       ways, too. They make introductions. They give good and eminently
       reasonable advice. They help with "boring" but important questions on
       the mechanics of running a company ("how do we hire an employee not
       based in the US?" or "can you recommend a good accounting firm?"). In
       short, they provide a network of people and resources to "make Unison
       happen better."

    ## Conclusion

       It doesn't take a huge number of people to have a big impact in
       software. Even a small team like ours building on the right ideas can go
       a very long way. But seeing all this through requires time and money.
       Seeds must be planted, watered, and given sun and time to grow. Most
       early-stage investors will at least pay lip service to this "gardening"
       style of investing. They'll certainly talk about how they like to fund
       big new ideas and support their growth. But in practice, people like
       this are rare.

       Though maybe they shouldn't be. 🌱

       Thanks y'all. 💜

       – Paul
  }}

blog.peopleAreWritingLibraries.index : Doc
blog.peopleAreWritingLibraries.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "It's exciting to see Unison gradually coming together, but even more exciting has been seeing people writing and publishing Unison code. I've been pretty busy reviewing pull requests to the Unison base libraries and there's already a lot of useful stuff there. Thanks to everyone who has contributed so far!"
      )
    , ("date", "2020-05-26")
    , ("authors", "runar-bjarnason")
    , ("categories", "news")
    , ("featuredImage", "/assets/thing14.svg")
    ] }}

  # People are writing Unison libraries now

    Last week we released another Unison alpha milestone. This release has a
    [number of bugfixes and performance improvements](https://github.com/unisonweb/unison/releases/tag/release%2FM1m).
    🌈⭐️

    It's exciting to see Unison gradually coming together, but even more
    exciting has been seeing people writing and publishing Unison code. I've
    been pretty busy reviewing pull requests to the
    [Unison base libraries](http://github.com/unisonweb/base), and there's
    already a lot of useful stuff there. Thanks to everyone who has contributed
    so far!

    A number of folks have been working on their own Unison libraries and we're
    collecting these [on a page of this site](https://share.unison-lang.org/).
    I want to highlight just one of these, which is a random number generator.
    There are many other cool libraries, but I picked this one at random. The
    main thing I want to highlight is just how easy it is to create and use
    Unison libraries.

    ## Starting up

       If you've been putting off trying out Unison because you think getting
       into a new language might be a lot of work and involve a lot of setup,
       then I've got good news for you: Unison requires almost no setup. You
       can just start coding.

       To get going with Unison, you can go through the
       [three minute quickstart guide](https://www.unison-lang.org/learn/quickstart/).
       It only has three steps.

       Once set up, `ucm` starts the Unison Codebase Manager:

       {{
       Image
         {{
         Unison Codebase Manager
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520213314979.png
         }}
         None }}

       I can now just start writing Unison code in any file in the directory
       from which I started `ucm`, as long as that file's name ends in `.u`. I
       open up a file `scratch.u` with `vim` (my favorite editor), and write my
       first definition, the obligatory `factorial` function:

       ``` unison
       factorial n = List.foldr (*) 1 (range 2 (n + 1))
       ```

       If I save my scratch file, Unison responds with:

       {{
       Image
         {{
         ucm output: factorial
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520215259737.png
         }}
         None }}

       It's telling me that `factorial` is a function that takes a `Nat` (a
       64-bit unsigned integer), and returns another `Nat`. I can add this
       function to my codebase:

       {{
       Image
         {{
         Adding factorial to codebase
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520223126406.png
         }}
         None }}

       I can try out my function right in the scratch file by adding a "watch
       expression", which is any line that starts with `>` (or an indentation
       block where the first line starts with `>`).

       ``` unison
       > factorial 10
       ```

       Unison reponds by evaluating my expression:

       {{
       Image
         {{
         watch expreission
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520215820928.png
         }}
         None }}

    ## Looking around the base library

       The `base` library is already full of good stuff, with new things being
       added almost daily now. To see what's here, I can browse with UCM. If I
       do `list .base` (or `ls .base`), I get a long list. I can `cd` into any
       namespace and look around with `ls`.

       In the definition of `factorial` above, I was using `foldr` and `range`.
       If I ask UCM to `find range`, it responds with everything it knows about
       with `range` in the name:

       {{
       Image
         {{
         find range
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520223808394.png
         }}
         None }}

       The second entry is the function I was using, `List.range`. I can ask
       for its definition either by name or by using the number from the list
       that UCM produced:

       {{
       Image
         {{
         view range
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520224130827.png
         }}
         None }}

       The `docs` command (try `help docs`) shows me the documentation for a
       given function or type, if it has any docs associated with it.

       {{
       Image
         {{
         docs
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520224626845.png
         }}
         None }}

    ## Let's have a look at a third-party library

       Looking at the
       [list of libraries that people have already made](https://share.unison-lang.org/),
       I want to pick one, kind of at random, and just play with it to give you
       a feel for what it's like to consume libraries in Unison. And speaking
       of random, it looks like one of them is
       [a random number generator that uses a Mersenne twister](https://github.com/atacratic/unison-random-mersenne),
       written by Chris Gibbs. Let's try that out.

       Chris has supplied handy install instructions, so let's just do as he
       says:

       ``` ucm
       .> pull https://github.com/atacratic/unison-random-mersenne.git:.releases._v1 external.unison_random_mersenne.v1
       ```

       Lots of stuff scrolls by, and Chris's library is now in my codebase. The
       namespace `external.unison_random_mersenne.v1` is kind of long for my
       taste, so I'm just going to move it under `lib.rng`.

       ``` ucm
       .> move.namespace external.unison_random_mersenne.v1 lib.rng
       ```

       I'm using tab completion for this instead of typing out the whole thing.
       I `cd lib.rng` and look around.

       {{
       Image
         {{
         cd lib.rng
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200520233757131.png
         }}
         None }}

       Looks like there's a `README`, which is a Unison value of type `Doc`. I
       can ask UCM to render any `Doc` with the `display` command. In the
       `README` there's a usage example which shows me how to generate some
       random numbers.

       I put a triple dash `---`, a "fold", on a line at the top of my
       `scratch.u` file, which tells Unison to ignore everything below. I've
       already added `factorial` to my codebase, so I don't need to think about
       that anymore. It goes below the fold. Above the fold, I put an
       expression to generate a single random number between 0 and 10 which I
       got from the README.

       ``` unison
       > mersenne.provide (nextFromRange 0 11) defaultSeed 'ask
       ---
       factorial n = List.foldr (*) 1 (range 2 (n + 1))
       ```

       I wonder what this `mersenne.provide` is. Let's ask Unison.

       {{
       Image
         {{
         mersenne.provide
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200522075051047.png
         }}
         None }}

       OK, so `provide` generates numbers by providing a `Store State` ability,
       where `State` is the Mersenne twister's internal state. The `Nat32` is
       the seed, and this `Ask n` thing is a computation that can ask for a
       random `n` (which in my case is going to be `Nat`).

       Looks like this library puts a lot of its guts on display, so I'm going
       to try to write a more abstract interface for it. What I really want for
       a random number generator ability is something like this:

       ``` unison
       ability RNG where
         nextNat : Nat
       ```

       I can write a (recursive) handler for this ability that uses the
       Mersenne twister:

       ``` unison
       mersenneRNG : Nat32 -> '{RNG,e} a ->{e} a
       mersenneRNG seed x =
         h = cases
           { nextNat -> k } -> handle (k !nat.next) with h
           { a } -> a
         mersenne.provide '(handle !x with h) seed 'ask
       ```

       Great! So now I can request a random `Nat` just by saying `nextNat`, and
       I can handle that request with `mersenneRNG`by providing a seed. But
       sometimes I don't want to provide a seed, and I just want to generate a
       random number as an `IO` effect. Let's try to feed it the system time.

       {{
       Image
         {{
         system type
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200522100603772.png
         }}
         None }}

       OK, we can get an `EpochTime`, which wraps a `Nat`, using `systemTime`.
       Can we turn that into a `Nat32` as required by `mersenneRNG`? A
       type-based `find` turns up 3 different functions:

       {{
       Image
         {{
         type based find
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200522100821121.png
         }}
         None }}

       Skimming the `docs` for these, I see that `truncate32` is probably the
       thing I want. It truncates the high 32 bits, leaving me with just the
       least significant bits of the clock. So I write:

       ``` unison
       clockSeed : '{IO} Nat32
       clockSeed _ =
         match !systemTime with
           EpochTime t -> truncate32 t
       ```

       And finally I use the `mersenneRNG` handler from earlier:

       ``` unison
       mersenneIO : '{RNG,e} a ->{IO,e} a
       mersenneIO x =
         mersenneRNG !clockSeed x
       ```

       An example of using this in a program might be:

       ``` unison
       main : '{IO} ()
       main = 'let
         printLine (Nat.toText (mersenneIO 'nextNat))
       ```

       I `add` all of that to a `scratch` namespace in my codebase:

       {{
       Image
         {{
         add to scratch namespace
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200522101957081.png
         }}
         None }}

       Let's try to run it. UCM provides a `run` command which provide the `IO`
       ability to something of a type like {{ Code (Word "'{IO} a") }}.

       {{
       Image
         {{
         run
         }}
         {{
         /assets/feed/people-are-writing-libraries/image-20200522102323333.png
         }}
         None }}

       Great! I got a random number using the system clock time as a seed.
       Maybe at some point I'll
       [send a pull request](https://www.unison-lang.org/learn/tooling/codebase-organization/#day-to-day-development-creating-and-merging-pull-requests)
       to Chris so he can incorporate some of this into his library.

    ## Conclusion

       I hope this gives you a taste of what it's like to work in Unison with
       the current alpha release, and that this encourages you to try it out
       and maybe contribute some libraries. Remember, it's early days yet, so
       little things you build now could make a big impact on the Unison
       community for the future.
  }}

blog.preConferenceSyntaxGuide.index : Doc
blog.preConferenceSyntaxGuide.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The wonderful team at Unison put together a guide especially for our conference visitors coming from different language communities. This guide will help you get up to speed with Unison syntax and concepts quickly."
      )
    , ("date", "2024-09-19")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # Pre-conference quick syntax guide

    You'll likely see a lot of Unison code during the Unison Forall conference.
    Here are some basics to get you started.

    ## General vibe

       Unison is a whitespace-sensitive language, here's what it looks like:

       ``` unison
       bottlesOfPop : Nat -> Text
       bottlesOfPop bottleRange =
         List.range 0 bottleRange
           |> List.map (elem -> Nat.toText elem ++ " bottles of pop on the wall")
           |> Text.unlines

       main: '{IO, Exception} ()
       main = do
         bottles = bottlesOfPop 15
         printLine bottle
       ```

    ## Types

       Types in Unison have capital case letters, like `User` or `Service`.

       Anything lowercase in a type signature is a type variable, e.g. the `a`
       in `Optional a` . In other languages that would be `Optional<A>` or
       `Optional[A]`.

       `[a]` is the type of lists, e.g. `[User]` is a list of users.

       `Nat` is the type of positive integers.

       Type signatures appear on the previous line of the definition, with a
       `:` :

       ``` unison
       four : Nat
       four = 4
       ```

    ## Functions

       Functions look like this:

           @source{Nat.inRange}

       The return type is after the last `->` in the signature, so
       `Nat.inRange` takes 3 `Nat` and returns a `Boolean`. Generic functions
       have type variables in their signature as lowercase letters:

       ``` unison
       List.map : (a -> b) -> [a] -> [b]
       ```

       Functions are called via whitespace, with parentheses used for
       precedence:

       ``` unison
       Nat.inRange 4 10 6
       Nat.inRange 4 10 (Nat.increment 5)
       ```

       Lambdas are written as `x -> ...` :

       ``` unison
       List.map (x -> x + 1) [1, 2, 3]
       ```

       The `|>` operator lets you call functions infix:

       ``` unison
       [1, 2, 3]
         |> List.map (x -> x + 1)
         |> List.filter isEven
       ```

       Functions can be defined inside other functions, and type signatures can
       be omitted:

       ``` unison
       List.takeWhile f xs =
         go acc list = ...
         go [] xs
       ```

    ## Abilities in signatures

       Types in the signature with in curly braces, `{Things, Like, This}` are
       the abilities (think, "effects") that the function requires in order to
       run.

       ``` unison
       IO.console.printLine : Text ->{IO, Exception} ()
       Random.bytes : Nat ->{Random} Bytes
       ```

       Functions with abilities are called like regular functions, but the type
       system provides some guard rails by keeping track of which abilities are
       required.

       Functions can also be generic in their ability list, which is also
       indicated by a lowercase type variable:

       ``` unison
       List.map: (a ->{g} b) -> [a] ->{g} b
       Stream.iterate! : (a ->{g} a) -> a ->{g, Stream a} Void
       ```

    ## Thunks

       Unison makes heavy use of thunks, i.e. functions of shape:

       ``` unison
       () ->{SomeAbility} SomeType
       ```

       There is syntactic sugar for thunks. In type signatures, thunks are
       written with a single quote `'`. In definitions, thunks are introduced
       by the `do` keyword followed by a block:

       ``` unison
       myThunk: '{IO, Exception} ()
       myThunk = do
         printLine "Hello"
         printLine "World"
       ```

       It's very common for functions to take thunks:

       ``` unison
       fork : '{IO} a ->{IO} ThreadId
       catchAll : '{IO, Exception} a ->{IO} Either Failure a

       catchAll do
         printLine "forking!"
         fork do
            ...
       ```

       Thunks can be forced by having their name followed by `()`:

       ``` unison
       readLine: '{IO, Exception} Text

       main: '{IO, Exception} ()
       main = do
         a = readLine()
         b = readLine()
         printLine (a ++ b)
       ```

    ## Abilities and handlers

       Abilities are declared with dedicated syntax:

       ``` unison
       ability Store s where
         put : s ->{Store s} ()
         get : '{Store s} s
       ```

       An ability is given behavior by a handler, which transforms the
       computation using that ability.

       Handlers are written as recursive functions that use
       `handle ... with cases` to pattern match on the computation being
       handled:

       ``` unison
       Store.runStore: s -> '{Store s} a ->{IO, Exception} a
       Store.runStore initial p =
         go state p = handle p() with cases
           { a } -> a
           { put newState -> resume } ->
             printLine "Writing state!"
             go newState resume
           { get _ -> resume } ->
             printLine "Getting state!"
             go state do resume state
         go initial p
       ```

       Handlers are just functions, and are called as such:

       ``` unison
       runStore 0 do
         c = get()
         put (increment c)
         put (increment c)
         toText get()
       ```

       [You can read more about abilities here.](https://www.unison-lang.org/docs/fundamentals/abilities/)
  }}

blog.projectBasedUcmCommands.index : Doc
blog.projectBasedUcmCommands.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "New and improved commands for safely undoing changes have landed in the Unison Codebase Manager with the latest release. Here's the backstory for what made them necessary, how to prepare, and why they're a big deal for the Unison workflow."
      )
    , ("date", "2024-07-23")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/thing15.svg")
    , ("status", "published")
    ] }}

  # New, safer commands for managing codebase state

    Prior to the 0.5.25 release, the Unison Codebase Manager (UCM) had a global
    log for undoing codebase changes. This meant that commands like `reflog`
    and `reset-root` could impact code across all projects and branches. The
    updated commands are scoped to a project and branch unless otherwise
    indicated. This makes it easier to manage changes to your codebase,
    improves the performance of the UCM, and reduces the risk of accidentally
    undoing changes in other projects.

    ## 📜 UCM story time

       The Unison codebase model has
       [evolved significantly](https://www.unison-lang.org/blog/projects-are-here/)
       over time to support projects. Originally, the codebase was one large
       monorepo that used namespaces to separate out different workstreams.
       That was okay for small applications and experimentation but required a
       ton of discipline adhering to namespace conventions for anything
       substantial.

       We've since changed to a system where most developer workflows take
       place within a project, but a few of our commands for rewinding codebase
       state retained their global scope. As a refresher, those commands were:

       * `reflog` and `reset-root` - used in tandem to view the log of changes
         and then reset them
       * `undo` - to rewind one step in the reflog
       * `history` - which displayed the term names associated with a change
         set

       Each had their own quirks, so Unison developers fell into one of three
       camps:

       **🔨The Sledgehammer: `reset-root`**

       `reflog` and `reset-root` provided a wide-angle view and nice ergonomics
       for resetting state, but the global nature of the log meant that you ran
       the risk of undoing changes in unrelated projects if you were switching
       between them. You could always retrieve the interleaved code (it's in
       the `reflog` after all) but shuffling through namespace hashes and
       bringing them back to life in your scratch file was not ideal.

       **🎰 The Gambler: `undo`**

       `undo` was handy if you updated some code by mistake and wanted to take
       one step back, but in practice, it was hard to know if `undo` was doing
       the conceptually "correct" thing, since actions like appending metadata
       or changes across projects were recorded in the log.

       {{ docAside {{ You'd use `undo` if you were feeling lucky! 🍀 }} }}

       **🦥 The Slowpoke: `history`**

       `history` was great because it was one of the only commands that would
       give you a list of the terms and types in a particular change set. It
       was not as commonly used because... reasons.

       {{
       Image
         {{
         The history command taking 30 seconds to run
         }}
         {{
         /assets/feed/projectBasedRoots/historyCommand.png
         }}
         (Some
           {{
           The aforementioned reasons, though it should be said this was not
           the norm.
           }}) }}

       {{
       docAside
         {{
         A bonus: issuing `history` provided you some time to get a cup of
         coffee or go for a nice walk.
         }} }}

    ## 🐣 The updated commands and changes

       We're happy to report that the new commands are much more
       straightforward:

       * `reflog` aka `branch.reflog` - shows changes to the codebase scoped to
         a branch.
       * `project.reflog` - shows interleaved `reflog` entries across all
         branches of a project
       * `global.reflog` - shows interleaved `reflog` entries across all
         projects in the codebase
       * `reset` - sets a branch to a previous state. You provide the hash of
         the state you want to return to and an optional branch argument.
       * `history` - shows the names of terms and types impacted by a change to
         the codebase state.
       * `undo` - safe to use! Only un-does one thing and does not impact other
         projects

    ## 💝 The benefits

       In addition to being easier to use, these commands being relative to a
       project means that they will be much snappier! When saving scratch files
       with code that happens to reference deep dependency trees, you'll notice
       a significant boost in speed. Watch expressions and parsing will be much
       faster.

       Another benefit of this feature is that it fixes the odd
       `.__projects.abcd1843729` prefix that would intermittently crop up in
       UCM printouts.

       {{ docAside {{ UCM Team! Here, you dropped this! 👑 }} }}

    ## ⚠️ Caveats and warnings

       This change fully deprecates the old non-project workspace, (accessible
       by the absolute path convention `.old.unison.code.here`). Never fear!
       The UCM will perform a migration for you and the contents of the legacy
       workspace will be migrated to a project called `legacy`.

       After upgrading to the newest version of the UCM, your `reflog` will
       look empty (since it's now a log of something based on the project, not
       the global scope), so if you are in the weeds with a particular change
       that might require a reset,
       __you should get to a good stopping point first.__

       The deprecated version of `reflog` is still technically there, but you
       should [contact the Unison team](https://unison-lang.org/discord) if you
       need to access it.

       The old `reset-root` command is marked as deprecated. Use this at your
       own peril.

       As always, the friendly Unison team is here to help if you need it!
  }}

blog.projectsAreHere.index : Doc
blog.projectsAreHere.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison Projects are here: collaborate, package, and organize your codebase!"
      )
    , ("date", "2023-06-28")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # 🎉 Unison Projects are here: collaborate, package, and organize your
  codebase!

    We've got some exciting news to share with you today: included in the M5a
    release of Unison is our
    [much heralded new feature, Unison projects](https://www.unison-lang.org/whats-new/projects-incoming/).
    The incredible team has been working tirelessly to bring you something that
    will greatly improve the Unison coding experience.

    {{
    docAside
      {{
      [Check out the release notes for version M5 of Unison for a breakdown of
      all the new UCM features.](https://github.com/unisonweb/unison/releases/tag/release%2FM5a)
      }} }}

    As a quick refresher, we've been creating projects as the custom Unison
    solution for a more robust repository and package management system. They
    form the foundation for a lot of new functionality, such as branch-based
    workflows, permissions, releases, and dependency management.

    We've created a walk-through video to give you a tour of some of the new
    features:

    {{
    Special
      (Embed
        (Any
          (Video
            [ MediaSource
                "https://www.youtube.com/embed/K4czM4zChpQ" (Some "youtube")
            ]
            []))) }}

    If you want to learn more about projects, check out our
    [introduction to projects doc](https://www.unison-lang.org/learn/projects/).

    So create some projects and come talk to us about them in the #libraries
    channel in the [Unison slack](https://unison-lang.org/slack). Happy coding!
    🌞
  }}

blog.projectsIncoming.index : Doc
blog.projectsIncoming.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Heads up: Unison is introducing a new codebase abstraction for organizing, packaging, and collaborating on code, Unison \"projects\". This is a high level overview of a few new concepts that will be introduced with the projects feature."
      )
    , ("date", "2023-04-03")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # Unison projects are shipping soon 🚀

    In the next few weeks, we'll be releasing a new abstraction for organizing,
    packaging, and collaborating on code. We're calling it "projects." There
    will be some new UCM commands and Unison Share features to support them.
    This post is to give folks a heads up so you have some idea of what to
    expect.

    Projects will be the basis for a lot of new functionality, such as pull
    requests, permissions (including private projects and multi-user
    collaboration), releases, and dependency management.

    The primary unit for grouping Unison code has thus far been namespaces.
    Namespaces are a bit like versioned directories for Unison code; they can
    contain other namespaces or Unison definitions. Their granularity and
    simplicity has enabled a ton of great work, but arguably we've been
    shoehorning complicated ecosystem needs into the namespace concept. Does
    your library need a log of its releases? Persist it in a namespace! Adding
    a dependency to your code? Put it in a special lib namespace. Contributing
    a feature to a library? Fork the namespace and merge it! All these
    workflows are done with low-level namespace manipulation commands which are
    easy to mess up.

    With projects, we're building more first-class support for these workflows,
    with thoughtfully designed dedicated commands that are easier to use.
    Namespaces aren't going away, they're just going to wear fewer hats.

    That's a bit about __why__ we're introducing projects, let's sketch out
    what they are at a high level. Projects will help segment your Unison code
    into logical repository-like units. A library you've authored, a service
    you maintain, or a company application you contribute to might each be
    defined as separate projects. You'll issue a UCM command to initialize
    them, and the created project will live at the top-level of your codebase.
    {{
    docAside
      {{
      [Here's Simon Højberg's introduction to the vision for Unison projects at
      last year's Unison Forall conference](https://youtu.be/aqLkcI_Yobc).
      }} }}

    Projects can be further segmented by having multiple __branches__. Each
    project will have a "main" branch, but you might also work in a
    "contributor branch" on a feature for another library. With branches,
    projects add a codebase primitive for supporting concurrent work streams.
    That's one step towards a fully-fledged PR process! You'll be able to
    switch between branches of a project, and when you push a branch to Unison
    Share, it will be linked to your Unison Share user.

    {{ docCallout
      None {{
      With the first release of the projects feature you will be able to:

      * Create a new project with the UCM
      * View and switch between your projects in the UCM terminal
      * Create a new branch or switch to an exiting branch in a project
      * Push a project to Unison Share for others to browse and download
      * Clone a project from Unison Share for contributing to it
      * Pull a project from Unison Share for including it as a dependency
      }} }}

    For now, nothing will change about your interactions with existing
    non-project Unison code. You can still jam on Unison code in namespaces
    without the formality of promoting them to projects because we think it's a
    great way to quickly break new ground for programming, and we don't want to
    get in the way of that. 😎 When the projects feature lands we'll be
    supporting contributors with a migration path for their existing libraries.
    A tutorial with the __actual__ UCM commands is forthcoming.

    {{ docCallout
      None {{
      To recap, the key things to remember before projects ship are:

      * Projects are a codebase abstraction for defining libraries and services
      * Projects enable a branch-based developer workflow
      * Projects open the door for pull requests via "contributor branches"
      }} }}

    So consider this is your notice: this is a big change! 🍾 We know it will
    entail some growing pains and have a few rough edges to start. After all,
    the team has basically been creating a code package manager, dependency
    system, changelog, code browsing, and collaboration workflow from the
    ground up. 🤘 Thanks for trying out new things with us!
  }}

blog.reducingChurn.index : Doc
blog.reducingChurn.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison doesn't have library dependency conflicts, and many sources of ecosystem churn just disappear. This fact got a brief mention in the Strange Loop 2019 talk, but that talk didn't make all the benefits totally clear. This article will attempt to highlight some of the more surprising benefits of Unison's approach."
      )
    , ("date", "2020-04-10")
    , ("categories", "viewpoints")
    , ("categories", "learn")
    , ("authors", "paul-chiusano")
    , ("featuredImage", "/assets/thing12.svg")
    ] }}

  # How Unison reduces ecosystem churn

    Unison doesn't have library dependency conflicts, and many sources of
    ecosystem churn just disappear. This fact got a brief mention in
    [the Strange Loop 2019 talk](https://www.youtube.com/watch?v=gCWtkvDQ2ZI),
    but that talk didn't make all the benefits totally clear. This article will
    attempt to highlight some of the more surprising benefits of Unison's
    approach.

    This topic is important because library churn disproportionately affects
    younger language ecosystems and can be a major reason that people wait to
    adopt new stuff: "I'd rather wait until things settle down".

    There’s a basic principle followed by Unison: correct definitions should
    never **require** upgrading. Though this sounds like it should be a given,
    existing language tooling does a poor job here and forces upgrade work for
    things like name changes, moving definitions, repurposing names for a new
    definition (even when the old definition is valid), and more. We can do
    better in Unison.

    ## A lot of churn is artificial

       In language ecosystems, library authors are regularly releasing new
       versions. Every time a new version arrives, any dependent libraries and
       applications need to upgrade if they want the latest features and fixes.
       Sometimes the new version is significantly incompatible with the old
       one, in which case authors will do "point releases" and backport some of
       the improvements to a backward-compatible version, but there’s a limited
       amount of this that can happen and it’s extra work for the maintainers.

       Just keeping up with library version churn can be lots of work. Some
       users are happy to do this because they get new functionality and
       bugfixes; other users are less happy, especially if they're just
       consuming a small and stable portion of a library. "Why am I forced to
       upgrade just because some functions I'm not even using got updated?"
       Library version churn is one reason why people are loath to add new
       dependencies and they resort to "vendoring" (copying and pasting library
       code into their codebase).

       We should not have to force upgrades of correct code. Existing languages
       don't (or can't) uphold this principle because of how they're designed.
       With Unison's design, we can eliminate these needless sources of churn:

       ### Definitions getting renamed or moved

           When a library's definitions change names or move elsewhere (perhaps
           spun off into a separate library), users get a tedious textual
           find/replace task to bring their code up to date. The definition is
           still correct and hasn't changed; it just has a new name. Since
           Unison definitions reference each other by hash instead of by name,
           any moving or renaming breaks no code and generates no upgrade work
           for users.

       ### Incompatible library versions

           Many systems make it inconvenient or impossible to use multiple
           versions of a library in the same codebase, because all the library
           versions "compete" for the same names. That seems silly; why do
           different definitions compete for the same names anyway? Because the
           code is stored as text and all references are by name. If you don't
           use the same names for each version, users will have a bunch of
           manual work to upgrade to the latest version, just like they would
           for any other name change. Unison solves this as before: by
           representing the codebase in a more structured way and referencing
           definitions by hash.

       ### Upgrades of stuff you don't care about

           Tracking dependencies at the level of whole libraries is imprecise
           and generates needless pressure to upgrade. You may be using 3
           functions from Alice’s library and would prefer to hold off on
           upgrades except for bugfixes to the functions you're actually using.
           But there's a problem: If __any__ of the libraries that depend
           transitively on Alice get an upgrade you want, then you must upgrade
           your usage of __all__ these libraries (including Alice's), since
           multiple library versions can't peacefully coexist. This churn
           becomes increasingly likely because libraries batch together lots of
           definitions, fixes, and improvements. In Unison, dependencies are
           tracked at the level of individual definitions, not whole packages.
           Multiple library versions can coexist, so you can grab the latest
           version of a library (to get new stuff you like) and continue using
           the old.

       ### Names getting repurposed

           Names are regularly __repurposed__ to point to new definitions, even
           when the old definitions are still perfectly valid. For instance, a
           library author might make a function a bit more generic by adding an
           extra parameter, or decide to switch the parameter order. That's
           fine, but the old definition was not wrong, so should users be
           forced to upgrade? No.

           Repurposing names is fine; it's hard to come up with good names for
           definitions, so using an old name for a related new definition often
           makes sense. The trouble is that
           __existing tooling doesn't distinguish between repurposing a name
           and upgrading a definition.__ Unison changes that by making a
           distinction:

           1. You can change the name of a definition or repurpose a name as
              often as you like.
           2. You can choose to replace one definition with another, because
              the old definition is buggy or invalid.

           You change or repurpose Unison names just by editing the namespace
           directly with `move.term`, `delete.type`, and related commands in
           the Codebase Manager. Separately, replacements are tracked in Unison
           __patches__ which are built up using distinct commands: `update`,
           `replace.term`, etc. Library authors use patches to let their users
           upgrade code from one version of the library to another. Patches
           identify their replacements by hash instead of by name, so they too
           are unaffected by any name shuffling.

           Though existing tooling conflates these two activities, replacing
           one definition with another (because the old definition is invalid)
           is actually different from repurposing a name (because the authors
           feel a name is better suited for a different definition). Keeping
           these concepts separate eliminates a lot of needless churn and gives
           library authors a lot more options.

    ## Learn more

       If this sounds interesting to you and you'd like more information on how
       it all plays out, either as a library consumer or a library author, see
       the documentation on
       [organizing your codebase](/docs/codebase-organization).
  }}

blog.roadmap.index : Doc
blog.roadmap.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Follow along with Unison's planned improvements and upcoming features for the language, tooling, cloud platform, and ecosystem."
      )
    , ("date", "2023-03-10")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/thing10.svg")
    , ("status", "published")
    ] }}

  # Unison publishes its public roadmap

    [We're excited to announce that we've published our public roadmap!](https://www.unison-lang.org/roadmap/)
    Check it out to see what we're working on now and what we're planning to
    work on in the future.

    Maybe your most wished-for feature is already on the roadmap. (Hello
    simplified update process! 👍) In any case, follow along with us as we work
    to improve the Unison tooling experience and add new features to the
    language.

    [Here's that roadmap link again for you.](https://www.unison-lang.org/roadmap/)
    Happy coding! 🌻
  }}

blog.shareSearchImprovements.index : Doc
blog.shareSearchImprovements.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "It's a search party! 🎊 Unison Share has a snappier search experience — here are some tips for using it."
      )
    , ("date", "2023-06-20")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # Improved search functionality for Unison Share

    Users of [Unison Share](https://share.unison-lang.org) can expect a faster
    experience when searching for Unison terms, thanks to a new search backend.

    If you haven't tried out the search functionality on Unison Share before,
    you should be aware of a few conventions:

    * You can currently only search for terms when inside a particular
      __project__. (You can't search all the projects on Unison Share for their
      copy of {jsonschema.lib.base.data.List.map} from the front page, sorry.)
    * The Unison Share search functionality is designed to find term
      definitions and their docs, not instances where a particular term is
      being called.
    * To search for a term, click, "search" in the project's sidebar or enter
      "/" for a shortcut to the search bar.

    {{
    Image
      {{
      Keyboard shortcuts for Unison Share
      }}
      {{
      /assets/feed/share-search-improvements/keyboardShortcuts.png
      }}
      (Some
        {{
        💡 Psst, did you know that there's a bunch of keyboard shortcuts for
        navigating Unison terms in Unison Share and the Local Codebase UI?
        }}) }}

    ## Here are some helpful search tips from Unison teammate Chris Penner:

       {{
       docAside
         {{
         Any namespace which either has a child namespace called `lib` in it,
         or which is a direct child of a lib namespace is considered a "project
         root" for the search functionality described here.
         }} }}

       {{
       docAside
         {{
         {{
         (Image
           {{
           Image of Unison Share offering to change perspective to the Success
           type.
           }}
           {{
           /assets/feed/share-search-improvements/changePerspective.png
           }}
           (Some {{ Oh Unison Share, if only it were that simple. 🙃 }})) }}
         }} }}

       1. Searches are scoped to the sidebar perspective
          * All searches will be performed from whichever project-root your
            perspective is within.
          * If you're not within any project roots, for example if you're
            search perspective is in your general `public` namespace, then it
            will search all projects reachable within your scratch namespace.
          * If your perspective is within a dependency, e.g.
            `.public.myproject.lib.base.data.List` then it will search within
            that dependency's project-root, in this case it will search in
            `.public.myproject.lib.base`
          * Dependencies of your current project-root are not currently
            included in the search.
       2. Search syntax matters.
          * Each search query is split into segments.
          * Names match a list of segments if each segment appears in the name
            in order, case-insensitively. E.g. The segments `["list", "map"]`
            match the name `base.data.List.foldMap`, but not
            data.''Map.toList''
          * Segments are split up by the following:
            * CamelCase, e.g. foldMap is split into `["fold", "Map"]`, and fM
              is split into `["f", "M"]`
            * Dots, e.g. List.Map -> `["List", ".", "Map"]`
            * Spaces, e.g. List Map -> `["List", "Map"]`

       Go ahead and give it a try! 🌻
  }}

blog.stackTracesM4d.index : Doc
blog.stackTracesM4d.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "To the tune of Ghostbusters: If there's something weird, and it don't look good, who you gonna call? Stack traces!"
      )
    , ("date", "2022-11-21")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/debug.svg")
    , ("status", "published")
    ] }}

  # Unison produces stack traces for errors

    If you haven't upgraded or downloaded the newest version of Unison,
    [M4d](https://www.unison-lang.org/learn/quickstart/#step-1-install-unison),
    it contains several quality of life improvements for users, including but
    not limited to a beloved feature for frustrated developers:
    **stack traces**.

    ## How to invoke stack traces

       A stack trace will be generated upon calls to {Exception.raise} and when
       {base.bug} has been called. It contains the names of the functions that
       have been called en-route to generating the failure, with the last term
       being the entry point to the program.

       **Check it out in action**

       {{
       Image
         {{
         gif of calling functions which produce stack traces
         }}
         {{
         /assets/feed/stackTracesM4d/stacktrace-demo.gif
         }}
         Optional.None }}

       {{
       docAside
         {{
         Fun fact, compiler engineer Dan Doel did this as a "miscellaneous
         task" one week. 🤯 Thanks Dan, we think you're incredible!
         }} }}

       A technical detail worth bearing in mind is that Unison supports
       [tail-call elimination](https://en.wikipedia.org/wiki/Tail_call), so
       functions that are in tail call position are evaluated without growing
       the function call stack. These functions won't show up in the
       stack-trace.

       We hope stack traces will help when you're stuck. Better yet, channel
       your inner Unison teammate, Cody, when he says: "I don't write bugs so
       I've never seen a stack trace." 😂
  }}

blog.summer2023Highlights.index : Doc
blog.summer2023Highlights.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Library highlights from the Unison ecosystem. New releases include utilities for web-protocols and defining web-services, terminal interactions, music and more. Check out the code samples and demos!"
      )
    , ("date", "2023-07-28")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # 🌞 Summer 2023 Unison ecosystem highlights

    The Unison ecosystem has been a hive of activity lately! After the launch
    of [Unison projects](https://www.unison-lang.org/learn/projects/), we've
    seen a number of new libraries materialize. Naturally, we took this as an
    opportunity to make fun things! Check out the demos and code snippets
    below. We hope this ecosystem synopsis inspires you to do the same.

    ## [Hotswapping Unison code](https://share.unison-lang.org/@dfreeman/hotswap)

       Inspiration struck Unison contributor
       [@dfreeman](https://share.unison-lang.org/@dfreeman) in the form of an
       offhand feature request in Unison's community slack. The nerd-sniping
       worked and now we have a library for live-updating Unison code as it's
       running. 🤯 It might have been a speculative idea at the time, but the
       result is [Hotswap](https://share.unison-lang.org/@dfreeman/hotswap): a
       library that enables you to record "placeholder" values in your program
       and then update them live during the program's runtime.

       {{
       docCallout
         (Some {{ 🔥 }})
         {{
         **A demo is worth a thousand words:**

         [We loved this library so much we created a cloneable project with
         steps for instrumenting hotswapping so you can try running it
         yourself!](https://share.unison-lang.org/@rlmark/hotSwapDemo/code/main)

         It's adapted from the excellent video demo in the project's README
         shown below:

         {{
         (Image
           {{
           An animated gif demonstrating a hotswap server that responds as it's
           sent code updates.
           }}
           {{
           https://github.com/typed-ember/glint/assets/108688/510cd588-bc2b-41c7-b058-114d17b8d687
           }}
           (Some
             {{
             Hot-swapping in action
             [from the project's README.](https://share.unison-lang.org/@dfreeman/hotswap)
             }})) }}
         }} }}

       The docs for this library are **fantastic** 🤌 so you can follow along
       with how the library was implemented, understand the caveats for using
       hot-swapping, and dream up new use cases.

    ## [Json Schema](https://share.unison-lang.org/@chuwy/jsonschema)

       Thanks to community member
       [@chuwy](https://share.unison-lang.org/@chuwy), Unison has a libray that
       can [model]({type Schema}), [derive]({derive}), and
       [validate]({Validation.run}) Json Schemas. For folks who have never used
       Json Schemas, they're a way to describe the shape of a Json document and
       [whew... the schema specification is **vast** 😅](https://json-schema.org/draft/2020-12/json-schema-core.html)!
       We're very grateful to have
       [@chuwy's](https://share.unison-lang.org/@chuwy) expertise at work in
       authoring this library. 📚

    ## [Routes](https://share.unison-lang.org/@unison/routes)

       Unison has a new abilities-based library for defining server routes. As
       you're writing Unison web apps, you can use the
       [Routes](https://share.unison-lang.org/@unison/routes) library to define
       how your application should respond if a given route is matched.

       Here's what defining routes looks like:

           @source{_hiRoute, _byeRoute}

       At the edge of your program, you can combine all of your routes together
       and serve them on a port.

           @source{_main}

       {{
       docAside
         {{
         The Routes library is built on top of the
         [URI Parser](https://share.unison-lang.org/@unison/uri-parser)
         library, which is also worth checking out for its extremely cool
         {type Parser} type.
         }} }}

    ## [Midi Sequencer](https://share.unison-lang.org/@alvaroc1/sequencer)

       Take a look at the ever expanding universe that is
       [Alvaro's project list](https://share.unison-lang.org/@alvaroc1), and
       you'll find a new library called
       [Sequencer](https://share.unison-lang.org/@alvaroc1/sequencer) for
       interacting with
       [the MIDI protocol](https://en.wikipedia.org/wiki/MIDI). Sequencer
       enables you to write Unison programs for playing music on Midi devices.

       You know what that means...

       {{
       docCallout
         (Some {{ 🎹 }})
         {{
         **It's time for a demo! 🎉**

         {{
         (Special
           (Embed
             (Any
               (Video
                 [ MediaSource
                     "/assets/feed/summer-2023-highlights/commandLineMusic.mp4"
                     None
                 ]
                 [])))) }}
         }} }}

       If you would like to join the Unison command line band,
       [pull the project here](https://share.unison-lang.org/@rlmark/commandLineKeys)
       or write something brand new using the
       [Sequencer library.](https://share.unison-lang.org/@alvaroc1/sequencer)

    ## [Terminus](https://share.unison-lang.org/@runarorama/terminus)

       Runar's terminal library is going to radically increase the amount of
       time you spend playing command line games while your non-Unison code
       compiles.

       Terminus provides a set of functions for interacting with the terminal,
       including the ability to write text to the screen, read input from the
       user, and store, move, or reset the cursor at different screen
       locations.

       {{
       docAside
         {{
         Terminus makes use of another Runar creation behind the scenes:
         [Signals](https://share.unison-lang.org/@runarorama/signals) - helpful
         utilities for communicating between threads. Check it out at work in
         the implementation for the {type Input} ability.
         }} }}

       {{
       docCallout
         (Some {{ 🐍 }})
         {{
         The terminus library ships with
         [an example snake game](https://share.unison-lang.org/@runarorama/terminus/code/releases/0.0.1/latest/namespaces/examples/snake).
         Just pull the project and enter `run examples.snake.main` in the UCM
         to start playing.
         }} }}

    ## [TLS simple](https://share.unison-lang.org/@runarorama/tls-simple)

       TLS primitives have existed in Unison's standard lib for a while, but
       [@runarorama](https://share.unison-lang.org/@runarorama) recently added
       a library that makes it easier to send encrypted messages over a secure
       channel in Unison. The TLS library is build atop a new TCP server
       library, also authored by Runar. Rather than managing TCP sockets
       yourself, you can use more ergonomic functions like {Tls.serve} and
       {Tls.connect}.

    ## [Unison tree-sitter grammar](https://github.com/kylegoetz/tree-sitter-unison)

       [Tree-sitter](https://github.com/tree-sitter/tree-sitter) is an
       open-source parsing library that can be used to build syntax
       highlighting, code folding, and other code editing features. If you've
       ever wished that your IDE could be "smarter" or more syntactically aware
       about its suggestions, tree-sitter exists to help languages support
       those features. Many programming languages publish tree-sitter grammars

       Unison's tree-sitter grammar, written by community member
       [Kyle Goetz](https://github.com/kylegoetz) is an __impressive__ feat.
       Unison's grammar is complex and Kyle dove into the Haskell code, combed
       through our language guide and documentation, and we can only imagine
       spent many hours working to support all of Unison's unique language
       features.

       We can't wait to incorporate this grammar into our IDE's. Thanks Kyle!

    ## [Web Sockets](https://share.unison-lang.org/@dfreeman/websockets)

       Unison contributor
       [@danfreeman](https://share.unison-lang.org/@dfreeman) has released a
       library for working with web sockets in Unison. Web sockets enable both
       the client and server to send and receive information in a two-way data
       stream. If you've always wondered how web-sockets work, check out the
       [websockets.serve](https://share.unison-lang.org/@dfreeman/websockets/code/releases/1.0.0/latest/terms/serve)
       function to see how http requests are upgraded to web-socket
       connections.

       The ecosystem is filling out with fundamental protocol libraries like
       this one. They're easy to take for granted if you've worked in older
       languages, so it's nice to be able to see their foundations in Unison.

    ## [XML Soup](https://share.unison-lang.org/@unison/xml/code/releases/1.1.0/latest/types/Soup)

       For your web-scraping needs,
       [@runarorama](https://share.unison-lang.org/@runarorama) has added the
       [Soup](https://share.unison-lang.org/@unison/xml/code/releases/1.1.0/latest/types/Soup)
       library for parsing and querying XML documents. It's nestled inside of a
       larger Unison [XML](https://share.unison-lang.org/@unison/xml) library,
       but {type Soup} is a user friendly interface for traversing through XML
       so its worth callling out separately.

       Fun fact: The Unison blog itself publishes an Atom XML feed:
       https://www.unison-lang.org/feed.xml. You can use the Soup library to
       parse and query the feed. Maybe it's time for a Unison RSS reader
       project? 🤔

           @source{_getPosts}

    ## [Plotter library](https://share.unison-lang.org/@alvaroc1/plotter)

       Unison's tooling for making beautiful charts and graphs is getting off
       the ground thanks to
       [Alvaro's plotter library](https://share.unison-lang.org/@alvaroc1/plotter).

       {{
       docCallout
         (Some {{ 📈 }})
         {{
         **Now you can move from using this...**

         {{
         (Image
           {{
           A Texas Instruments 83 graphing calculator
           }}
           {{
           /assets/feed/summer-2023-highlights/TI-83+.png
           }}
           None) }}

         **To using this...**

         {{
         (Image
           {{
           An image of equations graphed on a 2d plane using the plotter
           library
           }}
           {{
           /assets/feed/summer-2023-highlights/plotImage.png
           }}
           (Some {{ Ahhh yes... math 💀 }})) }}
         }} }}

  # 😄 Thank you to our contributors and community

    We're constantly wowed by the the ways that folks are using Unison's unique
    features to build new tools and libraries. Give our library author's a
    round of applause, or better yet, use their contributions to make something
    awesome. Happy coding!

    {{
    Image
      {{
      An animated gif of running a Unison program that prints the Unison logo
      to the terminal
      }}
      {{
      /assets/feed/summer-2023-highlights/unisonTerminal.gif
      }}
      None }}
  }}

blog.summer2023Highlights._byeRoute : '{Route} ()
blog.summer2023Highlights._byeRoute = do
  use Parser /
  use Text ++
  name = route GET (s "bye" / Parser.text)
  ok.text ("👋 bye " ++ name)

blog.summer2023Highlights._hiRoute : '{Route} ()
blog.summer2023Highlights._hiRoute = do
  use Parser /
  use Text ++
  name = route GET (s "hello" / Parser.text)
  ok.text ("👋 hello " ++ name)

blog.summer2023Highlights._main : '{IO, Exception} ()
blog.summer2023Highlights._main = do
  use Route <|>
  stop = serveSimple (_hiRoute <|> _byeRoute) 8080
  printLine "Server running. Press <enter> to stop."
  _ = readLine
  stop()

blog.typeBasedSearch.index : Doc
blog.typeBasedSearch.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "A peek behind the scenes at how we built type-directed search for Unison Share. Follow along as we discuss the kinds of queries we wanted to optimize for and how we designed the search functionality to fit them."
      )
    , ("date", "2024-08-14")
    , ("authors", "chris-penner")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/feed/typedBasedSearch/typeBasedSearchEx.png")
    , ("status", "published")
    ] }}

  # Behind the Scenes on Type Directed Search for Unison Share

    Hello! Today we'll be looking into type-based search, what it is, how it
    helps, and how to build one for the
    [Unison programming language](https://www.unison-lang.org/) at production
    scale.

    ## Motivating type-directed search

       If you've never used a type-directed code search like
       [Hoogle](https://hoogle.haskell.org/) it's tough to fully understand how
       useful it can be. Before starting on my journey to learn Haskell I had
       never even thought to ask for a tool like it, now I reach for it every
       day.

       Many languages offer some form of code search, or at the very least a
       package search. This allows users to find code which is relevant for the
       task they're trying to accomplish. Typically you'd use these searches by
       querying for a natural language phrase describing what you want, e.g.
       `"Markdown Parser"`.

       This works great for finding entire packages, but searching at the
       package level is often far too rough-grained for the problem at hand. If
       I just want to very quickly remember the name of the function which
       lifts a {type Char} into a {type Text}, I already know it's probably in
       the {type Text} package, but I can save some time digging through the
       package by asking a search precisely for definitions of this type.
       Natural languages are quite imprecise, so a more specialized
       query-by-type language allows us to get better results faster.

       If I search using Google for "javascript function to group elements of a
       list using a predicate" I find many different functions which do
       **some** form of grouping, but none of them quite match the shape I had
       in mind, and I need to read through blogs, Stack Overflow answers, and
       package documentation to determine whether the provided functions
       actually do what I'd like them to.

       In Haskell I can instead express that question using a type! If I enter
       the type `[a] -> (a -> Bool) -> ([a], [a])` into Hoogle I get a list of
       functions which match that type exactly, there are few other operations
       with a matching signature, but I can quickly open those definitions on
       Hackage and determine that `partition` is exactly what I was looking
       for.

       Hopefully this helps to convince you on the utility of a type-directed
       search, though it does raise a question: if type-directed search is so
       __useful__, why isn't it more **ubiquitous**?

       Here are a few possible reasons this could be:

       * Some languages lack a sufficiently sophisticated type-system with
         which to express useful queries
       * Some languages don't have a centralized package repository
       * Indexing every function ever written in your language can be
         computationally expensive
       * It's not immediately obvious how to implement such a system

       Read on and I'll do what my best to help with that last limitation.

    ## Establishing our goals

       Before we start building anything, we should nail-down what our search
       problem actually is.

       Here are a few goals we had for the Unison type-directed search:

       * It should be able to find functions based on a partial type-signature
       * The names given to type variables shouldn't matter.
       * The ordering of arguments to a function shouldn't matter.
       * It should be fast
       * It should should scale
       * It should be **good**...

       The last criterion is a bit subjective of course, but you know it when
       you see it.

    ## The method

       It's easy to imagine search methods which match **some** of the required
       characteristics. E.g. we can imagine iterating through every definition
       and running the typechecker to see if the query unifies with the
       definition's signature, but this would be **far** too slow, and wouldn't
       allow partial matches or mismatched argument orders.

       Alternatively we could perform a plain-text search over rendered type
       signatures, but this would be very imprecise and would break our
       requirement that type variable names are unimportant.

       Investigating prior art, Neil Mitchell's excellent Hoogle uses a linear
       scan over a set of pre-built function-fingerprints for whittling down
       potential matches. The level of speed accomplished with this method is
       quite impressive!

       In our case, Unison Share, the code-hosting platform and package manager
       for Unison is backed by a Postgres database where all the code is
       stored. I investigated a few different Postgres index variants and
       landed on a GIN (Generalized inverted index).

       If you're unfamiliar with GIN indexes the gist of it is that it allows
       us to quickly find rows which are associated with any given combination
       of search tokens. They're typically useful when implementing full-text
       searches, for instance we may choose to index a text document like the
       following:

       ``` raw
       postgres=# select to_tsvector('And what is the use of a book without pictures or conversations?');
                             to_tsvector
       -------------------------------------------------------
       'book':8 'convers':12 'pictur':10 'use':5 'without':9
       (1 row)
       ```

       The generated lexemes represent a fingerprint of the text file which can
       be used to quickly and efficiently determine a subset of stored
       documents which can then be filtered using other more precise methods.
       So for instance we could search for `book & pictur` to very efficiently
       find all documents which contain at least one word that tokenizes as
       `book` AND any word that tokenizes as `pictur`.

       I won't go too in-depth here on how GIN indexes work as you can consult
       the excellent
       [Postgres documentation](https://www.postgresql.org/docs/current/gin.html)
       if you'd like a deeper dive into that area.

       Although our problem isn't exactly full-text-search, we can leverage GIN
       into something similar to search type signatures by a set of attributes.

       The attributes we want to search for can be distilled from our
       requirements; we need to know which types are mentioned in the
       signature, and we need some way to **normalize** type variables and
       argument position.

       Let's come up with a way to **tokenize** type signatures into the
       attributes we care about.

    ## Computing Tokens for type signature search

       ### Mentions of concrete types

           If the user mentions a concrete type in their query, we'll need to
           find all type signatures which mention it.

           Consider the following signature: `Text.take : Nat -> Text -> Text`

           We can boil down the info here into the following data:

           * A type called {type Nat} is mentioned once, and it does **NOT**
             appear in the return type of the function.
           * A type called {type Text} is mentioned twice, and it **does**
             appear in the return type of the function.

           There really aren't any rules on how to represent lexemes in a GIN
           index, it's really just a set of string tokens. Earlier we saw how
           Postgres used an English language tokenizer to distill down the
           essence of a block of text into a set of tokens; we can just as
           easily devise our own token format for the information we care
           about.

           Here's the format I went with for our search tokens:
           `<token-kind>,<number-of-occurrences>,<name|hash|variable-id>`

           So for the mentions of {type Nat} in the signature of `Text.take` we
           can build the token: `mn,1,Nat`. It starts by namespacing the token
           with the type of search it's meant for (`mn` for Mention by Name).
           We store all tokens in the same `tsvector` column, so this prevents
           any potential conflicts between tokens whose data would otherwise be
           the same.Next I include the number of times it's mentioned in the
           signature followed by its fully qualified name with the path
           **reversed**.

           In this case {type Nat} is a single segment, but if the type were
           named `data.JSON.Array` it would be encoded as `Array.JSON.data.`

           Why? Postgres allows us to do **prefix** matches over tokens in GIN
           indexes. This allows us to search for matches for any valid suffix
           of the query's path, e.g. `mn,1,Array.*`, `mn,1,Array.JSON.*` or
           `mn,1,Array.JSON.data.*` would all match a single mention of this
           type, which can be useful when disambiguating common type names,
           e.g. you can search for `oauth.Config` separately from `http.Config`
           or `cloud.Config` for instance.

           Users don't always know **all** of the arguments of a function
           they're looking for, so we'd love for partial type matches to still
           return results. This also helps us to start searching for and
           displaying potentially relevant results while the user is still
           typing out their query.

           For instance `Nat -> Text` should still find `Text.take`, so to
           facilitate that, when we have more than a single mention we make a
           separate token for each of the `1..n` mentions. E.g. in
           `Text.take : Nat -> Text -> Text` we'd store both `mn,1,Text` AND
           `mn,2,Text` in our set of tokens.

           We can't perform arithmetic in our GIN lookup, so this method is a
           workaround which allows us to find any type where the number of
           mentions is greater than or equal to the number of mentions in the
           query.

       ### Type mentions by hash

           [This is Unison after all](https://www.unison-lang.org/docs/the-big-idea/),
           so if there's a specific type you care about but you don't care what
           the particular package has named that type, or if there's even a
           specific **version** of a type you care about, you can search for it
           by hash: E.g. `#abcdef -> #ghijk`. This will tokenize into
           `mh,1,#abcdef` and `mh,1,#ghijk`. Similar to name mentions this
           allows us to search using only a prefix of the actual hash.

       ### Handling return types

           Although we don't care about the order of **arguments** to a given
           function, the return-type **is** a very high value piece of
           information. We can add additional tokens to track every type which
           is mentioned in the return type of a function by simply adding an
           additional token with an `r` in the 'mentions' place, e.g.
           `mn,r,Text`

           We'll use this later to improve the scoring of returned results, and
           may in the future allow performing more advanced searches like "Show
           me all functions which produce a value of this type", i.e. functions
           which return that type but don't accept it as an argument, or
           perhaps "Show me all handlers of this ability", which corresponds to
           all functions which accept that ability as an argument but **don't**
           return it, e.g. `'mn,1,Stream' & (! 'mn,r,Stream')`.

           A note on higher-kinded types and abilities like `Map Text Nat` and
           `a -> {Exception} b`, we simply treat each of these as its own
           concrete type mention. The system could be expanded to include more
           token types for each of these, but one has to be wary of an
           explosion in the number of generated tokens and in initial testing
           the search seems to work quite well despite no special treatment.

       ### Mentions of type variables

           Concrete types are covered, but what about type variables? Consider
           the type signature: `const: b -> a -> b`.

           This type contains `a` and `b` which are **type variables**. The
           names of type variables are not important on their own, you can
           rename any type variable to anything you like as long as you
           consider its scope and rename all the mentions of the same variable
           within its scope.

           To normalize the names of type variables I assign each variable a
           numerical ID instead. In this example we may choose to assign `b`
           the number `1` and `a` the number `2`. However, we have to be
           careful because we **also** want to be indifferent with regard to
           argument order. A search for `a -> b -> b` should still find
           `const`! if we assigned `a` to `1` and `b` to `2` according to the
           order of their appearance we wouldn't have a match.

           To fix this issue we can simply sort the type variables according to
           their number of **occurrences**, so in this example `a` has fewer
           occurrences than `b`, so it gets the lower variable ID.

           This means that both `a -> b -> b` and `b -> a -> b` will tokenize
           to the same set of tokens: `v,1,1` for `a`, and `v,1,2`, `v,2,2`,
           and `v,r,2` for `b`.

    ## Parsing the search query

       We could require that all queries are properly formed type-signatures,
       but that's quite restrictive and we'd much rather allow the user to be a
       bit **sloppy** in their search.

       To that end I wrote a custom version of our type-parser that is
       extremely lax in what it accepts, it will attempt to determine the arity
       and return type of the query, but will also happily accept just a list
       of type names. Searching for `Nat Text Text` and `Nat -> Text -> Text`
       are both valid queries, but the latter will return better results since
       we have information about both the arity of the desired function and the
       return type. Once we've parsed the query we can convert it into the same
       set of tokens we generated from the type signatures in the codebase.

    ## Performing the search

       After we've indexed all the code in our system (in Unison this takes
       only a few minutes) we can start searching!

       For Unison's search I've opted to require that each occurrence in the
       query MUST be present in each match, however for better partial
       type-signature support I do include results which are missing specified
       return types, but will rank them lower than results with matching return
       types in the results.

       Other criteria used to score matches include:

       * Types with an arity closer to the user's query are ranked higher
       * How complex the type signature is, types with more tokens are ranked
         lower.
       * We give a slight boost to some core projects, e.g. Unison's standard
         library `base` will show up higher in search results if they match.
       * You can include a text search along with your type search to further
         filter results, e.g. `map (a -> b) -> [a] -> [b]` will prefer finding
         definitions with `map` somewhere in the name.
       * Queries can include a specific user or project to search within to
         further filter results, e.g. `@unison/cloud Remote`

    ## Summary

       I hope that helps shed some light on how it all works, and perhaps will
       help others in implementing their own type-directed-search down the
       road!

       Now all that's left is to go
       [try out a search or two](https://share.unison-lang.org/) :)

       If you're interested in digging deeper, Unison Share, and by-proxy the
       entire type-directed search implementation, is all Open-Source, so go
       check it out! It's changing and improving all the time, but
       [this module](https://github.com/unisoncomputing/share-api/blob/6ee875db4ac35156733a0f2c9349bc528736243f/src/Share/Postgres/Search/DefinitionSearch/Queries.hs)
       would be a good place to start digging.

       Let us know in the [Unison Discord](https://unison-lang.org/discord) if
       you've got any suggested improvements or run into any bugs. Cheers!
  }}

blog.ucm0523.index : Doc
blog.ucm0523.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The latest Unison release, version 0.5.23, is now available. This release includes some changes to the syntax for forcing delayed computations, improvements to the `todo` command, and several bug fixes."
      )
    , ("date", "2024-06-28")
    , ("authors", "rebecca-mark")
    , ("categories", "changelog")
    , ("status", "published")
    ] }}

  # Unison version 0.5.23 is out!

    This release includes some treats for everyday Unison users, like new
    syntax for forcing delayed computations, and a few fixes to the `merge`
    command. Check it out!

    ## Everyday-impact changes

       ❣️ Unison supports an **additional** syntax for forcing delayed
       computations. `foo()` is equivalent to `!foo`. You can write either
       syntax but `foo()` is preferred by the UCM when displaying things.

       ✅ The `todo` UCM command will tell you when you leave
       `todo "implement me"` around in your code. It also prints out name
       conflicts, if you end up with `foo#abc` and `foo#123` in your codebase,
       it'll tell you about that.

    ## Fixes and quality of life improvements

       🐜 The `merge` command received several bug fixes. If you experienced
       constructors being deleted or unnamed dependencies (hashes in your
       codebase) occurring after a `merge`, this release should help.

       🦺 Fixed a situation where the typechecker missed catching a disallowed
       ability. If an enclosing function does not permit a generic ability, you
       shouldn’t be able to call a function with an arbitrary ability inside of
       it!

       🔄 Fixed an issue where long ability lists in signatures created a
       round-trip printer bug. Some of us really took it to heart that
       Abilities compose. :sweat_smile:

    ## Deprecations and less common situations

       🪡 Patches are now hidden from `ls` as part of their continuing
       deprecation. (What are patches, you ask? Shh… don’t worry about it.)

       💤 Fixed a bug for sleeping with a large `Nat` value. You can write that
       Rip Van Winkle simulator program now.

       🪶 The team squashed some docs roundtrip bugs when header elements,
       `# Like this` , were included in tables and callouts.

       ### Share the news:

           * [Twitter](https://x.com/unisonweb/status/1806057418524094928)
           * [Mastodon](https://fosstodon.org/@unison/112684736057052117)
           * [LinkedIn](https://www.linkedin.com/posts/unison-computing_release-release0523-unisonwebunison-activity-7211823120746172416-sa_7?utm_source=share&utm_medium=member_desktop)
           * [Full release notes](https://github.com/unisonweb/unison/releases/tag/release%2F0.5.23)
  }}

blog.ucm0525.index : Doc
blog.ucm0525.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "This release includes a huge effort to scope the remaining UCM commands to Unison projects. It has some far-reaching changes and big quality-of-life improvements for managing codebase state."
      )
    , ("date", "2024-07-23")
    , ("authors", "rebecca-mark")
    , ("categories", "changelog")
    , ("status", "published")
    ] }}

  # UCM version 0.5.25 is here

    This release has some far-reaching changes and big quality-of-life
    improvements for managing codebase state:

    **New project-based scoping for UCM commands**

    Prior to the 0.5.25 release, the Unison Codebase Manager (UCM) had a global
    log for undoing codebase changes. We’ve revamped the core experience of
    managing codebase history so that the updated UCM commands are scoped to a
    project or named appropriately.

    🪵 `reflog` aka `branch.reflog` shows the history of the current branch.

    `⏪ reset #someHash /optionalBranch` resets a branch to the given state.

    🗂️ `project.reflog` shows reflog entries across all branches in the
    project.

    🌐 `global.reflog`shows reflog entries across all projects in the codebase.

    **New features and improvements**

    🔝 Absolute paths now refer to the root of the project

    🌳 More commands now accept paths/names from other branches in the form
    `/branch:path.in.project`

    🏎️ Increased scratch file parsing speed (faster watch expressions!)

    ✍️ Error message improvements

    **Warnings** - **please read**

    🏗️ This deprecates the old non-project workspace (it used to be accessible
    from an absolute path like `.old.legacy.stuff`) Everything in the
    non-project legacy code space will be moved to a project called “legacy”
    for you. (Thanks UCM!)

    ✋ After upgrading to the newest version of the UCM, your `reflog` will look
    empty (since it's now a log of something based on the project, not the
    global scope).

    👽 The old `reset-root` command is deprecated. Using it could lead to weird
    codebase states.

    🪿 This version will perform a codebase migration

    **Community Contributions**

    🏆 With gratitude to new UCM contributor
    [Eduard](https://github.com/neduard) and the continued hard work of the UCM
    team!

    **Share the news**

    * [Link to the full release notes](https://github.com/unisonweb/unison/releases/tag/release%2F0.5.25)
    * [Install instructions here](https://www.unison-lang.org/docs/quickstart/#installation-options?utm_content=release)
    * [Twitter](https://x.com/unisonweb/status/1815846867701215303)
    * [Mastodon](https://fosstodon.org/@unison/112837696191352957)
  }}

blog.ucm0526.index : Doc
blog.ucm0526.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "The latest version of Unison is here! This release has some nice UX improvements for everyday users of Unison, like a new rules for operator precedence, and a few bug fixes for ucm commands like merges and updates."
      )
    , ("date", "2024-09-06")
    , ("authors", "rebecca-mark")
    , ("categories", "changelog")
    , ("status", "published")
    ] }}

  # UCM version 0.5.26

    ## New features

       ❣️ We introduced operator precedence rules to the langauge, (so you can
       use fewer parens when doing things like writing boolean expressions!)

       {{
       docAside
         {{
         [This table is particularly nice as a reference for the new precedence
         rules](https://www.unison-lang.org/docs/language-reference/syntactic-precedence-operators-prefix-function-application/#operator-precedence)
         }} }}

       📇 We added the namespace directive for prefixing terms and types:

       ``` unison
       namespace brevity.is.the.soul.of

       type Wit = Wit Text

       -- versus --

       type brevity.is.the.soul.of.Wit = Wit Text
       ```

       🔢 We added support for writing binary numeric literals with the `0b`
       prefix: `0b101 == 5`

       🧟‍♂️ We revived `debug.find.global` and `debug.names.global` commands.
       (`find` and `names` are normally scoped to a project, this lets you
       search across all your projects.)

       📋 Better organization of the scratch file on failed updates - so you’ll
       have an easier time resolving conflicts.

    ## Major Fixes:

       * Improvements when running the `merge` command:
         * Fix for preserving type identities during `merge`.
         * Fix to LCA calculation that was misclassifying some fast-forward
           merges as regular merges.
       * Fixed an issue where out-of-date code would `run` after an `update`.

    ## Minor Fixes & Improvements:

       * Fixed a kind-checking bug that didn’t treat ability sets as an ability
       * Uppercase identifiers in patterns are now treated as constructors.
       * Sub-namespaces starting with `_` are now supported.
       * Various bug fixes for the transcript parser and LSP.
       * Fixed Unison Local launch issues on Windows.
       * Tweaked error messages for better clarity.

    ## New Community Contributors

       🐡 With gratitude to [@puffnfresh](https://github.com/puffnfresh) for
       fixing the Windows UI load issue in
       [#5288](https://github.com/unisonweb/unison/pull/5288)

       💯 Thank you to [@SimaDovakin](https://github.com/SimaDovakin) for adding
       the binary number literal notation
       [#5294](https://github.com/unisonweb/unison/pull/5294)

    ## Share the news

       * [Mastodon](https://fosstodon.org/@unison/113092860500529986)
       * [Twitter](https://x.com/unisonweb/status/1832177382721016154)
       * [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7237943083974156288)
       * [Full release notes](https://github.com/unisonweb/unison/releases/tag/release%2F0.5.26)
  }}

blog.ucm0527.index : Doc
blog.ucm0527.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison version 0.5.27 has arrived. This release includes a new command for searching through text or numeric literals in your codebase, and numerous fixes to type-directed name resolution and pretty printing."
      )
    , ("date", "2024-10-02")
    , ("authors", "rebecca-mark")
    , ("categories", "changelog")
    , ("status", "published")
    ] }}

  # UCM version 0.5.27

    ## New features

       This release adds text and numeric literal search in UCM. Search your
       codebase for strings and numeric constants with the experimental
       `text.find` command. Now you can `text.find "MyErrorString"` as part of
       your debugging process.

       {{
       Image
         {{
         A gif of entering the text.find command in the UCM
         }}
         {{
         /assets/feed/ucm-0527/textFindExample2.gif
         }}
         (Some {{ The text-based search in action }}) }}

    ## 🛠️ Fixes & UX improvements

       * Numerous fixes to pretty printing and name resolution logic
         * The experience of writing Unison code with inferred types should be
           more predictable
         * You should experience fewer “this term is ambiguous” errors when the
           term in question happens to have the same name as something in your
           indirect dependencies
       * Fixed handling of empty doc blocks
       * Fixes to parenthesizing and line-wrapping expressions involving
         operators

    ## 🐎 Speedups

       * Numerous optimizations in the standard runtime
       * Bugfixes and speedups for the JIT runtime

       [Full release notes here](https://github.com/unisonweb/unison/releases/tag/release%2F0.5.27)
  }}

blog.ucm0528.index : Doc
blog.ucm0528.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison version 0.5.28 is here. This release features a new workflow for the `edit` command and native ARM64 builds for Apple Silicon systems."
      )
    , ("date", "2024-11-14")
    , ("authors", "rebecca-mark")
    , ("categories", "changelog")
    , ("status", "published")
    ] }}

  # UCM version 0.5.28

    ## 🐣 New features

       **Apple Silicon builds**

       We now offer native builds for Apple Silicon (M1/M2) macOS
       architectures. To install Unison on an Apple Silicon machine, you no
       longer need to use Rosetta emulation.

       Homebrew installs will automatically detect your architecture and
       install the correct version of Unison, or you can manually download the
       Apple Silicon build:

       ``` raw
       mkdir -p unisonlanguage && cd unisonlanguage
         curl -L https://github.com/unisonweb/unison/releases/latest/download/ucm-macos-arm64.tar.gz \
           | tar -xz
         ./ucm
       ```

       **Enhanced `edit` command**

       The edit workflow has been refined:

       It used to be that entering `edit aTerm` would bring the term into your
       scratch file, appending a fold `---` to the term to give you a fresh
       workspace to make your changes. However, if you were working on a series
       of definitions that were still in-flight, you'd have to scroll down to
       remove the fold to continue working. This was a bit cumbersome since
       most of us work iteratively on large problem spaces, adding definitions
       as we go.

       The new behavior is as follows:

       * `edit` will add definitions to your __current__ fold by default. The
         desired `edit` targets will simply be put at the top of your working
         file.
       * `edit.new` will create a new fold if you want a fresh section for your
         changes.

    ## 🛠️ UX improvements and speed-ups

       * Improved branch sorting with fzf
         * We've fine-tuned branch navigation: now, the fzf search prioritizes
           branches in your current project, sorting them to the bottom for
           easier access. This should help you find the branches you’re
           actively working on more efficiently.
       * Pure top-level definitions are cached for faster runtime performance
         * Before this change, all pure top-level definitions were evaluated at
           every call site, which was unnecessary overhead. Now we detect these
           using type info from the codebase. For example, a top-level
           definition performing `IO` wouldn't be cached, but one which just
           returns a large string can safely be cached, and references to the
           definition will be replaced with the cached value. This should
           result in a noticeable speedup for many workloads.
       * Fix for `namespace` and `use` clauses in scratch files
         * We've resolved an issue where a `namespace` directive followed by a
           `use` clause in scratch files would not parse in Unison. Now, these
           clauses will be correctly applied to the definitions in your scratch
           file. `namespace` will open up a block which adds a prefix to all
           the definitions that follow it, and `use` will import definitions
           from other namespaces for use in your program.

    ## 🔮 Coming soon: mergetool support

       One of the most anticipated features on the horizon is mergetool
       support. This will simplify resolving merge conflicts within Unison,
       offering a better experience when working with branches and
       collaborating with others. Stay tuned for more updates.

       [Full release notes here](https://github.com/unisonweb/unison/releases/tag/release%2F0.5.28)
  }}

blog.unisonServicesPreview.index : Doc
blog.unisonServicesPreview.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "We've developed a nicer way to build microservices in Unison. This post is a quick preview. This hasn't been released yet, and some details may change, but it's coming soon!"
      )
    , ("date", "2023-04-14")
    , ("authors", "paul-chiusano, fabio-labella")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/unison-services-preview.svg")
    , ("status", "published")
    ] }}

  # Reimagining the microservice: an early preview

    We've developed a nicer way to build microservices in Unison. This post is
    a quick preview of what you can expect.

    {{
    docCallout
      (Some {{ 🧪 }})
      {{
      This feature hasn't been released yet, and some details may change, but
      it's coming soon! If you like the sound of this, you can join the
      [unison.cloud](https://www.unison.cloud) waitlist.
      }} }}

    Building a microservice-powered backend today typically means taking on a
    lot of work that's not your application's business logic, and isn't very
    interesting or differentiated. For instance:

    * Packaging a particular version of your service into a container image
    * Deploying that container to some infrastructure where it can be run
    * Managing communication between services, via JSON, HTTP, protocol
      buffers, and the like
    * Dealing with serialization code at the boundary between the service and
      some durable storage layer
    * Ensuring proper registration, discovery, and communication between
      services using appropriate service discovery patterns, tools, and
      platforms
    * Handling failure and resiliency, for example in long-running workflows

    Wouldn't it be nice if you could spend less time on these activities, and
    more time on the stuff that matters for your application?

    ## A simple "Hello world" service

       Let's have a look at a simple "Hello world" microservice (we'll just say
       "service" in the rest of this post), written and deployed to
       [Unison Cloud](https://www.unison.cloud) with a few lines of code:

       ``` unison
       hello : HttpRequest -> HttpResponse
       hello req = HttpResponse.ok (Body (Text.toUtf8 "Hello, world!"))

       deployHelloWorld = do cloud.services.http.deploy hello
       ```

       The service's logic is just a regular function which accepts an
       `HttpRequest` and returns an `HttpResponse`. We also use regular Unison
       code to deploy the service.

       Doing `run deployHelloWorld` in UCM will create and deploy the service:

       ``` haskell
       scratch/main> run deployHelloWorld

         Service deployed at https://3d03c8e7d82f1f4211e4d7762632c68.services.unison.cloud
         Visit https://services.unison.cloud to see all your running services.

         ServiceHash 0xs3d03c8e7d82f1f4211e4d7762632c68
       ```

       There's no packaging step, no building containers, or anything like
       that. You just call a function in the Unison Cloud API to deploy the
       service. Unison automatically uploads your function and all of its
       dependencies to Unison Cloud, caching them on the server.

       This service is now live on the internet. It's just like any other HTTP
       service and we can call it from the browser or from any other language.
       For instance, here's Python:

       ``` python
       import requests

       url = "https://3d03c8e7d82f1f4211e4d7762632c68.services.unison.cloud"
       response = requests.get(url)

       if response.status_code == 200:
         print(response.text)
       else:
         print("Error: ", response.status_code)
       ```

       Deployment of services takes mere seconds, and the
       [Unison Cloud](https://unison.cloud) implementation of services doesn't
       actually use any resources until the service is called. The platform
       will run and scale the service for you, and coming soon, services will
       even be JIT-compiled for speedy performance.

    ## Updating a service

       Let's make a trivial change to our service and redeploy it in seconds:

       ``` unison
       deployHelloWorld2 = do
         logic req = HttpResponse.ok (Body (Text.toUtf8 "👋, world!"))
         cloud.services.http.deploy logic
       ```

       Notice that the URL is different:

       ``` raw
       scratch/main> run deployHelloWorld

         Service deployed at https://0318cef3bf71ca76d9228e6d17f29bb21a.services.unison.cloud
         Visit https://services.unison.cloud to see all your running services.

         ServiceHash 0xs0318cef3bf71ca76d9228e6d17f29bb
       ```

       By default, service URLs are based on `ServiceHash`, which is a hash of
       the service implementation. Using hashes as the identity of a service
       means that services are immutable and content-addressed: you don't
       modify a service, you instead deploy a new one.

       We provide a separate layer for stably-named services whose
       implementations can evolve over time. (More on that in future posts)

       Content-addressing is
       [a recurring theme for Unison](https://www.unison-lang.org/learn/the-big-idea/)
       and content-addressed services have some nice properties. For instance,
       service deployment is idempotent, and we can deploy as many versions of
       the "same" service as we like without these versions interfering and
       without needing to set up multiple staging environments.

    ## Services can use effects

       Services don't have to just be pure functions from `HttpRequest` to
       `HttpResponse`. They can do lots of things, by leveraging Unison's
       [abilities](https://www.unison-lang.org/learn/fundamentals/abilities/):

       * They can perform distributed computation using the
         [`Remote`](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/distributed/latest)
         ability. Need to spawn a big map reduce job on the fly in response to
         a service request? Services can do that.
       * They can access secrets and configuration parameters specific to that
         service.
       * They can issue HTTP requests.
       * They can do logging, with logs consolidated and easily viewable in
         your Unison Cloud account.
       * (coming soon) They can access durable and scalable Unison-native
         storage, with no serialization boilerplate to persist and unpersist
         values.
       * And more...

       Over time, we can easily grow the set of capabilities that services get
       access to.

       For instance, let's add some logging to our "Hello World" service:

       ``` unison
       logic : HttpRequest ->{Log} HttpResponse
       logic req =
         log "Waving"
         HttpResponse.ok (Body (Text.toUtf8 "👋, world!"))

       deployHelloWorld3 = do cloud.services.http.deploy logic
       ```

    ## Typed services and inter-service calls without the boilerplate

       While HTTP is still the primary interface for most public-facing
       services, a lot of backends have services which are only called
       internally. It's unfortunate to have to pay the price of encoding /
       decoding boilerplate at each of these service call boundaries, and we
       can do better in Unison.

       So far we've been dealing with HTTP services, which have the shape
       `HttpRequest ->{Remote} HttpResponse`, but Unison supports typed
       services where the input and output types can be anything we like. To
       deploy one of these "Unison-native" services, we use a more general
       function `cloud.services.deploy` (instead of
       `cloud.services.http.deploy`).

       ``` unison
       cloud.services.deploy : (a ->{Remote} b) ->{IO,Exception} ServiceHash a b
       ```

       The argument to this function has the shape `a ->{Remote} b`. `deploy`
       returns a `ServiceHash a b` , where `a` is the input type of the service
       and `b` is the output type. For example, a user lookup service might be
       represented by a `ServiceHash Username User` and in general your
       services can work with arbitrarily complex types. You can even have
       higher-order services that accept functions as arguments!

       The big benefit here is that Unison-native service calls are typed, so
       there's no serialization code to write and you can never accidentally
       send the wrong type of data to a service. All you need to do is use:

       ``` unison
       Services.call : ServiceHash a b -> a ->{Services, Remote} b
       ```

       For instance, here's an example of some service logic that finds a
       user's playlist by name and returns a list of the track titles for that
       playlist. There's no converting to and from JSON blobs or whatever else,
       you just call a function with a typed value and get back a typed reply:

       ``` unison
       serviceCallEx
         : ServiceHash User [Playlist]
        -> ServiceHash Track Track.Title
        -> {Services, Remote} [Track.Title]
       serviceCallEx playlists trackTitle =
         Services.call playlists (User "alice")
           |> List.filter (p -> Playlist.name p == "Discovery Weekly")
           |> List.flatMap Playlist.tracks
           |> Remote.parMap (Services.call trackTitle)
       ```

       Notice that we're even collecting all the track titles for the playlist
       in parallel.

       If while writing this code, we make a mistake and try to send a value of
       the wrong type to a service call, we get a type error at compile time,
       not a runtime error sometime after the service has been deployed.

       ### An architecture for Unison-based backends

           Though it's still early days, we suspect that a common pattern when
           building backends with Unison will be to create a collection of
           typed, Unison-native services that can all call each other easily,
           and then a public-facing gateway service that speaks HTTP and
           delegates to the Unison-native services.

           It's this gateway service that will be called by the front-end or by
           other non-Unison services within your organization. (This gateway
           service may also be where common concerns such as authentication and
           authorization are dealt with.)

           Here's an example — this code creates a single HTTP service with two
           routes, each of which delegates to a different typed microservice:

           ``` unison
           serviceCalls : ServiceHash User Nat
                       -> ServiceHash User Nat
                       -> {IO,Exception} ServiceHash HttpRequest HttpResponse
           serviceCalls bumpUserCount accessUserCount =
             publicFacing req =
               getCount = do
                 Routes.get (root / "users" / "get-count")
                 user = parseUser (header "user")
                 n = Services.call accessUserCount user
                 HttpResponse.ok (Body (n |> Nat.toText |> toUtf8))
               bumpCount = do
                 Routes.post (root / "users" / "bump-count")
                 user = parseUser (header "user")
                 n = Services.call bumpUserCount user
                 HttpResponse.ok (Body (n |> Nat.toText |> toUtf8))
               Http.handler (getCount <|> bumpCount <|> 'notFound)

           cloud.services.http.deploy publicFacing
           ```

           Notice how within the public-facing service, we can call the other
           services `bumpUserCount` and `accessUserCount` without any encoding
           and decoding boilerplate.

    ## What's next?

       Be on the lookout for future posts showing more of what's possible with
       this model, and posts with fully-worked example services that you can
       fork and use as templates for your own work (for instance "A simple
       Hello World Slackbot").

       We'll be rolling out support for microservices on Unison Cloud in the
       coming months. If you're interested in getting access to the beta once
       it's available, sign up at [unison.cloud](https://unison.cloud).
  }}

blog.unisonShareIsOpenSource.index : Doc
blog.unisonShareIsOpenSource.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Unison Share is now open source! It's MIT licensed, just like the Unison language itself"
      )
    , ("date", "2024-05-08")
    , ("authors", "paul-chiusano")
    , ("authors", "chris-penner")
    , ("authors", "hojberg")
    , ("categories", "announcements")
    , ( "featuredImage"
      , "/assets/feed/unison-share-is-open-source/unison-share-is-open-source.png"
      )
    , ("status", "published")
    ] }}

  # Unison Share's implementation is now open source

    Hi folks, the implementation of Unison Share is now open source! It's MIT
    licensed, just like the Unison language itself. Here are links to the
    repositories:

    * [https://github.com/unisoncomputing/share-api](https://github.com/unisoncomputing/share-api)
    * [https://github.com/unisoncomputing/share-ui](https://github.com/unisoncomputing/share-ui)

    Unison Share uses Haskell + PostgreSQL for the backend, and Elm for the
    front-end. See the READMEs of those projects for notes on self-hosting.

    ## Why?

       In short, it's because we want the Unison language to belong to
       everyone. The core language and local tooling has always been open
       source, but as Unison Share has become so important to the basic Unison
       developer experience (it's how everyone hosts code and releases, docs,
       etc), it began to feel increasingly off that it was proprietary.

       Unison Computing is a Public Benefit Corp. Creating high-quality open
       source technology is part of our company's mission, and selling Unison
       Share was never really our business model.

       Instead, our company's main product is
       [Unison Cloud](https://unison.cloud), which we host or can install in a
       customer's own VPC (or even on-premise). But we are happy if the Unison
       ecosystem is much bigger than the cloud and if many folks use Unison
       "just" as a nice standalone programming language with great tooling.
       Everyone is welcome.

       Thanks again! If you're interested in contributing to Unison Share's
       implementation, [come by the Discord](https://unison-lang.org/discord)
       to chat.
  }}

blog.unison_2021YearInReview.index : Doc
blog.unison_2021YearInReview.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "2021 was a big year for Unison. We released a new alpha version roughly every other month, and each release came with some serious improvements. In total, we merged more than 600 pull requests. Here are some of the highlights."
      )
    , ("date", "2022-02-10")
    , ("authors", "runar-bjarnason")
    , ("categories", "news")
    , ( "featuredImage"
      , "/assets/feed/unison-2021-year-in-review/unison-2021.svg"
      )
    ] }}

  # Unison in 2021, 2022 and beyond: year in review and future plans

    2021 was a big year for Unison. We released a new alpha version roughly
    every other month, and each release came with some serious improvements. In
    total, we merged more than 600 pull requests. Here are some of the
    highlights.

    ## A beautiful UI for browsing Unison code

       {{
       Video.video
         "/assets/feed/unison-2021-year-in-review/feb-2022-unison-local.mp4"
         "/assets/feed/unison-2021-year-in-review/feb-2022-unison-local.png" }}

       Since a Unison codebase is not stored in text files, it's been a
       sticking point for developers that they haven't been able to easily
       browse their code and post it online for others to see. So this summer
       we rolled out a new user interface for browsing the Unison codebase
       through a web browser. This comes embedded in the Codebase Manager, so
       now when you start up `ucm` it also starts a local web server that lets
       you browse and search your code in a delightful way.

       All the code shown in the UI is hyperlinked to support clicking through
       to definitions. Documentation (written in Unison! — see below) is
       beautifully rendered.

       We have big plans for this UI, and in time it might become a
       full-fledged IDE for Unison.

  # Unison Share community hub

    We launched a new community hub at
    [share.unison-lang.org](https://share.unison-lang.org) where people can
    share their Unison code for others to see. It also aims to be the place
    developers go to read API documentation. It already hosts a whole bunch of
    libraries from the community, as well as the Base libraries.

    This site is running a version of the codebase UI, so the experience of
    browsing your local codebase vs a publicly shared library should be more or
    less the same.

  # Computable documentation format

    This past summer we rolled out a powerful new
    [computable documentation format](/docs/usage-topics/documentation/) which
    makes it a joy to write deeply interlinked documentation with embedded live
    examples. Documents are ordinary Unison values, so docs are actually
    written in Unison.

    For an example of this in action,
    [see the documentation for the `List` data type](https://share.unison-lang.org/latest/types/unison/base/List)
    in the Base library. All the examples are typechecked and evaluated live.
    Every Unison symbol that appears in the document is hyperlinked to its
    definition.

    See also our recently published article
    ["Spark-like distributed datasets in under 100 lines of Unison"](https://www.unison-lang.org/articles/distributed-datasets/).
    This article is 100% written in Unison. The code for the article
    [is on Unison Share](https://share.unison-lang.org/latest/namespaces/unison/website/articles/distributedDatasets).

  # Codebases are now SQL databases

    The first alpha release of Unison stored the codebase in a directory
    structure, similar to how e.g. Git stores repositories. Alpha testers
    quickly ran into the limitations of this format, so last year Unison
    switched over to using a
    [SQLite database to store the code](https://github.com/unisonweb/unison/blob/trunk/docs/repoformats/v2.markdown).
    Some codebases saw a 99.5% reduction in size as a result of this, UCM uses
    up to 75x less RAM, and the whole experience of manipulating the codebase
    is much snappier.

  # New, faster Unison runtime

    That first alpha version of Unison also ran on an inefficient runtime that
    was more of a proof-of-concept than anything else. We replaced it with an
    efficient virtual machine that piggybacks on the Haskell VM. It's much
    faster, and has revamped I/O and concurrency primitives including software
    transactional memory, and more. The new runtime uses a traditional compiler
    pipeline which takes the code through several intermediate stages before
    execution. We'll be reusing a lot of these stages when compiling to native
    code, coming this year!

  # Standalone binaries

    We also added support for
    [self-contained bytecode files](https://twitter.com/pchiusano/status/1470242716688728075).
    You can now do

    ``` ucm
    .> compile.output mymain binary
    ```

    This will output a small precompiled file `binary.uc` that contains your
    `main` function and its minimal transitive dependencies. This can be
    executed from the command line with very fast startup times via
    `ucm run.compiled binary.uc`, without the overhead of loading the UCM
    interactive shell or needing to invoke the Unison compiler.

  # Developer experience improvements

    Together we fixed a lot of bugs and improved the developer experience in
    lots of little ways this year:

    * We added new builtins and new functionality in the Base libraries.
    * We improved the performance of UCM in several important ways.
    * If you have [`fzf` installed](https://github.com/junegunn/fzf), UCM will
      now invoke it if you type `cd`, `find`, or `edit` without any arguments.
    * UCM now supports wildcard globbing via the `?` symbol. For example
      `edit ?.doc` to edit the docs for all the immediate children of the
      current namespace
    * There's now a command to generate HTML from Unison `Doc`s.
    * Type inference for [ability types](/docs/fundamentals/abilities/) is
      vastly improved.

  # Growing the Unison Computing team and community

    We doubled the size of the team at Unison Computing this year! Five new
    people joined the team, so there are now 10 people working on Unison full
    time.

    This is in addition to lots of people hacking on Unison in their spare
    time. More than a dozen new people added their efforts to the development
    of Unison this year. We hosted a Hacktoberfest event in October, during
    which the community came together to fix a whole bunch of issues.

    This year we also started hosting weekly community sessions on Wednesdays
    on [our Discord server](https://discord.gg/4De3u54Yj4). This is like a
    meetup where usually somebody will stream themselves live-coding something
    fun in Unison. You should come say hi!

  # Big plans for 2022

    We're working on some very exciting things in the new year!

    ## Unison Cloud beta

       We think
       [distributed cloud computing in Unison](https://www.unison-lang.org/articles/distributed-datasets/)
       is going to knock your socks off. This past year we've been busy
       building the technology for a futuristic fully-managed platform for
       distributed Unison execution. We're actively looking for companies who
       would like to try this out for real work. Go to
       [unison-lang.org/at-work](/at-work) if you're interested in working with
       us.

       The plan is to launch a beta version of Unison Cloud in Q1 / Q2 of this
       year! This will be a service that allows you run your Unison code on our
       managed infrastructure just as easily as running it on your own
       computer. We're hoping to offer a free tier for Unison enthusiasts.

    ## Codebase hosting designed for Unison

       So far, Unison developers have been mainly using GitHub to host their
       code. But this is not a great fit for Unison, for several reasons.
       Firstly, Git assumes that code is stored in text files, which is not the
       case for Unison. Secondly, the Unison codebase has its own internal
       history, its own notion of branches, and its own pull request mechanism,
       none of which can take advantage of Git.

       This year, all that is going to change. We're building our own codebase
       hosting specifically designed for Unison. So instead of camping in a
       tent out by the dumpsters behind GitHub, you'll be able to host Unison
       codebases and make them browsable via a beautiful interface like
       [share.unison-lang.org](https://share.unison-lang.org).

    ## Native compilation

       Unison currently compiles to a kind of bytecode which gets interpreted
       by a virtual machine that runs on top of the Haskell runtime. The plan
       this year is to get Unison compiling to fast native code. Dan Doel will
       be doing a blog post talking about the progress on that.

    ## New Unison website

       We're working on totally revamping
       [our website](https://unison-lang.org). But it's not just a change in
       content or look-and-feel. No, no. We're
       __rewriting the website in Unison__! That's right, the whole site will
       be a Unison data structure (of the
       [`Doc`](https://share.unison-lang.org/latest/types/unison/base/Doc)
       type), demonstrating how you can author rich computable content in the
       language.

    ## The first ever Unison conference

       We're planning a fully online free-to-attend Unison conference this
       spring. Stay tuned for details!

  # Join our community

    We're very excited to be bringing Unison into existence, and we want you to
    be a part of it!

    Stop by the [Unison Slack](https://unisonlanguage.slack.com/ssb/redirect).
    We're friendly and welcoming.

    [Install Unison and try it out](/docs)!
  }}

blog.visualizingRemote.index : Doc
blog.visualizingRemote.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Here's how we created a simple library for visualizing Unison's api for distributed computing."
      )
    , ("date", "2023-03-07")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/thing5.svg")
    , ("status", "published")
    ] }}

  # Visualizing remote computations in Unison

    For the past few weeks, the Unison community has been working on creating a
    small library for visualizing the execution of distributed computations. {{
    docAside
      {{
      We livestream together on Wednesdays, and we're very friendly,
      [join our Discord](https://unison-lang.org/discord)!
      }} }}
    [The library is being hosted on Unison Share here](https://share.unison-lang.org/@rlmark/p/code/latest/namespaces/public/projects/visualizeRemote)!
    This effort was inspired, in part, by the challenges we've written about in
    our earlier
    [Spark-like distributed datasets article](https://www.unison-lang.org/articles/distributed-datasets/)
    when it comes to tracking whether a distributed computation is being
    efficiently mapped and reduced before being awaited, or whether the
    computation is being forked and awaited with extraneous network hops.

    Here's one of those example map-reduce jobs with its visualization:

    ``` unison
    seqRegion : '{RemoteVis} Nat
    seqRegion = do
      use Nat +
      Seq.fromListAt RemoteVis.region! 16 (Nat.range 0 128)
        |> Seq.map (x -> x + 1)
        |> Seq.reduce 0 (+)
    ```

    {{
    Image
      {{
      Image of a branching series of forked and awaited paths in multiple
      Remote locations.
      }}
      {{
      /assets/feed/visualizingRemote/seqExample.png
      }}
      None }}

    We can see that our map-reduce function creates a tree-like structure, with
    parent tasks forking child tasks and awaiting their reduced results. It's
    nice to see that our forked tasks aren't interleaved with calls to await,
    which might be a sign that we are unnecessarily waiting for results before
    forking more work, and we can see that the computation fans out to
    different locations only at the leaf nodes, where the `map` will be
    performed, minimizing extra data transfers.

    These visualizations are generated upon running the program that they
    describe, and are designed to help users understand the behavior of their
    distributed program. The drawing we produce can be rendered and saved as a
    mermaid {type Doc} element, which is viewable in Unison Share or the Local
    Codebase UI code browser. The library is still in its early stages, but
    we're excited to share what we've got so far.

    Note, these drawings are not the same as a full observability tool for a
    distributed system. The nodes are labeled by their `TaskId`, not the values
    themselves, so this just gives us a sense of the "shape" of the
    computation. A production system would need to be able to handle thousands
    of potential events, and a diagram of such a computation would be too large
    to be useful. Our current goal is to create a tool that can help you
    understand the behavior of a small, locally run program, in the hopes that
    it enables easier adoption and learning.

    With that in mind, here's a taste of what the library can do.

    ## Drawing Remote primitive operations

       In Unison, you can send a program to a remote node and run it
       asynchronously there with `fork`, and you can wait for the result of a
       remote computation with `await`.

       ``` unison
       fork :
          Location g -> '{g, RemoteVis, Exception} t ->{RemoteVis} Task t
        fork loc a =
          RemoteVis.forkAt (RemoteVis.near loc RemoteVis.here!) a
       ```

       ``` unison
       await : Task a -> {RemoteVis} a
        await t =
          RemoteVis.reraise (RemoteVis.tryAwait t)
       ```

       {{
       docAside
         {{
         The single quote in {{ (docCode {{ '{g, Remote, Exception} a }}) }} is
         a delayed computation, or something with the form `() -> a`. You'd
         read the signature for fork as "fork takes a location and a delayed
         computation which uses the Remote and Exception effects in the process
         of returning a value".
         }} }}

       The first argument to `fork` is an abstract node in the system,
       represented by a {type Location} type, and the second argument is the
       program to be run on that node. Awaiting a remote computation will block
       until the result is available.

       Here's what you might see if you fork a few computations and await them
       locally, in the same location:

       ``` unison
       example2 : '{RemoteVis} Nat
         example2 = do
           task1 = forkAt here! '(1 + 1)
           task2 = forkAt here! '(2 + 2)
           a1 = await task1
           a2 = await task2
           a1 + a2
       ```

       {{
       Image
         {{
         Image of two tasks being forked and awaited.
         }}
         {{
         /assets/feed/visualizingRemote/twoTasks.png
         }}
         None }}

       The forked tasks are labeled by their auto-generated task id.

       And here's what you might see if you fork the following computations to
       be run on 3 random nodes, each with their own location subgraph, and
       later await them:

       ``` unison
       multipleLocations : '{RemoteVis} Nat
       multipleLocations = do
            task1 = fork region! '(1 + 1)
            task2 = fork region! '(2 + 2)
            task3 = fork region! '(3 + 3)
            await task1 + await task2 + await task3
       ```

       {{
       Image
         {{
         Image of tasks at multiple locations.
         }}
         {{
         /assets/feed/visualizingRemote/multipleLocations.png
         }}
         None }}

       Time flows roughly from top to bottom and we can see that these tasks
       are running "asynchronously" because no intermediate "awaiting" by the
       root node is being performed between the "fork" arrows.

       In light of this, it's much easier to spot the difference between a
       non-blocking remote program:

       ``` unison
       simpleReduce : '{RemoteVis} Nat
       simpleReduce = do
          task = fork RemoteVis.region! do
            task1 = fork here! '(1 + 1)
            task2 = fork here! '(2 + 2)
            await task1 + await task2
          await task
       ```

       {{
       Image
         {{
         Image of tasks being forked to a different location and then reduced
         there.
         }}
         {{
         /assets/feed/visualizingRemote/simpleReduce.png
         }}
         None }}

       And its blocking counterpart:

       ``` unison
       blockingReduce : '{RemoteVis} Nat
       blockingReduce = do
           task = fork RemoteVis.region! do
             res1 = await (fork here! '(1 + 1))
             res2 = await (fork here! '(2 + 2))
             res1 + res2
           await task
       ```

       {{
       Image
         {{
         Image of tasks being forked to a different location and then reduced
         non asynchronously.
         }}
         {{
         /assets/feed/visualizingRemote/blockingReduce.png
         }}
         None }}

       Tasks which are sent across __location__ boundaries are particularly
       interesting for working with the distributed library because they
       represent a potential network hop. They're represented by dashed arrows
       or labeled subgraph boxes.

       Thus far, the diagrams can be configured to render the following:

       * The task id for each task
       * The size (after compression) of the payload of each task
       * The location of each event, represented by a sub-graph in the diagram
       * Task cancellation, to observe orphaned tasks that are consuming
         resources

    ## Technical details

       {{
       docCallout
         None
         {{
         Three core things make these programatic drawings possible:

         1. "Remote" computations are expressed as an __ability__, meaning that
            your distributed programs are defined in terms of an an interface
            that doesn't depend on the underlying backend that runs them.
         2. Community member Alvaro Carrasco has written an impressive library
            for modeling different kinds of mermaid diagrams, so it's possible
            to create diagrams natively, using Unison data types instead of
            working with raw strings.
            [Check it out on Unison Share here!](https://share.unison-lang.org/@alvaroc1/p/code/latest/namespaces/public/mermaid/main)
         3. The Unison language has a "live" documentation format. Unison code
            can be directly rendered as documentation and is automatically
            updated when the underlying source code is updated.
         }} }}

       {{
       docAside
         {{
         The secret fourth thing is kindness. Ok, sorry for being cringe. 💀
         }} }}

       ### Distributed computations as an ability

           A full introduction to abilities is beyond the scope of this post,
           but to talk about how we're drawing these diagrams, we need to
           understand what Unison's effect management system, abilities, allows
           us to do. Ability handlers give us access to a snapshot of the
           running state of a computation. Every ability handler needs to
           decide how to resume the continuation of the program at the point in
           the program where the ability has been called. This means we can
           intercept an event like "Fork this program here" and store
           information about the task before performing the "fork" operation.

           {{
           docAside
             {{
             [You can read more about Unison's model for computational effects,
             abilities, here](https://www.unison-lang.org/learn/fundamentals/abilities/).
             }} }}

           The distributed library has long had a local handler for the
           `Remote` ability called `Remote.pure.run`. This handler is used for
           testing and experimenting with a distributed program before it is
           deployed to a real distributed system via a backend like the one
           provided by [Unison Cloud](http://unison.cloud/). It works by
           serializing the events that occur during the computation and storing
           their order relative to one another in a local task queue. There's
           no true concurrency happening when tasks are forked and awaited, so
           the local program may be considerably slower than one which runs in
           the Cloud.

           We decided to use the {type Stream} ability to emit events as they
           occur, in effect, creating a log of the distributed computation.
           This is another nice feature of Unison's effect system, one effect
           can be called in the context of another one, even when writing a
           handler for the effect. The core logic of a distributed program can
           be written in terms of just `Remote`, but our handler might be able
           to augment the runtime by writing a log line, emitting a drawing, or
           other effects.

           We'll see the {type Stream} and `Remote` effects included in the
           signature for our new local handler.

           ``` unison
           run.simple : Nonempty LocationId -> '{g, RemoteVis} a ->{g, Random, Scope s, Stream TraceEvent} Either Failure a
           ```

           {{
           docAside
             {{
             [The full source code for the library is available here](https://share.unison-lang.org/@rlmark/p/code/latest/namespaces/public/projects/visualizeRemote)
             }} }}

           When we want to produce the diagram, we fold over the {type Stream}
           of events, collecting a mapping of task ids to the events that they
           produced. We use this accumulated state to draw the nodes and edges
           of the graph. Loosely, we wanted to draw a diagram whose semantics
           conveyed:

           1. The fork/await relationship between tasks
           2. When a task is forked across a location boundary
           3. A very rough sense of a task being "in progress" relative to
              others
           4. When a task has been cancelled, or just forked and abandoned

       ### Mermaid diagrams as Unison values

           The diagrams we produced are known as
           [mermaid diagrams](https://mermaid.js.org/#/). Mermaid diagrams
           allow you to use markdown-like syntax to create a variety of diagram
           types. We've been using
           [the Unison mermaid library](https://share.unison-lang.org/@alvaroc1/p/code/latest/namespaces/public/mermaid/main)
           by Alvaro Carrasco to write data types which represent the various
           entities like "subgraphs" and "arrows". The Unison mermaid library
           creates an ADT capable of representing the mermaid DSL and
           serializing it. This saves us from managing plain {type Text} values
           like `subgraph 4e6f64652041 ["Node A"]` ourselves. Later, we
           transform the text blob produced from the library into a {type Doc}
           value, which is Unison's documentation format.

       ### Unison's live documentation format

           The final piece to enabling this feature is Unison's own
           documentation format. Docs in Unison are themselves Unison values,
           represented by the {type Doc} type. They can be saved and
           manipulated in the same way as any other Unison value.

           The handler from `Remote` to {type Doc} is relatively compact:

           ``` unison
           Remote.runToDoc : '{Remote} r -> Doc
           Remote.runToDoc remote =
             flowchart = at1 <| runDiagram docDefault remote
             Flowchart.toDoc flowchart
           ```

           {{
           docCallout
             None
             {{
             The intuition here is that __documentation itself__ can be a
             handler for the computational effect of "programming in a remote
             context". When the underlying remote computation changes, your doc
             will be updated to reflect the new state of the computation.
             }} }}

    ## Future work

       This library's overall goal is to make it easier for users of the
       distributed programming API to be able to reason about their program's
       control flow; we hope the increased visibility will be useful as the
       [Unison Cloud](https://www.unison.cloud/) races ever closer to general
       access. Rendering diagrams using the mermaid DSL in Unison's {type Doc}
       format is a just first step towards a more general solution for
       visualizing remote computations. Future versions of the library might
       leverage SVG's directly and associate the computation source code in the
       task tree with nodes in a diagram. The current implementation is
       beholden to the conventions of the mermaid rendering engine, and the
       local interpreter isn't terribly performant for non-trivial scenarios.
       In the more distant future, we may be able to consume logging from
       actual events in the Cloud and write a custom debugging {type Stream}
       handler for "tracer bullet" type traversals through a distributed
       system.

       If you're interested in the work we've been doing on distributed
       programming in Unison, or if you have a specific project in mind that
       would be a good fit for running in the cloud, check out the
       [Unison distributed programming library](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/distributed/latest)
       and tell us about it in the form for
       [Unison Cloud beta access](https://www.unison.cloud/)!
  }}

blog.visualizingRemote.index._blockingReduce : '{Remote} Nat
blog.visualizingRemote.index._blockingReduce = do
  use Nat +
  use Remote fork
  task = fork region! do
    res1 = await (fork here! do 1 + 1)
    res2 = await (fork here! do 2 + 2)
    res1 + res2
  await task

blog.visualizingRemote.index._multipleLocations : '{Remote} Nat
blog.visualizingRemote.index._multipleLocations = do
  use Nat +
  use Remote fork
  task1 = fork region! do 1 + 1
  task2 = fork region! do 2 + 2
  task3 = fork region! do 3 + 3
  await task1 + await task2 + await task3

blog.visualizingRemote.index._simpleReduce : '{Remote} Nat
blog.visualizingRemote.index._simpleReduce = do
  use Nat +
  use Remote fork
  task = fork region! do
    task1 = fork here! do 1 + 1
    task2 = fork here! do 2 + 2
    await task1 + await task2
  await task

blog.vscodeStartup.index : Doc
blog.vscodeStartup.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Enable auto-startup of the UCM with the Unison VS Code extension so you can start writing Unison code faster."
      )
    , ("date", "2022-11-22")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("status", "published")
    ] }}

  # The Unison VS Code extension includes auto-startup of the UCM

    We'd like to highlight a community contributed tooling improvement for VS
    Code users. Huge thank you to Tavish Pegram for adding this functionality!
    Previously, the Unison VS Code extension would alert you that there was no
    UCM instance running when you opened a directory with Unison scratch files.
    But since it's likely that you're opening `.u` suffixed files to write
    Unison code, now you can configure VS Code to start an instance of the UCM
    in the VS Code terminal.

    By default, the VS Code extension will open the codebase in your home
    directory by calling `ucm`, but if you have located your codebase somewhere
    else, you can change it by going to "Preferences > Settings > Extensions >
    Unison" in VS Code, and then changing the setting called "UCM command".

    {{
    Image
      {{
      configuration for Unison vs code settings
      }}
      {{
      /assets/feed/vscodeStartup/vsCodeSettings.png
      }}
      Optional.None }}

    You can disable the auto-startup with the "Automatically Open UCM" flag,
    also configurable in the extension settings.
  }}

blog.whereUnisonIsHeaded.index : Doc
blog.whereUnisonIsHeaded.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "A discussion of where Unison is headed. Covers both near-term features we're actively working on (or will likely be soon) and some more speculative but exciting possibilities... 🔮"
      )
    , ("date", "2024-06-03")
    , ("authors", "paul-chiusano")
    , ("categories", "news")
    , ("status", "published")
    , ("featuredImage", "/assets/feed/where-unison-is-headed.png")
    ] }}

  # Where Unison is headed

    Unison is built on the unusual idea of
    [content-addressed code](/learn/the-big-idea). Even though we knew early on
    that new things would be possible with this approach ("the math checks
    out!"), actually getting to a real usable technology
    [took years](/blog/experience-report-unison-in-production/).

    We now have an amazing foundation for continued innovation. There's a
    cohesive ecosystem of tools around Unison which are already quite useful
    today. But this is just the beginning. In the next 6 months, year, and
    beyond we will be entering the realm of science fiction. 🛸

    This is a long post with a lot of details of what we're thinking for the
    future, so here's a summary:

    1. Keep improving the core language, runtime, and tooling. Examples: adding
       an FFI to Unison, improving JIT compiler performance, more semantic
       merge capabilities, and a more graphical UCM experience.
    2. Make Unison Share an even nicer place to host your projects. Examples:
       "find usages", site-wide code search, multi-collaborator projects, and
       more.
    3. Major new Unison Cloud features: scheduled jobs, distributed event
       processing, resilient workflows, and high-performance native execution
       via our JIT compiler.

    Read on for the details! Items are marked as ⚙️ ("relatively easy or
    already in progress"), 🧪 ("a big effort, but very doable"), or 🛸 ("possibly
    science fiction or needing research, but seems broadly possible").

    Lots can change so don't take this post as a guarantee of when things are
    happening. We'll continue to keep [our roadmap](/roadmap) updated.

    ## New cloud capabilities

       In the next month we're planning to ship what seems like an
       inconsequential feature: the ability to launch daemon processes that run
       indefinitely "on at least one node at all times". This isn't necessarily
       a feature one programs with directly; instead it's a building block for
       all kinds of things:

       * High-performance and highly available in-memory distributed queues and
         topics
       * Scheduled jobs, cron for the cloud
       * Resilient workflows ("every 30 days, wake up and send an invoice to
         each customer")
       * Distributed event processing, streaming analytics, etc
       * … and lots more.

       These will be open source libraries running atop Unison Cloud daemons,
       so you'll have the same power to build similar features, or to customize
       the behavior for your unique needs. From early prototyping of the above,
       we're seeing (as usual) orders of magnitude reductions in how much code
       is required to express these kinds of systems.

       Compositionality makes a huge difference. All the things you build can
       talk to each other without serialization and networking boilerplate,
       without dependency conflicts, YAML engineering, and without having to
       build and ship around multi-GB containers. It's incredibly refreshing
       and makes working on these systems so much more fun.

       {{
       docCallout
         Optional.None
         {{
         **The right sources of complexity**

         Fabio was recently working on a Kafka-like distributed streaming
         system prototype (stay tuned!) which has some tricky parts, and he
         made the following observation on the experience of building
         interesting distributed systems with Unison: "it's challenging, but
         never tedious".

         There's still intricate code, but maybe it's 50 lines instead of 5000,
         and it's 50 lines concerned entirely with the part that matters.
         }} }}

       Other major features planned or being considered:

       * **JIT compiler for Unison Cloud nodes.** (⚙️) This will be a drop-in
         replacement requiring no Unison code changes, your code will just
         magically run faster. The rollout will happen seamlessly with no
         downtime and no need to redeploy your services!
       * **GPU pools and model inference pools in Unison Cloud,** (🧪) for easy
         multi-GPU distributed computations in a few lines of code. Our basic
         distributed computing API is designed to support multiple compute
         pools with different capabilities and which can all be mixed
         seamlessly in an overall distributed computation.
       * **Unison Cloud Edge,** (🧪) running on globally distributed
         infrastructure. These "edge" locations might have different included
         abilities than the main cloud pool (for instance, storage for the edge
         has different performance requirements and tradeoffs) but would still
         be able to seamlessly call Unison native services regardless of where
         they're hosted.
       * **"Unison Cloud in a box"** (⚙️) enterprise product to run our compute
         and storage fabric on your own infrastructure or VPC.
       * **Pro Tier managed cloud offering**, (🧪) for orgs wanting their own
         dedicated autoscaled compute pool in our public cloud.

    ## Core language and tooling

       Doing the basics well is important! These are all happening now or
       sometime in the next six months.

       1. **New and improved merge algorithm.** (✅) We've **just** released
          this, addressing a major annoyance with the previous workflow. Going
          forward, the large majority of merges and pulls should be clean,
          conflicting only if the two branches being merged have literally
          edited the same definitions. In the event of actual conflicts you'll
          have the same nice "just get your scratch file compiling" experience
          that we first got working for `update` and `upgrade`. Because Unison
          stores code in a more semantic way, entire classes of merge conflicts
          are just impossible! You'll never have conflicts due to things like
          order of imports changing, order of definitions in a file changing,
          formatting differences, and more.
       2. **Fast `clone` and `pull`.** (⚙️) Right now, to contribute to a
          project, you have to obtain the full history via a `clone` which
          takes a while (minutes for a large project with a long history).
          We'll likely address this with shallow clones. You don't need the
          full history of a project to contribute to it—only the person merging
          the contribution needs the history. The common case of opening a
          contribution can take seconds instead of minutes. In addition, we
          might tweak our sync protocol to be more efficient, especially for
          common cases like fetching a project release.
       3. **Faster JIT compiler performance.** (⚙️) The JIT is a lot faster
          than the current interpreter (about 60x faster straight line
          performance), but we also haven't done much to optimize the code it
          generates or the implementations of many builtins. There's a lot of
          easy wins here. We'll also be adding instant JIT compiler startup
          times via `run.native`. Right now we don't do anything smart to cache
          compiled code. We can instead use a little server running a code
          syncing protocol that only asks `ucm` to send missing dependencies,
          so startup is instant.
       4. **A myriad of quality of life improvements** and bugfixes that until
          now we've been putting off to work on major features. (⚙️)

       ### And beyond!

           Let's look at some more advanced capabilities we have in the works
           for core tooling. Even though these seem hard, a lot are pretty
           straightforward to do atop Unison's foundations:

           1. **Find usages on Share** (⚙️) based on Unison's fully accurate
              dependency graph. This feature is not hard, is already supported
              locally (the `dependents` command) and will ship "as soon as
              Simon has a few free days to build the front end". Also on Share,
              we'll be adding automated changelogs with hyperlinked diffs for
              every project release (similarly not difficult and reuses the
              work already done to produce hyperlinked diffs for
              contributions).
           2. **Site-wide code search on Share** (⚙️) across all projects, and
              all type signatures in those projects. This will be incremental,
              with results refined as you type and also supporting
              autocompletion. Unlike text-based code search, Unison understands
              your code semantically, so when you search for
              [`List.map`](http://List.map), it'll take you to that definition,
              in the project where it is originally defined. GitHub struggles
              here; since code is treated as as blobs of text, search results
              often take you to a random file in a random project where
              `List.map` appears as a call site… or in a comment!
           3. **New semantic merge capabilities.** (🧪) Imagine: Alice swaps the
              order of arguments for a function `foo` while Bob simultaneously
              writes a new function that calls `foo`. With a text-based version
              control system, Bob's code won't compile in the merged result.
              But in Unison, we can detect these sorts of refactorings and
              merge them automatically! But this example (which is actually not
              hard for us to do) just scratches the surface of what's possible.
              Some of these are easy while others require storing more
              structured information in the version history.

           By maintaining the structure of a codebase in an actual database
           instead of a bag of text files, so much of the basic experience of
           writing and interacting with code can be made better!

           Some other possibilities:

           * **Alternate syntaxes.** (🧪) Since code is stored in a database as
             its abstract syntax tree, that same AST can be viewed using a
             "Pythonic" syntax or a "C-like syntax". We've always known this
             was possible but haven't had the time to invest in it yet.
           * **Graphical UCM.** (🧪) The Unison codebase manager command line
             tool is pretty low tech, but it's been surprisingly effective.
             It's a single all-in-one tool that runs alongside your text editor
             and "just works" for most of the things you need to do with a
             Unison codebase (it's also an LSP server for Unison)… and yet, we
             can also do even better. Imagine a rich UI with a command palette
             with amazing autocomplete and inline help, and where output can be
             richly formatted. Don't worry, we can do this while continuing to
             support the existing terminal app.
           * **Interactive documentation.** (🛸) Imagine the Unison
             documentation type, but with interactive sections where users can
             write code and run it, getting feedback right away. Useful for
             building even richer tutorials, learning materials, and blog
             posts.
           * **Unison and Unison Share for other languages.** (🛸) Imagine if
             all languages could get the Unison Share experience of hyperlinked
             code, semantic merges, and more. Imagine all languages could get
             something like Unison's perfect incremental compilation and shared
             compilation cache. This is definitely a science project but a lot
             seems possible and it would be fun to explore if we weren't so
             busy with everything else. However, if anyone would like to hand
             us a large pile of money to work on this, please get in touch. 😀

    ## Core language improvements

       The core Unison language has been quite stable over the years. While we
       occasionally make tweaks to the syntax or pretty-printer, this doesn't
       break existing code. We've yet to make a backwards incompatible language
       change; code that was written years ago still runs unchanged.

       These are the language improvements that seem the most pressing right
       now:

       * ⚙️ **A foreign function interface.** We've held off working on this
         while the JIT was in progress, since the FFI obviously needs to
         interact with the runtime. With the JIT more stable, we can make it
         easy to access arbitrary C libraries from Unison. (Even though code
         that uses the FFI can't be distributed in the same way as pure Unison,
         that's fine, we plan to track usage of foreign libraries with
         abilities.)
       * 🧪 **Proper record types.** Either extensible records or regular
         "non-extensible" records. The current experience with record types is
         not great, because they are just regular data types with some
         autogenerated helper functions. A more first-class representation of
         records would be much better.

       Also potentially in the works for later:

       * 🧪 **Generalized algebraic data types.** This is
         [a known extension](https://arxiv.org/abs/1601.05106) to the basic
         type system that Unison uses, but we haven't gotten around to
         implementing it.
       * 🧪 **Typeclasses or something similar.** This has been discussed a lot
         over the years. While typeclasses a la Haskell aren't really a slam
         dunk for Unison, something like this feature can be incredibly
         convenient.

    ## Conclusion

       Phew, that was a lot!

       Unison was designed differently than most languages. This was done for
       good reason, to make new things possible, and it's paid off. Here are a
       few things we have **today** in Unison:

       * No builds. A perfect and shared incremental compilation cache.
       * Easy distributed computation, deployment with a function call, etc.
       * Hyperlinked code browsing and diffs, by default.
       * Computable docs with live hyperlinked examples.
       * Find usages, type-based search, and even
         [structural term rewriting](https://share.unison-lang.org/@unison/base/code/releases/3.5.0/latest/types/reflection/Rewrites)
       * Instant non-breaking renames.
       * … and more

       Unlike a lot of programming tech which has stagnated due to outdated
       assumptions about programming ("programs are single-machine
       computations" or "codebases are bags of text files"), Unison is only
       going to keep getting better. And not just bit by bit, but by huge
       leaps.

       Onward!

       – The Unison Team 💜
  }}

blog.wrapUp2022.index : Doc
blog.wrapUp2022.index =
  {{
  {{
  frontMatter
    [ ( "summary"
      , "Reflecting on Unison's 2022 progress. Highlights include the Unison Forall conference, Unison Share code hosting, Unison Cloud beta testing, and more."
      )
    , ("date", "2023-01-04")
    , ("authors", "rebecca-mark")
    , ("categories", "highlights")
    , ("featuredImage", "/assets/feed/wrapUp2022/yearInReview2022.png")
    , ("status", "published")
    ] }}

  # Unison's 2022 in Review

    2022 was a year of continued growth for the Unison ecosystem. We can't
    cover everything that happened in the past year, but here are some of the
    highlights.

    ## Unison Forall conference

       This year we held our first ever Unison language conference,
       [Unison Forall](https://hopin.com/events/unison-forall/registration).
       The conference, held online, brought together Unison enthusiasts and
       featured eleven speakers and hundreds of attendees. You can watch
       [recordings of the talks online here](https://www.youtube.com/playlist?list=PLQ0IlHfOk1GgbXSZAjOOls9PnrO4Dpsbb).

    ## Code hosting on Unison Share

       In 2021, we created [Unison Share](https://share.unison-lang.org/) as a
       hosted repository for Unison code. Unison Share renders Unison's
       [newly enriched](https://www.unison-lang.org/whats-new/latex-doc-support/)
       documentation format, provides click-through links to definitions, and
       allows you to browse a codebase graphically. But before this year we
       were still relying on the Git protocol and external hosting services for
       warehousing and exchanging code. This wasn’t a great fit because
       Unison’s codebase format is, after all, not text-based. We knew we
       needed a Unison-specific solution for sharing code, so in 2022 we added
       Unison-native codebase hosting to Unison Share and made it possible to
       `pull` and `push` code directly to remotely hosted codebases. This opens
       the door to more features for collaboration and library discovery in
       2023.

    ## Unison Cloud in beta testing

       We’ve started [unison.cloud](http://unison.cloud) private beta testing
       and will be opening it up to more people in the coming months. Unison
       Cloud has been steadily moving from the dream of writing cloud-native
       Unison code to a reality.

       {{
       docCallout
         (Some {{ ☁️ }})
         {{
         If you are interested in being a part of the Cloud beta-test, you
         should
         [read about our Trailblazers program and fill out the attached form
         link](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/cloud/main/;/terms/betaProgram?viewMode=presentation).
         }} }}

       {{
       Image
         {{
         Film still from Kubrick's 2001: A Space Odyssey, showing a monolith
         surrounded by early hominids.
         }}
         {{
         /assets/feed/wrapUp2022/monolith.jpg
         }}
         (Some
           {{
           Actual photo of us learning to use the Unison Cloud and preparing
           for the forthcoming breakthroughs in technology and science. Image
           courtesy of Stanley Kubrick.
           }}) }}

    ## Team news

       This year we welcomed Travis Staton as a new team member. He has been
       using his considerable Haskell expertise in the service of adding
       features to the Unison Codebase Manager and the Unison language itself.
       We're very glad you're here, Travis!

       While technically a 2023 addition, Unison has also recently welcomed
       distributed systems expert Fabio Labella to the team. You've probably
       seen Fabio helping answer questions in the Unison community slack, or
       maybe you've run into him sharing his knowledge of functional
       programming. Welcome, Fabio!

       The Unison team is distributed, which means we mostly interface with
       each other through various screens, but in 2022 we were able to meet in
       person for the first time! We held a team retreat in Boston, where we
       worked on planning and strategy. We also had a great time cooking
       together and exploring the city!

       {{
       Image
         {{
         Photo of the Unison team outside, arranged in two rows.
         }}
         {{
         /assets/feed/wrapUp2022/teamPhoto.jpg
         }}
         (Some
           {{
           The Unison team when we briefly materialized in corporeal space.
           }}) }}

    ## Native compilation progress

       The Unison language currently runs through an interpreter written in
       Haskell, but as of the
       [M4e release](https://github.com/unisonweb/unison/releases/tag/release%2FM4e)
       of the UCM, the Unison language contains an initial implementation of a
       [Chez Scheme](https://www.scheme.com/) backend capable of producing
       native executables. This represents a major performance improvement for
       the Unison runtime, with some benchmarks indicating that running native
       Unison code is hundreds of times faster. The native compilation
       feature-set is still being fleshed out, but the command to run your
       `main` function with this backend looks like:

       ``` ucm
       .> run.native myMainFunction
       ```

       You can read more about native compilation and these preliminary results
       in compiler engineer Dan Doel's own words in
       [this blog post](https://www.unison-lang.org/whats-new/jit-announce/).

    ## Language Server Protocol implementation

       This year we added an implementation of the
       [Language Server Protocol](https://microsoft.github.io/language-server-protocol/)
       for Unison. This means that Unison now has first-class support in many
       popular editors and IDEs. For those of us whose workflow is heavily
       indebted to IDE features like auto-completion, seeing types on hover, or
       having errors highlighted in the editor, this is a huge win for the
       developer experience. If you haven't tried it yet, you can read more
       about how to set up your editor with the LSP in the
       [Unison language server project documentation](https://github.com/unisonweb/unison/blob/trunk/docs/language-server.markdown).

       LSP support is in active development, and it seems like every week
       [there's a new feature or improvement](https://www.unison-lang.org/whats-new/autocomplete/)
       to discover.

    ## Base library development

       In 2022 we continued to expand the
       [base library](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/base/main).
       Newcomers and experienced programmers alike will benefit from the
       increased documentation coverage for the existing standard lib and new
       types and functions.

       A few of the additions to the base library include:

       * The {type Pattern} API for regex-like text matching and capturing
       * Optimized {type Set} and {type Map} implementations specific for
         containing {type Nat} values,
         [NatSet](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/base/main/;/types/data/NatSet)
         and
         [NatMap](https://share.unison-lang.org/@unison/p/code/latest/namespaces/public/base/main/;/types/data/NatMap)
       * New mutable and immutable {type mutable.Array} and
         {type mutable.ByteArray} collection types
       * {type time.Duration} and {type Instant} types for working with blocks
         of time, plus types like {type LocalDate} and {type OffsetDateTime} so
         you can experience the pain of managing time-zones

    ## Ecosystem growth

       This year saw a number of new projects and libraries built with Unison.
       Here are a few of our favorites:

       * A library for
         [optics](https://share.unison-lang.org/@staccatosemibreve/p/code/latest/namespaces/public/optics/latest)
         in Unison, complete with examples and cheatsheets!
       * A
         [redis client](https://share.unison-lang.org/@ceedubs/p/code/latest/namespaces/public/redis/latest)
       * [HTTP server](https://share.unison-lang.org/@stew/p/code/latest/namespaces/public/projects/httpserver/main)
         and
         [client](https://share.unison-lang.org/@stew/p/code/latest/namespaces/public/projects/httpclient/main)
         libraries
       * A library for parsing and representing the
         [Dhall configuration language in Unison](https://share.unison-lang.org/@hagl/p/code/latest/namespaces/public/dhall/latest)
       * The
         [Codec library](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/codec/latest)
         for serializing and deserializing Unison values into binary formats
       * A
         [resource library](https://share.unison-lang.org/@runarorama/p/code/latest/namespaces/public/resource/latest)
         for effectful provisioning and releasing of resources
       * A
         [complex number](https://share.unison-lang.org/@tarikozkanli/p/code/latest/namespaces/public/complex)
         library
       * A library for
         [drawing svg's](https://share.unison-lang.org/@alvaroc1/p/code/latest/namespaces/public/draw/latest)
         in Unison

       Folks are finding interesting applications for Unison and exploring new
       ways to use the language. If you have a project or idea that you're
       excited about, join us in the
       [#libraries channel in the Unison slack](https://unisonweb.org/slack)
       and let's talk about it!

    ## Unison website revamp

       A year ago the Unison website looked very different. In early 2022 we
       deployed a new, revamped website written almost entirely in Unison's own
       {type Doc} format. The website being Unison code means that it's easy to
       keep code samples up to date with the latest syntax and features. (So
       much so that sometimes the code examples outpace what's written, in
       which case you should message us in the
       [#documentation channel in Slack](https://unisonweb.org/slack) and we'll
       fix it!)

    ## Community events

       In 2022 we wanted to make sure that the Unison team was connected to
       writing Unison code with you all. We've been live-streaming and
       collaborating with the community on Wednesdays so that folks can ask
       questions, follow along, and learn from each other. Most of all we
       wanted to humanize the process of writing Unison code, messing things
       up, and trying new things.

       This December we capped off the year with a number of folks
       participating in [Advent of Code](https://adventofcode.com/2022). Advent
       of Code brought new people to Unison and inspired knowledge sharing and
       general conviviality. We collected highlights of solutions and write ups
       in
       [this blog post](https://www.unison-lang.org/whats-new/advent-of-code-highlights2022/).

    ## Learning Unison with Exercism

       We want it to be easy to learn and discover Unison. For that reason we
       partnered with [Exercism](https://exercism.org/) to develop our own
       [Unison language track](https://exercism.org/tracks/unison) in 2022. We
       chose Exercism because of their existing network of programming
       languages, because it's free, and because of their focus on creating a
       welcoming learning environment. This means that you can now learn Unison
       by solving programming problems in the browser or via the command line.

    ## Unison "projects" moves from idea to implementation

       Unison "projects" introduces an additional abstraction to the Unison
       codebase that better describes a unit of Unison code as a "library" or
       "application" with associated properties like versions, issues, and
       dependencies. Our existing concept of namespaces was a bit too granular
       to describe these concepts, so we spent a lot of time and care thinking
       about what a Unison-specific library and dependency system should look
       like.

       In the next iteration of Unison Share, when you click on a library,
       you'll see an overview of the project which looks something like this:

       {{
       Image
         {{
         A mock up of the Unison projects overview UI, showing library name,
         version, and summary.
         }}
         {{
         /assets/feed/wrapUp2022/projectOverview.jpg
         }}
         (Some
           {{
           A mock-up of a project overview page, showing the name of an example
           library, its version, the people who contribute, and basic stats.
           }}) }}

       From the project overview, you might choose to explore the code of the
       library, which will open a page displaying the current branch, number of
       releases, and issues, and readme.

       {{
       Image
         {{
         A mock up of project code view screen, showing readme, and a header
         containing releases, issues, merge requests and current branch.
         }}
         {{
         /assets/feed/wrapUp2022/projectCode.png
         }}
         (Some
           {{
           A mock-up of a project's code exploration entry point, with a header
           containing releases, issues, merge requests and current branch.
           }}) }}

       If you missed Simon introducing the projects concept at Unison Forall,
       you can watch it [here](https://youtu.be/aqLkcI_Yobc).

       Work is underway to bring this set of features to the Unison community.
       We're excited to share more about it in 2023!

    ## UCM developer experience improvements

       The UCM itself received many usability improvements in 2022. One major
       ergonomics shift for users of the UCM has been the change from globally
       available namespaces to scoped namespaces. A namespace can now reference
       the terms inside its child namespaces, but not the terms in its parent
       or sibling namespaces. This change makes it simpler to split your
       codebase into different libraries and applications, without unwanted
       references across namespaces.

       Other notable additions include:

       * The `add.run` command which adds the results of the last `run` to the
         codebase as a term
       * Snappier startup time for the UCM and general performance improvements
       * Support for the `do` keyword as syntax for delayed computations

  # Be a part of Unison in 2023

    We're excited to see what the year ahead has in store for Unison. If you've
    been following along with Unison for a while, thank you, we're glad you're
    here; and if you're new,
    [2023 is a great time to get started writing Unison. 😃](https://www.unison-lang.org/learn/quickstart/)
  }}

blog.writeupOfOurFirstUnisonMeetup.index : Doc
blog.writeupOfOurFirstUnisonMeetup.index =
  use Optional None
  {{
  {{
  frontMatter
    [ ( "summary"
      , "We had our first ever Unison meetup last Tuesday! If you missed it or just want to look back on it fondly (or if like me you struggle to remember anything from more than 2 days ago..), this post is for you!!"
      )
    , ("date", "2019-04-04")
    , ("authors", "paul-chiusano")
    , ("categories", "news")
    , ("categories", "announcements")
    , ("featuredImage", "/assets/thing1.svg")
    ] }}

  # Writeup of our first Unison meetup

    We had our
    [first ever Unison meetup last Tuesday](https://www.meetup.com/Boston-Unison/events/259532783/)!
    If you missed it or just want to look back on it fondly (or if like me you
    struggle to remember anything from more than 2 days ago..), this post is
    for you!! Myself, Arya, and Rúnar planned the agenda and presented.
    Overall: it was a lot of fun and I found it meaningful and motivating,
    thanks to everyone who came and who helped make it a success!

    After some pizza and mingling, I started by giving a quick intro to Unison
    and the motivation for it: programming is fun, useful, and beautiful, and
    deserves great languages and tools that make the programming process
    delightful or at least REASONABLE in all aspects. Sadly, very little about
    how programming works has been intentionally designed or crafted; things
    are often done some way because of uncareful decision made long ago when
    computers still had 640kb of memory and we just didn't know better. 😬
    Unison started as an experiment: what if you rethought programming today
    and tried to make it as amazing as possible?

    Our thesis: there's one area in particular where current programming
    languages and tools result in lots of complexity, and that's building
    distributed, elastic systems. Though we're trying to improve programming
    generally, making whole distributed systems simply describable using one
    language has been an important motivator for the work on Unison, and led us
    to some core technical decisions.

    From there, Arya and Rúnar introduced themselves and then we went right
    into a demo of Unison, as it stands today. It was a small group so we
    encouraged people to jump in with questions, and there were a lot of
    questions and discussion, which was all good! I'll include some of the
    questions inline as I go, and then some additional ones at the end. (Also,
    if you were at the event and this writeup is missing something, please
    leave a comment!)

    Rúnar kicked off the demo by starting the `unison` command line tool, which
    he put on one half of the screen, and a text editor (he's a Vim user) on
    the other side. We're used to thinking of "the codebase" as a bag of text
    files that we mutate in order to evolve our codebase, but in Unison, the
    codebase is a more structured object which undergoes a series of well-typed
    transformations and is never in a broken state, more like a purely
    functional data structure.

    He showed a little bit of the actual repository structure too: the codebase
    isn't just a giant binary database file, it has a directory structure
    that's designed with some cleverness to avoid ever producing a git merge
    conflict.

    > Q: How? A: There are a few tricks but an important idea is to name files
    based on a hash of their content. Thus, files in the codebase format never
    change, only new files are introduced, and git merges directories of such
    files by taking their union.

    When you start up `unison`, it watches for changes to `.u` files (which
    contain Unison code) in the current directory or any of its subdirectories.
    When it detects a change, it parses and typechecks any definitions in the
    file and then evaluates any "watch expressions", which are just lines
    starting with `>`. So one of the first things Rúnar did was open up a file
    `meetup1.u`, and type:

    ``` unison
    > 4 + 4
    ```

    After saving the file, `unison` instantly responded with:

    ``` ucm
    master>

    ┌
    │  1 | > 4 + 4
    │        ⧩
    │        8
    └
    ```

    Here's a screenshot of the setup:

    {{
    Image
      {{
      Basic setup writing Unison
      }}
      {{
      /assets/feed/writeup-of-our-first-unison-meetup/basic-setup.png
      }}
      None }}

    This makes for a nice little interactive loop when developing code, and it
    replaces the need for a REPL (no more typing import statements or switching
    to a separate line-oriented editor to quickly test your code).

    > Also note: the `meetup1>` prompt from the `unison` tool is saying that
    the `meetup1` is the current active branch. The Unison codebase has a
    notion of branches, which you can `fork`, `merge`, etc, similar to git, but
    they aren't modeled as git branches and you can easily reference code from
    multiple branches in the same program (which is useful for say, profiling
    or other cross-branch comparisons that are annoying to do in git).

    From there, Rúnar wrote a function `unfold`, which generates a list by
    repeatedly applying a function to some state to produce an output value and
    a new state. He then used it to generate the powers of 2 less than 100:

    ``` unison
    use Optional None Some

    unfold : s -> (s -> Optional (a, s)) -> [a]
    unfold s f = case f s of
      None -> []
      Some (a, s') -> a `cons` unfold s' f

    > unfold 1 (n -> if n < 100 then Some (n, n * 2)
                     else None)
    ```

    {{
    Image
      {{
      Unfold implementation
      }}
      {{
      /assets/feed/writeup-of-our-first-unison-meetup/unfold.png
      }}
      None }}

    Once he was satisfied with that, he typed `add` in the command line tool to
    add the `unfold` definition to the codebase. He then **deleted** the code
    from his `meetup1.u` scratch file!! We don't need the original source once
    the code has been slurped up into the codebase since we can view or edit it
    at any time later. He demonstrated this by typing `view unfold` which
    showed the very same `unfold` function he just wrote (but autoformatted)
    and then `edit unfold` which added this source code to the top of his
    scratch file for further editing.

    Rúnar showed a few other features of the `unison` tool: you can easily
    search for and view definitions that exist in the codebase, and you can
    trivially rename definitions. So for instance, he took a look at the
    `Optional` type, which is used by `unfold`:

    ``` ucm
    > view Optional

      type Optional a = None | Some a
    ```

    And he then did a `rename Optional.None Nothing` and `rename Optional.Some
                    Just`, renaming those two constructors of `Optional` to
    `Nothing` and `Just`. A subsequent `view unfold` showed this rename had
    been propagated:

    ``` unison
    unfold : s -> (s -> Optional (a, s)) -> [a]
    unfold s f = case f s of
      Nothing -> []
      Just (a, s') -> a `cons` unfold s' f
    ```

    He emphasized an important point here that this `rename` operation isn't
    like an IDE doing a bunch of text munging on your behalf, resulting in a
    massive textual diff and also breaking any code outside your IDE's purview
    (like your library's downstream users). Rather, the `unfold` definition and
    any other code that depends on `Optional` is __completely unchanged__ by
    the renaming of the `Optional` constructors, and you're free to make these
    name changes without fear of breaking anything (even code you don't know
    about). A `rename` is always 100% accurate and instantaneous. Nice!!

    Unison achieves this by giving a unique, content-based cryptographic hash
    for each definition, and referring to other code using these hashes. The
    mapping of names to hashes is just metadata for humans, used to resolve
    names to hashes at parse time when slurping up code into the codebase, and
    used for the other direction when displaying code for the user. Doing
    `ls -l unfold` (vs just `ls unfold`) shows the hashes alongside the
    signatures, which Rúnar also showed.

    People had a bunch of questions, here are a few of them:

    * Could the `find` / `ls` command show docstrings or other more useful
      information besides just the type signature?
      * Yes, totally, this is a good idea! Not implemented yet though.
    * Are these hashes affected by variable names?
      * No. Variable names are converted to their
        [De Bruijn index](https://en.wikipedia.org/wiki/De_Bruijn_index) as
        part of the hashing algorithm, so name choices don't affect the hash.
        For instance `id x = x` will hash the same as `identity a = a`, since
        both the `a` and `x` will have the same De Bruijn index of __0__.
    * What happens to comments?
      * Currently, they are thrown out by the lexer! This is pretty silly. An
        uncontroversial choice would be to just not do that and instead attach
        them to the AST.
      * But there is some room for innovation here, making comments more
        structured, rather than just blobs of freeform text. (For instance,
        imagine if comments mentioning `Optional.None` could be automatically
        renamed as well, with 100% accuracy.)
    * Are module cycles a thing?
      * No. You only have a cycle if you have mutually recursive definitions.
        You can never create a cycle by adding a new definition that references
        only previous definitions. This behavior comes for free because Unison
        tracks dependencies at the most fine-grained level possible: individual
        definitions.

    We pointed out that you can also give multiple names to the same hash and
    you can depend on a single definition rather than an entire library. This
    led to more good questions:

    * Hmm, how do these more fine grained dependencies work out in practice?
      What about the diamond dependency problem and dependency hell?
      * We punted on talking about this one in detail (but it would be cool to
        spend a session even just on this), but the basic answer is that many
        of these concerns just disappear with the Unison approach of making all
        definitions immutable and content addressed. We should do a follow-up
        post on this one.
    * Can people use their own naming preferences for the same definitions?
      * That makes total conceptual sense and would be easy to do but we
        haven't implemented anything for it yet.
    * What happens if two people pick the same name (say `frobnicate`) for
      different definitions?
      * That's fine as long as `frobnicate` names exist in separate branches:
        each Unison branch gets its own namespace. If those branches get
        merged, then Unison will encourage (but not require) that you rename
        one or both. In the meantime, the merged branch is still usable and the
        names will be shown as `frobnicate#2aQjd` and `frobnicate#9jfPv` (we
        call these names "hash-qualified").
      * Also: you can use qualified names, like `pchiusano.utils.frobnicate`
        and we expect people will do this. If people adopt this convention,
        name conflicts arise more when people working within the same project,
        like if Alice and Bob both add a different `frobnicate` definition to
        the same module.

  # Fuzzy string matching

    Rúnar then handed it over to me to implement something a little less
    trivial. I used his `unfold` function to implement a fuzzy text matching
    algorithm. Before prepping the talk, I was only familiar with using edit
    distance for this purpose, but I recently learned a nifty little algorithm,
    called
    [Strike A Match](http://www.catalysoft.com/articles/StrikeAMatch.html),
    which I implemented. The algorithm just
    __compares the overlap in the set of adjacent character pairs__. So, for
    instance, the text `"Alice"` and `"Alicia"` can be broken up into the
    character pairs:

    ``` raw
    "Alice"  -> {"Al", "li", "ic", "ce"}
    "Alicia" -> {"Al", "li", "ic", "ci", "ia"}
    ```

    Notice it has three character pairs in common (''{"Al", "li", "ic"}''),
    among 6 total in their union. So a simple metric of their similarity is
    just the size of the intersection divided by the size of the union
    (sometimes called the
    [Jacaard index](https://en.wikipedia.org/wiki/Jaccard_index)).

    First I started implementing `sliding`, a function to get all these
    adjacent character pairs, using `unfold`. I showed how you can type any
    unbound symbol (I like `hmm`) and have Unison tell you what type it's
    expecting there, which is handy when filling in arguments.

    {{
    Image
      {{
      Using unfold to generate adjacent character pairs (1)
      }}
      {{
      /assets/feed/writeup-of-our-first-unison-meetup/sliding.png
      }}
      None }}

    Eventually I got:

    ``` unison
    sliding : Text -> [Text]
    sliding t =
      step t = if Text.size t < 2 then None
               else Some (take 2 t, drop 1 t)
      unfold t step

    > sliding "Alicia"
    ```

    {{
    Image
      {{
      Using unfold to generate adjacent character pairs (2)
      }}
      {{
      /assets/feed/writeup-of-our-first-unison-meetup/sliding2.png
      }}
      None }}

    And then after that worked fine, I went ahead and used `sliding` to
    implement the similarity function:

    ``` unison
    -- number in 0 to 100 where 100 means sets are the same
    -- 0 they are totally different
    jacaard : Set a -> Set a -> Nat
    jacaard s1 s2 =
      100 * (Set.size (s1 `intersect` s2))
          / (Set.size (s1 `union` s2))

    -- uses type-directed name resolution to resolve to Set.fromSequence
    -- should be 50, since intersection is size 1, and union is size 2
    > jacaard (fromSequence [1]) (fromSequence [1,2])

    similarity : Text -> Text -> Nat
    similarity t1 t2 =
      jacaard (fromSequence (sliding t1))
              (fromSequence (sliding t2))

    > similarity "Alice" "Alice"
    > similarity "Alice" "Alicia"
    > similarity "Alice" "Bob"
    > similarity "French" "France"
    ```

    Here's the output:

    ``` raw
    ┌
    │  8 | > sliding "Alicia"
    │        ⧩
    │        ["Al", "li", "ic", "ci", "ia"]
    └
    ┌
    │  16 | > jacaard (fromSequence [1]) (fromSequence [1,2])
    │         ⧩
    │         50
    └
    ┌
    │  23 | > similarity "Alice" "Alice"
    │         ⧩
    │         100
    └
    ┌
    │  24 | > similarity "Alice" "Alicia"
    │         ⧩
    │         50
    └
    ┌
    │  25 | > similarity "Alice" "Bob"
    │         ⧩
    │         0
    └
    ┌
    │  26 | > similarity "French" "France"
    │         ⧩
    │         25
    └
    ```

    Success!!

    Since I've started programming with watch expressions that instantly update
    like this, I never want to go back to using a REPL for exploration or quick
    testing, and it's possible to extend the idea just a little bit to support
    writing tests that become a more permanent artifact of your codebase as
    well (and the test results can be perfectly incrementally computed).

  # Refactoring

    Arya then took over, showing our progress on making it nice to refactor a
    Unison codebase. He has more of a writeup
    [in this post](./updates.html#post-start). The basic idea is that you are
    never dealing with a morass of compile errors, many of which are misleading
    or covering up other errors. Instead, the command line tool walks you
    through the refactoring step by step, one update at a time, in a sensible
    order that avoids repeatedly updating the same definitions. Even though
    there's more work to do to make the actual UI for this nice, I'm convinced
    that the approach is the Right Thing™️ and in the future we'll look back on
    the status quo and wonder WTH we were thinking!

  # Other questions

    Here's a smattering of other questions that I remember (if I've missed any
    please leave a comment):

    * What's the type system?
      * Unison starts with Dunfield and Krishnaswami's
        [Complete and Easy Bidirectional Typechecking for Higher-Rank
        Polymorphism](https://www.cl.cam.ac.uk/~nk480/bidir.pdf). That type
        system has very good type inference and supports higher supports
        higher-rank types as well. I'd say our extensions to what's in the
        paper were very straightforward: we added data types, pattern matching,
        let / let rec, and a few other language constructs which weren't in the
        original paper for simplicity. Neel Krishnaswami was helpful in
        answering various questions we encountered while implementing it!
      * For Unison's algebraic effects, we adapted
        [Frank's type system](https://arxiv.org/abs/1611.09259), by Lindley,
        McBride, and McLaughlin, and Conor McBride helped in answering
        questions abaout it. Some of the changes vs Frank are kind of
        interesting and we'll probably do a writeup of that at some point.
    * What about bounded polymorphism and typeclasses? This deserves a longer
      post, but here are a few answers:
      * For just name overloading, Unison supports that via type-directed name
        resolution.
      * For effectful programming, you use algebraic effects, no need to pass
        dictionaries around.
      * Functions like `<`, `==`, etc, work for any type (actually we'll
        probably restrict their type a bit just to keep parametricity in tact).
        But these are builtins, you can't implement your own (could we somehow
        make that possible though?).
      * The only thing that Unison has which is as general as typeclasses is
        explicit dictionary passing. This can sometimes be a bit tedious.
      * Typeclasses are super convenient but I don't think that as is they're a
        good fit for Unison, and they have problems even in the Haskell world (
        [relevant post](http://pchiusano.github.io/2018-02-13/typeclasses.html)
        ). Also, not for nothing: they're a pain to implement.
      * Summary: We're thinking about it. If you've got ideas, let us know!

    There was an interesting discussion around typeclasses after the meetup
    (some folks headed over to a local pub for drinks and food). All the
    approaches to bounded polymorphism (typeclasses a la Haskell, modules a la
    ML / Scala, dictionary passing + implicit parameters, OO style subtyping
    ..) have strengths and weaknesses. And that's the problem: there's no
    approach that's a total slam dunk, which makes you think "YES, PROBLEM 100%
    SOLVED." Every approach has its issues. I'm hoping for some bolt of insight
    about this…

  # That's all!

    I hope this writeup was useful for folks. We're going to try doing the
    meetups monthly. Something else we've considered doing in addition to the
    in person meetups is an "online only" meetup over Twitch. If you're not
    local to the Boston area but have an interest in doing something like this,
    let us know!
  }}

blog._getPosts : Soup ->{Throw XMLError} [(Text, Text)]
blog._getPosts input =
  use Soup text
  blogXML = input // "feed"
  Each.toList do
    entry = blogXML |> descendants |> Soup.named "entry"
    title = entry // "title" |> text
    date = entry // "updated" |> text
    (title, date)

docs.atAGlance : Doc
docs.atAGlance =
  use List ++ +: :+ map
  use Nat * +
  use abilities index
  use wordle.utils.emojis learnMore
  {{
  # 👀 Unison at a glance

    This document contains code snippets with a minimum of exposition. Links
    are provided throughout to more comprehensive docs sections. If you haven't
    downloaded the UCM, [you might want to do that first. 😎]({quickstart})

    {{
    docAside
      {{
      Many of the code samples and snippets here are clickable! They link to
      code source definitions and docs.
      }} }}

    ## Hello World

       Write your Unison code in any `.u` suffixed
       ["scratch" file.]({_scratchFiles})

       The classic `helloWorld` program performs console interactions via the
       IO ability. [Read about how abilities model effects in Unison.]({index})

           @source{helloWorld}

       Execute the entry point to your program with the {{
       docTooltip {{ `run` }} ucmCommands.run }} UCM command.

       ``` ucm
       scratch/main> project.create hello-world
       hello-world/main> run helloWorld
       ```

       Or {{ docTooltip {{ `add` }} ucmCommands.add }} your `helloWorld`
       program to the codebase and run it by packaging it up in a binary
       executable!

       ``` ucm
       hello-world/main> add
       hello-world/main> compile helloWorld helloFile
       ```

       This will produce an executable file called `helloFile.uc` in the same
       directory as the codebase. You can then start your program in your
       terminal.

       ``` bash
       $ ucm run.compiled helloFile.uc
       ```

       {{
       learnMore
       }}[Learn more about executing Unison programs]({runningPrograms})

    ## Basic functions

       The following introduces a function `double` with one parameter.
       [Unison conventions for defining functions are detailed here]({functions})

           @source{glance.double}

       ``` unison
       > double 4
       ```

       The `>` in a scratch file runs the `double` function in a
       {{ docTooltip {{ watch expression }} watchExpression }}.

       {{
       learnMore
       }}[The Unison tour walks through watch expressions and other workflow
       features]({tour})

    ## Delayed computation syntax

       There are two ways to indicate that a computation is delayed in Unison.
       The first is the `do` keyword:

       ``` unison
       main : '{IO,Exception}()
       main = do
        printLine "`do` is commonly seen at the start of an indented block"
       ```

       The {{ docCode {{ ' }} }} symbol is the second syntax option for
       introducing a {{ docTooltip {{ thunk }} thunk }}.

       ``` unison
       Stream.toList (Stream.map Nat.increment '(emit 1))
       ```

       Calling, or "forcing" the delayed computation also has two options.
       Prepend `!` to the delayed computation or append `()` to call it.

           @source{streamList}

       ``` unison
       !streamList
       ```

       ``` unison
       streamList()
       ```

       [A more detailed look at delayed computations]({valuesAndFunctions.delayedComputations})

    ## Text manipulation

       Unison has a number of {type Text} splitting and searching functions:

       ```
       Text.filter isDigit "abc_10203_def" |> Text.split ?0
       ```

       Use {type Pattern} for more flexible regex-like text pattern operations.

       ```
       Pattern.run (Pattern.capture (Pattern.many (chars "🍎🍏"))) "🍏🍎🍎🍏123"
       ```

       [More examples for the Pattern API]({Pattern.doc})

    ## List literals

       Square brackets introduce a
       [Unison list.]({{ docLink (docEmbedTermLink do commonCollectionTypes) }})

       ```
       [0, 1, 2, 3] ++ [4, 5]
       ```

       The {++} is our {{ docTooltip {{ operator }} operators }} for list
       concatenation.

       ```
       head = 1 +: [2, 3, 4]
       head :+ 5
       ```

       [A variety of list patterns are available for lists.]({languageReference.listPatterns})

       {{
       learnMore
       }}[Learn more about common collection types in Unison]({commonCollectionTypes})

    ## List transformations

       ```
       Nat.range 0 10
         |> map (x -> x * 100)
         |> List.filter (const true)
         |> List.foldLeft (+) 0
       ```

       The {|>} operator is a "pipe" which passes the result of executing the
       expression on the left as an argument to function on right.

       The parenthesized `` x -> x * 100 `` argument to {map} is an example of
       [lambdas in Unison.]({_lambdaSyntax})

       {{
       learnMore
       }}[Learn more about operators like `|>`]({functionApplicationOperators})

    ## if/else and pattern matching

       The expression below is written with both
       [if then and else syntax]({ifThenAndElse}) and with
       [pattern matching syntax]({patternMatching})

       ``` unison
       use Nat mod
       isEven1 num =
         if mod num 2 === 0 then "even" else "odd"
       isEven2 num = match num with
         n | mod n 2 === 0 -> "even"
         _ -> "odd"
       ```

       Unison's [pattern matching features]({patternMatching2}) include
       variable binding, pattern guards (separated by `|`), and as-patterns
       (indicated with an `@`).

       ```
       match Some 12 with
         Optional.None -> "none"
         Some n| Nat.isEven n  -> "n is a variable and | is a pattern guard"
         opt@(Some n) -> "opt binds to the entire optional value"
       ```

       The `cases` syntax can take the place of a full `match ... with`
       expression.

       ``` unison
       foo n = match n with
         0 -> "zero"
         _ -> "not zero"
       ```

       ``` unison
       foo = cases
         0 -> "zero"
         _ -> "not zero"
       ```

    ## Type declarations

       A unison data type with uniqueness determined by its name:

       ``` unison
       type LivingThings
         = Animal
         | Plant
         | Fungi
         | Protists
         | Monera
       ```

       A recursive Tree data type with a single type parameter:

       ``` unison
       type Tree a
         = Empty
         | Node a (Tree a) (Tree a)
       ```

       The structural keyword means that types defined with the same structure
       are identical.

       [More on data types and the difference between structural and unique.]({uniqueAndStructuralTypes})

       Record types allow you to name the fields of your type.

       ``` unison
       unique type Pet = {
          age : Nat,
          species : Text,
          foodPreferences : [Text]
       }
       ```

       Creating a record type generates a series of helper methods to access
       and update the fields of the data type.

       ``` ucm
       scratch/main> add Pet

        ⍟ I've added these definitions:

            unique type Pet
            Pet.age                    : Pet -> Nat
            Pet.age.modify             : (Nat ->{g} Nat) -> Pet ->{g} Pet
            Pet.age.set                : Nat -> Pet -> Pet
       ```

       [Record type syntax in depth]({recordTypes})

    ## Exception handling

           @source{nonZero}

       ```
       catch do nonZero 0
       ```

       An exception is "raised" with the {type Exception} ability and "caught"
       with a handler.

       [Our error handling with abilities doc describes this pattern and more
       error types in detail.]({errorHandling})

    ## Using abilities

       [Abilities are used for effect management in Unison.]({index})

           @source{getRandomElem}

       ```
       toOptional! do splitmix 42 do getRandomElem [1, 2, 3, 4, 5]
       ```

       This plucks a random element from the list by its index with
       {Random.natIn}, a function using the [Random ability.]({type Random}) If
       the index is not present in the list, it uses the {type Abort} ability
       to halt execution.

       {splitmix} and {toOptional!} are examples of
       [ability handlers.]({usingAbilitiesPt1})

    ## Distributed computations

       Distributed computations can be expressed
       __in the Unison language itself__ through the `Remote` ability.
       [Read about the Remote ability and its features](https://share.unison-lang.org/@unison/cloud/code/main/latest/types/Remote)

           @source{distributed}

       This simple map/reduce code can operate over a distributed sequence,
       where the data may live in many different nodes in a cluster.
       [This distributed computation use case has been fleshed out in an
       article.](https://www.unison-lang.org/articles/distributed-datasets/)

    ## Issuing an http request

       Pull the library from [Unison Share.](https://share.unison-lang.org/)
       with the {{ docTooltip {{ `lib.install` }} libInstall }} command.

       ``` ucm
       myProject/main> lib.install @unison/http
       ```

           @source{exampleGet}

       The first part of this code uses data constructors from the http library
       to create a full uri out of an authority and path. The request is
       handled by passing it to the Http handler.

       [The http library has great docs!](https://share.unison-lang.org/@unison/http)

    ## Basic file operations

           @signatures{readFileUtf8, FilePath.writeFile, renameFile}

       Our standard library has a number of helpful File operations built in.
       They're located under the {type FilePath} and {type Handle} namespaces.

    ## Concurrency primitives

       Concurrency primitives like {type MVar}, {type TVar}, and {type STM} are
       built into the base library. {type TVar} and {type STM} make it easy to
       write lock-free concurrent mutable data structures. For instance, here’s
       a simple lock-free queue implementation and a few helper functions:

           @source{type TQueue, enqueue, dequeue}

       The block introduced by {STM.atomically} below ensures that no one can
       access state of the queue until after the actions in the block have
       taken place.

           @source{queueExample}

       {{ SectionBreak }}

       {{ atAGlance._nav }}
  }}

docs.atAGlance.streamList : '[Nat]
docs.atAGlance.streamList = toDelayedList do Stream.range 10 15

docs.atAGlance._nav : Doc
docs.atAGlance._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Take a tour of Unison and the UCM]({{
      (docLink (docEmbedTermLink do tour))
      }})

      {{ wordle.utils.emojis.learnMore }}
      [Read about the big idea behind Unison](/theBigIdea)
    }} }}
  }}

docs.contributeDocs : Doc
docs.contributeDocs =
  {{
  # 📃 Contribute to the Docs

    The Unison language website is written in Unison's own computable
    documentation format!

    If you have suggestions, fixes, or feedback for the language documentation
    content, you can file a Unison Share ticket in the
    [website Unison Share repo](https://share.unison-lang.org/@unison/website).
    The **content** is hosted on Unison Share in the
    [@unison/website](https://share.unison-lang.org/@unison/website) project,
    while the [Github website repo](https://github.com/unisonweb/website)
    houses the front end used for styling and rendering the documentation.

    PR's are also welcome! To submit a PR for doc content, you'll need to
    follow the [PR process]({creatingPrs}).

    ## Steps

       1. `scratch/main> clone @unison/website` to create a local copy of the
          website.
       2. `@unison/website/main> branch @user/feature` to create a {{
          docTooltip {{ contributor branch }} contributorBranch }} of the
          website.
       3. If you haven't already done so,
          [set your default author]({authorLicense}).
       4. Now `edit desiredTerm` and hack away. When you're ready, `update`
          your codebase to add the term.
       5. Important! If your change requires linking back and forth between two
          docs, the UCM will not permit the doc cycle to be created. This is
          for good reasons. Instead, one of the docs links will need to be a
          relative url path link, like this
          `[my doc reference](./path-to-doc)`. You can test your link by
          building the website locally.
       6. Push your branch to Unison Share and
          [follow the instructions to create a contribution]({creatingPrs}).
       7. Finally mention your PR in the #documentation channel in the
          [Unison slack](https://unison-lang.org/slack).
  }}

docs.divBy : Nat -> Nat ->{Stream Nat} Nat
docs.divBy a b =
  use Nat /
  if b === 0 then
    emit b
    b
  else a / b

docs.escapeQuoteLiteral : Doc
docs.escapeQuoteLiteral = docCode {{ \" }}

docs.exercises.controlFlow : Doc
docs.exercises.controlFlow =
  {{
  # Control flow exercises

    A few completely optional exercises about control flow to try.

    {{ SectionBreak }}

    {{ controlFlow.ex1 }}

    {{ SectionBreak }}

    {{ controlFlow.ex3 }}

    {{ SectionBreak }}

    {{ controlFlow.ex4 }}
  }}

docs.exercises.controlFlow.ex1 : Doc
docs.exercises.controlFlow.ex1 =
  {{
  {{ exercise }} Exercise: Rearrange pattern match cases

  The following pattern match is in disarray. The ordering of the case
  statements doesn't allow some cases to be reached. Reorder the cases so that
  the evaluation of the pattern match produces the desired `` true `` result
  for the boolean expression.

  ``` unison
  use Universal
  itDependsUpon : Optional Text -> Text
  itDependsUpon = cases
    _ -> "So much depends"
    Some textValue -> "upon"
    None -> "a red wheel barrow"
    Some x | size x === 3 -> "glazed with rain"
    optionalValue | Optional.contains "all" optionalValue -> "water"

  (itDependsUpon None === "a red wheel barrow") && (itDependsUpon (Some "spring") === "upon") && (itDependsUpon (Some "and") === "glazed with rain") && (itDependsUpon (Some "all") === "water")
  ```

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer:
    }}
    {{
    One possible answer:

    ``` unison
    itDependsUpon : Optional Text -> Text
      itDependsUpon = cases
        optionalValue  | Optional.contains "all" optionalValue -> "water"
        Some x         | Text.size x === 3 -> "glazed with rain"
        Some textValue -> "upon"
        None           -> "a red wheel barrow"
        _              -> "So much depends"
      (itDependsUpon None === "a red wheel barrow")
        && (itDependsUpon (Some "spring") === "upon")
        && (itDependsUpon (Some "and") === "glazed with rain")
        && (itDependsUpon (Some "all") === "water")
    ```

    Note, you could also have a working answer with the {Optional.None} case at
    the top of the match statement.
    }} }}
  }}

docs.exercises.controlFlow.ex2 : Doc
docs.exercises.controlFlow.ex2 =
  {{
  {{ exercise }} Exercise: Define a Unison data type

  Create a data type `Shape` which has two data constructors `Square` taking a
  {type Nat} representing the length of the sides and `Rectangle`, taking two
  {type Nat} values for the height and width of the rectangle. Then write a
  function `drawShape` which takes in a value of your Shape and a {type Char}
  and returns a list of list of characters forming the filled in body of that
  shape. The first list represents the y dimension and the inner list
  represents the x dimension. We've provided a {draw} function so you can test
  your implementation of `drawShape` against the two example values. Type
  `run testDraw1` and `run testDraw2` in the UCM to see your results.

      @source{draw}     @source{testDraw1}     @source{testDraw2}

  {{ Folded
    true {{ {{ wordle.utils.emojis.answer }} Answer: }} {{
    You can define the type for shape like this:

    ``` unison
    type Shape = Square Nat | Rectangle Nat Nat
    ```

    And one way `drawShape` can be implemented is below:

        @source{drawShape}
    }} }}
  }}

docs.exercises.controlFlow.ex2.answers.drawShape : Shape -> Char -> [[Char]]
docs.exercises.controlFlow.ex2.answers.drawShape shape char = match shape with
  Square l               ->
    use List fill
    side = fill l char
    fill l side
  Rectangle height width ->
    use List fill
    x = fill width char
    fill height x

docs.exercises.controlFlow.ex2.draw : [[Char]] -> '{IO} ()
docs.exercises.controlFlow.ex2.draw chars =
  line ln = fromCharList (intersperse ?\s ln)
  x = List.map line chars
  y = Text.join "\n" x
  do unsafeRun! do printLine y

docs.exercises.controlFlow.ex2.testDraw1 : '{IO} ()
docs.exercises.controlFlow.ex2.testDraw1 = draw (drawShape (Square 7) ?X)

docs.exercises.controlFlow.ex2.testDraw2 : '{IO} ()
docs.exercises.controlFlow.ex2.testDraw2 = draw (drawShape (Rectangle 12 8) ?X)

docs.exercises.controlFlow.ex3 : Doc
docs.exercises.controlFlow.ex3 =
  use wordle.utils.emojis answer
  {{
  {{ exercise }} Exercise: Practice using cases `syntax`

  Rewrite the following function to use `cases` instead of `match … with`:

  ``` unison
  authorMatcher : Text -> Optional Text
  authorMatcher book = match book with
    "Of Mice and Men" -> Some "John Steinbeck"
    "To Kill a Mockingbird" -> Some "Harper Lee"
    "The Tempest" -> Some "William Shakespeare"
    _ -> None
  ```

  {{
  Folded
    true
    {{
    {{ answer }} Answer
    }}
    {{
    The argument to the function can be inferred, remove the reference to it in
    the term definition and substitute `cases` for the `match book with`
    phrase.

    ``` unison
    authorMatcher : Text -> Optional Text
    authorMatcher = cases
      "Of Mice and Men" -> Some "John Steinbeck"
      "To Kill a Mockingbird" -> Some "Harper Lee"
      "The Tempest" -> Some "William Shakespeare"
      _ -> None
    ```
    }} }}

  Rewrite the following multi-argument function with the `cases` syntax.

  ``` unison
  use Nat
    matchTwo : Nat -> Nat -> Text
    matchTwo n1 n2 = match (n1,n2) with
      (a, b) | a < 3 -> "small number first"
      (a, b) | b < 3 -> "small number second"
      _ -> "big number"

    matchTwo 5 2
  ```

  {{ Folded true {{ {{ answer }} Answer }} {{     @source{matchTwo} }} }}
  }}

docs.exercises.controlFlow.ex3.answerCases.matchTwo : Nat -> Nat -> Text
docs.exercises.controlFlow.ex3.answerCases.matchTwo = cases
  a, b
    | a Nat.< 3 -> "small number first"
    | b Nat.< 3 -> "small number second"
  _, _ -> "big number"

docs.exercises.controlFlow.ex4 : Doc
docs.exercises.controlFlow.ex4 =
  {{
  {{ exercise }} Exercise: Rewrite an if/else expression as a pattern match

  This if / else expression can also be written as a case statement. Translate
  it so that it uses a `match` expression.

      @source{ex4.myText}

  The following are a few test cases which should pass for your match statement
  version of the function.

      @source{ex4.test1}     @source{ex4.test2}     @source{ex4.test3}
      @source{test4}     @source{test5}     @source{test6}

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer
    }}
    {{
        @source{answer.myText}
    }} }}
  }}

docs.exercises.controlFlow.ex4.answer.myText : Text -> Text
docs.exercises.controlFlow.ex4.answer.myText = cases
  "Testing123" -> "I'm a test"
  t
    | Text.size t Nat.> 8                           ->
      Text.repeat (Text.size t) "!"
    | Text.size t Nat.> 5 && Text.take 1 t === "a"  -> "Starts with A"
    | Text.size t Nat.> 5                           -> "Long word"
    | t === Text.reverse t                          -> "Mirror"
  _ -> "Other"

docs.exercises.controlFlow.ex4.myText : Text -> Text
docs.exercises.controlFlow.ex4.myText word =
  use Nat >
  use Text size
  if word === "Testing123" then "I'm a test"
  else
    if size word > 8 then Text.repeat (size word) "!"
    else
      if size word > 5 && Text.take 1 word === "A" then "Starts with A"
      else
        if size word > 5 then "Long word"
        else if word === Text.reverse word then "Mirror" else "Other"

test> docs.exercises.controlFlow.ex4.test1 =
  check (ex4.myText "Testing123" === "I'm a test")

test> docs.exercises.controlFlow.ex4.test2 =
  check (ex4.myText "Aaaaahh!" === "Starts with A")

test> docs.exercises.controlFlow.ex4.test3 =
  check (ex4.myText "Boooooooooo" === "!!!!!!!!!!!")

test> docs.exercises.controlFlow.ex4.test4 =
  check (ex4.myText "hannah" === "Long word")

test> docs.exercises.controlFlow.ex4.test5 =
  check (ex4.myText "wow" === "Mirror")

test> docs.exercises.controlFlow.ex4.test6 =
  check (ex4.myText "Nope" === "Other")

docs.exercises.valuesFunctions : Doc
docs.exercises.valuesFunctions =
  {{
  # Values and functions exercises

    A few exercises relevant to values and functions.

    {{ SectionBreak }}

    {{ valuesFunctions.ex1 }}

    {{ SectionBreak }}

    {{ valuesFunctions.ex2 }}

    {{ SectionBreak }}

    {{ valuesFunctions.ex3 }}

    {{ SectionBreak }}

    {{ valuesFunctions.ex4 }}

    {{ SectionBreak }}

    {{ valuesFunctions.ex5 }}
  }}

docs.exercises.valuesFunctions.ex1 : Doc
docs.exercises.valuesFunctions.ex1 =
  use List zipWith
  {{
  {{ exercise }} Exercise: Understand parentheses in type signatures

  {zipWith} is a function which takes in two lists and a function which
  operates on the elements in both lists sequentially until the end of one of
  the lists is reached.

  A mysterious parenthesis blight has wiped away the necessary parentheses to
  communicate this.

  ``` unison
  blightedZipWith: a -> b -> c -> [a] -> [b] -> [c]
  ```

  Where should the parentheses in the type signature go? Where should the
  implied parentheses go for this type signature?

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint
    }}
    {{
    ``` unison
    threeArgumentFunction : Nat -> Text -> Boolean -> Nat
    ```

    Is analogous to

    ``` unison
    threeArgumentFunction: Nat -> (Text -> (Boolean -> Nat))
    ```

    It's easy to conflate the order of function **application** (the order in
    which a function is called) with the order of its type notation. Here we're
    looking for a description of where to draw the implied and actual
    parentheses for how the function arrow `->` works in a type signature.
    }} }}

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer
    }}
    {{
    The required parentheses are as follows:

    ``` unison
    zipWith: (a -> b -> c) -> [a] -> [b] -> [c]
    ```

    The first argument to {zipWith} is a function with two arguments `a` and
    `b`. Lists `[a]` and `[b]` are the two lists being zipped, and `[c]` is the
    return type of the over all function.

    Adding the implied parentheses for the type signature yields:

    ``` unison
    zipWith: ((a -> (b -> c)) -> ([a] -> ([b] -> [c])))
    ```
    }} }}
  }}

docs.exercises.valuesFunctions.ex2 : Doc
docs.exercises.valuesFunctions.ex2 =
  {{
  {{ exercise }} Exercise: Understand parentheses when calling functions

  A similar parenthesis blight has afflicted the site where we're calling our
  function. Add both the implied and necessary parentheses to the following
  code

  ``` unison
  use Nat
  listA = [1,2,3,4,5]
  listB = [2,4,6,8,10]

  fixMe = List.zipWith a -> b -> a + b listA listB
  ```

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer
    }}
    {{
    The required parentheses are as follows:

    ``` unison
    use Nat
    listA = [1,2,3,4,5]
    listB = [2,4,6,8,10]

    fixMe = List.zipWith (a -> b -> a + b) listA listB
    ```

    Adding the implied parentheses for the order in which function application
    occurs:

    ``` unison
    use Nat
    listA = [1,2,3,4,5]
    listB = [2,4,6,8,10]

    fixMe = ((List.zipWith (a -> b -> a + b) listA) listB)
    ```
    }} }}
  }}

docs.exercises.valuesFunctions.ex3 : Doc
docs.exercises.valuesFunctions.ex3 =
  use List foldLeft
  use Nat +
  {{
  {{ exercise }} Exercise: Determine a type signature for a function from how
  it's called

  Write the signature for {foldLeft} given the following information:

  An example of how `foldLeft` is called is

  ```
  foldLeft (acc i -> Text.size i + acc) 0 ["a", "bb", "ccc", "ddd"]
  ```

  You can read about what {foldLeft} does by reading the docs linked here:
  {List.foldLeft.doc} or by entering `docs List.foldLeft` in the UCM.

  {{ ex3.hints.h1 }}

  {{ ex3.hints.h2 }}

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer
    }}
    {{
    Note, the actual signature of {foldLeft} contains a parameter in curly
    braces, `{e}`. {foldLeft} is __ability polymorphic,__ meaning that the step
    function provided to it can perform effects. We'll be covering those later
    in our section on Abilities.

        @signature{foldLeft}
    }} }}
  }}

docs.exercises.valuesFunctions.ex3.hints.h1 : Doc
docs.exercises.valuesFunctions.ex3.hints.h1 =
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint
    }}
    {{
    Our example uses a function {Text.size} to transform {type Text} into a
    number, and then adds the length of each text element together, but
    {jsonschema.lib.base.data.List.foldLeft} should be polymorphic--that is, it
    should not care if it is operating on is a List of Text, or a List of Char
    or a List of Boolean.
    }}

docs.exercises.valuesFunctions.ex3.hints.h2 : Doc
docs.exercises.valuesFunctions.ex3.hints.h2 =
  use jsonschema.lib.base.data.List foldLeft
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint
    }}
    {{
    The first argument to {foldLeft} is a function with two arguments, the
    first is the value that is being accumulated as the fold function is
    operating on each element on the list, the second corresponds to the
    element of the list.

    The second argument to the {foldLeft} function is the value that should be
    applied when the higher order function encounters the end of the list.

    The third argument to List.foldLeft is the list being folded over.
    }}

docs.exercises.valuesFunctions.ex4 : Doc
docs.exercises.valuesFunctions.ex4 =
  use Nat * decrement
  {{
  {{ exercise }} Exercise: Debug a Unison function which fails to typecheck

  ``` unison
  brokenFactorial : Nat -> Nat
  brokenFactorial n =
    use Universal Nat
    if n === 0 then 1 else n * brokenFactorial decrement n
  ```

  We'll cover the `use` keyword later, we're using it above to disambiguate a
  few function names.

  Something is wrong with this function. It does not typecheck, and the UCM
  prints out the following error. See if you can fix it.

  ``` unison
  This looks like a function call, but with a Nat where the function should be.  Are you missing an operator?

    5 |     if n === 0 then 1 else n * brokenFactorial decrement n
  ```

  {{ ex4.hints.h1 }}

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer
    }}
    {{
    Due to the order of function application, we need to surround the call to
    {decrement} with parentheses.

    ```
    let
      factorial : Nat -> Nat
      factorial n = if n === 0 then 1 else n * factorial (decrement n)
      factorial 3
    ```
    }} }}
  }}

docs.exercises.valuesFunctions.ex4.factorial : Nat -> Nat
docs.exercises.valuesFunctions.ex4.factorial n =
  use Nat * ==
  if n == 0 then 1
  else n * docs.exercises.valuesFunctions.ex4.factorial (Nat.decrement n)

docs.exercises.valuesFunctions.ex4.hints.h1 : Doc
docs.exercises.valuesFunctions.ex4.hints.h1 =
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint
    }}
    {{
    What is the order of function application in the `else` clause?
    }}

docs.exercises.valuesFunctions.ex5 : Doc
docs.exercises.valuesFunctions.ex5 =
  {{
  {{ exercise }} Exercise: Write your own Unison function

  Write a function which, when given a list, removes every other element from
  the list. So, `` ["a", "b", "c", "d"] `` becomes ``["a", "c"]``. The function
  should work on a list of any type.

  ``` raw
  removeEveryOther : [a] -> [a]
  removeEveryOther as = base.todo "Implement here"
  ```

  Some tests to validate this function are copied below, but they're also
  available under the `ex5.tests` namespace.

  ``` unison
  test> test1 = check(removeEveryOther ["a","b","c","d","e"] test.=== ["a", "c", "e"])
  test> test2 = check(removeEveryOther [1] test.=== [1])
  test> test3 = check(removeEveryOther [] test.=== [])
  ```

  {{ ex5.hints.h1 }}

  {{ ex5.hints.h2 }}

  {{ a1 }}
  }}

docs.exercises.valuesFunctions.ex5.answers.a1 : Doc
docs.exercises.valuesFunctions.ex5.answers.a1 =
  Folded
    true {{ {{ wordle.utils.emojis.answer }} Answer }} {{
    One possible answer:

        @source{removeEveryOther}
    }}

docs.exercises.valuesFunctions.ex5.answers.removeEveryOther : [a] -> [a]
docs.exercises.valuesFunctions.ex5.answers.removeEveryOther ns =
  iList = List.indexed ns
  tups = List.filter (tup -> Nat.mod (at2 tup) 2 === 0) iList
  List.map (tup -> at1 tup) tups

docs.exercises.valuesFunctions.ex5.hints.h1 : Doc
docs.exercises.valuesFunctions.ex5.hints.h1 =
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint
    }}
    {{
    Check out {jsonschema.lib.base.data.List.indexed} for a simple way to pair
    each element in the list with its index.
    }}

docs.exercises.valuesFunctions.ex5.hints.h2 : Doc
docs.exercises.valuesFunctions.ex5.hints.h2 =
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint
    }}
    {{
    Unison's modulo function is {Nat.mod}.
    }}

test> docs.exercises.valuesFunctions.ex5.tests.t1 =
  check
    (assertEquals (removeEveryOther ["a", "b", "c", "d", "e"]) ["a", "c", "e"])

test> docs.exercises.valuesFunctions.ex5.tests.t2 =
  check (assertEquals (removeEveryOther [1]) [1])

test> docs.exercises.valuesFunctions.ex5.tests.t3 =
  check (assertEquals (removeEveryOther []) [])

docs.fundamentals.abilities.abilityExercises.Stream.pipe :
  '{Stream a} () -> '{Ask a, Stream b} r -> '{Stream b} ()
docs.fundamentals.abilities.abilityExercises.Stream.pipe = todo "implement me"

docs.fundamentals.abilities.errorHandling : Doc
docs.fundamentals.abilities.errorHandling =
  use Abort abort
  use errorHandling divBy
  {{
  # Error handling with abilities

    We hope you've familiarized yourself with some of the common ways to
    [handle errors with Unison data types]({exceptionHandling}), this doc will
    discuss a different strategy for error management, using abilities. A more
    comprehensive introduction to abilities
    [can be found here](./usingAbilitiesPt1), but this doc does not rely on a
    detailed understanding of algebraic effects or writing ability handlers. In
    this doc we'll go through some common patterns and examples for expressing
    and handling errors with abilities in Unison.

    ## Why use abilities for error handling?

       Abilities allow us to express the possibility that an error might occur
       in a program __without__ the additional complexity of introducing a data
       type to enclose a function's desired output. Errors are still captured
       in the type signatures of functions through
       {{ docTooltip {{ ability requirements }} abilityRequirement }}, so
       you're still able to reason about the behavior of your program at the
       type level, but rather than managing the effect's presence in the
       remainder of the program through calls to functions like `flatMap` or
       `map` or special notation like `do` or `for expressions`, you can focus
       on the core behavior of your program, and delegate handling the error to
       enclosing handlers when absolutely necessary.

    ## Abort

       {type Abort} is an ability which expresses the termination of a program
       without additional information about the failure.

       {type Abort}'s sole {{
       docTooltip {{ request constructor }} requestConstructors }} is {abort}.
       Here's an example of when you might use {abort} in a function:

           @source{divBy}

       Note that the {type Abort} {{
       docTooltip {{ ability requirement }} abilityRequirement }} shows up in
       the return type of the function. This means that the caller of this
       function will either need to handle the ability or express the ability
       requirement in its own signature. In the example below `` myFunction ``
       calls `` divBy `` and therefore the {type Abort} ability requirement is
       present even though `` myFunction `` itself doesn't call {abort}.

           @source{myFunction}

       {{
       docCallout
         (Some style)
         {{
         In Unison it's common to translate between errors as represented by a
         data type and errors as expressed through abilities, so you'll find
         that the abilities in the base library have handlers that do just
         that. Look for functions prefixed `to` or `from` the ability type name
         like {toEither}.
         }} }}

       The {type Abort} ability requirement can be eliminated by translating it
       to an {type Optional} value with the handler {toOptional!}. Function
       executions which encounter the {abort} call get translated to
       {Optional.None} and function calls that are successful are wrapped in
       {Some}.

       ```
       toOptional! do divBy 1 0
       ```

       ```
       toOptional! do divBy 4 2
       ```

       Vice-versa, you can translate an {type Optional} value into the
       {type Abort} ability with the {Optional.toAbort} function.

       ``` unison
       Some 4 |> toAbort
       ```

    ## Throw

       The {type Throw} ability will stop a computation and return a value of a
       __specific type__ when an error condition occurs. For this reason
       {type Throw} is parameterized by the possible error type in function
       signatures which require it. {type Throw} has one request constructor,
       {throw}. Rewriting the {divBy} function to use {type Throw} yields:

           @source{divByThrow}

       We've chosen to {throw} a value of type {type Text} here, but in a
       larger application you might encode the particulars of your error in a
       custom data type.

       Structurally, the {type Throw} ability shares much in common with the
       {type Either} data type. Both capture information about the type of the
       error and both return a value of that type in the event of a failure.
       They offer the capability of providing enriched error reporting. You can
       eliminate the ability requirement for {type Throw} by translating it to
       a {type Either} with the {toEither} handler.

       ```
       toEither do divByThrow 1 0
       ```

    ## Exception

       The {type Exception} ability is similar to the {type Throw} ability,
       except the error type is pinned to be a data type called {type Failure}.
       For more information about how to construct a value of type
       {type Failure}
       [check out this document here.]({exceptionHandling.failure}) When a
       failure occurs, the Exception ability's request constructor,
       {Exception.raise}, surfaces relevant {type Failure} information to the
       enclosing handler. Many of the functions in the `base` library express
       the possibility of errors in terms of this ability.

       Here's how we might rewrite our function using {type Exception}:

           @source{divByException}

       In the above code, we're using the {Generic.failure} function to help
       generate a {type Failure} value. In a larger application with errors
       modeled as data types we might choose to construct our own
       {type Failure}.

       The base library provides a handler to translate the {type Exception}
       ability into value of type `Either Failure a`.

       ```
       catch do divByException 1 0
       ```

       {{
       docAside
         {{
         {type Exception} is common in the base library so a few functions
         exist for managing them. Check them out with the
         [`find`]({ucmCommands.find}) command in the UCM.
         }} }}

       ❗️ But if you're feeling bold you can also run…

       ```
       unsafeRun! do divByException 4 2
       ```

       If an exception is thrown the program will just crash.

       {{
       docCallout
         (Some important)
         {{
         The {type Exception} ability, along with the {type IO} ability, are
         the only two ability requirements that can remain unhandled in the
         return type of the function provided to the [`run`]({ucmCommands.run})
         command. The UCM runtime will stop the execution of the program which
         raises an {type Exception} with the {type Failure} in the console.
         }} }}

    ## Which strategy for error handling should I prefer?

       Given the correspondence between Unison abilities and Unison data types
       and the ease with which you can translate between the two with functions
       provided by the `base` library—which should you reach for idiomatically?

       {{
       docCallout
         (Some style)
         {{
         As a rule of thumb we suggest you use the abilities-based approach for
         error handling because it allows you to express the intent of your
         program in a "direct" manner. Some of the syntax that makes managing
         errors-as-data-types easy (`for` expressions, `do` notation, etc) is
         absent from Unison, so it's often the simplest way to write code.

         Of course, exercise your judgment and use whatever approach you like!
         😊
         }} }}
  }}

docs.fundamentals.abilities.errorHandling.divBy : Nat -> Nat ->{Abort} Nat
docs.fundamentals.abilities.errorHandling.divBy a b = match b with
  0 -> Abort.abort
  n -> a Nat./ b

docs.fundamentals.abilities.errorHandling.divByException :
  Nat -> Nat ->{Exception} Nat
docs.fundamentals.abilities.errorHandling.divByException a b = match b with
  0 -> Exception.raise (Generic.failure "Cannot divide by zero" b)
  n -> a Nat./ b

docs.fundamentals.abilities.errorHandling.divByOptional :
  Nat -> Nat -> Optional Nat
docs.fundamentals.abilities.errorHandling.divByOptional a b =
  toOptional! do errorHandling.divBy a b

docs.fundamentals.abilities.errorHandling.divByThrow :
  Nat -> Nat ->{Throw Text} Nat
docs.fundamentals.abilities.errorHandling.divByThrow a b = match b with
  0 -> throw "Cannot divide by zero"
  n -> a Nat./ b

docs.fundamentals.abilities.errorHandling.myFunction : Nat -> Nat ->{Abort} Nat
docs.fundamentals.abilities.errorHandling.myFunction a b =
  use Nat *
  errorHandling.divBy a b * 2

docs.fundamentals.abilities.exercises.ex1 : Doc
docs.fundamentals.abilities.exercises.ex1 =
  {{
  {{ exercise }} Implement functions with calls to Ability operations

  Given the type signatures below, implement the functions to satisfy the
  compiler using the request operations of the Ability or functions found in
  `.base`

  ``` unison
  getWithAbort : a -> Map a b ->{Abort} b
  getWithAbort key map = base.todo "implement me!"
  ```

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint: how do I see the request operations of
    an ability?
    }}
    {{
    In the UCM, you can enter `view Abort` to see the ability definition. The
    function signatures after the `where` keyword are the request operations.
    }} }}

  {{ Folded
    true {{ {{ wordle.utils.emojis.answer }} Answer: }} {{
    Using the {Optional.toAbort} function.

    ``` unison
    getWithAbort : a -> Map a b ->{Abort} b
    getWithAbort key map = toAbort (get key map)
    ```

    Pattern matching on {type Optional}

    ``` unison
    getWithAbort : a -> Map a b ->{Abort} b
    getWithAbort key map =
        match get key map with
          Some a -> a
          None   -> abort
    ```
    }} }}
  }}

docs.fundamentals.abilities.exercises.ex2 : Doc
docs.fundamentals.abilities.exercises.ex2 =
  {{
  {{ exercise }} Implement functions with Ability operations

  ``` unison
  rangeAverage : Nat ->{Store [Nat]} Float
  rangeAverage n = base.todo "implement me"
  ```

  Using the {type Store} ability to keep track of a {type List} of numbers,
  write a function which takes in some number `n` of {type Nat} as an upper
  bound of a list from `` 0 `` up to (but not including) `n` and returns the
  average of the final list.

  So, given an upper value of ``5``, the average produced would be the average
  of ``[0, 1, 2, 3, 4]``, or `` 2.0 ``

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer
    }}
    {{
    One possible solution is as follows:

    {{ (docSource [docSourceElement (docEmbedTermLink do averageOfRange) []])
    }}
    }} }}
  }}

docs.fundamentals.abilities.exercises.ex2.answers.averageOfRange :
  Nat ->{Store [Nat]} Float
docs.fundamentals.abilities.exercises.ex2.answers.averageOfRange n =
  use Float / fromNat
  use List +:
  use Nat + ==
  go = cases
    i
      | i == n    ->
        myList = Store.get
        listSize = List.size myList
        sum = List.foldLeft (acc element -> element + acc) 0 myList
        fromNat sum / fromNat listSize
      | otherwise ->
        Store.modify (currentList -> i +: currentList)
        go (i + 1)
  go 0

docs.fundamentals.abilities.exercises.ex2.answers.handleAverageOfRange : Float
docs.fundamentals.abilities.exercises.ex2.answers.handleAverageOfRange =
  withInitialValue [] do averageOfRange 5

docs.fundamentals.abilities.exercises.ex3 : Doc
docs.fundamentals.abilities.exercises.ex3 =
  {{
  {{ exercise }} Apply a handler to a function requiring abilities

  Check out the functions in the `base` libraries for operating on {type Store}
  and see if you can apply a handler to the function you wrote previously for
  [finding the average of a range]({abilities.exercises.ex2}). The handler
  should help you return the {type Float} value to check your function.

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.hint }} Hint: What kind of function am I looking
    for?
    }}
    {{
    You'll want a function whose return type does not require {type Store} in
    curly braces in its final value. The handler should run or "interpret" the
    program which performs a {type Store} ability into another value.
    }} }}

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer:
    }}
    {{
    One possible solution is as follows:

        @source{ex3.answers.handleAverageOfRange}

    {withInitialValue} handles a function that requires the {type Store}
    ability by setting the initial state of the {type Store}.
    }} }}
  }}

docs.fundamentals.abilities.exercises.ex4 : Doc
docs.fundamentals.abilities.exercises.ex4 =
  {{
  {{ exercise }} Debug an abilities issue

  The following watch expression is failing to typecheck.

  ``` unison
  randomIndex : [Nat] -> '{Random, Abort} Nat
  randomIndex list = 'let
    n = List.size list
    if n === 0 then abort else Random.natIn 0 n

  > toOptional! (Random.lcg 7 (randomIndex [1,2,3]))
  ```

  The UCM error is:

  ``` ucm
  The 2nd argument to `(<|)`

              has type:  Nat
        but I expected:  Unit ->{g, Abort} 𝕩

      142 | randomIndex : [Nat] -> '{Random, Abort} Nat
      143 | randomIndex list = 'let
      144 |   n = List.size list
      145 |   if n === 0 then abort else Random.natIn 0 n
      146 |
      147 | > toOptional! (lcg 7 (randomIndex [1,2,3]))
  ```

  Why is the error occurring and how might it be corrected?

  {{
  Folded
    true
    {{
    {{ wordle.utils.emojis.answer }} Answer:
    }}
    {{
    One possible solution is as follows:

    ```
    let
      randomIndex : [Nat] -> '{Abort, Random} Nat
      randomIndex list = do
        n = List.size list
        if n === 0 then Abort.abort else Random.natIn 0 n
      toOptional! do lcg 7 (randomIndex [1, 2, 3])
    ```

    {toOptional!} is a function which expects a delayed computation which
    performs the {type Abort} ability. The entire expression will need a {{
    (docCode {{ ' }}) }} symbol in front of the call to {lcg}
    }} }}
  }}

docs.fundamentals.abilities.faqs : Doc
docs.fundamentals.abilities.faqs =
  use Abort abort
  use errorHandling divBy
  {{
  # FAQ's for abilities

    ## Can I define an ability which references other abilities?

       You cannot, at present, define an ability that directly specifies
       another ability requirement in its request constructors. Let's say I
       wanted to write a Cache ability. I might want to express something like:

       ``` unison
       -- 🙅🏻‍♀️ you can't do this
       ability Cache k v where
         get : k -> {Cache k v, IO} v
         put : k -> v -> {Cache k v, IO} ()
       ```

       After all, I know it's likely the users of my service will want to do IO
       as a part of handling their get and put requests. However, we can't
       specify that in the ability definition. The preferred way to allow for a
       Cache ability to perform IO and exceptions would be to write a handler
       that interprets the `Cache` ability into the {type IO} ability.

    ## Can I require two of the same abilities in one function?

       No, you cannot require two of the same ability in a function.

       You might expect that the following function would fail.

       ``` unison
       cannotDo : '{Stream Nat, Stream Nat} Nat
       cannotDo = do 4
       ```

       Which Stream would we handle first? But the function below is also not
       allowed despite the fact that the two abilities are parameterized by
       different types.

       ``` unison
       cannotDoTypeConstructor : '{Store Nat, Store Text} Nat
       cannotDoTypeConstructor = do 4
       ```

       Our type system does not currently support this.

    ## What does `Request` mean?

       The {type Request} type is the type that Unison uses to model the {{
       docTooltip {{ request constructors }} requestConstructors }} of an
       ability.

       In the expression `handle !myEffect with myEffectHandler` the term
       `myEffectHandler` would have a type which looks __something__ like
       `Request (MyEffect) a -> a` - The exact semantics are described in the
       [language guide section on handlers]({abilityHandlers}).

       When defining your own handlers you might see the {type Request} type,
       but callers of handler functions shouldn't typically need to manage it
       directly.

    ## Why can't an ability be at the "top-level" of a value?

       For example, you can't do: `myTerm = printLine "Hi"`.

       Currently values at the "top level" of a program have to be pure, so
       it's more common to see
       [delayed computations](../valuesAndFunctions/delayedComputations) that
       contain abilities (expressed with the single quote syntax). This may
       change in a future version of Unison. Think of the ability constraint as
       a constraint on __the function arrow__ as opposed to a constraint on a
       value.

    ## How do I test something which requires the IO ability?

       Run a single test which performs IO with the
       [`io.test command`]({ioTest}). The `io.test` command expects a
       __delayed computation__ with {type IO} as an ability requirement. The
       rest of the Unison [testing conventions]({testing}) remain unchanged.

       You can also test functions which perform IO with Unison's
       [transcripts]({transcripts}) by interleaving Unison code which performs
       IO with UCM fenced codeblocks that call the [`run`]({ucmCommands.run})
       command.

       A document about writing Unison transcripts
       [can be found here.]({transcripts})

    ## How do you express failures when writing a custom ability?

       For example, if you write a `Http` ability or a `Cache` ability, you may
       want to capture the fact that a request may fail.

       It's tempting to write:

       ``` unison
       -- 🙅🏻‍♀️ you can't require an ability in the definition of an ability like this
        unique ability Http where
          handleRequest : Request -> {Exception} Response
       ```

       Instead, here are a few strategies that you'll see employed:

       * Rather than representing the failure in the definition of the ability
         itself, the __handlers__ of the ability can account for failure,
         calling other abilities that represent a failure state, or by using
         data types that represent the failure.
       * You might use a data type like {type Optional}, or {type Either} in
         the type signatures of your ability's operations themselves.
       * Some abilities contain a specific request constructor that represents
         failure.
         [For example, the Tokenizer ability on share](https://share.unison-lang.org/@stew/uniparsec/code/main/latest/namespaces/Parser/;/types/Tokenizer)
         This design decision is less common. A heuristic to use when deciding
         whether to build a "fail" operation into your ability is if the "fail"
         operation is one of the key behaviors of the effect you're trying to
         model, as opposed to an operational hazard.

    ## Why does a handler need a case which doesn't refer to the ability
    operations?

       Handlers have a case in their pattern match which takes the form
       `{r} -> ...`.

       This case needs to be present for the following reasons:

       * It yields the last executed value of the block being handled to the
         rest of the program.
       * It handles situations where an ability might be **required** by a
         function but is not ultimately used.

       For example, this function won't always need to call {abort}:

           @source{divBy}

       A handler for this function might look like:

       ```
       Abort.toOptional! : '{g, Abort} a ->{g} Optional a
       Abort.toOptional! f =
         handle f()
         with cases
           { r }               -> Some r
           { abort -> resume } -> Optional.None
       Abort.toOptional! do divBy 4 2
       ```

       Without the `{r} -> ...` case, you cannot typecheck the handler.

       ``` ucm
       Pattern match doesn't cover all possible cases:
             2 | Abort.toOptional! f = handle !f with cases
             3 |   {abort -> resume} -> None

       Patterns not matched:
        * { _ }
       ```

    ## What's the relationship between abilities and monads?

       That deserves a longer discussion. The short answer is that abilities
       are as expressive as monads.

       But for now
       [check out this gist!](https://gist.github.com/pchiusano/2e804c2aa81894c854a6b7f27c06fe28)

    ## I see some code which leaves off the ability requirements in an ability
    declaration, what gives?

       When defining an ability's operations, it's often a nice shorthand to
       leave off the implied ability requirement—that is, the `{Abort}` in
       @inlineSignature{abort}—after all, we know that an ability operation
       will be performing the ability in question and will require a handler.
       Unison will fill that in for us if we omit it, so we could have also
       defined the type signature of the abort operation as `Abort.abort : x`.

    ## 🚧🚧 🏗 More coming soon 🚧🚧


  }}

docs.fundamentals.abilities.forMonadicallyInclined : Doc
docs.fundamentals.abilities.forMonadicallyInclined =
  use wordle.utils.emojis learnMore
  {{
  # Abilities for the monadically inclined

    This section covers the purpose of monads, their alternatives, and why you
    might want to use abilities.

    ## How we ended up in the world with monads

       Little-known fact: Monads were introduced into functional programming
       because **Haskell is lazy (non-strict)**. Before we look into Haskell,
       let's look at strict languages.

       Mainstream languages (Java, JavaScript, Python, etc.) are based on
       strict evaluation:

       * the expressions are evaluated when they are bound to a name;
       * the function arguments are evaluated before they're applied to a
         function.

       Let's start with a simple snippet in a strict pseudo-language:

       ``` raw
       fun second(a: Int, b: Int, c: Int): Int =
         { println("Ignore everything and return second"); b }
       ```

       ``` raw
       let c = { println("Evaluating C"); 3 } // [1]

       let result = second(
         { println("Evaluating A"); 1 },      // [2]
         { println("Evaluating B"); 2 },      // [3]
         c
       )

       println(result)
       ```

       In this example, `c` is evaluated and printed first, then `a`, then `b`,
       and so on:

       ``` raw
       Evaluating C
       Evaluating A
       Evaluating B
       Ignore everything and return second
       2
       ```

       Such an evaluation strategy, roughly speaking, allows us to read code in
       sequential order: up to down, left to right. This might be taken for
       granted, but we can show/observe this because the **side-effects** (like
       printing to the console) **are executed** during the **evaluation** of
       the expression where they are defined.

       On the other hand, having this “natural” evaluation order and tying
       execution to evaluation the same way is not an option in Haskell.
       Haskell is non-strict. In a similar snippet, “a” and “c” are never used
       nor evaluated.

       ``` raw
       second a b c = b
       ```

       ``` raw
       result = ???
       ```

       We won't try to translate the rest of the snippet to Haskell — it
       wouldn't make much sense. The non-strictness raises too many questions.
       Would it even print `Evaluating A` or `Evaluating C`? If so, when? Both
       `a` and `c` are never used! If we call this `second` function multiple
       times, should we print `Evaluating A` or `Evaluating C` multiple times?
       It's non-strict! And so on.

       Luckily for us, we can avoid philosophizing by using monads! The idea is
       that we can embed these {{
       docTooltip
         {{
         native side-effects
         }}
         {{
         By native side-effects, we mean effects provided by the runtime; for
         example, printing to the console, exceptions, and interacting with the
         file system.
         }} }} in a data type and describe the sequencing using functions.

       For example, we can use the `putStrLn` function that returns `IO`:

       ``` haskell
       second a b c =
         putStrLn "Ignore everything and return second" >>= \_ -> return b

       main :: IO ()
       main =
         putStrLn "Evaluating C" >>= \_ ->
         return 3 >>= \c ->
         putStrLn "Evaluating A" >>= \_ ->
         return 1 >>= \a ->
         putStrLn "Evaluating B" >>= \_ ->
         return 2 >>= \b ->
         second a b c >>= \result ->
         putStrLn (show result)
       ```

       When we run this Haskell program, we once again see:

       ``` raw
       Evaluating C
       Evaluating A
       Evaluating B
       Ignore everything and return second
       2
       ```

       Okay, but why are we using monads and monad-like things outside of
       Haskell — where we don't have “this laziness issue”? Turned out that
       monads are great not just for modeling native effects but also for
       **any custom** or **user-defined effect.**

       ### Control flow

           **The actual superpower of monads is the embedding of control flow.**
           In other words, we can abstract control flow (and various patterns)
           as datatypes and use functions over values.

           Control flow is the order of execution — the path a program takes,
           based on instructions like conditions, loops, and function calls.
           For instance, do X, then do Y, and depending on some condition do S
           or Z (using `if/then/else`):

           ``` mermaid
           graph TD;
               X[doing X]-->Y;
               Y[doing Y]-->C{condition};
               C-->|true|S[doing S];
               C-->|false|Z[doing Z];
               S-->done;
               Z-->done;
           ```

           In traditional programming languages, the set of control flow
           patterns is fixed. Expanding it requires additional features, such
           as `try/catch`, `while` and `for` loops, `async` and `await`, and so
           on.

           Sometimes, we can represent complex patterns using simpler building
           blocks; for example, we can represent loops using conditionals (aka
           `if/then/else`):

           ``` raw
           fun loop(counter: Int, iterations: Int) =
             if counter >= max_iterations
               // Do something
             else
               // Do something else
               loop(counter + 1, iterations)
           ```

           Writing loops from scratch quickly becomes cumbersome. So, usually,
           we'll get built-in loops.

           Another example is checking if the value exists (checking for
           `null`, `nil`, whatever). It can be implemented using a simple
           check:

           ``` java
           String result = "";
           if (album != null) {
             result = album.getLast().toString();
           } else {
             result = "missing";
           }
           ```

           It also doesn't scale well:

           ``` java
           String result = "";
           if (artist != null
               && artist.getDiscography() != null
               && artist.getDiscography().getAlbums() != null
               && artist.getDiscography().getAlbums().getLast() != null) {
             result = artist.getDiscography().getAlbums().getLast().toString();
           } else {
             result = "missing";
           }
           ```

           That's why languages like Kotlin and Rust provide operators or
           special syntax to safely chain and deal with nullable values:

           ``` raw
           artist?.discography?.albums?.last?.toString() ?: "missing"
           ```

           ``` raw
           artist?.discography?.albums?.last.map(|album| album.to_string())
           ```

           Which are pretty much monads in disguise. We represent optionality
           as datatypes and use functions over **values**. And it's not just
           optionality. We can model various concepts (such as exceptions,
           iterating, sync / async, parsing, finalizing or closing resources,
           dependency injection, and cancellation) with monads and monad-like
           things:

           * `doSomething.handleErrorWith(doSomethingElse)`
           * `listOfItems.traverse(item => persistToDB(item))`
           * `(fetchFromOneService, fetchFromAnotherDataBase).parMapN(doSomethingWithResult)`

           The largest recent **“monadization”** we can observe in strict and
           mainstream languages is around **asynchronous programming**:
           Reactive Streams in Java, Futures in Scala, Promises in JavaScript
           and many other places.

           Eventually, languages catch up and acquire some sort of async/await
           syntax or lightweight threads, which replace monads (and monad-like
           things). But it takes time. For example, Java finally obtained
           virtual threads (see
           [Project Loom](https://wiki.openjdk.org/display/loom/Main)), but we
           have been doing asynchronous programming in Java thanks to “monads”
           for more than 10 years already!

           **This is the real superpower of monads.** This is why we use
           monads! They allow us, developers, to have more control over the
           flow of the program.

    ## The costs of monads

       However, let's not lie to ourselves, this is not the nicest snippet of
       code:

       ``` haskell
       second a b c =
         putStrLn "Ignore everything and return second" >>= \_ -> return b

       main :: IO ()
       main =
         putStrLn "Evaluating C" >>= \_ ->
         return 3 >>= \c ->
         putStrLn "Evaluating A" >>= \_ ->
         return 1 >>= \a ->
         putStrLn "Evaluating B" >>= \_ ->
         return 2 >>= \b ->
         second a b c >>= \result ->
         putStrLn (show result)
       ```

       Look at all the plumbing we have to do with monads. We describe the
       sequencing of effects using explicit combinators. It's nice that we have
       unified syntax for various effects (`pure`/`return`, `flatMap`/`bind`,
       etc.), but it's less nice that we have to deal with all the noise and
       syntax overhead. It’s also a cognitive overhead! We wouldn't have the
       phenomenon of monad tutorials and hate towards monads if it wasn't the
       case.

       And let's not even talk about monad transformers and problems with
       mixing effects 😖

       Direct style (code without monads) is straightforward. Effects are
       executed during the evaluation of an expression. Most of the code is
       just do-this-do-that:

       ``` raw
       // execute foo and pass the result to bar
       let x = foo()
       let y = bar(x)
       ```

       Sometimes, if we need to prevent execution, we can explicitly suspend
       evaluation:

       ``` raw
       // pass the foo itself
       let doFoo = () => foo
       let y = retry3Times(doFoo)
       ```

       In this example, we don't want to evaluate `foo` and don't want to
       execute its effects, because we want the retry function to do that.

       In the monadic world, `foo` is already `doFoo` — it's already suspended.
       We can pass **things** to functions, return them as results, and so on:

       ``` raw
       // pass the foo itself
       retry3Times(foo)
       ```

       It's amazing for building control flows and writing composable code, but
       we end up juggling two layers all the time: the layer of constructing it
       and the layer of when it will execute.

       ``` raw
       // pass the result of foo to bar
       foo >>= bar
       ```

       {{
       docAside
         {{
         {{ important }} Note that in a strict language, using monads can also
         trip up advanced people. For example, this causes a
         `StackOverflowError` in Scala with cats: `def bar = foo *> bar`
         }} }}

       This is taxing on an untrained brain. This is where we lose people.

       It might hurt to admit, but because most of the code is plain
       do-this-do-that, on average, it's is simpler to write and read
       **direct-style** code because thinking about one level at a time is less
       demanding than thinking about two.

       ### Monads vs. Direct Style

           Direct style is simple, yes, but only when it's possible. Each
           feature (or control-flow mechanism) needs to be supported by the
           language and usually comes with its own syntax.

           Another trade-off is effects tracking: the effects are not typed and
           it's not as painful to mix different effects.

           On the one hand, it's still easier to teach; on the other hand, it
           comes with annoying properties such as a lack of
           [**referential transparency**](https://en.wikipedia.org/wiki/Referential_transparency)
           and some presence of
           [**function coloring**](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function)
           (depends on the particular implementation).

           The latter can be frustrating with monads as well. Have you ever had
           to replace a bunch of `map`s with `traverse` when you introduce one
           additional monad (e.g., adding a log) in a deeply nested function?

           ``` scala
           def one(str: String): String

           def two(y: String): Option[String] =
             y.some.map(one(_))

           def three(x: Option[String]): Option[String] =
             x.flatMap(two(_))
           ```

           ``` scala
           // if String becomes IO[String]
           def one(str: String): IO[String]

           // map becomes traverse
           def two(y: String): IO[Option[String]] =
             y.some.traverse(one(_))

           // flatMap becomes flatTraverse
           def three(x: Option[String]): IO[Option[String]] =
             x.flatTraverse(two(_))
           ```

           {{
           docTable
             [ [{{  }}, {{ "Monads" }}, {{ "Direct Style" }}]
             , [{{ Arbitrary/User-defined Effects }}, {{ 👍 }}, {{ 👎👎👎 }}]
             , [ {{
                 Syntax
                 }}
               , {{
                 Unified, but has plumbing overhead
                 }}
               , {{
                 O(N) — each feature requires custom syntax
                 }}
               ]
             , [{{ Teachability }}, {{ 👎👎👎 }}, {{ 👍 }}]
             , [{{ Familiarity }}, {{ 👎 }}, {{ 👍 }}]
             , [{{ Typed Effects }}, {{ typed }}, {{ not typed }}]
             , [{{ Effects mixing }}, {{ 👎 }}, {{ 👍 }}]
             , [ {{
                 Function coloring
                 }}
               , {{
                 some (e.g., map vs traverse)
                 }}
               , {{
                 some (depends on the implementation)
                 }}
               ]
             , [{{ Referential transparency }}, {{ 👍👍👍 }}, {{ 👎👎 }}]
             ] }}

           So, can we do better?

       ### The worst of both worlds? Mixed styles

           Naturally, we want to have our cake and eat it too, so we wind up
           with a mix both — the cons of both! We are stuck in this world
           because we want the **power of monads** to embed user-defined
           effects and control flows, but at the same time, we never handled
           the **hate of monads**.

           {{
           docAside
             {{
             {{ style }} Note that a mix of styles isn't necessarily a bad
             thing. A bad thing is having no choice or being stuck in a local
             optimum. For instance, Unison allows
             [**error handling with abilities** and **data types**.](https://www.unison-lang.org/docs/fundamentals/control-flow/exception-handling/)
             }} }}

           Some effects are controlled by evaluation (direct style), and some —
           by explicit combinators (monadic style). As a result, we lose both
           the immediacy of the former and the systematic clarity of the
           latter.

           However, we don't have to stay here.

    ## The best of both worlds? Abilities

       Meet **abilities** — Unison's implementation of direct-style algebraic
       effects, also known as **effect handlers** and ambiguously as
       **algebraic effects**.

       {{
       docAside
         {{
         {{ reminder }} Actually, they are not very well known. That's why they
         are known by different names and come in many forms.
         }} }}

       Let's start with division:

       ``` unison
       1 / 0
       ```

       ``` ucm
       Encountered exception:
       divide by zero
       ```

       We can build a safer version by utilizing {type Exception} ability:

           @source{safeDiv1}

       We use the {Exception.raise} constructor to capture failure details
       (which aren't very interesting in this case). If we try to naively
       run/evaluate it, we get a compilation error:

       ``` ucm
       scratch/main> safeDiv 6 3
       ```

       ``` ucm
       The expression in red needs the {Exception} ability, but this location does not have access to any abilities.
       ```

       We can use the {catch} **handler**, which translates the
       {type Exception} into a value of type {type Either}:

       ```
       catch do safeDiv1 6 3
       ```

       ```
       catch do safeDiv1 6 0
       ```

       {{
       docAside
         {{
         {{ learnMore }} The handlers for effects is an impressive part of the
         concept, but we won't look too deep into it here.
         }} }}

       Let's try something more exciting and randomly generate both numbers via
       the `IO` ability (imagine fetching numbers from external services or
       something):

           @source{safeDiv2}

       {{
       docAside
         {{
         {{ learnMore }} Note that there is a dedicated {type Random} ability —
         we're using {randomNat} for illustration purposes.
         }} }}

       There are a couple of new things in this snippet. We **force** (execute)
       the computation of {randomNat} to get 2 random natural numbers and
       **delay** (suspend) the whole `safeDiv`, which is also reflected in the
       type signature.

       {{
       docAside
         {{
         {{ reminder }} Note that Unison also provides an alternative syntax
         for **forced** and **delayed** computations
         }} }}

       The idea behind forcing should be straightforward, but why should we
       delay a computation? The type `{IO, Exception} Nat` by itself is not
       allowed there, because {type IO} and {type Exception} abilities must be
       provided by a handler. The runtime can do it for us when we run the
       whole program (notice that we don't use {catch}):

       ``` ucm
       scratch/main> run safeDiv2
       ```

       As a result, we get something boring like `` 0 `` or ``2``. Let's make
       it fun by involving another ability:

           @source{safeDiv3}

       We can use the {type Store} ability to record the randomly generated
       division components. This time we must provide a handler for
       {type Store} — because Unison can't just guess or handle it for us —
       `withInitialValue "empty"` will do the job:

           @source{forMonadicallyInclined.final}

       Wow, look at this:

       ``` ucm
       scratch/main> run final
       ```

       ``` ucm
       6864436983616853973/1491537154359797591=4
       ```

       And we can keep going and going with adding new abilities. Notice how
       little syntax we used (no `bind` / `flatMap` or any specialized
       combinators) and how similar each iteration of `safeDiv` was.

       ### Control flow and the call stack

           In a nutshell, direct-style algebraic effects is “just” a nice
           interface over
           [**delimited continuations**](https://en.wikipedia.org/wiki/Delimited_continuation).

           **Control flow happens by affecting the call stack.** As a reminder:
           exceptions, loops, async, finalizing or closing resources,
           dependency injection, cancellation — all of these require some
           technique to jump through the function call stack. So, instead of
           manipulating the call stack “directly” via custom features, we can
           use monads or some other instrument.

           * **Direct style / Custom features:** The compiler does that.
           * **Monads:** We can manipulate the data structures that reify the
             call stack.
           * **Delimited continuations:** We can use user-level primitives to
             affect the call stack, but it's quite mind-breaking. Nobody wants
             that.
           * **Direct-style algebraic effects:** We can use delimited
             continuations via a better interface (types + syntax).

       ### The pros of direct-style algebraic effects

           What do we have now?

           Right up front, we get the ability to embed user-defined effects — a
           massive improvement over traditional direct style; plus the ability
           to write code in direct style — a considerable improvement in
           expressing control flow.

           We haven't demonstrated this,
           [but writing custom effects is more accessible than monads](https://www.unison-lang.org/docs/fundamentals/abilities/writing-abilities/).
           **You have to trust us on that.** Writing custom monads is an
           upper-intermediate or expert-only endeavor (especially when you have
           to deal with stack-safety in a strict language).

           At the same time, there's a limited amount of syntax. The language
           designers must make a few choices: around effect handlers,
           suspending and forcing execution. We saw two variations in the case
           of Unison. Still, there is no need to make a new syntax for every
           feature.

           Which leads us to teaching. Teaching people how to **use** effects
           is trivial (essentially, they need to grasp suspending and forcing
           computations).

           Remember how easy it was to add the {type Store} ability to existing
           abilities? We keep typed effects and peacefully mix them! And on top
           of all that, no more function coloring at all. There is no
           `map`/`traverse` distinction and so on.

       ### The elephant in the pure room

           Nothing comes for free. This might sound dramatic for people coming
           from monadic worlds, but the first thing we lose with direct-style
           algebraic effects is **referential transparency**.

           Imagine we have a program that initializes two mutable refs with
           `"empty"`, writes `"full"` into the first one, and then reads values
           from the both refs:

               @source{refExample1}

           When we `run refExample`, we get:

           ``` ucm
           "full|empty"
           ```

           If we decide to **dry** the code and naively extract the
           initialization into `emptyRef`:

               @source{refExample2}

           We get a different program because, when we `run refExample2`, we
           get:

           ``` ucm
           "full|full"
           ```

           Both `x` and `y` were updated because they are the same ref. What we
           wanted to do is to **suspend** the initialization and then **force**
           it twice (first time for `x` and second for `y`):

               @source{refExample3}

           Which would give us:

           ``` ucm
           "full|empty"
           ```

           As you can see, refactoring the code with abilities might require
           more brain activity than with monads. Even though it's a hurdle for
           people with a “monadic” background, it's not the end of the world.
           We gave up something important, but we also gained a ton.

       ### Other limitations and unknowns

           The drawbacks don't stop there. Direct-style algebraic effects is a
           novel concept (even comparatively to monads) — there are still some
           open questions and some unknowns. We need some time to explore their
           limitations.

           For example, static control flow (applicative-style code) is a niche
           use case (e.g., applicative parsers, applicative-style build tools)
           can't be expressed with abilities. Because there is no way not to
           evaluate effects or undo an effect.

           Are there more cases like this? We don't know yet. However…

    ## Takeaways

       If you are curious and want to explore the knowns and unknowns of
       abilities (and direct-style algebraic effects), now is the perfect time.

       At the end of the day, direct-style algebraic effects (delimited
       continuations) and monads have
       [the same expressive power](https://www.cambridge.org/core/journals/journal-of-functional-programming/article/on-the-expressive-power-of-userdefined-effects-effect-handlers-monadic-reflection-delimited-control/3FFAA9AD05B58A1467E411F80EE4E076)
       — they can express the same things.

       {{
       docTable
         [ [{{  }}, {{ Monads }}, {{ Direct Style }}, {{ Abilities }}]
         , [ {{
             Arbitrary/User-defined Effects
             }}
           , {{
             👍
             }}
           , {{
             👎👎👎
             }}
           , {{
             👍👍👍
             }}
           ]
         , [ {{
             Syntax
             }}
           , {{
             Unified, but has plumbing overhead
             }}
           , {{
             O(N) — each feature requires custom syntax
             }}
           , {{
             Unified, O(1)
             }}
           ]
         , [{{ Teachability }}, {{ 👎👎👎 }}, {{ 👍 }}, {{ 👍 }}]
         , [{{ Familiarity }}, {{ 👎 }}, {{ 👍 }}, {{ 👍 }}]
         , [{{ Typed Effects }}, {{ typed }}, {{ not typed }}, {{ typed }}]
         , [{{ Effects mixing }}, {{ 👎 }}, {{ 👍 }}, {{ 👍 }}]
         , [ {{
             Function coloring
             }}
           , {{
             some (e.g., map vs traverse)
             }}
           , {{
             some (depends on the implementation)
             }}
           , {{
             👍
             }}
           ]
         , [{{ Referential transparency }}, {{ 👍👍👍 }}, {{ 👎👎 }}, {{ 👌 / 👎 }}]
         , [ {{
             Call-stack manipulation
             }}
           , {{
             via data structures
             }}
           , {{
             compiler's job
             }}
           , {{
             via delimited continuations
             }}
           ]
         , [ {{
             Maturity
             }}
           , {{
             Limitations are known
             }}
           , {{
             Limitations are known
             }}
           , {{
             Novel, some unknowns
             }}
           ]
         , [{{ Static control flow }}, {{ 👍 }}, {{ 👎 }}, {{ 👎 }}]
         ] }}
  }}

docs.fundamentals.abilities.forMonadicallyInclined.final : '{IO, Exception} ()
docs.fundamentals.abilities.forMonadicallyInclined.final = do
  withInitialValue "empty" do
    use Text ++
    result = safeDiv3()
    printLine (Store.get ++ "=" ++ Nat.toText result)

docs.fundamentals.abilities.forMonadicallyInclined.refExample1 : '{IO} Text
docs.fundamentals.abilities.forMonadicallyInclined.refExample1 = do
  use IO ref
  use Text ++
  use mutable.Ref read
  x = ref "empty"
  y = ref "empty"
  mutable.Ref.write x "full"
  read x ++ "|" ++ read y

docs.fundamentals.abilities.forMonadicallyInclined.refExample2 : '{IO} Text
docs.fundamentals.abilities.forMonadicallyInclined.refExample2 = do
  use Text ++
  use mutable.Ref read
  emptyRef = IO.ref "empty"
  x = emptyRef
  y = emptyRef
  mutable.Ref.write x "full"
  read x ++ "|" ++ read y

docs.fundamentals.abilities.forMonadicallyInclined.refExample3 : '{IO} Text
docs.fundamentals.abilities.forMonadicallyInclined.refExample3 = do
  use Text ++
  use mutable.Ref read
  emptyRef = do IO.ref "empty"
  x = emptyRef()
  y = emptyRef()
  mutable.Ref.write x "full"
  read x ++ "|" ++ read y

docs.fundamentals.abilities.forMonadicallyInclined.safeDiv1 :
  Nat -> Nat ->{Exception} Nat
docs.fundamentals.abilities.forMonadicallyInclined.safeDiv1 a b =
  use Nat / ==
  if b == 0 then Exception.raise (Generic.failure "Oops. Zero" b) else a / b

docs.fundamentals.abilities.forMonadicallyInclined.safeDiv2 :
  '{IO, Exception} Nat
docs.fundamentals.abilities.forMonadicallyInclined.safeDiv2 _ =
  use Nat / ==
  a = randomNat()
  b = randomNat()
  if b == 0 then Exception.raise (Generic.failure "Oops. Zero" b) else a / b

docs.fundamentals.abilities.forMonadicallyInclined.safeDiv3 :
  '{IO, Exception, Store Text} Nat
docs.fundamentals.abilities.forMonadicallyInclined.safeDiv3 = do
  use Nat / == toText
  use Text ++
  a = randomNat()
  b = randomNat()
  Store.put (toText a ++ "/" ++ toText b)
  if b == 0 then Exception.raise (Generic.failure "Oops. Zero" b) else a / b

docs.fundamentals.abilities.index : Doc
docs.fundamentals.abilities.index =
  use Optional None
  {{
  # 🤖 Introduction to Abilities: A Mental Model

    One of Unison's more exciting language features is its support for
    abilities. They represent one of the ways in which a Unison program can
    manage computational effects in a program. Abilities are Unison's
    implementation of algebraic effects, as they're known in the literature 📚 -
    but don't worry, you don't need to have heard of them to use Unison
    abilities. In this section of the docs we'll build an intuition around the
    problems that algebraic effects are solving and form a mental model of what
    a program is doing when an ability is being called.

    {{ headsUp }} As a heads up: we're not going to talk about the syntax
    specifics of Unison's abilities in this doc, if you're looking for that
    head to the section where we describe
    [how to use an ability](./abilities/usingAbilitiesPt1), this doc is just
    about creating an internal computer so that you have an understanding of
    how Unison executes code which uses Abilities.

    ## What do we mean by effects

       A computational effect or an "effectful" computation is one which relies
       on or changes elements that are outside of its immediate environment.
       Some examples of effectful actions that a function might take are:

       * writing to a database
       * throwing an exception
       * making a network call
       * getting a random number
       * altering a global variable

       Loosely, you might think of an effectful computation as one which
       performs an action outside of its local scope compared to one which
       simply returns a calculable value. Sound like a large bucket? Yup,
       effects are important and common.

       So when functional programmers talk about managing effects, they're
       talking about expressing the basic logic of their programs within some
       guard rails provided by data structures or programming language
       constructs. We'll put off a full discussion of functional effect
       management, but in general, managing effects in functional programming
       is done by representing the side effecting behavior in a more explicit
       way, therefore rendering it easier to react to it in a program. Unison's
       support for abilities is __one such guard rail.__

    ## Abilities in pseudocode

       Abilities are one way to express computations that perform effects, but
       comparatively few programming languages make use of them, so one of the
       challenges for learning about abilities is gaining an intuition of "how
       does this work 🧐" or more specifically, "does this look like anything I
       already know?" If you've encountered or written code that makes use of
       try and catch blocks, then you've seen a concept that offers a good
       starting point for an understanding of abilities.

       Let's imagine the following code in a fictional language. 🪄

       ``` raw
       try {
         users = Database.getAllUsers
       } catch {
         case DatabaseException message -> print message
       }
       ```

       We know from looking at this code that the function call
       `Database.getAllUsers` is performing an __effect.__ It relies on the
       external resource of a database to gather the relevant entities and that
       resource might be unavailable or fail for some internal reason —
       represented by a `DatabaseException`.

       We also know that there's some degree of safety in this code because of
       the `try/catch` mechanism. The `try` block let's us know we're executing
       code that may throw an exception, and the `catch` block is a handler for
       the exceptions that might surface.

       {{
       docCallout
         None
         {{
         At its most general, an ability is a pairing of some kind of effect
         with a handler which responds to that effect and says what to do when
         it happens.
         }} }}

       Let's build on that understanding. Imagine we want to write something
       akin to a try/catch block, but rather than managing exceptions, we want
       to manage logging. Unlike exceptions, which mean that the program
       execution has stopped for some reason and can't continue with subsequent
       steps in the program, when a function creates the effect of writing a
       log line, it's typically in the process of doing something which should
       continue after the call to write a log.

       In our fictional language, we might couple the ability to write logs
       with something that handles the log statement by printing them out
       __and then resuming the program.__

       ``` raw
       log {
          friends = getFriends user
          if (length friends) == 0
          then Logger.warn "user has no friends ☹️"
          else Logger.debug "user has friends"
          startParty friends user
        } handle {
          …
        }
       ```

       Again, this language syntax doesn't exist, but we can assume the `log`
       block provides access to some kind of effectful logger. The code in the
       body of the block should log the user's number of friends and continue
       to execute the `startParty friends user` line of code.

       Just like a `try` block is followed by a `catch,` imagine the `log`
       block is followed by a generic `handle` block, whose job is to pattern
       match on the possible actions that `log` can do. That might look like
       this:

       ``` raw
       log {
         …
       } handle {
        case (Logger.debug message -> remainderOfProgram ) ->
          print ("Debug: " ++ message)
          remainderOfProgram
        case (Logger.warn message -> remainderOfProgram ) ->
          print ("Warn: " ++ message)
          remainderOfProgram
       }
       ```

       Our handler needs some way to represent the rest of the program or the
       "continuation" of the program after the Logger call is made. We might
       represent this by adding it to the pattern match, that way, when the
       handler receives a call to `Logger.warn` or `Logger.debug` we can call
       the `remainderOfProgram` after our desired log statement and resume the
       snapshot of the state of the program when the call to the Logger is
       made. `remainderOfProgram` in this example is just the representation of
       continuing on to `startParty friends user`.

       {{
       docCallout
         None
         {{
         At this point we know that an ability combines some notion of an
         effect with a handler that manages the effect, where the handler can
         __resume__ the computation that produced the effect.
         }} }}

       So far, the effects that we've been exploring, Exceptions and Logging,
       don't actually change the behavior of the business logic that follows.
       But what if the effect we'd like to run is something like saving and
       accessing a global variable, or getting input from a user? The remainder
       of the program is likely to be impacted by that operation. In our mental
       model of abilities, we need a way for the effect to alter the state of
       the program.

       This changes our idea of a handler a little bit. Previously, the handler
       only needed to capture two pieces of information to be effective:

       1. the operations of the ability that it's handling (i.e. Logger.debug
          or raised exceptions)
       2. some notion of finishing the computation that was in flight when an
          effect was performed.

       Let's say we want to write a very simple program that puts and then gets
       a value from a key value store. In our fake language we might express
       the core logic of our program something like this:

       ``` raw
       kvStore {
          KVStore.put "id" 5
          KVStore.get "id"
        } handle with mapBasedStorage Map.empty
       ```

       The block started by `kvStore` looks pretty uncontroversial, but
       `handle` looks different from a standard try/catch block. It looks like
       we're handing off the management of the effect to a function call which
       takes in some kind of in memory `Map`. 🤔 Abilities allow us to choose
       how we'd like to perform the effect in question via swappable handler
       functions. We might decide to use a `mapBasedStorage` function or a
       `fancyDistributedKVStore` function to run our key value store
       operations. The handler of an ability is where you'll find the
       implementation details for performing the effect, and the state that the
       ability might rely on is often passed along in the form of
       __arguments to the handler function.__

       {{
       docCallout
         None
         {{
         You might see this pattern repeated in many functional programming
         contexts: abilities allow us to establish a separation of concerns
         between the code which creates the effect and the code which manages
         the behavior of that effect.
         }} }}

       Let's think about what a handler should do to respond to a call to
       `KVStore.put` - we want to:

       1. grab the `key` and `value` arguments from `KVStore.put` when we're
          pattern matching on it.
       2. use them to update the map which is functioning as our data storage
       3. resume the remainder of the program with our chosen handler,
          `mapBasedStorage,` passing in the updated map

       It might look something like this:

       ``` raw
       mapBasedStorage map =
        case (KVStore.put key value -> resume) ->
          updated = put key value map
          resume () with mapBasedStorage updated
       …
       ```

       Calling our `mapBasedStorage` function with an updated map after the
       `put` request effectively "sets" the handler's state for subsequent
       interactions with the key value store effect.

       Now let's think about what a handler should do to respond to a call to
       `KVStore.get.`

       1. grab the `key` argument from `KVStore.get` in a pattern match.
       2. get it from our in-memory map based storage
       3. **pass that value back** to the program being executed
       4. ensure future calls to the key value store can be managed by the
          `mapBasedStorage` handler

       It might look something like:

       ``` raw
       mapBasedStorage map =
        case (KVStore.get key -> resume) ->
          desiredValue = get key map
          resume desiredValue with mapBasedStorage map
        …
       ```

       Notice how the desired value from the map can be managed by a handler
       and then passed back to the continuation named `resume.` Think of
       `resume` as a __function__ which is expecting the result of the ability
       operation being called as its argument. When the desired value is given
       to the resume function, it continues the main program.

       {{
       docCallout
         None
         {{
         An ability can resume the computation which performed it with a value
         tracked in the handler. Handlers allow us to pass information back to
         the program when an ability operation is called.
         }} }}

  # Summary

    Roughly, an ability can be broken down into two things, an interface which
    specifies some operations, and handlers which provide behavior to those
    operations. When a program uses an ability, the program halts its
    execution, hops over to the responsible handle block, finds the matching
    operation, performs the behavior specified there, and then resumes the
    program.

    Before going into the specificities of Unison's syntax for abilities, we
    wanted you to have an understanding of abilities on an operational level.
    In the next section about abilities, we'll talk more about how we use and
    represent abilities in actual Unison programs. We'll discuss how abilities
    are represented in function type signatures, what it means to handle an
    ability, and look at how they're defined.

    {{ index._nav }}
  }}

docs.fundamentals.abilities.index._nav : Doc
docs.fundamentals.abilities.index._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Ability syntax and usage in Unison](./abilities/usingAbilitiesPt1)

      {{ suggested }}
      [Error handling with Abilities](./abilities/errorHandling)

      {{ suggested }}
      [Writing ability handlers using the Key Value store example](./abilities/writingAbilities)
    }} }}
  }}

docs.fundamentals.abilities.usingAbilitiesPt1 : Doc
docs.fundamentals.abilities.usingAbilitiesPt1 =
  use Abort abort
  use Optional None
  {{
  # Using abilities part 1

    Here we'll cover how to use abilities from a pragmatic point of view. We
    hope you've built up an intuition about abilities with the
    [introduction to the mental model]({abilities.index}) for abilities. In
    this document we'll talk about the parts of an ability, write some code
    that uses abilities, and learn how Unison abilities are represented in type
    signatures.

    ## What and why

       Abilities are Unison's answer to the question, "how should we model and
       manage computational effects in a language?" An ability pairs an
       interface which describes an effect's operations with handlers that
       dictate how the effect should actually be performed. {{
       docAside
         {{
         If you're familiar with monadic error handling and need some extra
         convincing,
         [we wrote you a few more details about why you might use algebraic
         effects.](https://www.unison-lang.org/docs/fundamentals/abilities/for-monadically-inclined/)
         😎
         }} }}

       They offer a few benefits to the Unison programmer:

       {{
       docCallout
         None
         {{
         Abilities are visible in the type signature of functions, so the
         effectful behavior of your program is still represented in the type
         system. A function can't secretly {throw} an exception or {emit} a
         value without an ability requirement appearing in the function
         signature, so you can reason about a program's behavior at the type
         level.
         }} }}

       {{
       docCallout
         None
         {{
         They support a separation of concerns between the purpose of an effect
         and how the effect is ultimately executed. This facilitates easy
         testing of effectful components and prevents the core of a program
         from being polluted with logic for managing the effect.
         }} }}

       {{
       docCallout
         None
         {{
         They allow for a coding style that is relatively free of boilerplate
         and "type tetris" or "monadic plumbing 🪠"—particularly where multiple
         effects are being performed at once. This means fewer "flatMaps" in
         favor of vanilla function application, or calls to `traverse` when
         `map` plus an {{
         (docTooltip {{ ability requirement }} abilityRequirement) }} will
         suffice. (More on this later 😉.)
         }} }}

    ## A first encounter with Unison abilities

       We'll dive in with an example of code which uses an ability. Let's look
       at the following function signature

           @signature{usingAbilitiesPt1.stopIfTrue}

       From the name and signature of this function, we might surmise that
       {usingAbilitiesPt1.stopIfTrue} takes in a value, tests it against some
       condition, and does not permit subsequent functions to continue if the
       condition returns ``true``. The computational effect here is "hey,
       potentially stop running the program." In other languages with different
       effect management strategies, you might model this by throwing an
       exception or returning the "missing" case of a data type representing
       "something or nothing."

       Notice the `{Abort}` attached to the function arrow `->`. We read the
       return type of this signature as saying: "stopIfTrue is a function which
       __performs the Abort effect__" in the process of returning some value of
       type `a`. {type Abort} is what we call an ability in Unison and we say
       that the function {usingAbilitiesPt1.stopIfTrue} "requires the Abort
       ability" or has an
       {{ docTooltip {{ "Abort ability requirement" }} abilityRequirement }}.

       So how will we know what effectful operations are available for a given
       ability? To answer that we'll take a detour and look at how abilities
       are defined.

       ### Ability declarations

           Use the {{ docTooltip {{ `view` }} ucmCommands.view }} command in
           the UCM to `scratch/main> view Abort` and you should see something
           like:

               @source{type Abort}

           {{
           docAside
             {{
             {abort} returns an `a` or "any type" because a computation which
             "aborts" doesn't continue and therefore never returns a value, so
             a return type of "any type" can be considered valid.
             }} }}

           The code here is the __ability declaration__ for {type Abort}. The
           keyword
           [`structural` or `unique`]({{
           docLink (docEmbedTermLink do uniqueAndStructuralTypes)
           }}) specifies if the ability is unique by its name or by its
           structure --it's followed by the name of the ability and the keyword
           `where`. Then you'll see one or more __request constructors:__ type
           signatures that declare what operations an ability can perform. In
           this case, we see that the {type Abort} ability only declares one
           operation, {abort}.

           While you're here, check out a few more abilities in the UCM. Try
           `scratch/main> view Stream` or `scratch/main> view Store` to see
           their {{
           docTooltip {{ ability declarations. }} glossary.abilityDeclaration
           }} {type Abort} can {abort} a program, {type Stream} can {emit} a
           value, {type Store} can {Store.get} or {Store.put} a value, etc.
           These {{ docTooltip {{ request constructors }} requestConstructors
           }} are the building blocks for code that uses abilities; you'll
           either be calling them directly or building off functions that call
           them directly. It's important to understand what these functions
           generally __do__ but you'll notice there's no implementation here.
           You're just looking at an abstract interface for the effect being
           modeled. __How__ the operation is performed is provided later by the
           ability's handler.

           Let's look at the implementation of {usingAbilitiesPt1.stopIfTrue}
           to see how the {type Abort} ability is invoked.

               @source{usingAbilitiesPt1.stopIfTrue}

           We can see in the `if/else` clause that there's a call to the
           {abort} function from the ability. If a function requires an
           ability, the function has access to the suite of operations that the
           ability defines.

           What if we want to prevent an ability from being performed
           __at all__ in our function?

           🙅🏻‍♀️ We couldn't call any abilities from a function with a
           signature like:

           ``` unison
           stopIfTrue :(a -> Boolean) -> a  -> {} a
           ```

           The empty set of curly braces, `{}` is how you specify that a
           function is "pure" or performs __absolutely no effects.__

           That may not be what we want in this case though…
           {usingAbilitiesPt1.stopIfTrue} is pretty generic and we don't want
           to limit our user's style 😎. Let's pretend instead that we want to
           add a call to the {type Store} ability in our function. Combining
           multiple abilities in one function is easy to do in Unison by adding
           the ability to the curly braces separated by commas. This function
           stores a value before testing it with a
           {{ docTooltip {{ predicate }} predicate }}:

               @source{store.stopIfTrue}

           🤔 That's all very well and good but what if the caller of the
           function needs to perform an effect to actually run the predicate?
           We should represent that possibility in the type signature in some
           way so that callers of our function will know that it's ok to
           __effectfully__ test the predicate. We can do that by adding a
           generic ability requirement to both the higher order function
           `a -> Boolean` __and__ the overall function return type `a`.

               @signature{effectfulPredicate.stopIfTrue}

           The key here is that the potential ability is a lowercase variable
           (like `{g}` or `{e}`) which needs to be in the signature of the
           predicate __and__ in the return type of the overall function.
           Functions inherit the ability requirements of the functions that
           they call. That's why signatures like @inlineSignature{List.map}
           have a generic ability requirement in both the transformation
           function and their return type. It's common to combine operations on
           Unison data structures like {type List} or {type Optional} with
           abilities for functional effect management!

           Next we'll start trying to actually call these functions so we'll
           talk more about handlers and the rules for ability requirements in
           part 2 of this guide…

           {{
           docCallout
             (Some {{ 👉 }})
             {{
             To recap:

             The abilities that a function performs are visible in curly braces
             `{ }` to the right side of the function arrow in a type signature.

             Multiple ability requirements are represented in curly braces in a
             comma separated list: `{Abort, Exception, Stream Text, g}`

             Generic ability requirements are typically single lowercase letter
             variables in curly braces like `{e}`

             Pure functions perform no abilities and are represented with empty
             braces `{}`
             }} }}

           {{ usingAbilitiesPt1._nav }}
  }}

docs.fundamentals.abilities.usingAbilitiesPt1.effectfulPredicate.stopIfTrue :
  (a ->{g} Boolean) -> a ->{g, Abort} a
docs.fundamentals.abilities.usingAbilitiesPt1.effectfulPredicate.stopIfTrue
  predicate a =
  if predicate a then Abort.abort else a

docs.fundamentals.abilities.usingAbilitiesPt1.greet : '{IO, Exception} ()
docs.fundamentals.abilities.usingAbilitiesPt1.greet = do
  use Text ++
  printLine "Enter your name:"
  input = readLine()
  name = usingAbilitiesPt1.nonEmptyName input
  printLine ("Hello " ++ name)

docs.fundamentals.abilities.usingAbilitiesPt1.nonEmptyName : Text -> Text
docs.fundamentals.abilities.usingAbilitiesPt1.nonEmptyName name =
  optionalName : Optional Text
  optionalName =
    toOptional! do effectfulPredicate.stopIfTrue (text -> text === "") name
  Optional.getOrElse "Unknown Name" optionalName

docs.fundamentals.abilities.usingAbilitiesPt1.stopIfTrue :
  (a -> Boolean) -> a ->{Abort} a
docs.fundamentals.abilities.usingAbilitiesPt1.stopIfTrue predicate a =
  if predicate a then Abort.abort else a

docs.fundamentals.abilities.usingAbilitiesPt1.store.getAfterStore :
  '{g, Store a} b ->{g, Store a} a
docs.fundamentals.abilities.usingAbilitiesPt1.store.getAfterStore storeComp =
  storeComp()
  Store.get

docs.fundamentals.abilities.usingAbilitiesPt1.store.nonEmptyName : Text -> Text
docs.fundamentals.abilities.usingAbilitiesPt1.store.nonEmptyName name =
  storeIsHandled : '{Abort} Text
  storeIsHandled =
    do
      withInitialValue "Store Default Value" do
        store.stopIfTrue (text -> text === "") name
  abortIsHandled : Optional Text
  abortIsHandled = toOptional! storeIsHandled
  Optional.getOrElse "Optional Default Value" abortIsHandled

docs.fundamentals.abilities.usingAbilitiesPt1.store.stopIfTrue :
  (a -> Boolean) -> a ->{Abort, Store a} a
docs.fundamentals.abilities.usingAbilitiesPt1.store.stopIfTrue predicate a =
  Store.put a
  if predicate a then Abort.abort else a

docs.fundamentals.abilities.usingAbilitiesPt1._nav : Doc
docs.fundamentals.abilities.usingAbilitiesPt1._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Continue on to part 2

      {{ suggested }}
      [Using abilities part 2: applying handlers]({{
      (docLink (docEmbedTermLink do usingAbilitiesPt2))
      }})

      {{
      wordle.utils.emojis.learnMore
      }}[Why use abilities for our monadically inclined friends](./forMonadicallyInclined)
    }} }}
  }}

docs.fundamentals.abilities.usingAbilitiesPt2 : Doc
docs.fundamentals.abilities.usingAbilitiesPt2 =
  use Abort abort toBug
  use valuesAndFunctions delayedComputations
  {{
  # Using abilities part 2

    In [Part 1](./usingAbilitiesPt1) of the guide for using Unison abilities,
    we covered how to call ability operations and represent abilities in type
    signatures. This document will describe how to apply existing handlers from
    the base library to programs which use Unison abilities. {{ headsUp }} As a
    heads up, this doc doesn't go into conventions for
    [writing your own handlers](./writingAbilities) - it's just about using
    handlers.

    ## What is a handler?

       {{
       docAside
         {{
         A [working mental model]({abilities.index}) is that the handler is
         like the `catch` portion of a `try/catch` block.
         }} }}

       {{ _handlerDefinition }}

    ## Handling an ability

       First let's try to call {effectfulPredicate.stopIfTrue} in a function
       that neither provides a handler nor passes the ability requirement up
       the call chain.

       The following code tries to call {effectfulPredicate.stopIfTrue} in a
       pure function (remember, the `{}` means the function does not perform
       abilities).

       ``` unison
       nonEmptyName : Text -> {} Text
       nonEmptyName name =
         stopIfTrue (text -> text === "") name
       ```

       The error we get back is:

       ``` ucm
       The expression in red needs the {Abort} ability, but this location does not have access to any abilities.

         4 |   stopIfTrue (text -> text === "") name
       ```

       {{
       docCallout
         (Some important)
         {{
         This error is one to familiarize yourself with. It means that you've
         called a function which performs an ability without specifying the
         implementation for how the ability should be handled in a place where
         the ability requirement can't be passed along.
         }} }}

       In the above example, how could the program actually interpret the
       underlying call to {abort}? 🤔 We might want to abort by crashing the
       program, or we could abort by translating the ability into a data type,
       or we could abort by translating the operation into another ability that
       might be handled elsewhere. But {abort} has not been interpreted at this
       location in any of these ways, nor is the {{
       docTooltip {{ ability requirement }} abilityRequirement }} represented
       in the signature of the function that calls it.

       Fortunately, the Unison standard library provides handlers for the
       abilities we've seen, so let's translate {type Abort} into the
       {type Optional} data type and then provide a sensible default.

           @source{usingAbilitiesPt1.nonEmptyName}

       There are a few things to call attention to in the code.

       First, you'll notice that the {type Abort} ability requirement is
       nowhere to be found in the signature for
       {usingAbilitiesPt1.nonEmptyName}. It's been eliminated by the
       {toOptional!} handler function.

       Take a closer look at the signature of {toOptional!}:

           @signature{toOptional!}

       This function expects a __delayed computation__ so it's not as simple as
       slotting {effectfulPredicate.stopIfTrue} in as an argument. Instead we
       need to delay result of calling {effectfulPredicate.stopIfTrue}. We do
       this by surrounding the __entire expression__ we want delayed with
       parentheses and adding a single quote {{ docCode {{ ' }} }} to the
       front. {{
       docAside
         {{
         See the section on
         [delayed computations]({{
         (docLink (docEmbedTermLink do delayedComputations))
         }}) for a refresher.
         }} }}

       {{
       docCallout
         (Some important)
         {{
         It's easy to make the mistake of putting the single quote next to the
         function to delay without surrounding it in parentheses, thinking "the
         entire expression to the right will be evaluated and wrapped in the
         thunk." `'myEffect arg` only delays the __function__ `myEffect`
         whereas `'(myEffect arg)` delays the __result of evaluating__
         `myEffect arg`. The latter is typically what you want.
         }} }}

       With the call to {abort} interpreted into the {type Optional} data type,
       we can then use standard functional combinators on {type Optional} to
       provide a sensible default {type Text} value for our function.

       {{
       docCallout
         (Some style)
         {{
         By convention, handlers that do not return a delayed computation, like
         {toOptional!} or {toDefault!} end with an exclamation mark `!` to
         distinguish them from their counterparts which return delayed
         computations.

         Compare the signature of {toDefault!}

             @signature{toDefault!}

         with the corresponding signature returning the thunk in {toDefault}

             @signature{toDefault}
         }} }}

       We might have also chosen to interpret {type Abort} ability with {toBug}
       or {toDefault!}. Look at the similarities in the signatures of all three
       of these handlers:

           @signatures{toOptional!, toDefault!, toBug}

       All of them take in a delayed computation which performs the
       {type Abort} effect and return a value with the ability requirement
       removed.

       {{
       docAside
         {{
         Remember, the remaining `{g}` in the return type of these signatures
         is a pass-through representing other abilities that may be handled
         later.
         }} }}

    ## Handling multiple abilities

       We've seen how simple it is for functions to perform multiple effects at
       once with our {store.stopIfTrue} code. When a function performs multiple
       effects it's common to nest handlers inside one another, with each
       handler peeling off one ability requirement. Handlers are just functions
       after all!

       As a refresher the abilities we are trying to eliminate are in the
       signature @inlineSignature{store.stopIfTrue}

           @source{store.nonEmptyName}

       In the example above we're eliminating the {type Store} ability first
       with the {withInitialValue} handler. It's a function which ensures the
       {type Store} has been seeded with some value so if subsequent functions
       call {Store.get} they're guaranteed to return something.

       Then we eliminate the {type Abort} ability by transforming it into a
       {type Optional} value.

       One caveat: the order in which the handlers are applied can change the
       value returned! Handlers respect the
       [rules of regular function application]({languageReference.functionApplication}),
       so you might see them grouped with parentheses or
       [function application operators]({functionApplicationOperators}) when
       you're defining a Unison function that you intend to run in a {{
       docTooltip {{ watch expression }} watchExpression }} or with the UCM
       [`run`](ucmCommands.run) command.

    ## Abilities and top level definitions

       {{ style }} It's common to express the core of your Unison program in
       terms of abilities and translate your abilities into Unison standard
       data types or {type IO} because abilities cannot be left unhandled "at
       the top level" of a file

       🙅🏻‍♀️ A term like this will not typecheck:

       ``` unison
       tryEmit : {Stream Text}()
       tryEmit = Stream.emit "Hi"
       ```

       The quick solution for this is to
       [delay the computation]({delayedComputations}), with a thunk, so that
       the `{Stream Text}` abilities requirement is once again found on the
       right side of the arrow. With a delayed computation, the signature would
       become `tryEmit : '{Stream Text}()` or `tryEmit : () -> {Stream Text}()`
       without the syntactic sugar of the single quote.

       Any one of these will work:

       ``` unison
       tryEmit1 : '{Stream Text}()
       tryEmit1 = do Stream.emit "Hello World"

       tryEmit2 : '{Stream Text}()
       tryEmit2 _ =
         Stream.emit "Hello World"

       tryEmit3 : '{Stream Text}()
       tryEmit3 = '(Stream.emit "Hello World")
       ```

       {{
       docCallout
         Optional.None
         {{
         Abilities are a property of the __function__ that they're exercised
         in, not a property of a value. A good mental model for abilities is
         that the ability requirement can be thought of as decorating or being
         attached to the the __function arrow__.
         }} }}

       Note that the trick of adding a thunk to a value that performs an
       ability will enable your code to __typecheck,__ but the application of a
       handler is the only way to run an effectful function in a
       {{ docTooltip {{ watch expression }} watchExpression }}.

       ### The IO ability

           Unison has a special built-in handler for functions which perform
           I/O. The {type IO} ability is the only Unison ability whose handler
           is provided by the runtime, not by specific handler functions. {{
           docAside
             {{
             The {type IO} ability supports functionality like reading and
             writing from the file system, writing to the console, managing
             sockets, and other common operations. Check out the functions
             under the `base.IO` namespace to see more.
             }} }} If we'd like to integrate our existing function into one
           which performs I/O via the console, we can do that like this:

               @source{nameGreet}

           This function uses the {readLine} function in the base library to
           get the user's name and the {printLine} function to render it. Both
           are effectful and require the {type IO} and {type Exception}
           abilities. {readLine} returns a delayed computation, so in order get
           the {type Text} value from the user we evaluate the thunk with the
           exclamation mark. The entire function is wrapped in a thunk because
           `nameGreet _` is syntactic sugar for a delayed computation, so the
           final signature of the expression is:

               @signature{nameGreet}

           This signature is important for the IO handler. That's because at
           the top level of a Unison program, a function which performs
           {type IO} can only be called via the UCM with the `run` command.

           It just so happens the `run` command provides the implementation
           details for handling both the {type IO} and the {type Exception}
           abilities, so we don't need a specific {type Exception} handler in
           this case.

           {{
           docCallout
             (Some wordle.utils.emojis.hint)
             {{
             The `run` command expects a delayed computation with a signature
             of `'{Exception, IO} a`
             }} }}

           ``` ucm
           scratch/main> run nameGreet
           ```

           {{
           docCallout
             (Some important)
             {{
             To review:

             Handlers are functions that provide behavior to abilities - they
             often interpret the ability into data types or into other
             abilities.

             Don't forget your parens when a handler accepts a delayed
             computation, {{ (docCode {{ '{MyAbility} a }}) }}. 😎

             Abilities are properties of functions (not values), so they cannot
             be unhandled at the top level of a term.

             The {type IO} and {type Exception} handlers are provided by the
             Unison runtime. 🎉
             }} }}

           {{ usingAbilitiesPt2._nav }}
  }}

docs.fundamentals.abilities.usingAbilitiesPt2.nameGreet : '{IO, Exception} ()
docs.fundamentals.abilities.usingAbilitiesPt2.nameGreet _ =
  use Text ++
  printLine "Enter your name:"
  name = readLine()
  printLine ("Hello " ++ name)

docs.fundamentals.abilities.usingAbilitiesPt2._nav : Doc
docs.fundamentals.abilities.usingAbilitiesPt2._nav =
  {{
  # Where to next?

    {{ suggested }}
    [Error handling with abilities]({{
    docLink (docEmbedTermLink do errorHandling)
    }})

    {{ wordle.utils.emojis.learnMore }}
    [Writing ability handlers]({{
    docLink (docEmbedTermLink do writingAbilities)
    }})
  }}

docs.fundamentals.abilities.usingAbilitiesTut : Doc
docs.fundamentals.abilities.usingAbilitiesTut =
  {{
  # 🚧🚧 Caution! 🏗 This section is in progress 🚧🚧

    ## Using Abilities: A tutorial 🤖🐥🐿

       The RoboBirds Corporation has hired you to implement the backend for
       their fully automated bird feeding robot. They'd like a system that
       dispenses birdfood when a bird lands on the feeder, but does not offer
       any food to the squirrels who plagued their earlier product lines; the
       bird feeder should also track the current number of seed servings so
       that refill notifications can be sent to the birds' ~~serfs~~ human
       patrons. Naturally, you chose to write the core program in Unison. 😎
       With an understanding of the
       [mental model for how Unison manages functional effects]({abilities.index})
       and the basics of [Unison's syntax for abilities](./usingAbilitiesPt1),
       you'll be making use of Unison's abilities and built-in handlers for the
       implementation of this program. 🦆

       Breaking down the problem, there are at least three "effects" to manage:
       an effect which models some notion of internal state, an effect which
       can represent when the feeder is completely out of food, and an effect
       for sending notifications.

       Let's start with some simple data types to model the domain. If you
       haven't seen Unison's syntax for defining data types,
       [check out this document here]({{
       docLink (docEmbedTermLink do uniqueAndStructuralTypes)
       }}) and then come back!

           @source{type Animal}

           @source{type BirdFeeder}

           @source{type usingAbilitiesTut.Message}

       We can start by writing a basic food dispensing function without
       covering any of the desired additional features. It should take in an
       {type Animal} and a {type BirdFeeder} and return a {type BirdFeeder},
       with the intention that it might be called in some kind of repeated
       fashion, with the state of the birdfeeder changing each step.

           @source{dispenseFood1}

       Simple enough, this is an implementation without abilities, or a "pure"
       implementation. But the birds demand an efficient dispensation system! 🦉
       No energy should be wasted attempting to dispense food once the bird
       feeder is empty. Why not use the {type Abort} ability to represent when
       the `servingCount` is zero.

       {todo.TODO} foldable exercise here with just the signature

       Excellent. The birds are pleased.

       * Pure implementation
         * Basic state transition
       * Adding Abort
         * Show Ability definition
         * Show Ability in function signature
         * Explain why the ability in the signature is located where it is
         * Simple handler
       * Adding Stream
         * Ability definition with more complicated type `Stream a` instead of
           just `Abort`
         * Nested handler
       * Looping with Abilities
         * List.foldLeft / foldRight and the directionality of the arrow.
       * Adding complexity/ possible exercise: Input is Stream
       * Adding complexity: Add Store - swappable storage backend.
       * Adding complexity: file input
  }}

docs.fundamentals.abilities.usingAbilitiesTut.animals : [Animal]
docs.fundamentals.abilities.usingAbilitiesTut.animals =
  [Bird, Bird, Squirrel, Bird, Bird, Squirrel]

docs.fundamentals.abilities.usingAbilitiesTut.dispenseFood1 :
  Animal -> BirdFeeder -> BirdFeeder
docs.fundamentals.abilities.usingAbilitiesTut.dispenseFood1 = cases
  Bird, BirdFeeder servings -> BirdFeeder (servings Nat.- 1)
  Squirrel, feeder          -> feeder

docs.fundamentals.abilities.writingAbilities : Doc
docs.fundamentals.abilities.writingAbilities =
  use KVStore get put
  {{
  # Writing your own abilities

    Say you couldn't find an ability in `base` for your particular use-case;
    Unison also allows you to write your own abilities to model a particular
    effect.

    {{ headsUp }} This doc assumes some familiarity with the general
    [mental model](./) for what an ability is, and a working understanding of
    __using__ abilities and handlers. If not, check out
    [parts one](./usingAbilitiesPt1) and [two](./usingAbilitiesPt2), of this
    guide and head back.

    ## Writing ability declarations

       {{
       docAside
         {{
         {{ headsUp }} Some of this will be review from Part 1 of working with
         abilities,
         [you can skip to the handler definition section](#writing-handlers) if
         you feel confident in writing ability declarations.
         }} }} Here's an example ability declaration for an effect that models
       a key value store. You might choose to make this ability as a way to
       implement caching for a function without having to add a specific key
       value store as an argument to functions that require access to it. We'll
       put it to use in a bit.

           @source{type KVStore}

       Ability declarations start with the `ability` keyword, followed by the
       name of the ability and any lowercase type parameters that the ability
       might require. The type parameters here, lowercase `a` and `b`, mean
       that this store can contain keys and values of a specific type.

       The {get} and {put} function signatures are the operations of the
       ability, which we call __request constructors__. In general, an ability
       can contain any number of request constructors. When naming your
       operations, ask yourself: independent of a particular implementation,
       what are the operations of the effect that I'm trying to model? For the
       {type KVStore} ability, we wouldn't want to call the request operation
       "redisGet", and for this simple key value store ability a request
       constructor called "putWithCreateTime" arguably leaks implementation
       details into the ability definition that might best be relegated to a
       specific handler.

       In the signature for {get}, @inlineSignature{get}, the {{
       docTooltip {{ ability requirement }} abilityRequirement }} appears in
       the return type. On it's face, this makes sense, when you call the {get}
       or {put} operations, you will need to handle the ability it performs!

       {{
       docAside
         {{
         If you're curious about how to address error handling when defining
         your abilities,
         [head to the FAQ's]({{ (docLink (docEmbedTermLink do faqs)) }}) for
         more details there.
         }} }}

    ## {{ Anchor "writing-handlers" {{ Writing handlers }} }}

       We've defined the interface for our ability, but to supply the desired
       behavior to the ability when it's called, we need to write a special
       Unison function called a handler.

       {{
       docCallout
         (Some important)
         {{
         At a high level, a handler works by pattern matching on each of the
         functions of the ability. When a program evaluates a call to {get} it
         looks to the enclosing handler of the function, then finds the branch
         of the pattern match that reflects the operation of the ability that
         has been called, and performs the actions specified there.
         }} }}

       The following function will be the example we'd like to run with our
       handler. It writes two values into storage and gets one of them back,
       calling {Nat.toText} on it.

           @source{myProgram}

       We'll deep dive into the syntax of handlers by writing a handler for our
       {type KVStore} ability next.

  # The parts of a handler

    Let's look at a handler that enables interactions with a key value store
    backed by an in-memory {type Map}. Don't worry, we'll be breaking this
    down:

        @source{inMemory}

    Each section below provides an overview of what the handler is doing, with
    a link to optionally read more in-depth information on a particular handler
    concept.

    ## Line by line overview

       ``` unison
       inMemory : '{g, KVStore a b} r ->{g} r
       inMemory keyValueInteractions =
       ```

       * In type signature we see that the {type KVStore} ability is a delayed
         argument to the handler
       * It's polymorphic, meaning it can handle {type KVStore} interactions of
         any `a` or `b` type which return any value `r`
       * The argument `keyValueInteractions` is the function we're trying to
         run. In our example, it stands in for {myProgram}

       [Read more about the type signatures of handlers](#type-signature-handlers)

       {{ SectionBreak }}

       ``` unison
       …
         handle !keyValueInteractions with impl Map.empty
       ```

       * This is the next line that Unison would execute once the handler is
         provided.
       * It initializes the {type KVStore} with an empty map as the storage
         backing.
         * This {type Map} will be updated in subsequent interactions with the
           ability
       * The `handle… with` keywords tell Unison that this function is not just
         another function __using__ the ability, it is going to be
         __capturing the requests__ to the ability
       * Each time the `handle… with` block is repeated
         __it sets up the handler for the next request__; that's why its
         important to handle the `resume` variable

       [Read more about the `handle… with` keywords](#handle-with-keywords)

       {{ SectionBreak }}

       ``` unison
       …
           impl : Map a b -> abilities.Request {KVStore a b} r -> r
           impl map = cases
       …
       ```

       * `impl` is a helper function which holds state between requests
       * The
         [`cases` syntax](https://www.unison-lang.org/learn/fundamentals/control-flow/pattern-matching/#cases-syntax)
         used here is a way of pattern matching on the {type Request} argument.
       * The `Request` type represents interactions with {get} and {put}

       [Read more about the `Request` type](#request-type)

       {{ SectionBreak }}

       ``` unison
       …
         impl map = cases
           { pure } -> pure
       …
       ```

       * The `{pure} -> pure` line reflects the fact that a given program may
         never use the ability and determines the value returned by the handler
         in that situation
       * In our handler signature, the type of `pure` is `r`, and when applied
         to {myProgram}, the value `r` is of type {type Text}

       [Read more about returning pure values in handlers](#return-types)

       {{ SectionBreak }}

       ``` unison
       …
         {KVStore.get key -> resume}       ->
           handle resume (Map.get key map) with impl map
         {KVStore.put key value -> resume} ->
           updatedMap = Map.insert key value map
           handle !resume with impl updatedMap
       …
       ```

       * The handler "gets" values from the map when a program calls the {get}
         function
         * It returns the expected value to the "rest of the program",
           represented by the variable `resume`
       * The handler "puts" values into the map when a program calls the {put}
         function
         * It updates the internal state of the handler by calling `impl` with
           an updated map
       * resuming the "rest of the program" with another call to the `impl`
         function ensures subsequent interactions with the {type KVStore}
         ability are passed the appropriate state

       [Read more about resuming computations](#resuming-comp)

    ## Deep-dive: Writing handler concepts

       ### {{
       Anchor "type-signature-handlers" {{ The type signatures of handlers }}
       }}

           One way to read the type signature @inlineSignature{inMemory} is,
           "inMemory handles a function that uses a KVStore in the process of
           returning some value, r, and eliminates the ability, returning that
           r value."

           You'll notice a lowercase variable in the type signature, `{g}`
           being passed through the ability requirements for the handler as
           well. This means that this handler allows other abilities to be
           called in the function being handled and will pass along the ability
           requirement for its respective enclosing handler function to manage.

           {{
           docAside
             {{
             {{ reminder }} The single quote represents a thunk, or
             [delayed computation](../valuesAndFunctions/delayedComputations).
             }} }}

           The {inMemory} handler contains a helper function with the signature
           `impl : Map a b -> Request (KVStore a b) r -> r`. The helper
           function's first argument is the {type Map} that we'll be updating
           to contain state internal to the handler. The second argument
           starting with `Request (KVStore a b) r` is Unison's type which
           represents requests to perform the ability's operations (here those
           requests are things like `put 3 4` or `get 3`).

       ### {{ Anchor "resuming-comp" {{ Resuming computations }} }}

           If you look at the cases in our pattern match,
           `{KVStore.get k -> resume}`, you'll notice there's a variable
           representing the argument to {get} and also a variable called
           `resume`. This is because a handler allows you to access a snapshot
           of the of the __arguments to the request__ and the program state
           __as it is running.__ You might hear the variable for "resuming
           computations" called a
           {{ docTooltip {{ continuation }} continuation }}. `resume` is a
           function whose argument is always the return type of the request
           operation in question, for example, @inlineSignature{get} returns an
           {type Optional}, so that's the value provided to `resume` after
           looking up the key in the {type Map}.

           {{
           docAside
             {{
             Sometimes, when an ability operation has Unit as its return type,
             i.e. @inlineSignature{put}, you might see the syntax
             `handle resume () with` or `handle !resume with`. That's because
             "calling a function with no arguments" and "forcing a delayed
             computation with the bang operator" are synonymous.
             }} }}

           The fact that the {{ docTooltip {{ continuation }} continuation }}
           is reflected as a variable in the handler opens up possibilities
           for, say, terminating the computation, rerunning the computation, or
           even storing it!

       ### {{ Anchor "handle-with-keywords" {{ The handle ... with keywords }}
       }}

           It's important to initialize or `resume` a {{
           docTooltip {{ continuation }} continuation }} with the
           `handle... with` keywords. By wrapping the call to `resume` with a
           recursive call to the handler implementation, we're telling the
           program, "this is how you should handle the next request." In this
           way, we're ensuring that the next call to the ability is being
           managed appropriately. The handler given here can contain state
           between requests as an argument, like the `map` in our
           {type KVStore} example.

       ### {{ Anchor "request-type" {{ Handling the `Request` type }} }}

           The `handle` keyword is followed by a function which requires the
           ability in question and the `with` keyword expects a function which
           includes the {type Request} type as an argument. When a function
           includes the {type Request} type in its signature, it tells Unison
           that the function will be pattern matching on the operations of the
           ability.

           It's common for top-level handlers to accept a delayed computation,
           but remember, the {type Request} type represents actual requests to
           your ability, so don't forget the bang operator, `!`.

           {{
           docCallout
             (Some style)
             {{
             Handlers often follow a pattern where the top level of a handler
             will expose a signature with no explicit reference to the
             {type Request} type, like @inlineSignature{inMemory}, which in
             turn delegates to an `impl` handler containing the {type Request}
             pattern matching implementation. This means callers of the handler
             can write expressions like:

             ```
             (inMemory myProgram)
             ```

             instead of:

             ``` unison
             (handle !myProgram with inMemory.impl Map.empty)
             ```
             }} }}

       ### {{ Anchor "return-type" {{ The return type of a handler }} }}

           Handlers contain a "done" or "pass-through" or "pure" case for when
           functions which require an ability don't end up executing the
           ability operations, or when function is done calling the ability.
           This is represented by the pattern match case which does not
           reference the request constructors of the ability: `{pure} -> pure`.
           In our example handler, @inlineSignature{inMemory} the type of this
           "pure" case is represented by the `r`.

           Handlers can even change this value as part of the behavior they
           supply to the program. Say we wanted to return both the value, `r`
           __and__ the final state of the {type Map} after running the effect.
           We can do that by changing the `pure` case and associated type
           signature:

           {{
           docSource
             [docSourceElement (docEmbedTermLink do inMemoryWithMap) []] }}

           Now, without changing anything about our `` myProgram `` function,
           we have access to the {type Map}!

           ```
           inMemoryWithMap myProgram
           ```

  # Summary

    * Writing a handler involves pattern matching on the {{
      docTooltip {{ request constructors }} requestConstructors }} of the
      ability
    * You can explicitly control what value the program receives next through
      {{ docTooltip {{ continuations }} continuation }}
      * The second argument in the pattern match case represents the
        continuation: `{op -> resume}`
      * The type of the value provided to the continuation must be the return
        type of the ability operation being called
    * Handlers contain a "pure" case, `{pure} -> …`, which represents when the
      function is done calling the ability or when the ability is not called
    * The `handle` keyword expects a function which requires the ability and
      the `with` keyword expects a function with {type Request} as an argument

    {{ writingAbilities._nav }}
  }}

docs.fundamentals.abilities.writingAbilities.constantStore :
  b -> '{g, KVStore a b} r ->{g} r
docs.fundamentals.abilities.writingAbilities.constantStore
  providedValue keyValueInteractions =
  impl : Request {KVStore a b} r -> r
  impl = cases
    { pure } -> pure
    { KVStore.get key -> resume } ->
      handle resume (Some providedValue) with impl
    { KVStore.put k v -> resume } -> handle resume() with impl
  handle keyValueInteractions() with impl

docs.fundamentals.abilities.writingAbilities.discard :
  r -> '{g, KVStore a b} r ->{g} r
docs.fundamentals.abilities.writingAbilities.discard
  returnValue keyValueInteractions =
  impl : Request {KVStore a b} r -> r
  impl = cases
    { pure }                      -> returnValue
    { KVStore.get key -> resume } -> handle resume Optional.None with impl
    { KVStore.put k v -> resume } -> handle resume() with impl
  handle keyValueInteractions() with impl

docs.fundamentals.abilities.writingAbilities.inMemory :
  '{g, KVStore a b} r ->{g} r
docs.fundamentals.abilities.writingAbilities.inMemory keyValueInteractions =
  impl : Map a b -> Request {KVStore a b} r -> r
  impl map = cases
    { pure } -> pure
    { KVStore.get key -> resume } ->
      handle resume (Map.get key map) with impl map
    { KVStore.put key value -> resume } ->
      updatedMap = Map.insert key value map
      handle resume() with impl updatedMap
  handle keyValueInteractions() with impl Map.empty

docs.fundamentals.abilities.writingAbilities.inMemory.impl :
  Map a b -> Request {KVStore a b, g} r ->{g} r
docs.fundamentals.abilities.writingAbilities.inMemory.impl map = cases
  { pure } -> pure
  { KVStore.get key -> resume } ->
    handle resume (Map.get key map)
    with docs.fundamentals.abilities.writingAbilities.inMemory.impl map
  { KVStore.put key value -> resume } ->
    updatedMap = Map.insert key value map
    handle resume()
    with docs.fundamentals.abilities.writingAbilities.inMemory.impl updatedMap

docs.fundamentals.abilities.writingAbilities.inMemoryWithMap :
  '{g, KVStore a b} r ->{g} (r, Map a b)
docs.fundamentals.abilities.writingAbilities.inMemoryWithMap
  keyValueInteractions =
  impl : Map a b -> Request {KVStore a b} r -> (r, Map a b)
  impl map = cases
    { pure } -> (pure, map)
    { KVStore.get key -> resume } ->
      handle resume (Map.get key map) with impl map
    { KVStore.put key value -> resume } ->
      updatedMap = Map.insert key value map
      handle resume() with impl updatedMap
  handle keyValueInteractions() with impl Map.empty

docs.fundamentals.abilities.writingAbilities.myProgram :
  '{KVStore Nat Nat} Text
docs.fundamentals.abilities.writingAbilities.myProgram _ =
  use KVStore put
  put 3 4
  put 5 6
  maybeFour = KVStore.get 3
  Optional.map Nat.toText maybeFour |> Optional.getOrElse "nothing here"

docs.fundamentals.abilities.writingAbilities._nav : Doc
docs.fundamentals.abilities.writingAbilities._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Read about Abilities for the monadically inclined](./forMonadicallyInclined)

      {{ wordle.utils.emojis.learnMore }} [FAQ's about abilities](./faqs)
    }} }}
  }}

docs.fundamentals.abilities._handlerDefinition : Doc
docs.fundamentals.abilities._handlerDefinition =
  {{
  A handler is a Unison function which supplies the implementation or behavior
  for a given effect.

  Handlers eliminate the {{
  docTooltip {{ ability requirement }} abilityRequirement }} in a few common
  ways:

  * By interpreting the ability into a Unison data type or value
  * By interpreting the ability into __other abilities__
  }}

docs.fundamentals.controlFlow.aside.dataAccess : Doc
docs.fundamentals.controlFlow.aside.dataAccess =
  {{
  {{ wordle.utils.emojis.hint }} For folks who come from languages which use
  dot accessors, getters, or other shorthand methods to access fields of a
  record, this is **one** of the answers to the immortal question: "How do I
  get at the values in this thing?" We'll learn about others later when we
  cover data types in more depth.
  }}

docs.fundamentals.controlFlow.aside.exhaustivityChecking : Doc
docs.fundamentals.controlFlow.aside.exhaustivityChecking =
  {{
  {{
  docAside
    {{
    Unison does not currently perform exhaustivity checking on pattern matches,
    so the following code will typecheck

    ``` unison
    unique type CoffeeOrTea = Coffee Nat | Tea Nat

    myBeverage : CoffeeOrTea -> Nat
    myBeverage b = match b with
      Tea n -> n

    myBeverage (Coffee 5)
    ```

    But will fail when called:

    ``` ucm
    💔💥

      I encountered a blank expression with the following name/message:

      "pattern match failure"
    ```

    In the future, we plan to support exhaustive pattern matches.
    }} }}
  }}

docs.fundamentals.controlFlow.exceptionHandling : Doc
docs.fundamentals.controlFlow.exceptionHandling =
  use exceptionHandling bug failure
  {{
  # Error handling with data types

    There are a few common data-types that represent when a computation may
    fail. The reason we might represent "things that can go wrong" with a data
    type has [a storied history 🌯.]({forMonadicallyInclined}) Here, we'll
    simply make the assertion that wrapping errors in data types makes it
    easier for you to identify what's happening in your program and write
    programs whose behavior is well defined. {{
    docAside
      {{
      It's also common to represent failures in Unison using Abilities, but
      we'll be learning about those later.
      }} }}

    {{ headsUp }} For folks who are comfortable with functional data types for
    errors, you might want to familiarize yourself with the sections on
    [`bug`]({bug}) and [`Failure`]({failure}), which are more specific to
    Unison.

    {{ exceptionHandling.optional }}

    {{ exceptionHandling.either }}

    {{ bug }}

    {{ failure }}

    {{ exceptionHandling._nav }}
  }}

docs.fundamentals.controlFlow.exceptionHandling.bug : Doc
docs.fundamentals.controlFlow.exceptionHandling.bug =
  use base bug
  {{
  # Bug--for aborting programs

    In some circumstances, you may want to stop your program immediately
    without allowing any caller of the function to catch or handle the error.
    For that you can use the built in function {bug} in Unison. Unlike
    {type Optional} or {type Either} - if you call {bug} in a function, you do
    not need to represent the possibility of the failure in the function's
    signature as a data type for the caller to manage.

    You can provide a term or expression of any type to {bug} and the {{
    docTooltip {{ UCM }} {{ {{ ucm }} }} }} will render that value to the
    console.

    @typecheck ```
    superProgram : Boolean -> Nat
    superProgram bool =
      if Boolean.not bool then
        bug (Generic.failure "Fatal Issue Encountered" bool)
      else 100
    ```

    Calling the function above with `superProgram false` will abort the running
    program with the message

    ``` ucm
    💔💥

    I've encountered a call to builtin.bug with the following value:

      Failure (typeLink Generic) "Fatal Issue Encountered" (Any false)
    ```

    🚩 Use {bug} judiciously, as there is currently no way for a program to
    recover from a call to {bug}.
  }}

docs.fundamentals.controlFlow.exceptionHandling.either : Doc
docs.fundamentals.controlFlow.exceptionHandling.either =
  use Either Left Right fold mapLeft mapRight
  use Nat +
  use Text ++
  {{
  # Either success or failure

    We've encountered {type Either} before in our
    [introduction to pattern matching.]({{
    docLink (docEmbedTermLink do _dataTypesPatternMatching)
    }}) At its core, {type Either} is a data type which represents a
    computation that can return one of two kinds of values, but you'll often
    see it used to convey enriched error reporting. This doc introduces a few
    useful functions on {type Either} to get you started.

    {{
    docCallout
      (Some style)
      {{
      It's a convention to treat the {Left} side of the {type Either} as a
      failure case, while the {Right} side represents the success case in
      Unison code. This is most obvious in functions like {catch} or {toEither}
      which rely on this pattern to translate between different error
      representations. You wouldn't want to accidentally create an error type
      containing your successful values, so it's important to respect this
      convention.
      }} }}

    To apply a function to a value contained in the {Right} branch of the
    {type Either} data type, you can use {mapRight}. To apply a function to the
    value contained in the {Left} branch, you can use {mapLeft}. Here's what
    calls to those functions look like:

    {{
    docAside
      {{
      Unison does not currently have a right-biased `map` function for
      {type Either}. You can use {mapRight} for that.
      }} }}

    ```
    myEither : Either Text Nat
    myEither = Right 10
    mapRight (number -> number + 1) myEither
    ```

    Note that if you call {mapLeft} on a {Right}, the value will remain
    unchanged--the {{ docTooltip {{ lambda }} {{ {{ lambda }} }} }} argument to
    {mapLeft} can only be applied to a value when the {type Either} argument
    given is a {Left}.

    ```
    myEither : Either Text Nat
    myEither = Right 10
    mapLeft (message -> message ++ "!!!") myEither
    ```

    If you'd like to run one function if the Either returns a {Left} and
    another function when the Either returns a {Right}, you can use {fold}.
    Both the functions need to return the same type, which you can see from the
    signature of {fold}: @inlineSignature{fold}

    ```
    ifLeft : Char -> Text
    ifLeft c = Char.toText c
    ifRight : Nat -> Text
    ifRight nat = Nat.toText nat
    myEither : Either Char Nat
    myEither = Left ?z
    fold ifLeft ifRight myEither
    ```

    You can see more of the functions defined for Either with the
    [`find`]({ucmCommands.find}) command in the UCM.
  }}

docs.fundamentals.controlFlow.exceptionHandling.either.naming : Doc
docs.fundamentals.controlFlow.exceptionHandling.either.naming =
  {{
  The conventions for naming the `map` function on Either can vary from
  language to language.

  Unison's functions are not uniquely identified by **name** so there's nothing
  stopping you from giving functions in a Unison codebase a name which matches
  your preferred convention. {Either.mapRight} could be aliased
  `Either.rightMap` or `Either.map` according to your preference without
  disruption in your codebase.

  In the ucm, running `alias.term Either.mapRight Either.map` will create an
  alias, or `rename.term Either.mapRight Either.map` will rename it altogether.
  }}

docs.fundamentals.controlFlow.exceptionHandling.failure : Doc
docs.fundamentals.controlFlow.exceptionHandling.failure =
  use Generic failure
  {{
  # The Failure Type

    One of the types you'll want to familiarize yourself with is Unison's
    {Failure} type. You'll see this type in the signatures of some of the
    functions in the `base` library, for example @inlineSignature{catch}.
    {Failure} is a unique type whose purpose is to capture information about an
    error.

    Let's look at what we need to construct a failure.

        @signature{Failure}

    As an example, constructing a {type Failure} upon attempting to save a
    duplicate {type User} database error might look like

        @source{failure.example1}

    The first argument to the {{
    docTooltip {{ data constructor }} dataConstructor }} for {Failure} is a
    {Type}.

    You'll need to create a {Type} with the `typeLink` literal. The typelink
    literal allows us to represent a Unison type as a first class value.

    Commonly, the type that we're linking to is some data type which represents
    the domain of the error, for example {type DatabaseError} or
    {type Generic}.

    The second argument to {type Failure} is a {type Text} body which should be
    a descriptive error message.

    The third argument is of type {type Any}. {type Any} is another Unison
    built-in. It wraps any unison value. For example:

    ```
    Any 42
    ```

    or

    ```
    Any [1, 2, 3]
    ```

    You can use {type Any} to capture the value that has produced the error
    result. If that value is not useful for error reporting, you can always use
    {type Unit} as a placeholder, `Any ()`.

    {{ wordle.utils.emojis.learnMore }} Unison provides a helpful
    {type Generic} failure constructor, {failure} for when you don't have a
    particular type that models your error domain. It takes in an error message
    and a value of any type to produce a {type Failure}:
    @inlineSignature{failure}

        @source{genericFailure}
  }}

docs.fundamentals.controlFlow.exceptionHandling.failure.example1 : Failure
docs.fundamentals.controlFlow.exceptionHandling.failure.example1 =
  Failure
    (typeLink DatabaseError)
    "The username column already contains a value for entry: Bob"
    (Any (User.User "Bob"))

docs.fundamentals.controlFlow.exceptionHandling.failure.genericFailure :
  Failure
docs.fundamentals.controlFlow.exceptionHandling.failure.genericFailure =
  Generic.failure
    "A failure occurred when accessing the user" (User.User "Ada")

docs.fundamentals.controlFlow.exceptionHandling.opt1 : Doc
docs.fundamentals.controlFlow.exceptionHandling.opt1 =
  {{
  {type Optional} takes one type parameter representing the type of the value
  which or may not be present. If present, the value is wrapped in {Some} - as
  in ``Some "valueHere"``, and if not the value is {Optional.None}
  }}

docs.fundamentals.controlFlow.exceptionHandling.optional : Doc
docs.fundamentals.controlFlow.exceptionHandling.optional =
  use Optional None flatMap getOrElse map
  {{
  # Optional values

    In Unison, when the result of an expression may or may not be present, we
    can return the value in the {type Optional} data type. {type Optional} has
    one type parameter representing the type of the value which or may not be
    present. If present, the value is wrapped in {Some} - as in
    ``Some "valueHere"``, and if not the value returned is {None}. In some
    programming languages, the idea that a value might be missing is
    represented with `null` or some other keyword which can be returned in the
    place of any type--Unison does not have any such keyword. Take a look at
    the example below:

    ``` unison
    unique type Book = Book [Text]

    flipToPage: Nat -> Book -> Optional Text
    flipToPage desiredPage book =
      match book with
        Book pages -> List.at desiredPage pages
    ```

    In this function, we need to represent the fact that the caller of the
    function can request a page from a book that doesn't exist. We pattern
    match on the `Book` type to inspect the variable `pages`, and then use a
    function which returns an {type Optional} value, {List.at}, to see if the
    desiredPage is a valid index.

    {{
    docAside
      {{
      {{ wordle.utils.emojis.hint }} Didn't know what the "grab value by index"
      function was called, but know what its type should be? Use the type
      search in the UCM by entering your types prefixed with a colon
      `find : Nat -> [a] -> Optional a`. For type parameters, any letter will
      do.
      }} }}

    Simple enough, for missing value error conditions we can wrap our return
    value in {type Optional}. But how do callers of these optional functions
    react to this?

    Let's imagine you come across a function signature like this in a Unison
    codebase:

        @signature{cakeFactory}

    At a quick glance we can read the type signature of the function and
    without knowing anything about the internals of the function, we know that
    there's at least one circumstance in which we, the function callers,
    receive no cake! 🍰

    One way callers of the function can account for that is via
    [pattern matching]({{ docLink (docEmbedTermLink do patternMatching2) }}),
    in which case we can explicitly change the behavior of the enclosing
    function based on the {{ docTooltip {{ data constructors }} dataConstructor
    }} of {type Optional}.

    ```
    match cakeFactory [Kale, Egg, Sugar] with
      Some cake -> "🎉"
      None      -> "😢"
    ```

    Or we can pass the {type Optional} nature of the function's return type
    along via calls to functions like {map} and {flatMap}

    ``` raw
    cakeDescription : Optional Text
    cakeDescription =
      map (c -> "For sale, tasty cake!") <| cakeFactory [Sugar, Egg, Flour]
    ```

    Both {map} and {flatMap} will apply a given function to the {type Optional}
    value if it is present, saving you the trouble of doing a check for a value
    of {None}.

    To provide a default value in the case that a {None} is encountered, we
    could also use {getOrElse}. The first argument to {getOrElse} is the
    "fallback" value and the second is the optional value to inspect. Note that
    the default value must be the same type as the value wrapped inside the
    {type Optional} - so a default value of type {type Nat} can't be provided
    for a value of `Optional Boolean`.

    ```
    defaultCake = Cake "Vanilla"
    getOrElse defaultCake (cakeFactory [Kale, Sugar, Flour])
    ```

    {type Optional} doesn't provide enriched information beyond whether a value
    is present or not. If we need to communicate **why** our value is not there
    or some other information about what went wrong we'll need to reach for a
    different error handling data type.
  }}

docs.fundamentals.controlFlow.exceptionHandling.optional.cakeFactory :
  [Ingredient] -> Optional Cake
docs.fundamentals.controlFlow.exceptionHandling.optional.cakeFactory
  ingredients =
  if elem Kale ingredients then Optional.None else Some (Cake "🎂")

docs.fundamentals.controlFlow.exceptionHandling._nav : Doc
docs.fundamentals.controlFlow.exceptionHandling._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Learn more about defining your own Unison data types]({{
      (docLink (docEmbedTermLink do uniqueAndStructuralTypes))
      }})

      {{ suggested }} [Exercises about control flow]({exercises.controlFlow})

      {{ wordle.utils.emojis.learnMore }}
      [Error handling with abilities](../abilities/errorHandling)
    }} }}
  }}

docs.fundamentals.controlFlow.functionalLooping : Doc
docs.fundamentals.controlFlow.functionalLooping =
  use List foldLeft
  {{
  # Functional looping

    We'll dive right in with an example. Let's imagine you're tasked with
    writing a function to add up elements in a list.

    If we were to express this in a made up programming language—let's call it
    nosinU 🙃—with Unison-like syntax but a different paradigm we might do
    something like:

    ``` unison
    myTotal : [Nat] -> Nat
    myTotal list =
      var currentTotal = 0
      var currentIndex = 0
      -- remember, this is a made up language! 🙃
      while currentIndex < (length list)
        currentTotal += (unsafeAt currentIndex list)
        currentIndex += 1
      currentTotal
    ```

    Here we're keeping track of a few details—we care about the length of the
    list so we don't run off the end; we're continually updating the value of
    the current index to access the data in the list; and we are adding to the
    current total, which we change when we encounter each element. The core of
    what we're doing is building a running total, but our program is also
    concerned with how we're updating each of these pieces of information.

    Unison doesn't support looping or iteration with things like while loops,
    for loops, or break statements. One way to accomplish this in Unison is to
    rely on recursion.

    As very brief refresher, recursive functions work by dividing a problem
    into two broad categories: 1.) scenarios where the recursion can be
    considered "done" and will not make further recursive calls, and 2.) cases
    where the function is reducing the problem space and then calling itself
    again.

    An analogous recursive function which sums up the elements in a list might
    look like:

        @source{recursive.myTotal}

    This recursive function is using
    [pattern matching on a Unison list]({languageReference.listPatterns}) to
    establish a base case and a recursive case. When the list is empty, it
    returns the value ``0``, otherwise, it decomposes the list into the current
    element and its remainder, adding the current value to a recursive call.
    Note that this implementation of the sum function requires that the head
    element of the list be stored on the
    {{ docTooltip {{ call stack }} callStack }}.

    ## Tail call elimination

       Better yet, we can write this recursive function so that each successive
       call to `myTotal` doesn't grow the call stack. When the result of
       evaluating a function can be immediately returned to its enclosing
       caller, the function is in
       {{ docTooltip {{ "tail call position" }} tailCallPosition }}. The Unison
       compiler will perform an optimization called tail call elimination for
       functions like this.

           @source{tailRecursive.myTotal}

       Because these kinds of operations are so commonly performed on data
       structures, it's more common to delegate control over the looping logic
       to other functions which are based on the principles of recursion.

       In Unison we might use one of the class of {{
       docTooltip {{ higher-order functions }} {{ {{ higherOrderFunction }} }}
       }} which handle "folding" to express the kind of operation where each
       element in the data structure needs to be combined in a programmatic
       way.

           @source{fold.myTotal}

       The core parts of the operation we're performing are the same in both
       the {foldLeft} and original versions of the `myTotal` function: we
       initialize our `currentTotal` value with `0`, and each successive
       element of the list is added to that total in the body of the
       higher-order function which we provide to {foldLeft}. You can think of
       that function `(currentTotal element -> currentTotal + element)` as
       **declaring** the logic or intent of "add up a running total" - for this
       reason, you'll often hear this style called
       {{ docTooltip {{ declarative programming }} declarative }}.

       What if we wanted to write a function that breaks out of the loop in the
       event that a particular condition is hit?

       In our made up alternative language, you might make use of a `break`
       statement.

       ``` unison
       bottlesOfPop : [Nat] -> [Text]
       bottlesOfPop bottleRange =
         var bottleLocations = []
         var currentIndex = 0

         while currentIndex < (length list)
           bottle = unsafeAt currentIndex bottleRange
           if bottle > 10 then break else let
             bottleLocations += bottleLocations :+ ((toText bottle) ++ " bottles of pop on the wall")
           currentIndex += 1
         bottleLocations
       ```

       We have a few strategies for this in Unison. In this case we might use
       {List.takeWhile}, which starts from the leftmost element of the list and
       will continue taking elements from the list until the condition provided
       is no longer true. Then we might transform that list into the desired
       text value in a second call to {List.map}.

       ``` unison
       bottlesOfPop : [Nat] -> [Text]
       bottlesOfPop bottleRange =
         use Text ++
         ninetyNine =
           use Nat <=
           List.takeWhile (bottle -> bottle <= 10) bottleRange
         map (elem -> Nat.toText elem ++ " bottles of pop on the wall") ninetyNine
       bottlesOfPop (List.range 1 100)
       ```

       If we just wanted to gather all the elements which met a condition from
       the list, we might use a {List.filter} function to ensure that we are
       only operating over the desired subset of data. In each of these cases,
       the higher-order function is handling iteration. These and other
       functions can be found in the {type List} namespace.
  }}

docs.fundamentals.controlFlow.functionalLooping.fold.myTotal : [Nat] -> Nat
docs.fundamentals.controlFlow.functionalLooping.fold.myTotal list =
  use Nat +
  List.foldLeft (currentTotal element -> currentTotal + element) 0 list

docs.fundamentals.controlFlow.functionalLooping.recursive.myTotal :
  [Nat] -> Nat
docs.fundamentals.controlFlow.functionalLooping.recursive.myTotal = cases
  [] -> 0
  head +: tail ->
    head
      Nat.+ docs.fundamentals.controlFlow.functionalLooping.recursive.myTotal
        tail

docs.fundamentals.controlFlow.functionalLooping.tailRecursive.myTotal :
  [Nat] -> Nat
docs.fundamentals.controlFlow.functionalLooping.tailRecursive.myTotal list =
  use Nat +
  loop : [Nat] -> Nat -> Nat
  loop innerList currentTotal = match innerList with
    []           -> currentTotal
    head +: tail -> loop tail (head + currentTotal)
  loop list 0

docs.fundamentals.controlFlow.functionalLooping._nav : Doc
docs.fundamentals.controlFlow.functionalLooping._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Learn about error handling with data types]({{
      (docLink (docEmbedTermLink do exceptionHandling))
      }})
    }} }}
  }}

docs.fundamentals.controlFlow.ifThenAndElse : Doc
docs.fundamentals.controlFlow.ifThenAndElse =
  use Boolean not
  use base bug
  {{
  # Controlling program execution

    This section details a few of the fundamental language constructs for
    directing the order in which a program executes.

    We'll refer to this as {{
    docTooltip {{ "control flow" }} {{ {{ glossary.controlFlow }} }} }} from
    now on and we'll cover how to write if/else statements, how to pattern
    match, how to deal with the concept of looping or iterating through
    collections, and some error handling basics.

  # If, then, else

    {{ _ifElseBlocksSum }} Your first argument to the conditional must be an {{
    docTooltip {{ expression }} {{ {{ expression }} }} }} which returns a
    {type Boolean}. This could be a [code block]({_blockSyntax}) or some
    condition which you'd like to test extracted in a function. {{
    docAside
      {{
      Often, pattern matching is used in place of an if/else block in Unison,
      we'll cover that in a bit.
      }} }}

    ```
    myList : [Nat]
    myList = [1, 2, 3, 4, 5, 6, 7]
    mySimpleTerm =
      if Search.elem 5 myList then "high five" else "no five found"
    mySimpleTerm
    ```

    {{
    docAside
      {{
      {{ reminder }} Remember that Unison codebases are not mutable bags of
      text files so the spacing of your conditional expression is only
      important insofar as the arguments to each part are a valid
      [code block]({_blockSyntax}). That's the
      [big technical idea]({_bigTechnicalIdea}) that powers Unison programs.
      }} }}

    If we wanted many if/else statements expressing multiple conditions, we'd
    express it with successive `else if` blocks:

    ```
    myList = Nat.range 0 99
    myListFunction =
      if Search.elem 100 myList then "100 found"
      else
        if List.any (elem -> Nat.mod elem 2 === 0) myList then "Even found"
        else "Condition not met"
    myListFunction
    ```

    ## Boolean Expressions

       {type Boolean} values can be combined with operators like {Boolean.and},
       also represented as `&&` in Unison and {Boolean.or}, also represented as
       `||`.

       ```
       false
         && bug "oh no"
       ```

       For an expression where the first argument to `&&` is false, as in the
       one above, the latter argument will never be evaluated.

       ```
       true
         || bug "oh no"
       ```

       For an expression where the first argument to `||` is true, the latter
       argument will never be evaluated.

       To negate a boolean value, use {not}.

       ```
       not true
       ```

       {{ ifThenAndElse._nav }}
  }}

docs.fundamentals.controlFlow.looping : Doc
docs.fundamentals.controlFlow.looping =
  {{
  # Looping

    You might be familiar with some kind of looping convention from other
    programming languages but for folks who come from {{
    docTooltip {{ imperative languages }} {{ {{ imperative }} }} }} we'll talk
    briefly about Unison's strategies for handling iterative actions. {{
    headsUp }} Heads up: this document will likely be review for folks who are
    familiar with functional programming conventions for looping—if that's you,
    [skip to the end of the doc]({_summaryLoopingConstructs}), where we briefly
    describe some Unison conventions around recursion.

    {{ functionalLooping }}

    {{ _summaryLoopingConstructs }}

    {{ functionalLooping._nav }}
  }}

docs.fundamentals.controlFlow.patternMatching : Doc
docs.fundamentals.controlFlow.patternMatching =
  {{
  # Pattern matching part 1

    We've seen how to conditionally evaluate programs with the
    [`if true then "this" else "that"` syntax](./ifThenAndElse). With pattern
    matching we can change the {{
    docTooltip {{ control flow }} glossary.controlFlow }} of our program based
    on a richer set of conditions. We'll explore how to pattern match on
    {{ docTooltip {{ literal values }} glossary.literal }}, add "guards" for
    more granular conditions for our pattern, and explore structural pattern
    matching based on data types.

    {{ _literalPatternMatching }}

    {{ _variablesGuards }}

    {{ _casesSyntax }}

    {{
    docCallout
      (Some {{ {{ reminder }} }})
      {{
      Summary:

      * Pattern matching allows us to inspect both the content the structure of
        our data.
      * Features like guard patterns and variable patterns allow us to apply
        conditions which may be local to the structure of that data to direct
        the flow of a program.
      * Guard patterns are expressed with a single pipe, `|`, with a boolean
        expression on the right.
      * The `match ... with` syntax can by simplified with `cases` when
        matching on the last arguments to a function.
      }} }}

    {{ patternMatching._nav }}
  }}

docs.fundamentals.controlFlow.patternMatching.listPatterns : Doc
docs.fundamentals.controlFlow.patternMatching.listPatterns =
  use Text ++
  {{
  # Pattern matching on {type List}

    Pattern matching on {type List} elements has its own special syntax. {{
    docAside
      {{
      The
      [documentation for `List`](https://share.unison-lang.org/@unison/base/code/main/latest/types/data/List)
      goes in-depth about the data structure itself, check it out!
      }} }}

    ## Head and tail pattern matching

       You can use pattern matching to scrutinize the first (left-most) element
       of a list with the `+:` syntax.

       ```
       match ["a", "b", "c"] with
         head +: tail -> head
         _            -> "empty list"
       ```

       The `+:` is unpacking the first element `head` to its text value `"a"`
       while keeping the remaining elements `tail` as a {type List}. The
       underscore will match the "empty list" case. We could have also
       expressed `_ -> "empty list"` as `[] -> "empty list"` or
       `List.empty -> "empty list"`. All three are valid ways of testing for
       the empty list case.

       You can also pattern match on the __last__ (right-most) element of a
       list in Unison:

       ```
       match ["a", "b", "c"] with
         firsts :+ last -> last
         _              -> "empty list"
       ```

       Put together, you can even pattern match on both ends of the list:

       ```
       match ["a", "b", "c"] with
         first +: midSection :+ last -> first ++ last
         _                           -> "fallback"
       ```

       {{
       docCallout
         (Some wordle.utils.emojis.hint)
         {{
         If you find that you're mixing up `:+` and `+:` in your pattern
         matches, remember that the colon `:` goes on the side of the
         COL-lection.
         }} }}

       However, let's say you wanted to pattern match on the first 2 elements
       of a given list. It might be __tempting__ to do a multi-item pattern
       match with successive `+:` {{ docTooltip {{ operators }} operators }},
       but recall that {{
       docTooltip {{ function application }} glossary.functionApplication }}
       for operators always starts at the leftmost sub-expression.

       🙅🏻‍♀️ This will not work:

       ``` unison
       match ["a","b","c"] with
         first +: second +: remainder -> "nope"
         _ -> "empty list"
       ```

       `first +: second` is expecting `second` to be a type {type List}, but
       what we're trying to express is that it's the unwrapped second element.
       Instead, if you want to pattern match on a particular list segment
       length or list segment values, you can use the `[_]` list constructor
       syntax.

       Our example above can be rewritten:

       ```
       match ["a", "b", "c"] with
         [first, second] ++ remainder -> first ++ " yes!"
         _                            -> "fallback"
       ```

       Or if we don't care about binding the list elements to variables, we can
       use underscores to pattern match on any list that has exactly `[_]`
       elements:

       ```
       match ["a", "b", "c"] with
         [_, _] ++ remainder -> "list has at least two elements"
         _                   -> "fallback"
       ```
  }}

docs.fundamentals.controlFlow.patternMatching._nav : Doc
docs.fundamentals.controlFlow.patternMatching._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Pattern matching on data types]({{
      (docLink (docEmbedTermLink do patternMatching2))
      }})

      {{ wordle.utils.emojis.learnMore }}
      [Read more on pattern matching in the Unison language guide]({matchExpressionsAndPatternMatching})
    }} }}
  }}

docs.fundamentals.controlFlow.patternMatching2 : Doc
docs.fundamentals.controlFlow.patternMatching2 =
  {{
  # Pattern matching part 2

    {{ _dataTypesPatternMatching }}

    {{ _asPatterns }}

    {{ patternMatching.listPatterns }}

    {{ patternMatching2._nav }}
  }}

docs.fundamentals.controlFlow.patternMatching2._nav : Doc
docs.fundamentals.controlFlow.patternMatching2._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Defining your own Unison types](../dataTypes/uniqueAndStructuralTypes)

      {{ wordle.utils.emojis.learnMore }}
      [Pattern matching in the language guide]({matchExpressionsAndPatternMatching})
    }} }}
  }}

docs.fundamentals.controlFlow.tailCallSumm : Doc
docs.fundamentals.controlFlow.tailCallSumm =
  {{
  Unison supports tail call elimination. Functions in tail call position
  (including mutually recursive functions) are evaluated without growing the
  stack.
  }}

docs.fundamentals.controlFlow._asPatterns : Doc
docs.fundamentals.controlFlow._asPatterns =
  use Either Left Right
  {{
  # As-patterns (the @ in a pattern match)

    Let's say you want to pattern match on the {Right} side of an
    {type Either}, inspect its content, and use the entire {Left} value in an
    expression to the right of your arrow in a match case. With our current
    tools you could do something like this:

    ```
    myMatch : Either Text Text -> Either Text Text
    myMatch = cases
      Right _ -> Right "I found a Right"
      Left b  | b === "oh no" -> Left b
      Left _  -> Left "I found a Left"
    myMatch (Left "oh no")
    ```

    Reconstructing `` Left b `` is fairly simple for a small data type like
    {type Either}, but imagine a data type called {type Hydra} where you need
    multiple values to form an instance of the type.

        @source{type Hydra}

    Reconstructing the {Heads} value on the right hand side of the arrows from
    variables in the pattern match could become onerous.

    ``` unison
    slayHydra : Nat -> Hydra -> Optional Hydra
    slayHydra attack = cases
      Heads h1 h2 immortal h4 h5
        | attack Nat.!= immortal -> Some (Heads h1 h2 immortal h4 h5)
        | attack Nat.== immortal -> None
    ```

    This is where the "as-pattern" or `@` symbol in a pattern match can be
    useful. Rewriting the function above to use an as-pattern looks like:

        @source{slayHydra}

    The as-pattern binds a variable name to some part of the element being
    pattern matched on. Its form is `variableName@someElement`. That variable
    can then be used to the right of the arrow in your pattern match.
  }}

docs.fundamentals.controlFlow._asPatterns.slayHydra :
  Nat -> Hydra -> Optional Hydra
docs.fundamentals.controlFlow._asPatterns.slayHydra attack = cases
  hydra@(Heads h1 h2 immortal h4 h5) | attack Nat.!= immortal -> Some hydra
  Heads h1 h2 immortal h4 h5         | attack Nat.== immortal -> Optional.None
  Heads _ _ _ _ _                    -> Optional.None

docs.fundamentals.controlFlow._casesSyntax : Doc
docs.fundamentals.controlFlow._casesSyntax =
  {{
  # Cases syntax

    When writing a pattern match where the last value or set of values are
    being compared against successive cases, or "scrutinized", you can use the
    `cases` shorthand rather than writing out the full match statement.

    So a match expression with one argument might look like this when fully
    written out:

    ``` unison
    myMatch : Nat -> Text
    myMatch nat = match nat with
      n | n < 3 -> "small number"
      _ -> "big number"
    ```

    But it can also be expressed as:

    ``` unison
    myMatch : Nat -> Text
    myMatch = cases
      n | n < 3 -> "small number"
      _ -> "big number"
    ```

    At first glance it might appear that there is no argument to the `myMatch`
    function, but when we see the `cases` keyword, we know that there is at
    least one inferred argument being tested against the cases in our match
    expression.

    Two or more arguments can also be scrutinized with the `cases` syntax, but
    when multiple arguments are being tested, they are __comma separated__ in
    the case statements.

    ``` unison
    twoCases : Nat -> Nat -> Text
    twoCases = cases
      n1, n2 | n1 === n2 -> "same value"
      _, _ -> "different values"
    ```
  }}

docs.fundamentals.controlFlow._casesSyntax.myMatch : Nat -> Text
docs.fundamentals.controlFlow._casesSyntax.myMatch = cases
  n
    | n Nat.< 3 -> "small number"
    | otherwise -> "big number"

docs.fundamentals.controlFlow._casesSyntax.twoCases : Nat -> Nat -> Text
docs.fundamentals.controlFlow._casesSyntax.twoCases = cases
  n1, n2
    | n1 Nat.== n2 -> "same value"
    | otherwise    -> "different values"

docs.fundamentals.controlFlow._datatypesEither : Doc
docs.fundamentals.controlFlow._datatypesEither =
  use Either Left Right
  {{
  # Your first Unison data type

    Let's take a look at a pre-made data type, {type Either}. Either is used to
    represent situations in which a value can be one type or another.

    In Unison, Either is defined in the base library like this (we'll break
    down what these parts mean shortly):

        @source{type Either}

    {{
    docAside
      {{
      {{ reminder }} The UCM command for seeing the source code of a Unison
      term or type is [`view`]({ucmCommands.view}) as in `view Either`
      }} }} The keyword `type` indicates that we're looking at a type
    definition, as opposed to a
    [term definition]({{ docLink (docEmbedTermLink do terms) }}). Unison types
    are given a modifier of `structural` or `unique`—structural here means that
    types which share Either's structure are treated as identical to Either and
    therefore are interchangeable in Unison code, even if they're given a
    different name. {type Either} is the name we've given to our type, and the
    two letters `a` and `b` are type parameters. {{ _typeParamConvention }} You
    can think of `a` and `b` as placeholders which represent any type. When we
    construct a value of type Either, we "fill in" the placeholder.

    On the right hand side of the equals are the __data constructors__ of the
    type. We use data constructors to create a value of the type being
    described, so to create an {type Either} we have two options: `` Left a ``
    or ``Right b``. They're separated by pipes `|`. When you see the pipe think
    "or."

    {{ docAside {{ {{ _vsOopConstructors }} }} }}

    {{
    docCallout
      (Some {{ {{ reminder }} }})
      {{
      In summary: you can read the line     @source{type Either} as
      {type Either} is a {Left} containing an `a` or a {Right} containing a
      `b`. Unison data types are often composed by slotting other Unison types
      into one data constructor or another. Sometimes those types are not
      specified, like for `a` and `b` in {type Either}, and sometimes they're
      pinned down to a concrete type.
      }} }}

    We'll return to
    [explore more in-depth about data types](../dataTypes/uniqueAndStructuralTypes)
    later.
  }}

docs.fundamentals.controlFlow._dataTypesPatternMatching : Doc
docs.fundamentals.controlFlow._dataTypesPatternMatching =
  {{
  # Intro to Unison datatypes and pattern matching

    We've been applying pattern matching to {{
    docTooltip {{ literal }} glossary.literal }} values at this point. But
    pattern matching is frequently done on more complicated types, where we can
    use the cases of the pattern to decompose the data type into its
    constituent parts. Here we'll talk about Unison data types in the context
    of pattern matching.

    {{ _datatypesEither }}

    ## Decomposing data types with pattern matching

       With our whirlwind intro to the parts of a data type behind us, we'll
       return to how to pattern match on the different data constructors of a
       given type.

       Let's say we wanted a function to tell us which utensils should be
       paired with a lunch order. We'll use the following types:

           @source{type Lunch}     @source{type Utensil}

       Our function should take in a type {type Lunch} as an argument and
       return a {type List} of type {type Utensil}. We know that there are only
       three ways to make a value of type {type Lunch}, so we match on the data
       constructor name followed by the number of fields that the constructor
       contains.

       ``` unison
       placeSetting : Lunch -> [Utensil]
       placeSetting = cases
         Soup soupName   -> [Spoon]
         Salad saladName -> [Fork, Knife]
         _               -> [Spoon, Fork, Knife]
       ```

       Pattern matching on the data constructors of the type enables us to
       inspect and make use of the values they contain. In the example above we
       don't end up using the variables that are bound to the fields in the
       data, so we could have also represented them as underscores, like
       ``Soup _ -> [Spoon]``, but we can imagine a function where that would
       become important: {{ docAside dataAccess }}

       ``` unison
       placeSetting : Lunch -> [Utensil]
       placeSetting = cases
         Soup "Hearty Chunky Soup"   -> [Fork, Spoon]
         Soup _                      -> [Spoon]
         Salad _                     -> [Fork, Knife]
         Mystery mysteryMeal isAlive ->
           use Text ==
           if (mysteryMeal == "Giant Squid") && isAlive then [Knife]
           else [Spoon, Fork, Knife]
       ```

       The first case is an example of how to combine a literal pattern match
       with a data constructor, and the second and third cases are an example
       of how to match on any value that {Lunch.Soup} or {Salad} data
       constructor might enclose. Our last case extracts the values being
       provided to the {Mystery} data constructor as
       [pattern match variables]({_variablesGuards}) for use on the right.

       Note, the underscores above represent the fact that the value being
       provided to the data constructor isn't important for the logic of our
       expression on the right. The underscores do, however, need to be
       present. Every parameter to the data constructor needs to be represented
       in the pattern either by a variable, as in our {Mystery} case, or by an
       underscore, otherwise Unison will return a pattern {{
       docTooltip {{ arity }} glossary.arity }} mismatch error.
  }}

docs.fundamentals.controlFlow._dataTypesPatternMatching.placeSetting :
  Lunch -> [Utensil]
docs.fundamentals.controlFlow._dataTypesPatternMatching.placeSetting = cases
  Lunch.Soup "Hearty Chunky Soup" -> [Fork, Spoon]
  Lunch.Soup _ -> [Spoon]
  Salad _ -> [Fork, Knife]
  Mystery mysteryMeal isAlive ->
    if mysteryMeal Text.== "Giant Squid" && isAlive then [Knife]
    else [Spoon, Fork, Knife]

docs.fundamentals.controlFlow._ifElseBlocks._nav : Doc
docs.fundamentals.controlFlow._ifElseBlocks._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }} [Pattern matching in Unison](./patternMatching)

      {{ wordle.utils.emojis.learnMore }}
      [Language reference for conditional expressions]({conditionalExpressions})
    }} }}
  }}

docs.fundamentals.controlFlow._ifElseBlocksSum : Doc
docs.fundamentals.controlFlow._ifElseBlocksSum =
  {{
  Unison's syntax for conditional logic is `if true then executeThis else
              executeThat`.
  }}

docs.fundamentals.controlFlow._literalPatternMatching : Doc
docs.fundamentals.controlFlow._literalPatternMatching =
  {{
  # Pattern matching on literals

    In some circumstances you might see pattern matching being used as a
    concise chain of if / else statements.

    ``` unison
    foodUnit : Text -> Text
    foodUnit f =
      "👇 compare f with the following..."
      match f with
        "Pie"     -> "slice"
        "Coffee"  -> "cup"
        "Soup"    -> "bowl"
        "Pancake" -> "stack"
        _         -> "???"
    ```

    The first part of the pattern match syntax `match f with` identifies the
    target value that the pattern match will make its comparisons against.
    After the `with` keyword, Unison expects a series of arrow `->` separated
    cases. In the example above, the value `f` will be compared against each
    value to the left of the arrow, starting from the top. The order in which
    the cases appear is important for the pattern match because if the value of
    `f` matches something on the left, Unison will evaluate the right side of
    the arrow.

    In our example, we've provided a "catch-all" case at the end of the pattern
    match. It starts with an underscore: `` _ -> "fallback value" ``

    {{ style }} It's a common practice to provide a catch-all. The following
    code will currently typecheck, but willlikely be a type error in a future
    version of Unison:

    ``` unison
    mySoupCount : Text -> Nat
    mySoupCount name =
      "👇 no fallback value"
      match name with
        "Chicken Noodle" -> 4
        "Miso"           -> 7
        "Borscht"        -> 5
        "Chowder"        -> 5

    mySoupCount "Gazpacho"
    ```

    The error returned by the UCM reads:

    ``` ucm
    💔💥

     I've encountered a pattern match failure in function `mySoupCount` while scrutinizing:

       "Gazpacho"

     This happens when calling a function that doesn't handle all possible inputs
     I'm sorry this message doesn't have more detail about the location of the failure. My makers plan
     to fix this in a future release.
    ```
  }}

docs.fundamentals.controlFlow._summaryLoopingConstructs : Doc
docs.fundamentals.controlFlow._summaryLoopingConstructs =
  use List map
  use Nat - ==
  {{
  # Recursion conventions in Unison

    You do not need to annotate recursive functions with their return type for
    a program to typecheck.

    ``` unison
    sum listOfNats = match listOfNats with
       [] -> 0
       head +: tail -> head + (sum tail)

    sum [9,8,7,6]
    ```

    {{ tailCallSumm }}

  # Effectful recursion

    Recursive code can perform effects too. When your code performs an ability
    for some kind of computational effect, your function signature should
    include an {{ docTooltip {{ ability requirement }} abilityRequirement }} in
    curly braces in the return type of the function. See below for an example.

    ```
    loop : Nat ->{Stream Nat} ()
    loop = cases
      n
        | n == 0    -> ()
        | otherwise ->
          emit n
          loop (n - 1)
    Stream.toList do loop 10
    ```

    Many of the {{ docTooltip {{ higher-order functions }} higherOrderFunction
    }} on data types in the `base` library are already ability polymorphic. In
    the signature for {map}, @inlineSignature{map}, the `{𝕖}` symbol in the {{
    docTooltip {{ lambda }} lambda }} argument means that the transformation
    function `a -> b` can perform an effect in the process of mapping over each
    element.
  }}

docs.fundamentals.controlFlow._typeParamConvention : Doc
docs.fundamentals.controlFlow._typeParamConvention =
  {{
  Type parameters in Unison are lowercase by convention. For example:

      @source{type Box}
  }}

docs.fundamentals.controlFlow._typeParamConventionGotcha : Doc
docs.fundamentals.controlFlow._typeParamConventionGotcha = {{  }}

docs.fundamentals.controlFlow._variablesGuards : Doc
docs.fundamentals.controlFlow._variablesGuards =
  {{
  # Variables in pattern matching

    Let's say we want to save a value on the left-hand side of the case
    statements for use when evaluating the expression on the right-hand side.
    Let's do that below:

    ``` unison
    magicNumber : Nat -> Text
    magicNumber guess = match guess with
      42 -> "magic 🪄"
      n -> toText n ++ " is not the magic number. Guess again."
    ```

    Here `n` is a variable that will bind to any value of type {type Nat}. It's
    also functioning as a fallback value, and in the example above whatever
    value it has can be used to produce a desired {type Text} result.

  # Guard patterns

    Guard patterns are a way we can build further conditions for the match
    expression. They can reference variables in the case statement to further
    refine if the right side of the arrow should be run. A guard pattern is
    started with pipe character `|` where the right of the `|` needs to return
    something of type {type Boolean}. If the value to the right side of the
    pipe `|` is ``true``, the block on the right of the arrow will be executed.

    ``` unison
    matchNum : Nat -> Text
    matchNum num = match num with
      oneTwo | (oneTwo === 1) || (oneTwo === 2) -> "one or two"
      threeFour | (threeFour === 3) || (threeFour === 4) -> "three or four"
      fiveSix | (fiveSix === 5) || (fiveSix === 6) -> "five or six"
      _ -> "no match"
    ```

    We've combined variables with guard patterns and boolean operators in our
    pattern match statement. The variable `oneTwo` without the guard pattern
    would match anything of type {type Nat}, but we can specify in the pattern
    guard that the variable `oneTwo` should either be the {{
    docTooltip {{ literal }} {{ {{ glossary.literal }} }} }} value `` 1 `` or
    ``2``.

    You might see multiple guard patterns being used for the same match
    expression case. For example:

    {{
    docAside
      {{
      This syntax is commonly chosen by the Unison pretty printer when you've
      saved a pattern match expression to your codebase and re-opened it for
      editing.
      }} }}

    ``` unison
    myMatch : Nat -> Text
    myMatch num = match num with
      n
        | n < 3 -> "small number"
        | n > 100 -> "big number"
        | otherwise -> "medium number"
    ```

    Each pipe `|` is followed by a boolean expression and an expression to
    execute if the boolean is ``true``. The last case `| otherwise -> ` in this
    syntax is a pass-through to catch all other cases. In the context of this
    pattern match form, `otherwise` simply means ``true``.
  }}

docs.fundamentals.controlFlow._vsOopConstructors : Doc
docs.fundamentals.controlFlow._vsOopConstructors =
  use Color RGB
  {{
  {{ wordle.utils.emojis.hint }} If you're coming from the land of Object
  Oriented Programming, you might be familiar with the notion of a
  "constructor" as a special way to create an instance of an object. A good
  mental model for what a Unison data constructor is doing is that it is a
  **function** whose return type is the data type on the left.

  You might think of the data constructor ``RGB``:

      @source{type controlFlow.Color}

  as a function called `Color.RGB` that takes three {type Nat} arguments to
  produce a value of type `Color`.

      @signature{RGB}
  }}

docs.fundamentals.dataTypes.recordTypes : Doc
docs.fundamentals.dataTypes.recordTypes =
  use Nat +
  use Volunteer example
  use Volunteer.age modify set
  {{
  # Record types

    If we want to give the fields in a {{
    docTooltip {{ data constructor }} {{ {{ dataConstructor }} }} }} their own
    names, we can use Unison's syntax for record types. When you define a
    record type, Unison will automatically generate functions which allow you
    to set a value of the data type, to get a value from the data type, and
    modify a value in the data type.

    Let's add a record type to model the idea of a volunteer.

    ``` unison
    unique type Volunteer
      = { preferredName : Text,
        age : Nat,
        desiredStartDate : Text,
        endDate : Optional Text,
        daysAvailable : Set DaysOfWeek }
    ```

    Record types are started with the name of the type, but instead of a data
    constructor, you'll see open curly braces to the right of the equals sign.
    Each field name is named and given a type in a comma-separated list. Record
    types are supported for types which have a __single__ data constructor.
    Unison creates a data constructor for you with the same name as the overall
    type.

    Imagine if we had to remember what each field meant for {Volunteer} without
    these names! 😵 Record types can be useful when the data constructor for a
    type gets exceptionally long, and therefore component parts would benefit
    from receiving a human readable name.

    Upon saving the scratch.u file, we can see that Unison has derived a series
    of functions for each of our named fields.

    ``` ucm
    ⍟ These new definitions are ok to `add`:

          type DaysOfWeek
          type Volunteer
          Volunteer.age                     : Volunteer -> Nat
          Volunteer.age.modify              : (Nat ->{g} Nat) -> Volunteer ->{g} Volunteer
          Volunteer.age.set                 : Nat -> Volunteer -> Volunteer
          Volunteer.daysAvailable           : Volunteer -> Set DaysOfWeek
          Volunteer.daysAvailable.modify    : (Set DaysOfWeek ->{g} Set DaysOfWeek)
                                              -> Volunteer
                                              ->{g} Volunteer
          Volunteer.daysAvailable.set       : Set DaysOfWeek -> Volunteer -> Volunteer
          Volunteer.desiredStartDate        : Volunteer -> Text
          Volunteer.desiredStartDate.modify : (Text ->{g} Text) -> Volunteer ->{g} Volunteer
          Volunteer.desiredStartDate.set    : Text -> Volunteer -> Volunteer
          Volunteer.endDate                 : Volunteer -> Optional Text
          Volunteer.endDate.modify          : (Optional Text ->{g} Optional Text)
                                              -> Volunteer
                                              ->{g} Volunteer
          Volunteer.endDate.set             : Optional Text -> Volunteer -> Volunteer
          Volunteer.preferredName           : Volunteer -> Text
          Volunteer.preferredName.modify    : (Text ->{g} Text) -> Volunteer ->{g} Volunteer
          Volunteer.preferredName.set       : Text -> Volunteer -> Volunteer
    ```

    Creating a value for a {type Volunteer} doesn't involve any additional
    overhead. There's no requirement for mentioning the field names.

    ```
    example
    ```

    But with these programmatically generated methods, we can easily change the
    value of one field:

    ```
    set 500 example
    ```

    Here we've simply overwritten the original value for our example's `age`
    field. The first argument to {set} is your desired value of the field and
    the second argument is the original {type Volunteer}. The return type of
    our `set` function is {type Volunteer}, and remember, Unison values are
    immutable, so this is a copy of the original {type Volunteer}.

    If we didn't have a specific value to set, we can provide a function which
    describes __how__ one field should be transformed using the `modify`
    function which is generated for each field in a record.

    ```
    modify (age -> age + 1) example
    ```

    Here we're using the {modify} function created for the record's `age.`
    Checkout the signature @inlineSignature{modify} and note that you couldn't,
    for example, use the modify function to change from an `age` expressed in
    terms of {type Nat} to an age expressed in terms of some type representing
    Geologic Time. 🦕

    Using the record type syntax we can also streamline the process of getting
    the value of one field. Here's what getting the value for our example's age
    looks like using the {Volunteer.age} function that Unison provides for us.

    ```
    Volunteer.age example
    ```

    Compare this to having to pattern match on the value to get a value:

    ``` unison
    getAge : Volunteer -> Nat
    getAge = cases Volunteer _ age _ _ _ -> age
    getAge example
    ```

    Of course, you can still pattern match on a record type--you do not need to
    mention the field names in your pattern match cases--those conventions
    don't change.

    {{
    docCallout
      (Some {{ 🌻 }})
      {{
      Summary:

      * Record types allow you to define a type with individually named field
        names
      * Record types are for types with a single data constructor
      * Record types automatically generate functions which get, set, and
        modify values for the record
      }} }}

    {{ recordTypes._nav }}
  }}

docs.fundamentals.dataTypes.recordTypes._nav : Doc
docs.fundamentals.dataTypes.recordTypes._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }} [Learn about Abilities in Unison]({abilities.index})

      {{ wordle.utils.emojis.learnMore }}
      [Read more about record types in the language reference]({recordType})
    }} }}
  }}

docs.fundamentals.dataTypes.uniqueAndStructuralTypes : Doc
docs.fundamentals.dataTypes.uniqueAndStructuralTypes =
  {{
  # Defining your own Unison data types

    We've seen a whirlwind introduction to Unison data types before, but here
    we'll equip you with the information you need to create your own types.
    We'll talk about the `structural` and `unique` keywords, and learn about
    Unison's syntax for defining types with named fields.

    Let's say we are modeling a local library--we might want to start by
    representing a couple of book genre options. In a scratch.u file, we'll
    write something like:

    ``` unison
    type Genre
      = Fiction
      | Poetry
      | CookBooks
      | Science
      | Biography
    ```

    Let's break down the anatomy of this code. The `type` keyword tells the UCM
    that we're creating a new type as opposed to a
    [term definition]({{ docLink (docEmbedTermLink do terms) }}). A type
    definition is `unique` or "identified by its name" by default, but it can
    accept a modifier of `structural` or an optional modifier of `unique`
    explicitly. This keyword tells Unison whether the type is unique by its
    name or by its structure (more on that in a bit). The values after the
    equals sign are known as
    {{ docTooltip {{ data constructors }} dataConstructor }}. Each data
    constructor is separated by a pipe `|` which means that the {type Genre}
    type can be {Poetry} or {Fiction} or {CookBooks} etc.

    {{ docAside _vsOopConstructors }}

    The data constructors for {type Genre} above don't have any arguments, so
    they don't contain data beyond tagging something as being one thing or
    another at the moment.

    {{
    docCallout
      (Some style)
      {{
      By convention, the UCM will put the data constructors for a type in a
      namespace which shares the type name; so the data constructors for the
      type {type Genre} can be referenced like `Genre.Poetry` or
      `Genre.CookBooks`
      }} }}

    ## The meaning of "unique"

       We indicated earlier that {type Genre} is `unique` by its name. By
       applying the modifier `unique` we've indicated to the type system that
       the name of this type is __semantically__ important. An example of a
       structurally identical type might be a {type Weekday} (below):

       ``` unison
       structural type Weekday = Mon | Tues | Wed | Thurs | Fri
       ```

       Neither {type Weekday} nor {type Genre} accept type parameters to
       construct a value of the type, and both have five data constructors
       which each have zero arguments, but obviously these model very different
       domains. Because we've indicated that the type {type Genre} is unique,
       it cannot be substituted by a {type Weekday} or anything else with its
       same structure.

    ## What happens if we create identical structural types?

       Say we want to represent an author type with a name, a birth year, and a
       {type Set} of {type Genre} that they might might be filed under. Let's
       try to make this one a `structural` type.

       ``` unison
       structural type Author = Author Text Nat (Set Genre)
       ```

       In this case, the {type struct.Author} type has a single data
       constructor which happens to be called "Author." Following the data
       constructor name, we specify the __types__ that are needed to make an
       author: {type Text}, {type Nat}, and a {type Set} of {type Genre}. Note
       that calling the data constructor here the same name as the type is just
       a convention, we could have given the type a differently named data
       constructor altogether.

       Creating an instance of this {type struct.Author} type looks like:

       ``` unison
       authorExample : Author
       authorExample =
         genres = Set.fromList [CookBooks]
         Author "Julia Child" 1912 genres
       ```

       We'd also like to model the idea of a book with a title, a publication
       year, and a set of genres that might describe it.

       ``` unison
       structural type Book = Book Text Nat (Set Genre)
       ```

       Great, let's write a function which tries to find a book for a given
       author. In our scratch file we might write something like:

       ``` unison
       bookFinder : Author -> [(Author, Book)]-> Optional Book
       bookFinder author list =
         map = Map.fromList list
         get author map
       ```

       When we save our scratch file we see the following output:

       ``` ucm
       ⍟ These new definitions are ok to `add`:

         type Genre
         type Author
         type Book
         bookFinder : Author -> [(Author, Author)] -> Optional Author
       ```

       Our types show up as expected, there's a `Genre`, an `Author`, and a
       `Book` that can be added, but taking a closer look at our signature for
       {bookFinder} you'll notice that the types that we wrote in our function
       definition earlier seem to have been changed! 🤔 This is because the
       types as we've defined them are equivalent to the Unison type system.
       Both `Book` and `Author` have data constructors which take in a
       {type Text}, a {type Nat}, and a {type Set} of the same things. These
       two types are freely interchangeable in Unison programs. This is a
       situation in which we might want to make both types unique by their
       **name** to avoid any mix-ups. While `Book` and `Author` are
       structurally identical, it matters that the types mean different things.

       ``` unison
       type Author = Author Text Nat
       ```

       ``` unison
       type Book = Author Text Nat
       ```

       Now our UCM output reflects our named types.

       ``` ucm
       ⍟ These new definitions are ok to `add`:

         bookFinder : Author -> [(Author, Book)]-> Optional Book
       ```

  # Why use structural types?

    It might seem like structural types introduce confusion when modeling a
    domain, after all, the role of a type system is to help enforce what types
    are compatible with each other. Consider the following: you're a library
    developer and you introduce a structural type called `Maybe`. Maybe is
    fairly abstract in nature, but you intend to use it to capture when a thing
    "might be" present or not. (I know, suspend your disbelief here.) The
    things that a "Maybe" contains are not specific, so you've used the type
    parameters `t` to define it.

    ``` unison
    structural type Maybe t =  Just t | Nothing
    ```

    When you save your `scratch.u` file to add `Maybe` to the codebase, you
    discover that it's structurally identical to the {type Optional} data type
    in `base`.

    ``` ucm
    ⍟ These new definitions are ok to `add`:

      structural type Maybe t
        (also named Optional)
    ```

    You've got a suite of helpful functions to work with already! The functions
    in your program which were written to return a `Maybe` can be manipulated
    by the functions for {type Optional}.

    {{
    docAside
      {{
      Abilities can also be either structural or unique. Many of the abilities
      that you'll find in base are structural abilities.
      }} }}

    Structural types can be useful when writing code with fewer domain-specific
    requirements. There are some cases in which using a structural type might
    reveal that you don't need to reinvent the wheel. One rule of thumb to help
    decide whether to make a type structural or not is to think if the type
    you're defining has additional semantics or expected behavior beyond the
    information that's given in the type signature.

    {{
    docCallout
      (Some {{ 🌻 }})
      {{
      Summary:

      * Define a type with the `type` keyword `type Foo = Bar Nat | Baz Text`
      * A type is "unique" by default
      * Use the `structural` keyword to make a type which is only known by its
        structure, `structural type Foo = Foo Nat` is the same as
        `structural type Bar = Bar Nat`
      * Structural types are considered equivalent when their {{
        (docTooltip {{ data constructors }} dataConstructor) }} and parameters
        are structurally identical.
      }} }}

    {{ uniqueAndStructuralTypes._nav }}
  }}

docs.fundamentals.dataTypes.uniqueAndStructuralTypes._nav : Doc
docs.fundamentals.dataTypes.uniqueAndStructuralTypes._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # What to read next

      {{ suggested }} [Record types]({recordTypes})

      {{ wordle.utils.emojis.learnMore }}
      [Language reference for Unison's type system]({types})
    }} }}
  }}

docs.fundamentals.dataTypes._recordTypes.Volunteer.age : Volunteer -> Nat
docs.fundamentals.dataTypes._recordTypes.Volunteer.age = cases
  Volunteer _ age _ _ _ -> age

docs.fundamentals.dataTypes._recordTypes.Volunteer.age.modify :
  (Nat ->{g} Nat) -> Volunteer ->{g} Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.age.modify f = cases
  Volunteer preferredName age desiredStartDate endDate daysAvailable ->
    Volunteer preferredName (f age) desiredStartDate endDate daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.age.set :
  Nat -> Volunteer -> Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.age.set age1 = cases
  Volunteer preferredName _ desiredStartDate endDate daysAvailable ->
    Volunteer preferredName age1 desiredStartDate endDate daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.daysAvailable :
  Volunteer -> Set DaysOfWeek
docs.fundamentals.dataTypes._recordTypes.Volunteer.daysAvailable = cases
  Volunteer _ _ _ _ daysAvailable -> daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.daysAvailable.modify :
  (Set DaysOfWeek ->{g} Set DaysOfWeek) -> Volunteer ->{g} Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.daysAvailable.modify f = cases
  Volunteer preferredName age desiredStartDate endDate daysAvailable ->
    Volunteer preferredName age desiredStartDate endDate (f daysAvailable)

docs.fundamentals.dataTypes._recordTypes.Volunteer.daysAvailable.set :
  Set DaysOfWeek -> Volunteer -> Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.daysAvailable.set
  daysAvailable1 = cases
  Volunteer preferredName age desiredStartDate endDate _ ->
    Volunteer preferredName age desiredStartDate endDate daysAvailable1

docs.fundamentals.dataTypes._recordTypes.Volunteer.desiredStartDate :
  Volunteer -> Text
docs.fundamentals.dataTypes._recordTypes.Volunteer.desiredStartDate = cases
  Volunteer _ _ desiredStartDate _ _ -> desiredStartDate

docs.fundamentals.dataTypes._recordTypes.Volunteer.desiredStartDate.modify :
  (Text ->{g} Text) -> Volunteer ->{g} Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.desiredStartDate.modify f = cases
  Volunteer preferredName age desiredStartDate endDate daysAvailable ->
    Volunteer preferredName age (f desiredStartDate) endDate daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.desiredStartDate.set :
  Text -> Volunteer -> Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.desiredStartDate.set
  desiredStartDate1 = cases
  Volunteer preferredName age _ endDate daysAvailable ->
    Volunteer preferredName age desiredStartDate1 endDate daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.endDate :
  Volunteer -> Optional Text
docs.fundamentals.dataTypes._recordTypes.Volunteer.endDate = cases
  Volunteer _ _ _ endDate _ -> endDate

docs.fundamentals.dataTypes._recordTypes.Volunteer.endDate.modify :
  (Optional Text ->{g} Optional Text) -> Volunteer ->{g} Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.endDate.modify f = cases
  Volunteer preferredName age desiredStartDate endDate daysAvailable ->
    Volunteer preferredName age desiredStartDate (f endDate) daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.endDate.set :
  Optional Text -> Volunteer -> Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.endDate.set endDate1 = cases
  Volunteer preferredName age desiredStartDate _ daysAvailable ->
    Volunteer preferredName age desiredStartDate endDate1 daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.example : Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.example =
  Volunteer "Carl Sagan" 40 "July 24th, 1989" Optional.None avail

docs.fundamentals.dataTypes._recordTypes.Volunteer.example.avail :
  Set DaysOfWeek
docs.fundamentals.dataTypes._recordTypes.Volunteer.example.avail =
  Set.fromList [DaysOfWeek.Mon, DaysOfWeek.Tues, DaysOfWeek.Wed]

docs.fundamentals.dataTypes._recordTypes.Volunteer.preferredName :
  Volunteer -> Text
docs.fundamentals.dataTypes._recordTypes.Volunteer.preferredName = cases
  Volunteer preferredName _ _ _ _ -> preferredName

docs.fundamentals.dataTypes._recordTypes.Volunteer.preferredName.modify :
  (Text ->{g} Text) -> Volunteer ->{g} Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.preferredName.modify f = cases
  Volunteer preferredName age desiredStartDate endDate daysAvailable ->
    Volunteer (f preferredName) age desiredStartDate endDate daysAvailable

docs.fundamentals.dataTypes._recordTypes.Volunteer.preferredName.set :
  Text -> Volunteer -> Volunteer
docs.fundamentals.dataTypes._recordTypes.Volunteer.preferredName.set
  preferredName1 = cases
  Volunteer _ age desiredStartDate endDate daysAvailable ->
    Volunteer preferredName1 age desiredStartDate endDate daysAvailable

docs.fundamentals.dataTypes._uniqueAndStructuralTypes.bookExample :
  struct.Author
docs.fundamentals.dataTypes._uniqueAndStructuralTypes.bookExample =
  struct.Author.Author "Mrs Dalloway" 1925 (Set.singleton Fiction)

docs.fundamentals.dataTypes._uniqueAndStructuralTypes.bookFinder :
  struct.Author -> [(struct.Author, struct.Author)] -> Optional struct.Author
docs.fundamentals.dataTypes._uniqueAndStructuralTypes.bookFinder book list =
  map = Map.fromList list
  Map.get book map

docs.fundamentals.dataTypes._uniqueAndStructuralTypes.struct.authorExample :
  struct.Author
docs.fundamentals.dataTypes._uniqueAndStructuralTypes.struct.authorExample =
  genres = jsonschema.lib.base.data.Set.fromList [CookBooks]
  struct.Author.Author "Julia Child" 1912 genres

docs.fundamentals.valuesAndFunctions.commonCollectionTypes : Doc
docs.fundamentals.valuesAndFunctions.commonCollectionTypes =
  {{
  # Common collection types

    Unison provides a variety of data types for managing collections of values.
    We'll show the basics of how to create instances of common collection types
    here.

    ## Lists

       One of the common things you'll be doing as a Unison programmer is
       managing ordered collections of one type or another. One of Unison's
       native data structures for this is {type List}, which we can create
       between square brackets.

       ``` unison
       desserts : [Text]
       desserts = ["Eclair", "Peach cobbler", "Ice cream"]
       ```

       Lists can only contain values of one type at a time, and are
       {{ docTooltip {{ eagerly evaluated }} eager }}.

       An empty list is simply represented `` [] `` or with {List.empty}.

       For the curious, the documentation for {type List} describes the
       underlying data structure and details many of the common operations you
       might perform with it. {{
       docAside
         {{
         Looking for information about how to pattern match on {type List}
         values?
         [Check out this document.]({{
         (docLink (docEmbedTermLink do patternMatching.listPatterns))
         }})
         }} }}

    ## Maps

       The {type Map} type is Unison's way of mapping unique keys to values.

       You can create a map with a single object with `` Map.singleton 1 "a" ``
       where `` 1 `` is the key and `` "a" `` is the value associated with that
       key.

       Currently Unison does not have special {type Map} construction syntax so
       one easy way to create a multi-item map is from a {type List} of tuples

       ```
       Map.fromList [(1, "a"), (2, "b"), (3, "c")]
       ```

       What's printed above for a {type Map} might look more complicated than
       it really is. {internal.Bin} and {internal.Tip} are just the {{
       docTooltip {{ data constructors }} dataConstructor }} for {type Map}.
       You'll likely be working with Maps through functions in the base library
       instead of dealing with these terms directly. Check out a few {type Map}
       manipulation functions with `find data.Map` in the UCM.

       Issue the {{ docTooltip {{ `docs Map` }} ucmCommands.docs }} command in
       the UCM to read the {type Map} documentation itself.

    ## Sets

       You can create a {type Set} from a list of elements with the
       {Set.fromList} constructor

       ```
       Set.fromList ["🍎", "🍎", "🍊", "🍐", "🍋", "🍊"] |> Set.toList
       ```

       Creating a {type Set} value enables efficient functions like
       {Set.contains} and {Set.union} that you might be familiar with from
       other languages.

       You can explore these types and more collection apis
       [in the `base` library](https://share.unison-lang.org/@unison/base).

       {{ commonCollectionTypes._nav }}
  }}

docs.fundamentals.valuesAndFunctions.commonCollectionTypes._nav : Doc
docs.fundamentals.valuesAndFunctions.commonCollectionTypes._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Defining Unison functions]({{
      (docLink (docEmbedTermLink do functions))
      }})

      {{ wordle.utils.emojis.learnMore }}
      [More on Unison lists]({jsonschema.lib.base.data.List.doc})
    }} }}
  }}

docs.fundamentals.valuesAndFunctions.definingOperators : Doc
docs.fundamentals.valuesAndFunctions.definingOperators =
  use Nat *
  {{
  # Defining operators

    Operators are functions that take two arguments and are called with the
    name of the function between its arguments, as in ``4 * 3``. We call this
    kind of syntax, "infix notation". You can write your own operators in
    Unison with a few special syntax conventions.

    Operator names in Unison can only be comprised of the characters
    `!$%^&*-=+<>~\\/|:`. So `==>` is a valid operator name but `=hi!>` is not.

    You can wrap your operator in parenthesis followed by two arguments to
    define it.

    ``` unison
    (^) x y = Nat.pow x y
    ```

    Or you can define the operator with the symbols between its arguments:

    ``` unison
    x ^ y = Nat.pow x y
    ```

    Without the parenthesis or infix definition, the UCM would fail to parse
    `^` as a valid function definition.

    Calling these functions can be done with the infix notation, `2 ^ 3`, or
    with the regular function application syntax, `^ 2 3`.

    You might want your operator to be prefixed with a namespace so it's
    located in a specific place in your codebase. Prepend the namespace inside
    the parentheses:

    ``` unison
    (aNamespace.^) x y = Nat.pow x y
    ```

    Or add it in between the arguments:

    ``` unison
    x aNamespace.^ y = Nat.pow x y
    ```

    {{ definingOperators._nav }}
  }}

(docs.fundamentals.valuesAndFunctions.definingOperators.^) : Nat -> Nat -> Nat
x docs.fundamentals.valuesAndFunctions.definingOperators.^ y = Nat.pow x y

docs.fundamentals.valuesAndFunctions.definingOperators._nav : Doc
docs.fundamentals.valuesAndFunctions.definingOperators._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Special operators for function application]({{
      (docLink (docEmbedTermLink do functionApplicationOperators))
      }})

      {{ wordle.utils.emojis.learnMore }}
      [Language reference for defining operators]({operatorDefinitions})
    }} }}
  }}

docs.fundamentals.valuesAndFunctions.delayedComputations : Doc
docs.fundamentals.valuesAndFunctions.delayedComputations =
  {{
  # Delayed computations

    {{ docCallout (Some {{ 📒 }}) tldr }}

    Values in Unison are not, by default, lazily evaluated. But sometimes, you
    may want to delay a value or calculation until it's actually needed.

    For example the term `` longText `` in the following snippet is evaluated
    strictly:

    ``` unison
    longText : Text
    longText = "🐵 Imagine infinite monkeys on infinite typewriters 🙊…"
    coinflip : Boolean -> Text
    coinflip bool = if bool then longText else "Hi"
    ```

    But you might not actually need to evaluate ``longText``—there are
    circumstances where the calculation of a value might be very expensive or
    could introduce surprising behavior if run
    {{ docTooltip {{ eagerly }} eager }}.

    One way you might solve for this is to create a "thunk": a function with no
    arguments which returns the desired value when it's called.

    ``` unison
    longText : () -> Text
    longText _ = "🐵 Imagine infinite monkeys on infinite typewriters 🙊…"
    ```

    Because this is a common pattern, Unison provides the single quote,
    {{ docCode {{ ' }} }}, as syntactic sugar for representing a signature with
    the form `() -> a`.

    We can rewrite the type `() -> Text` as just {{ docCode {{ 'Text }} }}.

        @source{longText}

    Just as Unison provides syntax for representing delayed computations in a
    __type signature__, there are a few ways to delay an expression in Unison.

    {{
    docCallout
      (Some important)
      {{
      These are all valid ways to implement a function for the type
      {{ (docCode {{ 'Text }}) }}:

      * `myFunction = '"delayed with single quote"`
      * `myFunction _ = "delayed with underscore argument"`
      * `myFunction = do "delayed with do keyword"`

      All three are equivalent in meaning.
      }} }}

    When we want to run the thunk, we can call it by adding a `()` to the end
    of the function with no spaces, representing the idea: "I'm calling this
    function with zero arguments".

    ```
    longText()
    ```

    Unison also provides the `!` symbol as syntactic sugar for calling a thunk.
    The `!` is prepended to the function name.

    ``` unison
    !longText
    ```

    To review: the single quote, {{ docCode {{ ' }} }}, an underscore `_`, or
    the `do` keyword introduce a {{ docTooltip {{ thunk }} thunk }} and
    appending `()` or prepending `!` executes it.

    ## Caveat: Delayed computations with multiple arguments

       Let's say we have a function that has one argument and returns a delayed
       value of {type Text}.

       ``` unison
       coinflip : Boolean -> 'Text
       coinflip bool = do if bool then longText() else "Hi"
       ```

       We want to call `coinflip` with its argument and force the thunk to get
       a value.

       We can always write the function call with `()` to force the thunk:

       ``` unison
       coinflip true ()
       ```

       But the `!` syntax applies to the the value to its __immediate__ right,
       so we have to surround the function application for `coinflip true` in
       parentheses before prepending the `!` symbol.

       ``` unison
       !(coinflip true)
       ```

       The single quote syntax for delaying a computation has the same gotcha
       as the `!` syntax. You might think you're delaying the result of a
       function call with `'Nat.increment 5` but you're actually delaying the
       __function__, not result of calling it.

       You'll need parenthesis around the entire expression to delay the result
       of a function call with the single quote syntax.

       ``` unison
       delayed6 = '(Nat.increment 5)
       ```

       The `do` keyword delays the result of everything to its right, so you
       don't need to wrap the entire expression in parentheses.

       ``` unison
       delayed6 = do Nat.increment 5
       ```

       {{ delayedComputations._nav }}
  }}

docs.fundamentals.valuesAndFunctions.delayedComputations.coinflip :
  Boolean -> Text
docs.fundamentals.valuesAndFunctions.delayedComputations.coinflip bool =
  if bool then longText() else "Hi"

docs.fundamentals.valuesAndFunctions.delayedComputations.longText : 'Text
docs.fundamentals.valuesAndFunctions.delayedComputations.longText =
  do "🐵 Imagine infinite monkeys on infinite typewriters 🙊…"

docs.fundamentals.valuesAndFunctions.delayedComputations.tldr : Doc
docs.fundamentals.valuesAndFunctions.delayedComputations.tldr =
  {{
  **Syntax cheat-sheet**

  * Type signature for a delayed computation
    * @inlineSignature{readLine}
  * Writing a delayed computation
    * `myFunction arg = '("single quote" ++ arg)`
    * `myFunction arg _ = "underscore argument" ++ arg`
    * `myFunction arg = do "special keyword" ++ arg`
  * Calling a delayed computation
    * `myFunction "arg" ()`
    * `!(myFunction "arg")`
  }}

docs.fundamentals.valuesAndFunctions.delayedComputations._nav : Doc
docs.fundamentals.valuesAndFunctions.delayedComputations._nav =
  use wordle.utils.emojis learnMore
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }} [Control flow fundamentals]({ifThenAndElse})

      {{ learnMore }}
      [Refer to the language reference on delayed computations]({languageReference.delayedComputations})

      {{ learnMore }}
      [Abilities and top-level delayed computations]({{
      (docLink (docEmbedTermLink do faqs))
      }})
    }} }}
  }}

docs.fundamentals.valuesAndFunctions.functionApplicationOperators : Doc
docs.fundamentals.valuesAndFunctions.functionApplicationOperators =
  use wordle.utils.emojis hint
  {{
  # Operators for function application

    When working with Unison code, you might encounter the following {{
    docTooltip {{ operators }} {{ {{ operators }} }} }} which are provided by
    the {{ shareSlug "@unison/base" }} library. They are commonly used for
    manipulating the order in which a function is applied to its arguments.

    ## {{ docCode {{ a {<<} b }} }}

           @signature{<<}

       {<<}, also known as "compose," takes in two functions and returns a new
       function that applies the rightmost function to its argument and then
       applies the leftmost function to the result. In other words, it takes a
       function of type `b -> c` and a function of type `a -> b` and returns a
       function of type `a -> c`.

       {{
       docAside
         {{
         {{ hint }} If the order of function application for {<<} is tricky to
         remember, read the {<<} symbol as "after"
         }} }}

           @source{composeEx}

       Piping multiple functions together with the compose operator looks like:

           @source{composeMultiEx}

       The expression is actually parsed:

       ``` unison
       ((Boolean.not << Nat.isEven) << Text.size)
       ```

       Giving us a function that expects {Text.size}'s argument of {type Text}
       and returning the final result of applying the {Boolean.not} function.

       {{
       docCallout
         (Some {{ {{ reminder }} }})
         {{
         Repeated infix operator application is generally grouped with the
         leftmost expressions happening first. In other words, they are
         __left-associative__. Read more about this in the language guide
         section about
         [operators and function application]({syntacticPrecedenceOperatorsPrefixFunctionApplication})
         }} }}

    ## {{ docCode {{ a {>>} b }} }}

           @signature{>>}

       {>>}, also known as `andThen`, is like `compose` with the function
       argument order reversed. It takes in two functions `a->b` and `b->c` and
       returns a function from `a->c`.

           @source{andThenEx}

       Piping together multiple {>>} calls looks like:

           @source{andThenMultiEx}

    ## {{ docCode {{ a {|>} b }} }}

           @signature{|>}

       While {>>} returns a function, {|>} allows us to apply an argument to a
       function, returning the value of that function call. When using {|>}
       it's helpful to remember that the function argument should be on the
       __left hand__ side of the operator. The value of this operator might not
       be immediately obvious—after all, why use special operators for function
       application when parentheses will suffice 🤔—but you'll often see
       multiple instances of the {|>} operator chained together to form a
       complete expression. {{
       docAside
         {{
         {{ hint }} When you see {|>} think of the pipe operator in bash or
         read it as "pipe forward"
         }} }}

           @source{pipeRightEx}

       You might find that there's a greater fit between the semantic order of
       this expression and the order in which the function calls are applied
       than in the non {|>} version of this expression:

           @source{pipeEx}

       {{
       docCallout
         (Some important)
         {{
         When chaining the {|>} operator in a multi-line expression, if the
         operator is the first thing on a new line, it should be indented.

         ``` unison
         List.range 0 10
            |> map (pow 2)
            |> sum
         ```

         If the operator is the **last** thing on the line, the following
         expression does not need to be indented.

         ``` unison
         range 0 10 |>
         map (pow 2) |>
         sum
         ```
         }} }}

    ## {{ docCode {{ a {<|} b }} }}

           @signature{<|}

       When using {<|}, the function should be on the left hand side of the
       operator with the function's argument on the right hand side. You can
       read the {<|} operator as "pipe backwards." You might choose to use this
       operator when the argument to the function in question needs some
       "pre-processing" which would otherwise involve parentheses.

           @source{pipeBackwardsEx}

       Note that the {<|} operator does not change the precedence of the
       operator function calls. The leftmost sub-expression is still executed
       first. You can use parentheses to change the grouping.

       {{ functionApplicationOperators._nav }}
  }}

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.andThenEx :
  Boolean
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.andThenEx =
  (>>) Nat.isEven Boolean.not 4

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.andThenMultiEx :
  Boolean
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.andThenMultiEx =
  (>>) (Text.size >> Nat.isEven) Boolean.not "Boo"

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.composeEx :
  Nat -> Boolean
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.composeEx =
  Boolean.not << Nat.isEven

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.composeMultiEx :
  Text -> Boolean
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.composeMultiEx =
  Boolean.not << Nat.isEven << Text.size

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeBackwardsEx :
  Optional Nat
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeBackwardsEx =
  Optional.filter Nat.isEven <| pipeBackwardsEx.wrap 5

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeBackwardsEx.wrap :
  Nat -> Optional Nat
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeBackwardsEx.wrap
  n =
  Some n

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeEx :
  Boolean
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeEx =
  isSome (Optional.filter Nat.isEven (Some 5))

docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeRightEx :
  Optional Nat
docs.fundamentals.valuesAndFunctions.functionApplicationOperators.pipeRightEx =
  use Nat +
  Some 5 |> Optional.filter Nat.isEven |> Optional.map (n -> n + 1)

docs.fundamentals.valuesAndFunctions.functionApplicationOperators._nav : Doc
docs.fundamentals.valuesAndFunctions.functionApplicationOperators._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Delayed computations in Unison]({{
      (docLink (docEmbedTermLink do valuesAndFunctions.delayedComputations))
      }})

      {{ wordle.utils.emojis.learnMore }}
      [Language reference for defining operators]({operatorDefinitions})
    }} }}
  }}

docs.fundamentals.valuesAndFunctions.functions : Doc
docs.fundamentals.valuesAndFunctions.functions =
  {{
  # Functions

    Functions are also terms in Unison, so they're governed by the same
    conventions. A type signature is followed by a corresponding function
    implementation like this:

        @source{addOne}

    We know {addOne} is a function by the right arrow `->`. When we see the
    arrow in a type signature, we might read the left side in human language as
    "takes in a" and the right side of the arrow as "returns a", as in, "addOne
    is a function which takes in a Nat and returns a Nat."

    Great! But what if we need more than one argument to our function.
    {addNums} is a function which adds two numbers together to get a total.

        @source{addNums}

    In Unison type signatures, your function arguments are indicated to the
    left of each arrow `->`, and the return type of the signature is the last
    type on the right of the arrow.

    Unison function arguments are {{ docTooltip {{ curried }} curried }}, so if
    we wanted, we could express {addOne} in terms of {addNums} by providing one
    argument to the function at a time.

    {{
    docAside
      {{
      `` (addNums 1) `` is sometimes said to be “partially applied” since we
      haven’t provided all its arguments
      }} }}

    ```
    addOneCurried : Nat -> Nat
    addOneCurried count =
      plusOne : Nat -> Nat
      plusOne = addNums 1
      plusOne count
    addOneCurried 100
    ```

    Function arguments are separated by __spaces__ so calling a two argument
    function in Unison looks like:

    ```
    addNums 4 5
    ```

    When calling a multi-argument function, we can draw the implied parentheses
    for the order in which the function arguments are applied like this:

    ``` unison
    add3 : Nat -> Nat -> Nat -> Nat
    add3 a b c = a + b + c

    ((add3 1) 2) 3
    ```

    {{ docTooltip {{ Function application }} glossary.functionApplication }}
    starts with the leftmost argument--you can think of it as each argument
    being fed to successive functions from left to right. This might seem
    obvious, but later when signatures and their implementations get more
    complicated, an intuition for this becomes more important. You can always
    use parentheses to regroup expressions as needed.

    {{
    docCallout
      (Some {{ {{ reminder }} }})
      {{
      While we as developers give our functions and variables human readable
      names, to the Unison codebase, terms are not identified by their text
      based names. Unison terms are unique by their **content**. So if you
      [`add`]({ucmCommands.add}) a term definition `abc text = "123" ++ text`
      to the ucm, and later write another term definition with a different name
      `doReMi text = "123" ++ text` you'll see that the terms can be referred
      to by either name.

      ``` ucm
      ⍟ These new definitions are ok to `add`:

        doReMi : Text -> Text
          (also named abc)
      ```
      }} }}

    {{ _blockSyntax }}

    {{ _lambdaSyntax }}

    {{ functions._nav }}
  }}

docs.fundamentals.valuesAndFunctions.functions.addNums : Nat -> Nat -> Nat
docs.fundamentals.valuesAndFunctions.functions.addNums n1 n2 =
  use Nat +
  n1 + n2

docs.fundamentals.valuesAndFunctions.functions.addOne : Nat -> Nat
docs.fundamentals.valuesAndFunctions.functions.addOne n1 =
  use Nat +
  n1 + 1

docs.fundamentals.valuesAndFunctions.functions._nav : Doc
docs.fundamentals.valuesAndFunctions.functions._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Defining operators, a special kind of function]({{
      (docLink (docEmbedTermLink do definingOperators))
      }})

      {{ exercise }} [Exercises for values and functions]({valuesFunctions})

      {{ wordle.utils.emojis.learnMore }}
      [Deep dive into Unison's function application rules]({languageReference.functionApplication})
    }} }}
  }}

docs.fundamentals.valuesAndFunctions.oldFunctionsContent : Doc
docs.fundamentals.valuesAndFunctions.oldFunctionsContent =
  use List map
  {{
  Frequently, you'll want to apply a function to each element in the list, so
  let's take a look at {map}.

  {{ _polymorphismLinkAside }}

  A simplified view of the type signature of `map` is
  `map : (a -> b) -> [a] -> [b]` where `a` and `b` are type variables. This
  means that our function {map} applies to a list of some type `a`, whether
  that be a list of {type Nat}, a list of {type Text}, or a list of lists! We
  call this kind of function "polymorphic", and our type variables are really a
  short-hand way of saying, "for all the possible values that are an `a` and
  `b`, we promise our function will operate over them."

  {{
  docAside
    {{
    Many of the type signatures for polymorphic types that you'll see in the
    UCM using the [find]({ucmCommands.find}) command look a good deal more
    complicated than the one we described above for {map}. The actual signature
    for `map` is @inlineSignature{map}. The symbols in curly braces `{𝕖}`
    represent abilities, and we'll be covering those in depth later.
    }} }}

  # Higher order functions

    The first argument to [List.map]({map}) is `(a -> b)`. In Unison functions
    can be passed as arguments to other functions. A function that takes a
    function as an argument is sometimes referred to as a "higher order"
    function. Many of the functions which operate over Unison collection types
    are "higher order", taking a function argument which describes how the
    collection should be transformed.

    If we were to omit the parentheses from our {map} signature, we'd end up
    with a very odd function, which takes in an `a`, `b`, and a list of `a`,
    all as separate arguments.

    ``` unison
    brokenMap: a -> b -> [a] -> [b]
    brokenMap myA singleB listOfAs =
      todo "???"
    ```

    We can draw the implied parentheses in the __type signatures__ of a
    multi-parameter function like this:

    ``` unison
    add3 : Nat -> (Nat -> (Nat -> Nat))
    add3 a b c = a + b + c
    ```

    Notice how they all nest towards the right? The function arrow `->` is
    right-associative. That means `add3` is a function which when given a
    {type Nat} will return a __function__ of `(Nat -> (Nat -> Nat))`. So, if
    you want something different from this, like when an argument is a higher
    order function, break up your type signatures with parentheses.

    Remember when we said that {{
    docTooltip {{ function application }} glossary.functionApplication }}
    starts at the leftmost element so group your function arguments with
    parentheses? This is the corollary to that in type signatures.

    {{
    docCallout
      (Some {{ {{ reminder }} }})
      {{
      Read more about the {type List} data structure itself in
      [the documentation for the data type]({List.doc}) and check out a few
      more of the functions which operate on lists with the UCM command
      `find base.List` or by exploring the {type List} namespace in the
      [local codebase UI]({{ (docLink (docEmbedTermLink do localCodebaseUI)) }}).
      }} }}
  }}

docs.fundamentals.valuesAndFunctions.readingTypeSignatures : Doc
docs.fundamentals.valuesAndFunctions.readingTypeSignatures =
  use Function id
  use List map zipWith
  use Nat *
  {{
  # Reading Unison type signatures

    This doc is for folks who come from languages with non-Haskell like ways of
    expressing type signatures. The Haskell folks might want to skip to the
    section where we talk about [ability requirements](#ability-requirements).

    ## Basic type signatures

       We've seen basic type signatures in Unison before, when learning about
       [defining functions](./functions). As a brief review, the signature for
       `multiply` below takes two {type Nat}'s as parameters and returns a
       {type Nat}.

       ``` unison
       multiply3 : Nat -> Nat -> Nat -> Nat
       multiply3 a b c = a * b * c
       ```

       Because functions are {{ docTooltip {{ curried }} curried }} in Unison,
       the implied parentheses in the type signatures of a multi-parameter
       function are drawn like this:

       ``` unison
       multiply3 : Nat -> (Nat -> (Nat -> Nat))
       multiply3 a b c = a * b * c
       ```

       Notice how they all nest towards the right? The function arrow `->` is
       __right-associative.__ That means `multiply3` is a function, which when
       given a {type Nat}, will return a __function__ of
       `(Nat -> (Nat -> Nat))`.

       Remember when we said that {{
       docTooltip {{ function application }} glossary.functionApplication }}
       starts at the leftmost element? This is the corollary to that in type
       signatures.

       When you want to define a function with a different implied argument
       order than this, like when an argument is itself a function, use
       parentheses in your type signature.

       ```
       multiplyF : (Nat -> Nat) -> Nat -> Nat -> Nat
       multiplyF f a b = f (a * b)
       multiplyF Nat.increment 0 1
       ```

       Without the parentheses to designate the first argument as a function,
       this function would have four arguments of type {type Nat}.

    ## Type parameters

       Thus far, we've been defining functions that have concrete types like
       {type Text} or {type Bytes} as their arguments. Unison functions can
       also use type parameters to represent functions that operate over many
       different types. We call these functions polymorphic. Type variables are
       introduced in a type signature with __lower case__ letters. {{
       _polymorphismLinkAside }}

       This is the implementation of {id}:

           @source{id}

       {id} contains a type parameter `a` because __any other type__ can be
       assigned to that type variable and it will return a value of that
       specific type. `a` can be a bound to a {type Text} when called with a
       text argument, as in ``id "hi"``, or `a` can be a {type List} of
       {type Nat} when called with a value like ``id [5, 4, 3]``, etc, etc.

    ## Ability requirements

       Let's take a closer look at the signature for {map}. In addition to the
       usual arguments, `(a -> b)` and `[a]`, you'll see `{𝕖}` to the right
       side of the function arrows.

           @signature{map}

       The `{e}` is a generic ability requirement, we'll be talking about
       [abilities in depth later]({abilities.index}), but for the purpose of
       reading Unison type signatures, the `{e}` is a type variable which
       stands in for the set of possible effects a function can perform.

    ## All together now!

       Take a look at the signature for {zipWith}, we'll parse it together.

           @signature{zipWith}

       Here's some information we can glean from just the type signature:

       * {zipWith} is polymorphic, we know this from the lowercase type
         parameters
       * It takes 3 arguments, the parentheses indicate the first is a
         function, the second is a list of type `a` and the third is a list of
         type `b`
       * The "zipping" function provided as an argument has two parameters
         itself of type `a` and `b`
       * The "zipping" function is permitted to perform effects, represented by
         the `{e}`
       * The return type of {zipWith} is a list of type `c`--in the process of
         returning that value, the overall function can perform effects.

       {{ readingTypeSignatures._nav }}
  }}

docs.fundamentals.valuesAndFunctions.readingTypeSignatures._nav : Doc
docs.fundamentals.valuesAndFunctions.readingTypeSignatures._nav =
  use wordle.utils.emojis learnMore
  {{
  # Where to next:

    {{ suggested }}
    [Special operators for function application]({{
    docLink (docEmbedTermLink do functionApplicationOperators)
    }})

    {{ learnMore }} [Scoping rules for type variables]({scopedTypeVariables})

    {{ learnMore }}
    [Abilities in functions signatures]({abilitiesInFunctionTypes})
  }}

docs.fundamentals.valuesAndFunctions.terms : Doc
docs.fundamentals.valuesAndFunctions.terms =
  use Int -
  use Nat +
  {{
  # Defining terms

    In Unison, we can give a value a name, for example:

    ``` unison
    favoritePie : Text
    favoritePie = "Apple pie"
    ```

    We call these definitions "term declarations", and they typically have two
    parts. The first, `favoritePie : Text` is the type signature, and it tells
    Unison and other programmers what type your term is. You might read this in
    human language as `favoritePie` has the type {type Text}. Unison is able to
    infer the type of a given term so you might see this first part omitted for
    simple definitions.

    The second line `favoritePie = "Apple pie"` supplies the implementation for
    your term.

    {{
    docCallout
      (Some style)
      {{
      By convention, types are capitalized in Unison, whereas term names are
      "camelCase."
      }} }}

    The value assigned to a Unison term doesn't vary while a program is
    running, so if you try to reassign it like this:

    ``` unison
    favoritePie = "Apple pie"
    favoritePie = "Peach pie"
    ```

    The {{ docTooltip {{ UCM }} ucm }} will fail to typecheck:

    ``` ucm
    I found 1 name with multiple definitions:

    favoritePie
    ```

    {{
    docAside
      {{
      {{ reminder }} As a reminder, you can write your Unison code in any file
      that ends in the `.u` file suffix. When you start your Unison codebase
      manager, it monitors all the Unison source files in the directory you
      started the `ucm` from. The Unison codebase manager typechecks your code
      upon saving the file.
      }} }}

  # Tuples

    Tuples are a way to join together values of different types into one value.

    ``` unison
    dessertOrder : (Text, Text, Nat)
    dessertOrder = ("Alice", "Blueberry pie", 5)
    ```

    A tuple is specific to the length of values joined together and the types
    of each of those values, so they're useful for structured data. There is no
    upper limit to the number of things you can put in a tuple in Unison.

    If you try to add values to your tuple without changing the corresponding
    type, or supply a value of the wrong type, the UCM will fail to typecheck.

    ``` unison
    dessertOrder : (Text, Text, Nat)
    dessertOrder = ("Alice", "Blueberry pie", "Chocolate cake", 2 )
    ```

    ``` ucm
    I found a value  of type:  Text where I expected to find:  Nat

      38 | dessertOrder : (Text, Text, Nat)
      39 | dessertOrder = ("Alice", "Blueberry pie", "Chocolate cake", 2 )

      from right here:

      39 | dessertOrder = ("Alice", "Blueberry pie", "Chocolate cake", 2 )
    ```

    When we want to un-tuple one of these values, we can use extraction
    functions which start with ``at1``.

    ```
    dessertOrder = ("Alice", "Blueberry pie", 5)
    at2 dessertOrder
    ```

    {{ _tupleDecomposition }}

  # A few more types

    We've seen a couple of basic types already, but here's a rudimentary
    vocabulary of Unison types to get you started writing Unison programs.

    {{
    docTable
      [ [{{ **Name** }}, {{ **Purpose** }}, {{ **Example** }}]
      , [ {{
          Text
          }}
        , {{
          textual data
          }}
        , {{
          `` "textBlob" `` or `"""multi-line text"""`
          }}
        ]
      , [{{ Char }}, {{ single character }}, {{ `` ?a `` }}]
      , [{{ Bytes }}, {{ byte literal }}, {{ `0xsdeadbeef0d0a` }}]
      , [ {{
          Nat
          }}
        , {{
          64 bit positive whole numbers. 0 to 2^64 - 1
          }}
        , {{
          `` 5 + 5 ``
          }}
        ]
      , [ {{
          Int
          }}
        , {{
          64 bit signed positive or negative whole numbers. -2^64/2 to 2^64/2 -
          1
          }}
        , {{
          `` +4 - +9 ``
          }}
        ]
      , [{{ Float }}, {{ 64 bit floating point numbers }}, {{ `` 3.14159 `` }}]
      , [ {{
          Boolean
          }}
        , {{
          true or false values for logic
          }}
        , {{
          `` true || false ``
          }}
        ]
      ] }}

    {{ terms._nav }}
  }}

docs.fundamentals.valuesAndFunctions.terms._nav : Doc
docs.fundamentals.valuesAndFunctions.terms._nav =
  use wordle.utils.emojis learnMore
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Create a few common Unison collections]({{
      (docLink (docEmbedTermLink do commonCollectionTypes))
      }})

      {{ learnMore }}
      [Read a deep dive into tuple syntax in the language reference]({tupleTypes})

      {{ learnMore }}
      [For a full list of Unison literals, checkout the language reference
      section on literals]({literals})
    }} }}
  }}

docs.fundamentals.valuesAndFunctions._blockSyntax : Doc
docs.fundamentals.valuesAndFunctions._blockSyntax =
  use Nat +
  {{
  # Block syntax

    A block is a section of Unison code which is grouped together to organize
    smaller units of code. One of the many places you'll start a code block is
    after a term definition. We can introduce a code block via indentation or
    via a `let` block.

    ``` unison
    repeatNum : Nat -> Text
    repeatNum num =
      text = Nat.toText num
      Text.repeat num text
    ```

    In the example above, we've opted to use indentation to delimit the code
    block. Everything at the same indentation level is within the same block
    and therefore shares the same
    {{ docTooltip {{ lexical scope }} {{ {{ lexicalScope }} }} }}. The exact
    same code with a `let` block looks like:

    ``` unison
    repeatNum : Nat -> Text
    repeatNum num = let
      text = toText num
      Text.repeat num text
    ```

    🪆 Blocks can be nested within other blocks, and terms in inner blocks can
    reference terms from their enclosing blocks.

    ``` unison
    nesting : [Text]
    nesting =
      parent = "outer"
      inner1 = let
        child1 = "child1"
        inner2 = let
          child2 = "child2"
          [parent, child1, child2]
        inner2
      inner1
    ```

    The last thing evaluated in a code block is the return value for that
    entire code block. Below we have a series of expressions whose values are
    ultimately discarded even though each line of the code block is actually
    executed.

    ```
    myFunction : Text
    myFunction =
      x = 1 + 1
      y = "I am unreachable!"
      z = ?a
      "I am what is returned."
    myFunction
    ```

    The UCM will fail to compile a block which contains a sub-expression that
    is not used or bound to a variable and does not return {type Unit}. That
    means the following function will fail to typecheck and cannot be added to
    the codebase because both `` 1 + 1 `` and the doc fragment are not used
    elsewhere in the function.

    ``` raw
    invalidFunction : Text
    invalidFunction =
      Debug.trace "I am ok because I return unit!" ()
      1 + 1
      {{I am an unused expression}}
      "returned value"
    ```

    {{
    docAside
      {{
      Sometimes you might want to add a doc fragment to a sub-expression in a
      block to annotate your code with a comment. To do this, prefix the doc
      expression with `_ =`.
      }} }}

    Check out the full
    [language reference for block syntax]({blocksAndStatements}) for more
    details.
  }}

docs.fundamentals.valuesAndFunctions._higherOrderFunctions : Doc
docs.fundamentals.valuesAndFunctions._higherOrderFunctions =
  use jsonschema.lib.base.data.List map
  {{
  # Higher order functions

    In Unison functions can be passed as arguments to other functions. A
    function that takes a function as an argument is sometimes referred to as a
    "higher order" function. Many of the functions which operate over Unison
    collection types are "higher order", taking a function argument which
    describes how the collection should be transformed.

    For example {map} is a higher order function because it expects a function
    argument as an argument `(a -> b)`.

        @signature{map}
  }}

docs.fundamentals.valuesAndFunctions._lambdaSyntax : Doc
docs.fundamentals.valuesAndFunctions._lambdaSyntax =
  use Nat +
  use jsonschema.lib.base.data.List map
  {{
  # Lambda syntax

    Lambdas, or anonymous functions are unnamed functions which are defined
    without going through the entire term declaration process. They're
    typically used when the function doesn't need to be reused elsewhere in the
    program or when the function itself is very simple. They're often found as
    the arguments to [higher order functions]({_higherOrderFunctions}).

    While we could define the function below as a separate term to pass into
    [List.map]({map}), it's much simpler to define in-line.

    ```
    a = [1, 2, 3, 4, 5]
    map (elem -> elem + 1) a
    ```

    The section `elem -> elem + 1` is the lambda. Anything to the left of the
    arrow represents the parameters to the function and the expression to the
    right is the function body.

    Anonymous functions can be simple, like the `elem -> elem + 1` example
    above, or they can be more complicated, multi-line expressions when
    combined with the [block syntax]({_blockSyntax}).

    ```
    map
      (i -> let
        x = i + 1
        y = x + 1
        z = y + 1
        z) [1, 2, 3]
    ```

    You can do simple pattern decomposition in lambdas with the `cases` syntax.

    ```
    map (cases (a, b) -> a + b) [(1, 2), (3, 4)]
    ```

    This can be useful when you want to destructure a tuple or other data
    types.

    A lambda with two arguments is represented by separating the function
    arguments with spaces.

    ```
    jsonschema.lib.base.data.List.foldLeft (acc a -> a + acc) 0 [1, 2, 3, 4]
    ```

    You can also choose to ignore the argument to the lambda altogether with
    the underscore symbol, as in the following function:

    ``` unison
    a = [1, 2, 3, 4, 5]
    List.map (_ -> 10) a
    ```
  }}

docs.fundamentals.valuesAndFunctions._polymorphismLinkAside : Doc
docs.fundamentals.valuesAndFunctions._polymorphismLinkAside =
  {{
  {{
  docAside
    {{
    If you're curious you can read more about polymorphism in the
    [language reference section on polymorphic types]({polymorphicTypes})
    }} }}
  }}

docs.fundamentals.valuesAndFunctions._summary : Doc
docs.fundamentals.valuesAndFunctions._summary =
  {{
  # Basics summary

    {{ _termsFunctionsSummary }}
  }}

docs.fundamentals.valuesAndFunctions._termsFunctionsSummary : Doc
docs.fundamentals.valuesAndFunctions._termsFunctionsSummary = {{ TODO! }}

docs.fundamentals.valuesAndFunctions._tupleDecomposition : Doc
docs.fundamentals.valuesAndFunctions._tupleDecomposition =
  {{
  # Tuple pattern decomposition

    Let's say you're working with data that's modeled by a tuple composed of a
    {type Text}, a {type Bytes}, and a {type Text}. Later when writing a
    function which uses this tuple you might need to access the values at each
    position in the tuple and bind them to a variable name. You could do this
    with the {at1}, {at2}, and {at3} functions defined on {type Tuple}

    ```
    getByteSize : (Text, Bytes, Text) -> Nat
    getByteSize tuple3 =
      use Bytes ++
      use Text toUtf8
      first = at1 tuple3
      bytes = at2 tuple3
      last = at3 tuple3
      Bytes.size (toUtf8 first ++ bytes ++ toUtf8 last)
    getByteSize ("Shepherds", 0xsdeadbeef, "Pie")
    ```

    But you can also rewrite the function to decompose the tuple into the
    desired variable names in one line. Just make sure the number of variables
    you're defining matches the tuple structure.

    ``` raw
    getByteSize : (Text, Bytes, Text) -> Nat
    getByteSize tuple3 =
      _ = "tuple decomposition 👇"
      let
        (first, bytes, last) = tuple3
        size (toUtf8 first ++ bytes ++ toUtf8 last)
    ```

    {{
    docCallout
      (Some wordle.utils.emojis.hint)
      {{
      You can't decompose a tuple into terms at the {{
      (docTooltip {{ top level }} topLevelDeclaration) }} of a Unison program.
      So `(first, bytes, last) = ("Shepherds", 0xsdeadbeef, "Pie")` outside of
      the body of another Unison function would fail to typecheck.
      }} }}
  }}

docs.fundamentals.valuesAndFunctions._tupleDecomposition.getBytesSize :
  (Text, Bytes, Text) -> Nat
docs.fundamentals.valuesAndFunctions._tupleDecomposition.getBytesSize = cases
  (first, bytes, last) ->
    Bytes.size (Text.toUtf8 first Bytes.++ bytes Bytes.++ Text.toUtf8 last)

docs.glance.bankTransfers : '{IO, Exception} ()
docs.glance.bankTransfers _ =
  use Int toText
  use TVar new read
  use Text ++
  (act1, act2) =
    STM.atomically do
      account1 = new +200
      account2 = new +350
      transfer +100 account1 account2
      transfer +50 account1 account2
      act1 = read account1
      act2 = read account2
      (act1, act2)
  printLine ("Balance account1: " ++ toText act1)
  printLine ("Balance account2: " ++ toText act2)

docs.glance.delayGreet : 'Text
docs.glance.delayGreet = do glance.greet "Joy"

docs.glance.double : Nat -> Nat
docs.glance.double x =
  use Nat *
  x * 2

docs.glance.exampleGet : '{IO, Exception} HttpResponse
docs.glance.exampleGet _ =
  uri = net.URI.parse "https://share.unison-lang.org/@unison/httpclient"
  req = do Http.get uri
  Http.run req

docs.glance.getRandomElem : [a] ->{Abort, Random} a
docs.glance.getRandomElem list =
  index = Random.natIn 0 (List.size list)
  List.at! index list

docs.glance.greet : Text -> Text
docs.glance.greet name =
  use Text ++
  "Hi " ++ name

docs.glance.incrementTVar : TVar Nat ->{STM} ()
docs.glance.incrementTVar n =
  use Nat +
  TVar.modify n (x -> x + 1)

docs.glance.nonZero : Nat ->{Exception} Nat
docs.glance.nonZero = cases
  n
    | n Nat.== 0 -> Exception.raise (Generic.failure "Zero was found" n)
    | otherwise  -> n

docs.glance.Pet.age : Pet -> Nat
docs.glance.Pet.age = cases Pet age _ _ -> age

docs.glance.Pet.age.modify : (Nat ->{g} Nat) -> Pet ->{g} Pet
docs.glance.Pet.age.modify f = cases
  Pet age species foodPreferences -> Pet (f age) species foodPreferences

docs.glance.Pet.age.set : Nat -> Pet -> Pet
docs.glance.Pet.age.set age1 = cases
  Pet _ species foodPreferences -> Pet age1 species foodPreferences

docs.glance.Pet.foodPreferences : Pet -> [Text]
docs.glance.Pet.foodPreferences = cases
  Pet _ _ foodPreferences -> foodPreferences

docs.glance.Pet.foodPreferences.modify : ([Text] ->{g} [Text]) -> Pet ->{g} Pet
docs.glance.Pet.foodPreferences.modify f = cases
  Pet age species foodPreferences -> Pet age species (f foodPreferences)

docs.glance.Pet.foodPreferences.set : [Text] -> Pet -> Pet
docs.glance.Pet.foodPreferences.set foodPreferences1 = cases
  Pet age species _ -> Pet age species foodPreferences1

docs.glance.Pet.species : Pet -> Text
docs.glance.Pet.species = cases Pet _ species _ -> species

docs.glance.Pet.species.modify : (Text ->{g} Text) -> Pet ->{g} Pet
docs.glance.Pet.species.modify f = cases
  Pet age species foodPreferences -> Pet age (f species) foodPreferences

docs.glance.Pet.species.set : Text -> Pet -> Pet
docs.glance.Pet.species.set species1 = cases
  Pet age _ foodPreferences -> Pet age species1 foodPreferences

docs.glance.queueExample : '{IO, Exception} ()
docs.glance.queueExample _ =
  runQueue : '{STM} Nat
  runQueue _ =
    queue = TQueue.fromList [1, 2, 3, 4, 5]
    enqueue 6 queue
    dequeue queue
    dequeue queue
  result = STM.atomically runQueue
  printLine (Nat.toText result)

docs.glance.readFile : '{IO, Exception} ()
docs.glance.readFile _ =
  filePath = FilePath "tmp.txt"
  read : Handle ->{IO, Exception} Bytes
  read fileHandle =
    go acc =
      use Bytes ++
      use Nat <
      bs = getBytes fileHandle 4096
      if Bytes.size bs < 4096 then acc ++ bs else go (acc ++ bs)
    go Bytes.empty
  fileHandle : '{IO, Exception} Handle
  fileHandle _ = FilePath.open filePath FileMode.Read
  bracket fileHandle Handle.close (file -> read file |> fromUtf8 |> printLine)

docs.glance.runIncrement : '{IO, Exception} ()
docs.glance.runIncrement _ =
  res = STM.atomically do
    init = TVar.new 0
    incrementTVar init
    TVar.read init
  printLine (Nat.toText res)

docs.glance.transfer : Int -> TVar Int -> TVar Int ->{STM} ()
docs.glance.transfer amount acct1 acct2 =
  use Int + -
  use TVar read write
  balanceFrom = read acct1
  balanceTo = read acct2
  write acct1 (balanceFrom - amount)
  write acct2 (balanceTo + amount)

docs.glossary.abilityDeclaration : Doc
docs.glossary.abilityDeclaration =
  {{
  # Ability declaration

    The ability declaration defines the name and the request operations of an
    ability. It also specifies if an ability is unique by its name or
    structural.
  }}

docs.glossary.abilityRequirement : Doc
docs.glossary.abilityRequirement =
  {{
  # Ability requirement

    An ability requirement is expressed in curly braces within the type
    signature of a function. It specifies that an ability may be performed in a
    given function and therefore the caller of the function needs to provide a
    handler for the ability or pass the ability requirement along to its
    callers.

    In the function @inlineSignature{nat!}, the `{Random}` is the ability
    requirement.
  }}

docs.glossary.absolutePath : Doc
docs.glossary.absolutePath =
  {{
  # Absolute path

    An absolute path is a path that starts at the root of the codebase.
    Absolute paths are prefixed with a dot, `.`, and are used to refer to
    namespaces.

    ``` ucm
    aProject/main> merge .absoluteNamespace.path lib.base
    ```
  }}

docs.glossary.arity : Doc
docs.glossary.arity =
  {{
  # Arity

    The arity of a function or data constructor describes the number of
    arguments that it takes.

    For example, the function `addThree : Nat -> Nat -> Nat -> Nat` is a
    function of arity 3.

    Some arities are common enough they get special terms:

    * A "nullary" function has 0 arguments
    * A "unary" function has 1 arguments
    * A "binary" function has 2 arguments
    * A "ternary" function has 3 arguments
  }}

docs.glossary.associativity : Doc
docs.glossary.associativity =
  use Nat +
  {{
  # Associativity

    Associativity is a property of a binary function where the parentheses
    grouping parts of an expression which uses it can be rearranged without
    impacting the result.

    For example the {+} function is associative:

    ```
    1 + 2 + 3 + 4
    ```

    ```
    1 + 2 + 3 + 4
    ```
  }}

docs.glossary.branch : Doc
docs.glossary.branch =
  {{
  # Unison branch

    A branch, in Unison's project model, represents an independent development
    workstream. Much like git branches, they enable workflows like creating
    PR's and maintaining different features of a project. Branches inherit the
    codebase state of the branch they were created from.
  }}

docs.glossary.callStack : Doc
docs.glossary.callStack =
  {{
  # Call stack

    The call stack is a data structure which represents the "nested" nature of
    code execution when one function calls another. As functions are called,
    they are put on the stack, and when they finish executing, they are popped
    off the stack. This allows the program to keep track of the chain of child
    function calls in relation to their parents.
  }}

docs.glossary.continuation : Doc
docs.glossary.continuation =
  {{
  # Continuation

    A continuation is a representation of the current state of the execution of
    the program. It renders the process of returning a computed value to the
    rest of the program explicit. You can think of a continuation as a function
    whose one argument is the return value of the current line being executed
    and whose return value is some type representing the remainder of the
    program.

    Unison exposes control over continuations when writing ability handlers to
    support operations like exception handling, caching, and stateful
    computations.
  }}

docs.glossary.contributorBranch : Doc
docs.glossary.contributorBranch =
  {{
  # Contributor branch

    A contributor branch is a special type of branch that represents when a
    user is working on another person's project. When you `clone` another
    user's project, you're creating a new branch of the project that is
    associated with your Unison Share username. Contributor branches take the
    form `@owner/projectName/@contributor/branch`.
  }}

docs.glossary.controlFlow : Doc
docs.glossary.controlFlow =
  {{
  # Control flow

    Control flow describes any of the ways that a programmer and the
    programming language direct the order in which a program executes.

    Core concerns of control flow might include:

    * How to do one operation in one circumstance, but another in a different
      circumstance
    * The order in which functions are called
    * How to repeat a section of code
    * What representation should be used when a program fails
    * How to run things many things at once
  }}

docs.glossary.curried : Doc
docs.glossary.curried =
  {{
  # Currying

    Currying means that functions with multiple arguments are expressed as a
    series of functions which each accept one argument. So `addNums` is a
    function which takes in a number and returns a __function__, which takes in
    another number.

    [Learn more online](https://en.wikipedia.org/wiki/Currying)
  }}

docs.glossary.dataConstructor : Doc
docs.glossary.dataConstructor =
  {{
  # Data constructor

    Found on the right hand side of the equals sign in a type declaration, a
    data constructor describes how to construct a value of some type.

    For example, the {type Optional} type has two data constructors,
    {Optional.None} and {Some}:

        @source{type Optional}
  }}

docs.glossary.declarative : Doc
docs.glossary.declarative =
  {{
  # Declarative programming

    In declarative programming, the programmer is responsible for describing
    **what** a program should execute, as opposed to the fine-grained details
    of **how** a program should execute. Declarative programming focuses on
    describing the desired result of the program, handing details like order of
    execution or iteration off to other functions which are often provided by
    the core language.

    **See also**

    [imperative programming]({imperative})
  }}

docs.glossary.deterministic : Doc
docs.glossary.deterministic =
  {{
  # Deterministic

    A function which is deterministic will always return the same result for
    the given set of input values.
  }}

docs.glossary.eager : Doc
docs.glossary.eager =
  {{
  # Eager evaluation

    Eager evaluation means that values and expressions are evaluated as soon as
    they are bound to a variable, as opposed to when they are called.
  }}

docs.glossary.expression : Doc
docs.glossary.expression =
  use Nat +
  use Text ++
  {{
  # Expression

    An expression is a unit of code that evaluates to a value. The right side
    of the `=` in any term declaration is an expression.

    In Unison, every expression has a type, which represents a set of values

    Here are some examples of expressions:

    Arithmetic expression

    ```
    5 + 4
    ```

    The right side of the equals is the expression

    ```
    author = "Claudia Rankine" ++ "!"
    author
    ```

    evaluating the term yields the value of that expression.
  }}

docs.glossary.functionApplication : Doc
docs.glossary.functionApplication =
  {{
  # Function application

    Function application refers to the way in which a language evaluates a
    function and its arguments when it is called.

    For a function `f` taking an argument `x`, it's common to say "we apply `f`
    to `x`."

    See the language reference section on
    [function application]({languageReference.functionApplication}) for Unison
    specifics.
  }}

docs.glossary.gitUrls : Doc
docs.glossary.gitUrls =
  {{
  # Git urls

    UCM commands like `push` and `pull` can reference git urls for Unison code
    which is not hosted on Unison's own code-hosting platform, Unison Share.

    This can have which have one of the following forms:

    * `git(git@github.com:user/repo)` refers to the root of a git repository
    * `git(git@github.com:user/repo).some.remote.path` refers to the
      `.some.remote.path` namespace of the git repository
    * `git(git@github.com:user/repo:some-branch)` pulls a git branch called
      `some-branch` from the git repository
    * `git(https://github.com/org/repo:someGitBranch).some.remote.path` pulls
      the `some.remote.path` namespace from a branch of the repository

    The UCM tab completion provides some handy shortcuts:

    * `gh` to "git(https://github.com:" (which you can complete with
      org/reponame.git)
    * `ghs` to "git(git@github.com:" (which you can complete with
      org/reponame.git)
    * `gl` to "git(https://gitlab.com/"
    * `gls` to "git(git@gitlab.com:" (which you can finish with
      org/reponame.git)
  }}

docs.glossary.higherOrderFunction : Doc
docs.glossary.higherOrderFunction =
  {{
  # Higher order function

    A function that takes another function as an argument.

    The following are all examples of higher order functions:

    *     @signature{List.flatMap}
    *     @signature{Stream.filter}
    *     @signature{Optional.contains}
  }}

docs.glossary.imperative : Doc
docs.glossary.imperative =
  {{
  # Imperative programming

    In imperative programming, the programmer is responsible for writing
    **how** a program should execute. Imperative programming uses statements to
    direct the program in a sequential manner. For example, when iterating
    through a list you might write a statement like `index += 1` to both
    increment and set an index variable.

    We use the term "imperative programming" to describe a programming
    paradigm. It's a fuzzy description which is applied to languages but is
    often a matter of style and of what language constructs a programming
    language provides.
  }}

docs.glossary.lambda : Doc
docs.glossary.lambda =
  use jsonschema.lib.base.data.List map
  {{
  # Lambda

    A function which is not bound to a term.

    In the expression `` map (a -> a + 1) [1, 2, 3] `` the first argument to
    {map}, ``a -> a Nat.+ 1``, is the lambda or anonymous function.
  }}

docs.glossary.lexicalScope : Doc
docs.glossary.lexicalScope =
  {{
  # Lexical Scope

    Lexical scope is a way of describing where a term can be accessed in a
    program.

    Terms in inner levels of nested indentations or 'let' blocks can make use
    of terms in outer levels, but not vice-versa.
  }}

docs.glossary.literal : Doc
docs.glossary.literal =
  {{
  # Literal

    A literal is a constant value which we represent in a common or short-hand
    form in a program. A literal's value can be interpreted without a variable
    name. All of the following are examples of literals:

    ``` unison
    55
    "hello world"
    ?c
    false
    [1, 2, 3, 4]
    ```

    Unison literals are enumerated in the
    [Literals section of the language reference]({literals}).
  }}

docs.glossary.operators : Doc
docs.glossary.operators =
  use Nat *
  use Weighted <|>
  {{
  # Operators

    Operators are functions which are called in an infix manner, as in
    ``5 * 8``. They're commonly expressed in terms of short symbols like `+` or
    `<<`.

    **Examples**

        @signature{*}

        @signature{<|>}
  }}

docs.glossary.predicate : Doc
docs.glossary.predicate =
  {{
  # Predicate

    A predicate is an expression that evaluates to a {type Boolean}, commonly
    found as a higher order function argument.

    In the function @inlineSignature{Optional.filter} the first argument
    `a -> {g} Boolean` is a predicate.
  }}

docs.glossary.project : Doc
docs.glossary.project =
  {{
  # Unison project

    A Unison project is a Unison codebase concept that represents a library,
    application, or other code package that can be shared, collaborated on, and
    versioned. You can create and manipulate projects with UCM commands and
    view your projects on Unison Share.
  }}

docs.glossary.referentialTransparency : Doc
docs.glossary.referentialTransparency =
  {{
  # Referential transparency

    A property of a program where every expression can be replaced by the
    result of its execution.

    Given the same argument, a referentially transparent function will always
    return the same value no matter what context the function is called in.
  }}

docs.glossary.remoteMapping : Doc
docs.glossary.remoteMapping =
  {{
  # Remote mapping

    A remote mapping is a mapping between a project's local branch and a remote
    repository's branches. When you push a branch to Unison Share, you create a
    remote mapping between the local branch and your Unison Share user's remote
    branch. Subsequent pushes will update the remote branch if not otherwise
    specified.

    ``` ucm
    myProject/main> push
    ```

    This creates a remote mapping between `myProject/main` and
    `@myUser/myProject/main`.

    ``` ucm
    @unison/base/myFeature> push
    ```

    The above `push` command will actually push to a remote branch named
    `@unison/base/@myUsername/myFeature.` Your username will automatically be
    added to the remote branch name when you push a project that you don't own
    to Unison share.
  }}

docs.glossary.requestConstructors : Doc
docs.glossary.requestConstructors =
  {{
  # Request constructors

    In an [ability declaration]({glossary.abilityDeclaration}), the request
    constructors are the operations that the ability can run.

    For example, the request constructor for the {type Throw} ability is
    {throw}
  }}

docs.glossary.tailCallPosition : Doc
docs.glossary.tailCallPosition =
  {{
  # Tail call position

    When we say a function call is in tail call position we mean that the
    result of evaluating the function call can immediately be returned to its
    enclosing function! This is especially relevant for recursive functions,
    but the property of being "in tail call position" can apply to any function
    call inside another.

    The recursive function below is not in tail position because adding `n +` a
    recursive call means that the value for `n` is placed on the stack each
    time the function is called. The last thing that the function is doing is
    not immediately returning a value, rather, it's returning `0`, which then
    needs to be added to each value of `n` that we computed along the way.

    ``` unison
    addUp : Nat -> Nat
    addUp n = if n === 0 then 0 else n + (addUp (drop n 1))
    ```

    It's common to define inner functions which keep track of interim or
    accumulated values to enable tail call elimination.

    ``` unison
    addUpLoop : Nat -> Nat
    addUpLoop i =
      loop : Nat -> Nat -> Nat
      loop num total =
        if num === 0 then total else loop (drop num 1) (num + total)
      loop i 0
    ```

    Here, the last thing that the inner function `loop` is doing is returning
    the value `total` to the caller. The state that would have been kept on the
    function call stack is tracked as a parameter in the inner function `loop.`
  }}

docs.glossary.thunk : Doc
docs.glossary.thunk =
  {{
  # Thunk

    A thunk is a function which takes no arguments and returns a value. Its
    type is: `() -> a` and it's used to delay calculating a value until
    "forced" or evaluated.
  }}

docs.glossary.ucm : Doc
docs.glossary.ucm =
  {{
  # UCM

    "UCM" stands for "Unison Codebase Manager." It's the all-in-one tool you'll
    use to explore and modify a Unison codebase and run Unison programs.
  }}

docs.glossary.useClause : Doc
docs.glossary.useClause =
  {{
  # `use` clause

    The use clause allows code in the current [lexical scope]({lexicalScope})
    to use terms and types in the given namespace without referencing them by
    their fully qualified names.

    ``` unison
    use Nat drop +

    (drop 5 4) + 8
    ```

    `use` can be called without referencing specific terms--''use List'' brings
    everything under the {type List} namespace into scope, or it can reference
    specific definitions, as in, `use List map flatMap`
  }}

docs.glossary.watchExpression : Doc
docs.glossary.watchExpression =
  {{
  # Watch expression

    In a file with the `.u` extension, any line beginning with `>` is a watch
    expression. A watch expression tells the UCM to execute the Unison
    expression to the right of the symbol and render the result to the console.

    Watch expressions cannot execute code whose abilities are not enclosed by a
    handler.
  }}

docs.glossary._namespace : Doc
docs.glossary._namespace =
  {{
  # Namespace

    In Unison, a namespace is a mapping of names to their underlying
    definitions.

    We often think of these names as forming a tree, much like a directory of
    files, and names are like file paths in this tree.
  }}

docs.howCanUnisonHelp : Doc
docs.howCanUnisonHelp =
  {{
  # 🤓 Software development is complex. How can Unison help?

    {{
    docTable
      [ [{{ The problem }}, {{ Our remedy }}]
      , [ {{
          **Cloud infrastructure management overhead:** Cloud infrastructure
          management can be cumbersome, and not every team has a deep bench of
          devops knowledge. Writing and testing cloud platform integrations is
          often based on brittle configuration files or one-off scripts.
          }}
        , {{
          **Unison code deploys Unison services.**
          [Our cloud computing platform, Unison Cloud,](https://www.unison.cloud/)
          aims to make deploying long-running services, serverless functions,
          and batch jobs to the cloud as easy as calling a regular function.
          }}
        ]
      , [ {{
          **Inter-service communication boilerplate:** Developing encoders and
          decoders for various interface definition languages is part of the
          overhead we've payed for distributed architectures.
          }}
        , {{
          **Native service calls** in Unison eliminate the need for
          intermediaries. Service calls are typechecked function calls.
          }}
        ]
      , [ {{
          **Challenges in database schema versioning:** Translating your typed
          domain models to and from database schemas involves writing mapping
          boilerplate, losing type information, keeping versioned clients in
          sync, and managing the risks of schema migrations.
          }}
        , {{
          **Unison supports native, typed, transactional storage in the Cloud.**
          That means no writing sql adapters, no special query languages, just
          store and access Unison data.
          }}
        ]
      , [ {{
          **Testing and profiling distributed systems:** Testing the
          integration of an entire distributed system often involves setup and
          teardown of resources or copious data mocking.
          }}
        , {{
          **Unison's effect system separates your business logic from its
          implementation** so our model for distributed computation, the
          {type Remote} ability, can run against test backends that focus on
          observability, tracing or performance.
          }}
        ]
      , [ {{
          **Unnecessary merge conflicts:** Dealing with semantically
          unimportant merge conflicts is at best a papercut and at worst a big
          waste of development time.
          }}
        , {{
          **Semantically aware merges.** If one sub-expression of a Unison
          function is the same across both versions, there's no need to include
          it in the conflict. Unison code is normalized upon saving to the
          codebase so there's no need to worry about whitespace or formatting
          changes.
          }}
        ]
      , [ {{
          **Dependency management nightmares:** Upgrading a library can mean
          resolving binary incompatibilities or version conflicts within
          transitive dependencies.
          }}
        , {{
          **A Unison function can __always__ call its dependencies.** Library
          upgrades can be programmatically supported or simply ignored, even in
          the case of conflicting versions.
          }}
        ]
      , [ {{
          **Institutional inertia:** Is watching your build pipeline fail for
          the umpteenth time or wading through thankless maintenance tasks
          causing disillusionment with the field of software development?
          }}
        , {{
          **Unison is a community of curious and compassionate developers.**
          We're excited about the future of programming and we're building a
          language that will help you focus on what you love about programming.
          }}
        ]
      ] }}
  }}

docs.index : Doc
docs.index =
  {{
  # 👋 Welcome fellow Unison programmers!

    If you want to write Unison applications and libraries, you are in the
    right place. The Unison language and ecosystem was thoughtfully designed to
    offer a delightful way to write code.

    {{
    docCallout
      Optional.None
      {{
      **There are many ways to get started**

      🏇
      [See the install and quickstart guide and just start coding]({{
      (docLink (docEmbedTermLink do quickstart))
      }})

      🤯 [What's the big idea behind Unison?](/theBigIdea)

      🖼️
      [Check out code hosting on Unison Share](https://share.unison-lang.org/)

      🌤️
      [Looking to deploy your Unison program? Head to the Cloud](https://www.unison.cloud/)

      🎉
      [Come say hi to the friendly Unison community](https://www.unison-lang.org/discord)
      }} }}

    If you want a sense of what Unison code looks like, below are a few
    bread-and-butter language fundamentals with links to more comprehensive
    docs:

    {{ atAGlance }}
  }}

docs.installInstructions : Doc
docs.installInstructions =
  {{
  # Installation options

    The current release is for Mac OS X, 64-bit Linux, and Windows users!

    {{
    Folded
      true
      {{
      **Option 1: Installing or updating using Homebrew**
      }}
      {{
      First [install homebrew](https://brew.sh/) if you haven't already.

      Then from the command line enter these commands (or better yet, paste
      them into your console):

      ``` raw
      brew tap unisonweb/unison
      brew install unison-language
      ```

      This will install the Unison codebase manager executable ucm. If you're
      upgrading from a previous version, just do
      `brew upgrade unison-language.`

      Note: if you get prompted for a GitHub username and password at this
      point, make sure you spelled unisonweb/unison correctly.
      }} }}

    {{
    Folded
      true
      {{
      **Option 2: Install Debian / Ubuntu users**
      }}
      {{
      Unison Stable Release

      ``` raw
      curl shttp://debian.unison-lang.org/public.gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/unison-computing.gpg
      echo 'deb [arch=amd64 signed-by=/etc/apt/trusted.gpg.d/unison-computing.gpg] https://debian.unison-lang.org/ bookworm main' | sudo tee /etc/apt/sources.list.d/unison-computing.list
      sudo apt update
      sudo apt install unisonweb
      /usr/bin/ucm
      ```

      Unison Nightly Release

      ``` raw
      sudo apt install apt-transport-https
      curl https://debian.unison-lang.org/public.gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/unison-computing.gpg
      echo 'deb [arch=amd64 signed-by=/etc/apt/trusted.gpg.d/unison-computing.gpg] https://debian.unison-lang.org/ bookworm nightly' | sudo tee /etc/apt/sources.list.d/unison-computing.list
      sudo apt update
      sudo apt install unisonweb
      /usr/bin/ucm
      ```
      }} }}

    {{
    Folded
      true
      {{
      **Option 3: Install manually for Mac and Linux users**
      }}
      {{
      Linux

      ``` raw
      mkdir -p unisonlanguage && cd unisonlanguage
      curl -L https://github.com/unisonweb/unison/releases/latest/download/ucm-linux-x64.tar.gz \
      	| tar -xz
      ./ucm
      ```

      Mac (Intel)

      ``` raw
      mkdir -p unisonlanguage && cd unisonlanguage
      curl -L https://github.com/unisonweb/unison/releases/latest/download/ucm-macos-x64.tar.gz \
        | tar -xz
      ./ucm
      ```

      Mac (Apple Silicon)

      ``` raw
      mkdir -p unisonlanguage && cd unisonlanguage
      curl -L https://github.com/unisonweb/unison/releases/latest/download/ucm-macos-arm64.tar.gz \
        | tar -xz
      ./ucm
      ```
      }} }}

    {{
    Folded
      true
      {{
      **Option 4: Install manually for Windows users**
      }}
      {{
      1. Set your default terminal application to “Windows Terminal” for best
         results. Search for “Terminal” in Settings, or follow
         [this how-to.](https://bit.ly/3IXwdlY)
      2. Download
         [UCM](https://github.com/unisonweb/unison/releases/latest/download/ucm-windows-x64.zip)
         and extract it to a location of your choosing.
      3. Run `ucm.exe` 🎉
      }} }}

    {{
    Folded
      true
      {{
      **Option 5: Nix installation**
      }}
      {{
      Head to
      [https://github.com/ceedubs/unison-nix/#usage](https://github.com/ceedubs/unison-nix/#usage)
      and follow the instructions in the readme there.
      }} }}

    ## Unison Language Server installation

       Unison has a Language Server Protocol (LSP) integration!
       [Instructions for downloading and setting up the Unison Language Server
       are available here.](https://github.com/unisonweb/unison/blob/trunk/docs/language-server.markdown)
  }}

docs.labs.wordle.docs.breakdown : Doc
docs.labs.wordle.docs.breakdown =
  use emojis next
  {{
  # 🥽 Wordle lab breakdown

    Depending on your existing experience with Unison, you can pick and choose
    how much direction and information you need about each of the following
    components. In broad strokes, this is how we suggest tackling the problem.
    We've provided some stub signatures and each section contains a link to a
    more detailed page. At the end we've listed some options for extending the
    project that we won't dive into here.

    ## Install and set up the project

       Once you have the UCM running, create a project for your Wordle clone.

       ``` ucm
       scratch/main> project.create wordle
       wordle/main>
       ```

       The UCM will create the `main` branch of your project for you and
       download the latest `base` library into the `lib` namespace. You can
       explore it with commands like `ls` and `view` or open a UI view of your
       local codebase with `ui`.

    ## Core logic and data modeling

       * Implement Wordle’s core comparison logic: given a 5 letter target word
         and a 5 letter user guess, return the guess with each character
         annotated with one of the three Wordle result options

       {{
       docSignature
         [ docEmbedSignatureLink do stubs.Guess.score
         , docEmbedSignatureLink do stubs.Target.fromText
         , docEmbedSignatureLink do stubs.Guess.fromText
         ] }}

       {{ next }}
       [More details for core logic]({{
       docLink (docEmbedTermLink do coreLogic)
       }})

    ## Rendering a guess to the console

       * Colorize console feedback with
         [The Terminus library](https://share.unison-lang.org/@runarorama/terminus)
         from Unison Share
       * Print out a rendered result to the console with IO

       {{
       docSignature
         [ docEmbedSignatureLink do stubs.renderChar
         , docEmbedSignatureLink do stubs.renderRow
         , docEmbedSignatureLink do stubs.renderGuesses
         ] }}

       {{ next }}
       [More details for rendering guesses]({{
       docLink (docEmbedTermLink do colorizeResult)
       }})

    ## Input validation and error handling

       * Validate length of guesses
       * Rerunning console interactions

       {{ docSignature [docEmbedSignatureLink do stubs.getUserInput] }}

       {{ next }}
       [More details for input validation]({{
       docLink (docEmbedTermLink do validation)
       }})

    ## Game loop state and dictionary

       * Query
         [a provided file of 5 letter words](https://gist.github.com/rlmark/fef2a315cba90522cc1dd81461070109)
         for more validation options
       * Write the loop which captures the user's guesses using IO and other
         abilities
       * Run wordle, package it for sharing

       {{
       docSignature
         [ docEmbedSignatureLink do stubs.gameLoop
         , docEmbedSignatureLink do stubs.main
         ] }}

       {{ next }}
       [More details for game loop state]({{
       docLink (docEmbedTermLink do docs.gameLoop)
       }})

    ## Wordle solver challenge task

       * Write a wordle __solver__: see if it can outcompete your human friends

       {{ next }}
       [Optional: Wordle solver details]({{
       docLink (docEmbedTermLink do hard)
       }})

    ## Additional challenges

       {{ next }}
       [Optional: More challenges]({{
       docLink (docEmbedTermLink do challenges)
       }})

    ## That's it!

       {{ getStarted }} Give it a whirl! 🎉
  }}

docs.labs.wordle.docs.challenges : Doc
docs.labs.wordle.docs.challenges =
  {{
  # More challenge options

    ## Optimization of word lookup

       It would be nice if the player of our Wordle game didn’t need to wait
       for the entire dictionary file to be read into memory given that it’s
       looking for only a few words. The dictionary file is sorted and each
       word is 5 letters long, so we should be able to check for the presence
       of a word using a binary search algorithm which has been modified to
       seek through the file.

       * Functions of particular interest to this task:
         * {seek}
         * {type SeekMode}

    ## Validation with HTTP requests

       For word validation, a simple file lookup is a great start, but this
       file doesn’t contain support for valid words that are plural or
       past-tense. A variety of free API’s exist for simple word validation.
       [Take a look at this one from Dictionary Api.](https://dictionaryapi.dev/)
       Then use the
       [http client hosted on Unison Share](https://share.unison-lang.org/@stew/code/latest/namespaces/public/projects/http)
       to incorporate more robust guess validation.

    ## Constructing a custom ability

       Rewrite the game loop as a Console ability, the ability should be able
       to get user input, and write text out. A simple handler might interpret
       the Console ability into IO, and a more complicated console loop handler
       might conditionally run an interaction using the Console ability until a
       given predicate returns false.
       [Check out the example ability handlers here](https://www.unison-lang.org/docs/fundamentals/abilities/#creating-and-handling-abilities)

    ## Other command line games

       The fundamental interactions for this command-line game are shared with
       a variety of other games like Battleship, Connect4, etc. If you write
       one, post it!
  }}

docs.labs.wordle.docs.codebaseSetup : Doc
docs.labs.wordle.docs.codebaseSetup =
  {{
  # 🧰 Codebase and tooling setup

    If you haven't downloaded the Unison codebase manager,
    [check out our quickstart guide](https://www.unison-lang.org/learn/quickstart/#step-1-install-unison)
    and head right back here! The install directions are at the top. ⏱ Be sure
    to wait for the `base` library to download. We'll need it to complete the
    labs.

    From now on, issuing the command `ucm` in your terminal will open the
    default Unison codebase. The default codebase is located in `~/.unison`.

    Now that you've created a codebase, you may want to think about
    [creating an author and license for your codebase](https://www.unison-lang.org/learn/tooling/configuration/#setting-default-metadata-like-license-and-author).

    Set up a remote repository for your codebase by creating a new repository
    on your favorite git hosting website. You can perform an initial sync with
    your remote Unison share codebase by running the `push.create` command in
    the UCM. It should look something like:

    ``` ucm
    scratch/main> push.create myUser.public.myProject .myProject
    ```

    You may want to familiarize yourself with the UCM operations and basic
    functions mentioned in
    [the Unison Tour doc](https://www.unison-lang.org/learn/tour/), if you
    haven't done that already.
  }}

docs.labs.wordle.docs.colorizeResult : Doc
docs.labs.wordle.docs.colorizeResult =
  use stubs Result
  {{
  # 🎨 Render a colorized result

    Wordle wouldn't be complete without the results being appropriately hued!
    🧑🏼‍🎨 Fortunately, we can rely on a library for bulk of this functionality.
    Take a look at the
    [Terminus library for ANSI terminal interactions](https://share.unison-lang.org/@runarorama/terminus)
    We'll use that for producing green and yellow text.

    Pull that library down and install it as a dependency with the `pull`
    command. It should look something like

    ``` ucm
    wordle/main> pull @runarorama/terminus/releases/0.0.2 lib.terminus_0_0_2
    ```

    {{
    docAside
      {{
      The command for pulling the library is available from the "Download
      Latest Version" button on the library's page on Unison Share.
      }} }}

    See if you can write a function that renders the {type Result} of a user's
    guess appropriately.

    * A character that is in its proper location should be green
    * A character that exists in the target word should be yellow
    * All others can remain unchanged

    Users will likely need to see the history of their guesses, so it would be
    nice if we also had a rendering function that could print out the grid of
    guesses too.

    @typecheck ```
    renderChar : Result -> Text
    renderChar = todo "render single character"
    renderRow : [Result] -> Text
    renderRow results = todo "render the guessed word"
    renderGuesses : [[Result]] -> Text
    renderGuesses guesses = todo "render the list of the user's guesses"
    ```

    Then write a function which exercises all the functionality we've written
    thus far, including creating the {type stubs.Target}, and
    {type stubs.Guess} values, tallying up their results, and printing them to
    the console with the {printLine} function found in base. You can call it
    whatever you'd like but you should use the `run` command to start it, and
    it should have the signature:

    {{ docSignature [docEmbedSignatureLink do stubs.renderTest] }}

    You may have to play around with different colors in the foreground or
    background to get a readable colorized letter depending on your console.

    {{
    Folded
      true
      {{
      {{ wordle.utils.emojis.hint }} **Terminus library usage help**
      }}
      {{
      Here's an example of how you can set the foreground and background color
      of text using the library.

      ``` unison
      colorize = do
        style.fg (Bright IsoColor.Red)
        printLine "I am red"
        style.fg (Bright IsoColor.Green)
        printLine "I am green"
        style.bg (Bright IsoColor.Blue)
        printLine "I have a blue background"
        style.reset
        printLine "I am back to normal"
      ```

      Enter `run colorize` in the UCM to see the output.

      These functions work by adding an ansi escape sequence to the given text
      argument. The terminal can interpet specific byte sequences as commands
      instead of text.

      [More on ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code)
      }} }}

    {{
    Folded
      true
      {{
      {{ wordle.utils.emojis.learnMore }} **{printLine} and the IO ability**
      }}
      {{
          @signature{printLine}

      The curly braces indicate {printLine} has two
      [ability requirements](https://www.unison-lang.org/learn/fundamentals/abilities/using-abilities-pt1/#a-first-encounter-with-unison-abilities).
      Abilities are one of the ways we encode computational effects in the
      Unison language. We can read this signature as "printLine is a function
      which performs the IO and Exception abilities in the process of returning
      unit."

      If you'd like, you can pause here and check out
      [an introduction to abilities](https://www.unison-lang.org/learn/fundamentals/abilities/).
      But for now you should know that abilities can be broken down into two
      things:

      1. An interface which specifies the abstract operations of an effectful
         computation
      2. Handlers which supply the specific implementation for how the effect
         should behave

      The handler for the {type IO} ability is special because it can only be
      supplied by the Unison runtime itself. You can run a function which
      performs the {type IO} and {type Exception} abilities with the UCM
      [`run` command](https://www.unison-lang.org/learn/ucm-commands/run/).
      Instead of wrapping the code that performs an ability with a handler
      function in the program, you'll issue the `run` command in the UCM
      console itself. The run command expects a
      [delayed computation](https://www.unison-lang.org/learn/fundamentals/values-and-functions/delayed-computations/),
      which is commonly introduced by the keyword, `do`.
      }} }}

    ## Resources

       * [How to pull code from Unison Share](https://www.unison-lang.org/docs/tooling/unison-share/#pulling-code-from-unison-share)
       * [An introduction to abilities](https://www.unison-lang.org/learn/fundamentals/abilities/)
       * [Unison syntax for delayed computations](https://www.unison-lang.org/learn/fundamentals/values-and-functions/delayed-computations/)
       * [How to run code which performs IO](https://www.unison-lang.org/learn/usage-topics/running-programs/)

    ## Solution

       {{
       Folded
         true
         {{
         {{ wordle.utils.emojis.answer }}
         **Walk through rendering and running what we have so far**
         }}
         {{
         The {{ (docLink (docEmbedTermLink do stubs.renderChar)) }} function
         uses an earlier ansi library to set the foreground and background
         colors with functions prefixed `fg` and `bg`, respectively. The
         terminus library implementation should work similarly. These functions
         operate on {type Text} values so we first have to turn the {type Char}
         back into {type Text} values first.

         {{
         (docSource
           [docSourceElement (docEmbedTermLink do basic.renderChar) []]) }}

         The pipe forward operator, {|>} is being used here to take the result
         of running the function on the left hand side and apply it as an
         argument to the function on the right.

         Both {{ (docLink (docEmbedTermLink do basic.renderRow)) }} and {{
         (docLink (docEmbedTermLink do basic.renderGuesses)) }} make use of the
         {Text.join} function to concatenate {type Text} values with a
         character delimeter.

         {{
         (docSource
           [ docSourceElement (docEmbedTermLink do basic.renderRow) []
           , docSourceElement (docEmbedTermLink do basic.renderGuesses) []
           ]) }}

         Here's what a running test of what we've written so far might look
         like:

         {{
         (docSource
           [docSourceElement (docEmbedTermLink do basic.renderTest) []]) }}

         ``` ucm
         wordle/main> run renderTest
         ```
         }} }}

    ## Next steps

       {{ emojis.next }}
       [Validation for user guesses]({{
       docLink (docEmbedTermLink do validation)
       }})
  }}

docs.labs.wordle.docs.coreLogic : Doc
docs.labs.wordle.docs.coreLogic =
  use Text normalize
  {{
  # 🧱 Core logic and data modeling

    Write a function,
    [`Guess.score`]({{ docLink (docEmbedTermLink do stubs.Guess.score) }}),
    with the following signature:

    {{ docSignature [docEmbedSignatureLink do stubs.Guess.score] }}

    Given a 5 letter target and a 5 letter user guess, it should return the
    guess with each character annotated as one of the following:

    * in the correct place
    * in the target word but not in the correct place
    * not in the target word

    We've given this function a signature which suggests we've created our own
    data types for this step. The data constructors for these types currently
    contain a placeholder type, {type TODO}, which you can replace with what
    you think the type should enclose.

    In Unison it's common to provide functions called `fromText` or `toMyType`
    which create values of a given type, for example {Text.toBag} or
    {Nat.toInt}. We should have those for our Wordle guess and target types
    too!

    {{
    docSignature
      [ docEmbedSignatureLink do stubs.Target.fromText
      , docEmbedSignatureLink do stubs.Guess.fromText
      ] }}

    Choose your data representations wisely!

    {{
    Folded
      true
      {{
      {{ emojis.video }} **How to define a function**
      }}
      {{
      See how to write a simple Unison function together:

      {{
      (Video.video
        "/assets/labs/wordle/normalizeFunction.mp4"
        "/assets/labs/wordle/wordle.png") }}
      }} }}

    {{
    Folded
      true
      {{
      {{ wordle.utils.emojis.learnMore }} **How search for functions by type**
      }}
      {{
      If you ever find yourself wondering "🤔 What's the Unison name for that
      function which turns a List into a Set?" or "🧐 How do I break apart Text
      into its constituent characters?" you may want to use the type-based
      `find` command.

      When you want to search by type, the `find` command is followed by a
      colon `:` and then a type signature.

      ``` ucm
      wordle/main> find : List a -> Set a

        1. .base.Set.fromList : [k] -> Set k
      ```

      ``` ucm
      wordle/main> find : Text -> [Char]

        1. .base.Text.toCharList : Text -> [Char]
      ```

      You might also try using Unison's `view` command in combination with
      [`fzf`](https://github.com/junegunn/fzf) to quickly scan through
      approximate matches to function names. Just enter `view` in the UCM with
      no arguments and then start typing the name of a type whose functions you
      want to view.
      }} }}

    {{
    Folded
      true
      {{
      {{ wordle.utils.emojis.hint }} **Data type definition suggestions**
      }}
      {{
      The user and target word will initially be entered as type {type Text}
      values, but dealing with the raw {type Text} values might not be optimal
      for making the kinds of comparisons needed to produce a result.

      Why not create three types that contain various
      [collection types](https://www.unison-lang.org/learn/fundamentals/values-and-functions/common-collection-types/)
      and types from `base` to model this domain?

      1. A `Target` data type which contains enough information to check for
         the existence of a {type Char} in the target, and the location (an
         index perhaps? 😉) of a character in the target.
      2. A `Guess` data type which contains information about the guessed
         word's characters and their locations.
      3. A `Result` data type which represents the result of comparing a
         `type Char` from the `Guess` with the `Target`.
      }} }}

    ## Resources

       * [Intro to Unison terms and functions](https://www.unison-lang.org/learn/fundamentals/values-and-functions/terms/)
       * [How to define data types](https://www.unison-lang.org/learn/fundamentals/data-types/unique-and-structural-types/)
       * [Common collection types](https://www.unison-lang.org/learn/fundamentals/values-and-functions/common-collection-types/)

    ## Solutions

       {{
       Folded
         true
         {{
         {{ wordle.utils.emojis.answer }} **An implementation walk through**
         }}
         {{
         One possible way to model the domain:

             @source{type basic.Guess}

             @source{type basic.Target}

             @source{type basic.Result}

         Let's look how we might transform a raw text value into our respective
         {type basic.Guess} and {type basic.Target} types.

         First, we'll write a {{ (docLink (docEmbedTermLink do normalize)) }}
         function to lowercase and strip whitespace from the incoming text. We
         don't want the {type basic.Guess} to fail to match the
         {type basic.Target} because of casing or whitespace issues.

         {{ (docSource [docSourceElement (docEmbedTermLink do normalize) []])
         }}

         Then we break down the {type Text} body into a {type List} of
         {type Char} with the {toCharList} function from `base.` Working in the
         {type List} type allows us to call {List.indexed} so we can pair the
         character with its index for position lookup later.

         {{
         (docSource
           [docSourceElement (docEmbedTermLink do basic.Guess.fromText) []]) }}

         We do the same sequence of transformations for the {type basic.Target}
         type, with the additional step of calling {Set.fromList} to create a
         {type Set} which includes the indices of the characters, and we can
         define a function to create a mapping of characters to their number of
         occurrences in the target word.

         {{
         (docSource [docSourceElement (docEmbedTermLink do countLetters) []])
         }}

         {{
         (docSource
           [docSourceElement (docEmbedTermLink do basic.Target.fromText) []])
         }}

         Next we'll break down the overall {{
         (docLink (docEmbedTermLink do basic.Guess.score)) }} function
         implementation.

         {{
         (docSource
           [docSourceElement (docEmbedTermLink do basic.Guess.score) []]) }}

         We first define a helper function that can take a single character and
         its position in the guess, as well as a tuple that represents both the
         current target and the results of each letter comparison so far. The
         function then decides which of the result types the current character
         fits into.

         Firstly, it can simply check if the character, position tuple is in
         the target set, which results in a new target with one less occurrence
         of the character and a new {basic.Result.InPlace} to append to the
         results.

         If the character, position tuple is not in the target set, it must
         then check how many occurrences of the character are in the current
         target. If there never were any, or there are no more left, then the
         new result is {basic.Result.NotFound}. If there are still occurrences
         left, then the new result is {basic.Result.Exists}, and we must update
         the target to reduce the occurrences by 1.

         The final score function then becomes simply a foldLeft call over the
         guess, with the helper function as the folding function. The starting
         state is the target and an empty list of results.
         }} }}

    ## Next steps

       {{ emojis.next }}
       [Render a colorized result to the console]({{
       docLink (docEmbedTermLink do colorizeResult)
       }})
  }}

docs.labs.wordle.docs.gameLoop : Doc
docs.labs.wordle.docs.gameLoop =
  use basic main
  use emojis next
  use wordle.utils.emojis answer learnMore
  {{
  # 🕹 Game loop state and dictionary

    ## Keep track of game state

       There are a few final features to complete our Wordle clone. We need to
       limit the user to six guesses and read a file representing the
       dictionary.

       First try to write a function,
       {{ docLink (docEmbedTermLink do stubs.gameLoop) }}, which does the
       following:

       * Gets the user's guess from the console
       * Renders the result of the guess with the user's previous guesses
       * Lets the user know if they have guessed successfully or run out of
         attempts.

       {{ docSignature [docEmbedSignatureLink do stubs.gameLoop] }}

    ## Load the dictionary file

       Thus far we've been assuming that a bunch of five letter words
       represented by a {type Set} of {type Text} will be provided as an
       argument to our functions. We still need to write the function which
       generates this data. To do that we'll read in a file.

       Try to write a function,
       {{ docLink (docEmbedTermLink do stubs.loadDict) }}, which returns the
       words in the
       [words file](https://gist.github.com/rlmark/fef2a315cba90522cc1dd81461070109).
       Each five letter word is separated by a newline character. For the sake
       of convenience you might want to place it in the same folder where
       you're calling the UCM from.

       {{ docSignature [docEmbedSignatureLink do stubs.loadDict] }}

    ## Write the `main` function

       Your `main` function is what the ucm `run` command will execute. It
       should do the following:

       * Create the target word (hard-coding it is fine for now)
       * Read the dictionary file
       * Kick off the game loop 🍾

       When you're done post your wordle in the
       [#beginner-friendly slack channel](http://unison-lang.org/slack) so the
       Unison crew and others can ~~procrastinate~~ play it! 😁

       {{
       Folded
         true
         {{
         {{ wordle.utils.emojis.hint }}
         **See a breakdown of each of the arguments in {{
         (docLink (docEmbedTermLink do stubs.gameLoop)) }}**
         }}
         {{
         {{ (docSignature [docEmbedSignatureLink do stubs.gameLoop]) }}

         Imagine we call {{ (docLink (docEmbedTermLink do stubs.gameLoop)) }}
         with the following named arguments:
         {{
         (docExample 3 do
           turns target results -> stubs.gameLoop turns target results)
         }}.

         * `turns` is a {type Nat} representing the number of guesses a user
           has had
         * `target` is the word of the day
         * `results` is the history of the user's guesses, for rendering
           purposes
         * The `Ask` ability requirement can be thought of as an environment
           which provides the dictionary

         Think about which of these are tracking state which should change
         based on the user's input.
         }} }}

       {{
       Folded
         true
         {{
         {{ learnMore }} **How to read files using the {type IO} ability**
         }}
         {{
         To perform a file read we'll need {readFileUtf8} function from base.

             @signature{readFileUtf8}

         * {type FilePath} is the type representing directories and files. It's
           constructed from a {type Text} value representing the path: ``
           (FilePath "myFile.txt") ``
         * The {readFileUtf8} function reads the contents of a file as a
           {type Text} value but you can read bytes with {FilePath.readFile}.
         }} }}

       {{
       Folded
         true
         {{
         {{ learnMore }} **Handling the {type Ask} ability**
         }}
         {{
         The handler for {type Ask} is called {provide}.

             @signature{provide}

         When functions call {ask} for a value in the environment, it makes
         sense that the value they should get is supplied by {provide}.

         The second argument to {provide} is a delayed computation.

         Note that `provide 42 '(myAskFunction a b)` is different from
         `provide 42 'myAskFunction a b`.
         [Read more about this difference here.](https://www.unison-lang.org/learn/fundamentals/values-and-functions/delayed-computations/)
         }} }}

       {{
       Folded
         true
         {{
         {{ learnMore }} **Packaging and sharing Unison code**
         }}
         {{
         To share your Unison source code, `push` your code to your Unison
         Share and set its visibility to public in the Share UI.

         ``` ucm
         wordle/main> push
         ```

         The push command with no arguments will push the current namespace to
         a correspondingly named remote repository on Unison Share.

         You can also create a standalone executable file from your main
         function for other folks to run with the
         [`compile`](https://www.unison-lang.org/learn/ucm-commands/#compile)
         command in the UCM.
         [Read more about standalone binaries here](https://www.unison-lang.org/learn/usage-topics/running-programs/#stand-alone-binaries)
         }} }}

    ## Resources

       * [Download link for 5 letter word dictionary file](https://gist.github.com/rlmark/fef2a315cba90522cc1dd81461070109)
       * [Providing handlers for Unison abilities](https://www.unison-lang.org/learn/fundamentals/abilities/using-abilities-pt2/)
       * [How to run and package Unison programs](https://www.unison-lang.org/learn/usage-topics/running-programs/#stand-alone-binaries)

    ## Solutions

       {{
       Folded
         true
         {{
         {{ answer }}
         **{{ (docLink (docEmbedTermLink do basic.gameLoop)) }} implementation**
         }}
         {{
         {{ (docLink (docEmbedTermLink do basic.gameLoop)) }} is a recursive
         function which determines if the user has won, keeps track of the
         state of the user's turn, and prints the user's past guesses.

         {{
         (docSource [docSourceElement (docEmbedTermLink do basic.gameLoop) []])
         }}
         }} }}

       {{
       Folded
         true
         {{
         {{ answer }}
         **{{ (docLink (docEmbedTermLink do basic.loadDict)) }} implementation**
         }}
         {{
         {{ (docLink (docEmbedTermLink do stubs.loadDict)) }} loads the
         {type Text} from the dictionary file as raw text, then splits it on
         the new line character.

         {{
         (docSource [docSourceElement (docEmbedTermLink do basic.loadDict) []])
         }}

         {{ (docLink (docEmbedTermLink do basic.readFile)) }} is the function
         which handles the file reading as described above. Inside {{
         (docLink (docEmbedTermLink do basic.readFile)) }} is a recursive
         function calling {getBytes} in 4096 byte chunks at a time (the size of
         a page of memory in most OS architectures).

         {{
         (docSource [docSourceElement (docEmbedTermLink do basic.readFile) []])
         }}
         }} }}

       {{
       Folded
         true
         {{
         {{ answer }}
         **{{ (docLink (docEmbedTermLink do main)) }} function implementation**
         }}
         {{
         {{ (docLink (docEmbedTermLink do main)) }} is our "edge of the world
         🗺" function. We've hard-coded the file path to a dictionary file, and
         hard-coded the target word for this iteration of the code.

         It's here that we provide a handler for the {type Ask} ability. The
         handler for {type Ask} is {provide}, which provides the set of five
         letter words as its first argument to the {{
         (docLink (docEmbedTermLink do basic.gameLoop)) }} function which
         requires it.

         {{ (docSource [docSourceElement (docEmbedTermLink do main) []]) }}
         }} }}

    ## Next steps

       {{ next }}
       [Check out the challenge task for this lab]({{
       docLink (docEmbedTermLink do hard)
       }})

       {{ next }}
       [Explore other ways to extend this code]({{
       docLink (docEmbedTermLink do challenges)
       }})
  }}

docs.labs.wordle.docs.gameLoop.fileTest : '{IO, Exception} ()
docs.labs.wordle.docs.gameLoop.fileTest _ =
  filePath = FilePath "test"
  fileHandle = FilePath.open filePath FileMode.Read
  performRead fileHandle =
    use Text ++
    first = getBytes fileHandle 5
    second = getBytes fileHandle 5
    text = first |> fromUtf8 ++ (second |> fromUtf8)
    printLine text
  bracket (do fileHandle) Handle.close performRead

docs.labs.wordle.docs.hard : Doc
docs.labs.wordle.docs.hard =
  {{
  # 🤖 Challenge: Wordle solver

    But wait, the humans can't have all the fun! Yes, our computer friends want
    to play Wordle too. Our challenge to you now that you've written a Wordle
    clone is to write a Wordle __solver__.

    This is a freeform challenge, and we're excited to see what you produce!

    Think about some of the ways you can reduce the set of dictionary words
    based on previous guesses.

    It's ok if your Wordle solver takes in the target word as an input for
    verification, but it would be cheating to use it otherwise. 🥸

    {{
    Folded
      true
      {{
      {{ wordle.utils.emojis.hint }} **Suggested signatures**
      }}
      {{
      You could try something like the following as an overall signature: {{
      (docSignature [docEmbedSignatureLink do solve]) }}

      {{ (docLink (docEmbedTermLink do solve)) }} might call two helper
      functions in a loop: {{
      (docSignature
        [docEmbedSignatureLink do guesser, docEmbedSignatureLink do refine]) }}
      }} }}
  }}

docs.labs.wordle.docs.intro : Doc
docs.labs.wordle.docs.intro =
  {{
  # 🧩 Wordle clone lab intro

    The Unison team has playing and sharing variations on Wordle as of late! We
    want more Wordles to do! Your first overall project is to write a command
    line app for others to play.

    If you haven’t ever tried Wordle,
    [give it a shot here.](https://www.nytimes.com/games/wordle/index.html)
    It’s free... for now!

    For the uninitiated, the rules are simple: a player has 6 guesses to figure
    out a target 5 letter word. If a letter from the guess is present in the
    target word, but in the wrong location, that letter from the player's guess
    turns yellow, if a letter is present in the word and in the right location,
    the letter turns green. The player wins if they are able to guess the
    target word in 6 guesses or less. If the player loses, the word is lost to
    the sands of time. ⏳😢

    {{
    Video.video
      "/assets/labs/wordle/wordleCloneIntro.mp4"
      "/assets/labs/wordle/wordle.png" }}

    ## What this project covers

       **Unison fundamentals:**

       * Functions, values, and tuples
       * Basic collection manipulation and translations
       * Constructing and decomposing data types
       * Using basic abilities from `base`

       **IO operations:**

       * Console interactions
       * File reading

       **UCM workflow:**

       * Incorporating hosted library code
       * Running a program + packaging it for sharing

    ## How should I proceed through the lab?

       We've broken things up into broad sections to tackle. The
       [project breakdown]({{ docLink (docEmbedTermLink do breakdown) }})
       provides the highest level implementation suggestions, with links to
       deep-dives for each component. Each component section starts with a
       general suggestion for what to implement and provides explanations,
       example videos, and references for how to accomplish various tasks. You
       can tackle things in your own way, or unfold the hints (
       {{ wordle.utils.emojis.hint }}), answers (
       {{ wordle.utils.emojis.answer }}), and opportunities to learn more (
       {{ wordle.utils.emojis.learnMore }}) for as much structure as you need.

       Don't hesitate to ask questions if you have them! The #beginner-friendly
       channel in the [Unison Discord](https://discord.gg/unison) is a good
       place to ask.

    ## Next steps

       {{ emojis.next }}
       [Head to the project breakdown for an implementation plan]({{
       docLink (docEmbedTermLink do breakdown)
       }})
  }}

docs.labs.wordle.docs.validation : Doc
docs.labs.wordle.docs.validation =
  use basic overrideLookup
  use wordle.utils.emojis learnMore
  {{
  # ✅ Validate user guesses

    While we can now create {type basic.Target} and {type basic.Guess} values
    and print the [Result]({type stubs.Result}) of their evaluation to the
    console, we're missing a key part of the Wordle experience! A user should
    not be able to guess a word that's shorter or longer than five characters,
    and the user should not be able to guess a nonsense word. If the user tries
    to do this, they should get a helpful message and have the opportunity to
    guess again.

    Given the signature below, write the function,
    {{ docLink (docEmbedTermLink do stubs.getUserInput) }}:

    {{ docSignature [docEmbedSignatureLink do stubs.getUserInput] }}

    It should do the following:

    * Read the user input from the console
    * Check its length
    * Check if it's a real word using the `Set Text` representing valid 5
      letter words.
      * Let the user override the dictionary validation (pluralization and
        past-tense aren't well reflected)
    * Continue to prompt the user until the user enters a valid guess

    {{
    Folded
      true
      {{
      {{ learnMore }} **Getting user input with `readLine`**
      }}
      {{
      We learned how to print a response to the console with {type IO} using
      {printLine}—now we need to __get__ the user's response. The function for
      that is {readLine} from the `base` library.

          @signature{readLine}

      {readLine} is a
      [delayed computation](https://www.unison-lang.org/learn/fundamentals/values-and-functions/delayed-computations/),
      so it won't try to read the user's input unless we call it with the `!`
      operator. The `!` operator is syntactic sugar for calling a function with
      no arguments, `() -> a`.
      }} }}

    {{
    Folded
      true
      {{
      {{ emojis.video }} **Running the console in a loop**
      }}
      {{
      Watch an example of running input and output in a loop:

      {{
      (Video.video
        "/assets/labs/wordle/consoleLoop.mp4" "/assets/labs/wordle/wordle.png")
      }}
      }} }}

    {{
    Folded
      true
      {{
      {{ learnMore }} **Using the {type Ask} ability**
      }}
      {{
      In the signature provided for
      {{ (docLink (docEmbedTermLink do stubs.getUserInput)) }}, we're using the
      {type Ask} ability to represent the data we receive when we read the
      dictionary file into memory. {type Ask} has one request constructor,
      {ask} which we can call when we need to inspect the dictionary data.
      Otherwise, the {type Ask} ability requirement can simply be passed
      through the function call chain.

      Use the {type Ask} ability when you need to pass around data in an
      environment, but don't want to provide it explicitly as an argument to
      each upstream function.
      }} }}

    ## Resources

       * [Unison syntax for delayed computations](https://www.unison-lang.org/learn/fundamentals/values-and-functions/delayed-computations/)
       * [If then and else clauses](https://www.unison-lang.org/learn/fundamentals/control-flow/if-then-and-else/)
       * [Using abilities in Unison](https://www.unison-lang.org/learn/fundamentals/abilities/using-abilities-pt1/)
       * [Looping conventions in Unison](https://www.unison-lang.org/learn/fundamentals/control-flow/looping/)

    ## Solutions

       {{
       Folded
         true
         {{
         {{ wordle.utils.emojis.answer }}
         **Walk through rendering and running what we have so far**
         }}
         {{
         The implementation for {{
         (docLink (docEmbedTermLink do basic.getUserInput)) }} is a series of
         if/else clauses. (Alternatively, you could use pattern matching.)

         {{
         (docSource
           [docSourceElement (docEmbedTermLink do basic.getUserInput) []]) }}

         We have to call the {readLine} function with `!` because it's a
         delayed computation and would otherwise never prompt the user for
         input. We then strip trailing whitespace and lowercase the input by
         default with {{ (docLink (docEmbedTermLink do Text.normalize)) }}.

         The first condition that we check is the length of the user's input.
         If it's not ``5``, we start the {{
         (docLink (docEmbedTermLink do basic.getUserInput)) }} function over
         again.

         The second condition is if the user's guess is in the dictionary,
         represented by a {type Set} of {type Text}. We're using the {type Ask}
         ability to provide this information. We'll provide the dictionary to
         the Ask ability in a later step.

         Finally, we provide the user an override option with
         {{ (docLink (docEmbedTermLink do overrideLookup)) }}. The dictionary
         provided doesn't do a great job at identifying pluralized versions of
         words or past-tense verb forms. (See the
         [challenge options]({{ (docLink (docEmbedTermLink do challenges)) }})
         for some ideas about how to solve this.)

         {{
         (docSource [docSourceElement (docEmbedTermLink do overrideLookup) []])
         }}

         Only if the word is 5 letters long, present in the dictionary
         {type Set}, or if the user accepts the override will we then call the
         {{ (docLink (docEmbedTermLink do basic.Guess.fromText)) }} function we
         wrote earlier.
         }} }}

    ## Next steps

       {{ emojis.next }}
       [Game loop state and dictionary]({{
       docLink (docEmbedTermLink do docs.gameLoop)
       }})
  }}

docs.labs.wordle.solutions.basic.countLetters : [Char] -> Map Char Nat
docs.labs.wordle.solutions.basic.countLetters charList =
  charList
    |> List.sort
    |> groupConsecutive
    |> List.map (Nonempty.head &&& List.Nonempty.size)
    |> Map.fromList

docs.labs.wordle.solutions.basic.gameLoop :
  Nat -> basic.Target -> [[basic.Result]] ->{IO, Exception, Ask (Set Text)} ()
docs.labs.wordle.solutions.basic.gameLoop turn target pastGuesses =
  use List :+
  use Nat + >=
  if turn >= 6 then printLine "Alas! Better luck next time! 🤡"
  else
    guess = basic.getUserInput()
    result = basic.Guess.score guess target
    results = pastGuesses :+ result
    printLine (basic.renderGuesses results)
    if basic.isVictory result then printLine "🎉 Yay! 🎊"
    else docs.labs.wordle.solutions.basic.gameLoop (turn + 1) target results

docs.labs.wordle.solutions.basic.getUserInput :
  '{IO, Exception, Ask (Set Text)} basic.Guess
docs.labs.wordle.solutions.basic.getUserInput _ =
  use Nat !=
  use basic.Guess fromText
  use docs.labs.wordle.solutions.basic getUserInput
  input = readLine()
  normalized = Text.normalize input
  if Text.size normalized != 5 then
    printLine "🖐 guess must be a 5 letter word"
    getUserInput()
  else
    dict = ask
    if Set.contains normalized dict then fromText normalized
    else
      acceptOverride = basic.overrideLookup normalized ()
      if acceptOverride then fromText normalized else getUserInput()

docs.labs.wordle.solutions.basic.Guess.fromText : Text -> basic.Guess
docs.labs.wordle.solutions.basic.Guess.fromText input =
  normalized = Text.normalize input
  charList = toCharList normalized |> jsonschema.lib.base.data.List.indexed
  basic.Guess.Guess charList

docs.labs.wordle.solutions.basic.Guess.score :
  basic.Guess -> basic.Target -> [basic.Result]
docs.labs.wordle.solutions.basic.Guess.score guess target =
  use List :+
  use Map adjust
  use Nat -
  use basic Result Target.Target
  use basic.Result NotFound
  scoreHelper :
    (basic.Target, [Result]) -> (Char, Nat) -> (basic.Target, [Result])
  scoreHelper targetAccs = cases
    (c, i) ->
      (target', acc) = targetAccs
      (Target.Target m ls) = target'
      if basic.inLocation (c, i) target' then
        ( Target.Target (adjust (x -> x - 1) c m) ls
        , acc :+ basic.Result.InPlace c
        )
      else
        match Map.get c m with
          Optional.None -> (target', acc :+ NotFound c)
          Some 0 -> (target', acc :+ NotFound c)
          Some _ ->
            ( Target.Target (adjust (x -> x - 1) c m) ls
            , acc :+ basic.Result.Exists c
            )
  let
    (basic.Guess.Guess list) = guess
    (_, result) = List.foldLeft scoreHelper (target, []) list
    result

docs.labs.wordle.solutions.basic.inLocation :
  (Char, Nat) -> basic.Target -> Boolean
docs.labs.wordle.solutions.basic.inLocation tup = cases
  basic.Target.Target _ indexedChars -> Set.contains tup indexedChars

docs.labs.wordle.solutions.basic.isVictory : [basic.Result] -> Boolean
docs.labs.wordle.solutions.basic.isVictory result =
  List.all
    (cases
      basic.Result.InPlace _ -> true
      _                      -> false) result

docs.labs.wordle.solutions.basic.loadDict :
  FilePath -> '{IO, Exception} Set Text
docs.labs.wordle.solutions.basic.loadDict filePath _ =
  if FilePath.exists filePath then
    printLine "📚 Dictionary found! This may take a second... ⏰"
    text = (<|) basic.readFile filePath ()
    t = xml.lib.base.Text.split ?\n text |> Set.fromList
    printLine "📗 Dictionary created."
    t
  else Exception.raise (Generic.failure "Dictionary file not found" filePath)

docs.labs.wordle.solutions.basic.loadDictBuiltin :
  '{IO, Exception} Optional (Set Text)
docs.labs.wordle.solutions.basic.loadDictBuiltin _ =
  use FilePath exists
  use Text size
  loc1 = FilePath "/usr/share/dict/words"
  loc2 = FilePath "/usr/dict/words"
  filePath : Optional FilePath
  filePath =
    if exists loc1 then Some loc1
    else if exists loc2 then Some loc2 else Optional.None
  Optional.map
    (f ->
      let
        printLine "📚 Dictionary found! This may take a second... ⏰"
        text = basic.readFile f ()
        filtered =
          xml.lib.base.Text.split ?\n text
            |> List.filter (w -> size w === 5 || size w === 4)
        t = Set.fromList filtered
        printLine "📗 Dictionary created."
        t)
    filePath

docs.labs.wordle.solutions.basic.loadDictBuiltin.doc : Doc
docs.labs.wordle.solutions.basic.loadDictBuiltin.doc =
  {{ Only for mac / linux users }}

docs.labs.wordle.solutions.basic.main : '{IO, Exception} ()
docs.labs.wordle.solutions.basic.main _ =
  printLine "🥳 Welcome to WORDLE!"
  filePath = FilePath "dict"
  dict = basic.loadDict filePath ()
  target = "party"
  if Boolean.not (Text.size target === 5) then
    Exception.raise
      (Generic.failure "The word of the day must be 5 letters long" target)
  else
    printLine "Guess a five letter word"
    provide dict do basic.gameLoop 0 (basic.Target.fromText target) [[]]

docs.labs.wordle.solutions.basic.overrideLookup :
  Text -> '{IO, Exception} Boolean
docs.labs.wordle.solutions.basic.overrideLookup normalized _ =
  use Text ++
  printLine
    ("🤔 That wasn't in the dictionary.\nWould you like to use "
      ++ normalized
      ++ " as your guess?")
  basic.yesNo()

docs.labs.wordle.solutions.basic.readFile : FilePath -> '{IO, Exception} Text
docs.labs.wordle.solutions.basic.readFile filePath =
  read : Handle ->{IO, Exception} Bytes
  read fileHandle =
    go acc =
      use Bytes ++
      use Nat <
      bs = getBytes fileHandle 4096
      if Bytes.size bs < 4096 then acc ++ bs else go (acc ++ bs)
    go Bytes.empty
  fileHandle : '{IO, Exception} Handle
  fileHandle _ = FilePath.open filePath FileMode.Read
  do bracket fileHandle Handle.close (file -> read file |> fromUtf8)

docs.labs.wordle.solutions.basic.renderChar : basic.Result -> Text
docs.labs.wordle.solutions.basic.renderChar = cases
  basic.Result.NotFound c ->
    Char.toText (ascii.toUpper c) |> bg.black.span |> fg.white.span
  basic.Result.Exists c ->
    Char.toText (ascii.toUpper c) |> bg.black.span |> fg.yellow.span
  basic.Result.InPlace c ->
    Char.toText (ascii.toUpper c) |> bg.black.span |> fg.green.span

docs.labs.wordle.solutions.basic.renderGuesses : [[basic.Result]] -> Text
docs.labs.wordle.solutions.basic.renderGuesses resultList =
  List.map basic.renderRow resultList |> Text.join "\n"

docs.labs.wordle.solutions.basic.renderRow : [basic.Result] -> Text
docs.labs.wordle.solutions.basic.renderRow results =
  Text.join "" (List.map basic.renderChar results)

docs.labs.wordle.solutions.basic.renderTest : '{IO, Exception} ()
docs.labs.wordle.solutions.basic.renderTest = do
  use basic Guess.fromText
  use basic.Guess score
  guess1 = Guess.fromText "hello"
  guess2 = Guess.fromText "there"
  target = basic.Target.fromText "world"
  results1 = score guess1 target
  results2 = score guess2 target
  printLine (basic.renderGuesses [results1, results2])

docs.labs.wordle.solutions.basic.Target.fromText : Text -> basic.Target
docs.labs.wordle.solutions.basic.Target.fromText input =
  normalized = Text.normalize input
  charList = toCharList normalized
  charsWithIndex =
    charList
      |> jsonschema.lib.base.data.List.indexed
      |> jsonschema.lib.base.data.Set.fromList
  mapChars = countLetters charList
  basic.Target.Target mapChars charsWithIndex

docs.labs.wordle.solutions.basic.Text.normalize : Text -> Text
docs.labs.wordle.solutions.basic.Text.normalize input =
  Text.trim input
    |> toCharList
    |> jsonschema.lib.base.data.List.map ascii.toLower
    |> fromCharList

docs.labs.wordle.solutions.basic.tmp.writeDictFile : '{IO, Exception} ()
docs.labs.wordle.solutions.basic.tmp.writeDictFile _ =
  f = FilePath "/usr/share/dict/words"
  text = basic.readFile f ()
  filtered = Text.split ?\n text |> List.filter (w -> Text.size w === 5)
  filteredText = Text.join "\n" filtered
  tmp.writeFile (FilePath "dict") filteredText

docs.labs.wordle.solutions.basic.tmp.writeFile :
  FilePath -> Text ->{IO, Exception} ()
docs.labs.wordle.solutions.basic.tmp.writeFile path content =
  fileHandle : '{IO, Exception} Handle
  fileHandle _ = FilePath.open path Write
  bracket fileHandle Handle.close (h -> putBytes h (Text.toUtf8 content))

docs.labs.wordle.solutions.basic.yesNo : '{IO, Exception} Boolean
docs.labs.wordle.solutions.basic.yesNo _ =
  printLine "enter \"y\" or \"n\""
  input = readLine() |> Text.normalize
  match input with
    "y" -> true
    "n" -> false
    _   -> docs.labs.wordle.solutions.basic.yesNo()

docs.labs.wordle.solutions.stubs.characterResult :
  (Char, Nat) -> stubs.Target -> stubs.Result
docs.labs.wordle.solutions.stubs.characterResult tuple target =
  todo "implement characterResult"

docs.labs.wordle.solutions.stubs.gameLoop :
  Nat -> stubs.Target -> [[stubs.Result]] ->{IO, Exception, Ask (Set Text)} ()
docs.labs.wordle.solutions.stubs.gameLoop turn target pastGuesses =
  todo "implement gameLoop"

docs.labs.wordle.solutions.stubs.getUserInput :
  '{IO, Exception, Ask (Set Text)} stubs.Guess
docs.labs.wordle.solutions.stubs.getUserInput _ = todo "implement getUserInput"

docs.labs.wordle.solutions.stubs.Guess.doc : Doc
docs.labs.wordle.solutions.stubs.Guess.doc =
  {{
  Implement the {type stubs.Guess} data constructor, replacing the {type TODO}
  placeholder with other types.
  }}

docs.labs.wordle.solutions.stubs.Guess.fromText : Text -> stubs.Guess
docs.labs.wordle.solutions.stubs.Guess.fromText input = todo "Guess.fromText"

docs.labs.wordle.solutions.stubs.Guess.score :
  stubs.Guess -> stubs.Target -> [stubs.Result]
docs.labs.wordle.solutions.stubs.Guess.score = todo "implement Guess.score"

docs.labs.wordle.solutions.stubs.guesser : Set Text -> stubs.Guess
docs.labs.wordle.solutions.stubs.guesser dict = todo "implement guesser"

docs.labs.wordle.solutions.stubs.inLocation :
  (Char, Nat) -> stubs.Target -> Boolean
docs.labs.wordle.solutions.stubs.inLocation tup target =
  todo "implement inLocation"

docs.labs.wordle.solutions.stubs.isVictory : [stubs.Result] -> Boolean
docs.labs.wordle.solutions.stubs.isVictory result = todo "implement isVictory"

docs.labs.wordle.solutions.stubs.loadDict :
  FilePath -> '{IO, Exception} Set Text
docs.labs.wordle.solutions.stubs.loadDict filePath _ =
  todo "implement loadDict"

docs.labs.wordle.solutions.stubs.loadDictBuiltin :
  '{IO, Exception} Optional (Set Text)
docs.labs.wordle.solutions.stubs.loadDictBuiltin _ =
  todo "implement loadDictBuiltin"

docs.labs.wordle.solutions.stubs.main : '{IO, Exception} ()
docs.labs.wordle.solutions.stubs.main _ = todo "implement main"

docs.labs.wordle.solutions.stubs.overrideLookup :
  Text -> '{IO, Exception} Boolean
docs.labs.wordle.solutions.stubs.overrideLookup normalized _ =
  todo "implement overrideLookup"

docs.labs.wordle.solutions.stubs.readFile : FilePath -> '{IO, Exception} Text
docs.labs.wordle.solutions.stubs.readFile filePath = todo "implement readFile"

docs.labs.wordle.solutions.stubs.refine :
  Set Text -> stubs.Guess -> stubs.Target -> Set Text
docs.labs.wordle.solutions.stubs.refine dict guess target =
  todo "implement refine"

docs.labs.wordle.solutions.stubs.renderChar : stubs.Result -> Text
docs.labs.wordle.solutions.stubs.renderChar result =
  todo "implement renderChar"

docs.labs.wordle.solutions.stubs.renderGuesses : [[stubs.Result]] -> Text
docs.labs.wordle.solutions.stubs.renderGuesses resultList =
  todo "implement renderGuesses"

docs.labs.wordle.solutions.stubs.renderRow : [stubs.Result] -> Text
docs.labs.wordle.solutions.stubs.renderRow results = todo "implement renderRow"

docs.labs.wordle.solutions.stubs.renderTest : '{IO, Exception} ()
docs.labs.wordle.solutions.stubs.renderTest = do todo "implement renderTest"

docs.labs.wordle.solutions.stubs.Result.doc : Doc
docs.labs.wordle.solutions.stubs.Result.doc =
  {{
  Replace the placeholder type {type TODO} with what you think the
  {type stubs.Result} type should enclose.
  }}

docs.labs.wordle.solutions.stubs.solve :
  Set Text -> stubs.Target -> [stubs.Guess]
docs.labs.wordle.solutions.stubs.solve dict target = todo "implement solve"

docs.labs.wordle.solutions.stubs.Target.doc : Doc
docs.labs.wordle.solutions.stubs.Target.doc =
  {{
  Implement the {type stubs.Target} data constructor, replacing the {type TODO}
  placeholder with other types
  }}

docs.labs.wordle.solutions.stubs.Target.fromText : Text -> stubs.Target
docs.labs.wordle.solutions.stubs.Target.fromText input = todo "Target.fromText"

docs.labs.wordle.solutions.stubs.yesNo : '{IO, Exception} Boolean
docs.labs.wordle.solutions.stubs.yesNo _ = todo "implement yesNo"

docs.labs.wordle.utils.Callout.body : Callout -> Doc
docs.labs.wordle.utils.Callout.body = cases Callout.Callout _ _ body -> body

docs.labs.wordle.utils.Callout.body.modify :
  (Doc ->{g} Doc) -> Callout ->{g} Callout
docs.labs.wordle.utils.Callout.body.modify f = cases
  Callout.Callout emoji title body -> Callout.Callout emoji title (f body)

docs.labs.wordle.utils.Callout.body.set : Doc -> Callout -> Callout
docs.labs.wordle.utils.Callout.body.set body1 = cases
  Callout.Callout emoji title _ -> Callout.Callout emoji title body1

docs.labs.wordle.utils.Callout.emoji : Callout -> Doc
docs.labs.wordle.utils.Callout.emoji = cases Callout.Callout emoji _ _ -> emoji

docs.labs.wordle.utils.Callout.emoji.modify :
  (Doc ->{g} Doc) -> Callout ->{g} Callout
docs.labs.wordle.utils.Callout.emoji.modify f = cases
  Callout.Callout emoji title body -> Callout.Callout (f emoji) title body

docs.labs.wordle.utils.Callout.emoji.set : Doc -> Callout -> Callout
docs.labs.wordle.utils.Callout.emoji.set emoji1 = cases
  Callout.Callout _ title body -> Callout.Callout emoji1 title body

docs.labs.wordle.utils.Callout.title : Callout -> Doc
docs.labs.wordle.utils.Callout.title = cases Callout.Callout _ title _ -> title

docs.labs.wordle.utils.Callout.title.modify :
  (Doc ->{g} Doc) -> Callout ->{g} Callout
docs.labs.wordle.utils.Callout.title.modify f = cases
  Callout.Callout emoji title body -> Callout.Callout emoji (f title) body

docs.labs.wordle.utils.Callout.title.set : Doc -> Callout -> Callout
docs.labs.wordle.utils.Callout.title.set title1 = cases
  Callout.Callout emoji _ body -> Callout.Callout emoji title1 body

docs.labs.wordle.utils.emojis.answer : Doc
docs.labs.wordle.utils.emojis.answer = {{ 🔑 }}

docs.labs.wordle.utils.emojis.getStarted : Doc
docs.labs.wordle.utils.emojis.getStarted = {{ 🖥 }}

docs.labs.wordle.utils.emojis.hint : Doc
docs.labs.wordle.utils.emojis.hint = {{ ✨ }}

docs.labs.wordle.utils.emojis.learnMore : Doc
docs.labs.wordle.utils.emojis.learnMore = {{ 📚 }}

docs.labs.wordle.utils.emojis.next : Doc
docs.labs.wordle.utils.emojis.next = {{ 👉 }}

docs.labs.wordle.utils.emojis.video : Doc
docs.labs.wordle.utils.emojis.video = {{ 🎥 }}

docs.labs.wordle.utils.foldedCallout : Callout -> Doc
docs.labs.wordle.utils.foldedCallout = cases
  Callout.Callout emoji title body ->
    {{
    docCallout (Some
    emoji){{ {{ Folded true {{ docBold {{ title }} }} {{ body }} }} }}
    }}

docs.labs.wordle.utils.TODO : Doc
docs.labs.wordle.utils.TODO = {{ 🏗 TODO 🚧 }}

docs.languageReference.abilitiesAndAbilityHandlers : Doc
docs.languageReference.abilitiesAndAbilityHandlers =
  {{
  # Abilities and ability handlers

    Unison provides a convenient feature called __abilities__ which lets you
    use the same ordinary Unison syntax for programs that do (asynchronous)
    I/O, stream processing, exception handling, parsing, distributed
    computation, and lots more. Unison's system of abilities (often called
    "algebraic effects" in the literature) is based on
    [the Frank language by Sam Lindley, Conor McBride, and Craig McLaughlin](https://arxiv.org/pdf/1611.09259.pdf).
    Unison diverges slightly from the scheme detailed in this paper. In
    particular:

    * Unison's ability polymorphism is provided by ordinary polymorphic types,
      and a Unison type with an empty ability set explicitly disallows any
      abilities. In Frank, the empty ability set implies an ability-polymorphic
      type.
    * Unison doesn't overload function application syntax to do ability
      handling; instead it has a separate
      [`handle` construct]({abilityHandlers}) for this purpose.

    {{ abilitiesInFunctionTypes }}

    {{ theTypecheckingRuleForAbilities }}

    {{ abilityInference }}

    {{ userDefinedAbilities }}

    {{ abilityHandlers }}

    {{ patternMatchingOnAbilityConstructors }}
  }}

docs.languageReference.abilitiesInFunctionTypes : Doc
docs.languageReference.abilitiesInFunctionTypes =
  {{
  # Abilities in function types

    The general form for a function type in Unison is `I ->{A} O`, where `I` is
    the input type of the function, `O` is the output type, and `A` is the set
    of __ability requirements__ of the function. More generally, this can be
    any comma-separated list of types, like `I ->{A1,A2,A3} O`.

    A function type in Unison like `A -> B` is really syntactic sugar for a
    type `A ->{e} B` where `e` is some set of abilities, possibly empty. A
    function that definitely requires no abilities has a type like `A ->{} B`
    (it has an empty set of abilities).
  }}

docs.languageReference.abilityDeclaration : Doc
docs.languageReference.abilityDeclaration =
  {{
  {{ glossary.abilityDeclaration }}

  It takes the following general form:

  ``` unison
  unique|structural ability A p_1 p_2 … p_n where
      Request_1 : Type_1
      Request_2 : Type_2
      Request_n : Type_n
  ```

  This declares an ability type constructor `A` with type parameters `p_1`
  through `p_n`, and request constructors `Request_1` through `Request_n`

  **Examples**

      @source{type Throw}

      @source{type Store}
  }}

docs.languageReference.abilityHandlers : Doc
docs.languageReference.abilityHandlers =
  {{
  # Ability handlers

    {{
    docAside
      {{
      Learning materials for writing ability handlers are also
      [available on the website here](https://www.unison-lang.org/learn/fundamentals/abilities/writing-abilities/).
      }} }}

    A constructor `{A} T` for some ability `A` and some type `T` (or a function
    which uses such a constructor), can only be used in a scope where the
    ability `A` is provided. Abilities are provided by `handle` expressions:

    ``` unison
    handle e with h
    ```

    This expression gives `e` access to abilities handled by the function `h`.
    Specifically, if `e` has type `{A} T` and `h` has type `Request A T -> R`,
    then `handle e with h` has type `R`. The type constructor `Request` is a
    special builtin provided by Unison which will pass arguments of type
    `Request A T` to a handler for the ability `A`. Note that `h` __must__
    accept an argument of type `Request A T` to handle `e` of type `{A} T` -
    ultimately, a type error will result if an ability is required in a scope
    where it is not provided by an enclosing handle expression.

    The examples in the next section should help clarify how ability handlers
    work.
  }}

docs.languageReference.abilityInference : Doc
docs.languageReference.abilityInference =
  {{
  # Ability inference

    When inferring ability requirements for `f`, the ability requirements
    become the union of all requirements for functions that can be called
    within the body of the function.
  }}

docs.languageReference.abilityPatterns : Doc
docs.languageReference.abilityPatterns =
  {{
  **Ability patterns (or `Request` patterns)**

  An __ability pattern__ only appears in an ability handler and has one of two
  forms (see [Abilities and ability handlers]({abilitiesAndAbilityHandlers})
  for details):

  1. `{C p1 p2 … pn -> k}` where `C` is the name of an ability constructor in
     scope, and `p1` through `pn` are patterns such that `n` is the arity of
     `C`. Note that `n` may be zero. This pattern matches if the scrutinee
     reduces to a fully applied invocation of the ability constructor `C` and
     the patterns `p1` through `pn` match the arguments to the constructor. The
     scrutinee must be of type `Request A T` for some ability `{A}` and type
     `T`. The variable `k` will be bound to the continuation of the program. If
     the scrutinee has type `Request A T` and `C` has type `X ->{A} Y`, then
     `k` has type `Y -> {A} T`.
  2. `{p}` where `p` is a pattern. This matches the case where the computation
     is __pure__ (the value of type `Request A T` calls none of the
     constructors of the ability `{A}`). A pattern match on a `Request` is not
     complete unless this case is handled.

  See the section on
  [abilities and ability handlers]({abilitiesAndAbilityHandlers}) for examples
  of ability patterns.
  }}

docs.languageReference.absolutelyQualifiedIdentifiers : Doc
docs.languageReference.absolutelyQualifiedIdentifiers =
  {{
  # Absolutely qualified identifiers

    Note that absolutely qualified identifiers are much less prevalent with the
    advent of Unison projects. They refer to a term from the root of the entire
    codebase, not the root of a particular project, so their usage is limited
    to legacy support of a pre-project era.

    [Namespace-qualified identifiers]({namespaceQualifiedIdentifiers}) are
    relative to a “current” namespace, which the programmer can set (and
    defaults to the root of the current project). To ignore the current
    namespace, an identifier can have an __absolute qualifier__. An absolutely
    qualified name begins with a `.`. For example, the name `.base.List` always
    refers to the name `.base.List`, regardless of the current project or
    namespace, whereas the name `base.List` will refer to `lib.base.List` if
    the current namespace contains the `base` library in its `lib` namespace.
  }}

docs.languageReference.asPatterns : Doc
docs.languageReference.asPatterns =
  {{
  # As-patterns

    An __as-pattern__ has the form `v@p` where `v` is a
    [regular identifier]({identifiers}) and `p` is a pattern. This pattern
    matches if `p` matches, and the variable `v` will be bound in the body to
    the value matching `p`.

    For example, this expression evaluates to ``3``:

        @source{matchExpression}
  }}

docs.languageReference.basicLexicalForms : Doc
docs.languageReference.basicLexicalForms =
  {{
  # Basic lexical forms

    See the sections on:

    * [Identifiers]({identifiers}), for example `foo`, `foo.bar`, and `+`.
    * [Blocks and statements]({blocksAndStatements}), for example: `x = 42`.
    * [Literals]({literals}), for example: ``1``, ``"hello"``, ``[1, 2, 3]``.
    * [Comments]({comments}), for example `-- this is a comment`.
    * [Pattern matching]({matchExpressionsAndPatternMatching}), for example
      `match (x,y) with (1, "hi") -> 42`.
  }}

docs.languageReference.blankPatterns : Doc
docs.languageReference.blankPatterns =
  {{
  # Blank patterns

    A __blank pattern__ has the form `_`. It matches any expression without
    creating a variable binding.

    For example:

    ```
    _ = 42
    "Always matches"
    ```
  }}

docs.languageReference.blocks.syntacticalPrecedence : Doc
docs.languageReference.blocks.syntacticalPrecedence =
  {{
  # Syntactic precedence

    Keywords that introduce blocks bind more tightly than
    [function application](./functionApplication). So `f let x` is the same as
    `f (let x)` and `f if b then p else q` is the same as
    `f (if b then p else q)`.

    Block keywords bind more tightly than
    [delayed computations]({languageReference.delayedComputations}) syntax. So
    {{ docCode {{ 'let x'' }} }} is the same as `_ -> let x` and
    `!if b then p else q` is the same as `(if b then p else q) ()`.

    Blocks eagerly consume expressions, so `if b then p else q + r` is the same
    as `if b then p else (q + r)`.
  }}

docs.languageReference.blocksAndStatements : Doc
docs.languageReference.blocksAndStatements =
  use Nat +
  {{
  # Blocks and statements

    A block is an expression that has the general form:

    ``` raw
    statement_1
    statement_2
    …
    statement_n
    expression
    ```

    A block can have zero or more statements, and the value of the whole block
    is the value of the final ``expression``. A statement is either:

    1. A [term definition]({termDefinition}) which defines a term within the
       scope of the block. The definition is not visible outside this scope,
       and is bound to a local name. Unlike top-level definitions, a
       block-level definition does not result in a hash, and cannot be
       referenced with a [hash literal]({literalHashReferences}).
    2. A [Unison expression]({expressions}). In particular, blocks often
       contain __action expressions__, which are expressions evaluated solely
       for their effects. An action expression has type `{A} T` for some
       ability `A` (see
       [Abilities and Ability Handlers]({abilitiesAndAbilityHandlers})) and
       some type `T`.
    3. A [`use` clause]({useClauses}).

    An example of a block:

    ```
    x = 4
    y = x + 2
    f a = a + y
    f 10
    ```

    A number of language constructs introduce blocks. These are detailed in the
    relevant sections of this reference. Wherever Unison expects an expression,
    a block can be introduced with the `let` keyword:

    ``` unison
    let <block>
    ```

    Where `<block>` denotes a block as described above.

    {{ lexicalSyntaxOfBlocks }}
  }}

docs.languageReference.booleanConjunctionDisjunction : Doc
docs.languageReference.booleanConjunctionDisjunction =
  {{
  # Boolean conjunction and disjunction

    A __Boolean conjunction expression__ is a {type Boolean} expression of the
    form `a && b` where `a` and `b` are {type Boolean} expressions. Note that
    {&&} is not a function, but built-in syntax.

    The evaluation semantics of `a && b` are equivalent to
    `if a then b else false`.

    A __Boolean disjunction expression__ is a {type Boolean} expression of the
    form `a || b` where `a` and `b` are {type Boolean} expressions. Note that
    {||} is not a function, but built-in syntax.

    The evaluation semantics of `a || b` are equivalent to
    `if a then true else b`.
  }}

docs.languageReference.booleanExpressions : Doc
docs.languageReference.booleanExpressions =
  {{
  # Boolean expressions

    A Boolean expression has type {type Boolean} which has two values, `` true
    `` and ``false``.

    {{ conditionalExpressions }}

    {{ booleanConjunctionDisjunction }}
  }}

docs.languageReference.builtInTypeConstructors : Doc
docs.languageReference.builtInTypeConstructors =
  {{
  # Built-in type constructors

    Unison has the following built-in type constructors.

    * `(->)` is the constructor of function types. A type `X -> Y` is the type
      of functions from `X` to `Y`.
    * {type Tuple} is the constructor of tuple types. See
      [tuple types]({tupleTypes}) for details on tuples.
    * {type List} is the constructor of list types. A type `List T` is the type
      of arbitrary-length sequences of values of type `T`. The type `[T]` is an
      alias for `List T`.
    * {type Request} is the constructor of requests for abilities. A type
      `Request A T` is the type of values received by ability handlers for the
      ability `A` where current continuation requires a value of type `T`.
  }}

docs.languageReference.builtInTypes : Doc
docs.languageReference.builtInTypes =
  {{
  # Built-in types

    Unison provides the following built-in types:

    * {type Nat} is the type of 64-bit natural numbers, also known as unsigned
      integers. They range from 0 to 18,446,744,073,709,551,615.
    * {type Int} is the type of 64-bit signed integers. They range from
      -9,223,372,036,854,775,808 to +9,223,372,036,854,775,807.
    * {type Float} is the type of
      [IEEE 754-1985](https://en.wikipedia.org/wiki/IEEE_754-1985)
      double-precision floating point numbers.
    * {type Boolean} is the type of Boolean expressions whose value is `` true
      `` or ``false``.
    * {type Bytes} is the type of arbitrary-length 8-bit byte sequences.
    * {type Text} is the type of arbitrary-length strings of Unicode text. They
      can be introduced with single quotes or triple quotes, for multi-line
      strings.
    * {type Char} is the type of a single Unicode character.
    * The trivial type `()` (pronounced “unit”) is the type of the nullary
      tuple. There is a single data constructor of type `()` and it’s also
      written ``()``.

    See [literals]({literals}) for more on how values of some of these types
    are constructed.
  }}

docs.languageReference.comments : Doc
docs.languageReference.comments =
  {{
  # Comments

    A line comment starts with `--` and is followed by any sequence of
    characters. A line that contains a comment can’t contain anything other
    than a comment and whitespace.

    Multi-line comments are supported by starting a comment block with `{-` and
    ending it with `-}`.

    Comments in Unison aren't actually committed to the Unison codebase. For
    that reason they're used primarily to annotate code while you're working on
    it, and not for documentation. If you want to add a comment to a definition
    that will be persisted in the codebase, use the {type Doc} syntax.

    ``` unison
    {-
      Hi there!
      {-
        This is a valid comment
      -}
      Comments will disappear when added to the codebase!
    -}
    ```

    A line starting with `---` is a __fold__. Any text following the fold is
    ignored by Unison.

    ``` unison
    --- Anything below this line is ignored by Unison.
    ```
  }}

docs.languageReference.conditionalExpressions : Doc
docs.languageReference.conditionalExpressions =
  {{
  # Conditional expressions

    A __conditional expression__ has the form `if c then t else f`, where `c`
    is an expression of type {type Boolean}, and `t` and `f` are expressions of
    any type, but `t` and `f` must have the same type.

    Evaluation of conditional expressions is non-strict. The evaluation
    semantics of `if c then t else f` are:

    * The condition `c` is always evaluated.
    * If `c` evaluates to ``true``, the expression `t` is evaluated and `f`
      remains unevaluated. The whole expression reduces to the value of `t`.
    * If `c` evaluates to ``false``, the expression `f` is evaluated and `t`
      remains unevaluated. The whole expression reduces to the value of `f`.

    The keywords `if`, `then`, and `else` each introduce a
    [block](./blocksAndStatements) as follows:

    ``` unison
    if
        true
      then
        "codeblock here"
      else
        "another codeblock"
    ```
  }}

docs.languageReference.constructorPatterns : Doc
docs.languageReference.constructorPatterns =
  use Optional None
  {{
  # Constructor patterns

    A __constructor pattern__ has the form `C p1 p2 … pn` where `C` is the name
    of a data constructor in scope, and `p1` through `pn` are patterns such
    that `n` is the {{ docTooltip {{ arity }} {{ {{ glossary.arity }} }} }} of
    `C`. Note that `n` may be zero. This pattern matches if the scrutinee
    reduces to a fully applied invocation of the data constructor `C` and the
    patterns `p1` through `pn` match the arguments to the constructor.

    For example, this expression uses {Some} and {None}, the constructors of
    the {type Optional} type, to return the 3rd element of the list `xs` if
    present or `0` if there was no 3rd element.

    ```
    xs = [0, 2, 3, 4, 5]
    match List.at 3 xs with
      None   -> 0
      Some x -> x
    ```
  }}

docs.languageReference.delayedComputations : Doc
docs.languageReference.delayedComputations =
  {{
  # Delayed computations

    An expression can appear __delayed__ as `do e` or ` 'e`, which are both the
    same as `_ -> e` and `() -> e`. If `e` has type `T`, then `do e` and ` 'e`
    both have the type `forall a. a -> T`.

    If `c` is a delayed computation, it can be __forced__ with `c()` or `!c`.
    The expression `c` must conform to a type `() -> t` for some type `t`, in
    which case `!c` has type `t`.

    Delayed computations are important for writing expressions that require
    [abilities]({abilitiesAndAbilityHandlers}). For example:

        @source{program}

    This example defines a small I/O program. The type `{IO, Exception} ()` by
    itself is not allowed as the type of a top-level definition, since the
    {type IO} and {type Exception} abilities must be provided by a handler, see
    [abilities and ability handlers]({abilitiesAndAbilityHandlers}). Instead,
    {program} has the type @inlineSignature{program} (note the {{
    docCode {{ ' }} }} indicating a delayed computation). Inside a handler for
    {type IO}, this computation can be forced with `!program`.

    Inside the program, `!readLine` has to be forced, as the type of {readLine}
    is @inlineSignature{readLine}, a delayed computation which, when forced,
    reads a line from standard input.

    {{ syntacticPrecedence }}
  }}

docs.languageReference.delayedComputations.program : '{IO, Exception} ()
docs.languageReference.delayedComputations.program = do
  use Text ++
  printLine "What is your name?"
  name = readLine()
  printLine ("Hello, " ++ name)

docs.languageReference.delayedComputations.syntacticPrecedence : Doc
docs.languageReference.delayedComputations.syntacticPrecedence =
  {{
  # Syntactic precedence

    The reserved symbols {{ docCode {{ ' }} }} and `!` bind more tightly than
    function application, So {{ docCode {{ 'f x }} }} is the same as
    `(_ -> f) x` and `!x + y` is the same as `(x ()) + y`.

    These symbols bind less tightly than keywords that introduce blocks, so {{
    docCode {{ do x }} }} and {{ docCode {{ 'let x }} }} are both the same as
    `_ -> let x` and `!if b then p else q` is the same as
    `(if b then p else q) ()`.

    Additional {{ docCode {{ ' }} }} and `!` combine in the following way:

    * `` do do syntacticPrecedence.x `` is the same as `(_ -> (_ -> x))` or
      `(_ _ -> x)`.
    * `!!x` is the same as `x () ()`.
    * `!'x` and {{ docCode {{ '!x }} }} are both the same as `x`.

    You can use parentheses to precisely control how {{ docCode {{ ' }} }} and
    `!` get applied.
  }}

docs.languageReference.delayedComputations.syntacticPrecedence.x : Nat
docs.languageReference.delayedComputations.syntacticPrecedence.x = 42

docs.languageReference.destructuringBinds : Doc
docs.languageReference.destructuringBinds =
  use List +: :+
  use Nat +
  {{
  # Destructuring binds

    Tuples and data types can be decomposed with
    [pattern matching]({matchExpressionsAndPatternMatching}), but Unison also
    provides several ways to more concisely bind variable names to the
    corresponding parts of a data structure.

    ## Destructuring tuples

       Variables can be assigned to the constituent parts of a tuple by
       surrounding the variable definition with parentheses and separating the
       variables with commas.

       ```
       tuple = (1, 2)
       let
         (first, second) = tuple
         first + second
       ```

       {{ style }} If a tuple is passed as an argument to a
       {{ docTooltip {{ lambda }} {{ {{ lambda }} }} }}, you can use the
       `cases` keyword as a way to destructure the tuple.

       ```
       jsonschema.lib.base.data.List.map
         (cases (first, second) -> second) [(1, 2), (3, 4)]
       ```

    ## Destructuring data types

       The fields of a data type can also be bound to variables by
       destructuring their {{
       docTooltip {{ data constructors }} {{ {{ dataConstructor }} }} }}

       Say you have a simple {type Box} type:

           @source{type Box}

       You could write a function that adds two `Box Nat` types together by
       accessing the {type Nat} elements like this:

           @source{addBox}

       So destructuring a data type takes the form
       `(DataConstructor field1 field2 … fieldN) = instanceOfDataType`

    ## Usage notes

       Currently, Unison does not support decomposition in
       [term definitions,]({termDefinition}) so a function which accepts a
       tuple or data type as a parameter cannot be destructured when the
       function parameter is first named. This means a
       [termDeclaration]({termDeclarations}) like @inlineSignature{addTwo}
       **can not** be implemented with a term definition which starts with
       `addTwo (one,two) = one + two`. The decomposition of the tuple would
       have to be done on a separate line.

       In some languages you can use list constructors like {+:} or {:+} to
       name separate elements in the list. We do not currently support that
       feature for term definitions, but you __can__ use them in pattern
       matching; see [list pattern matching]({languageReference.listPatterns})
       for more details.

       ``` unison
       -- you can't do this
       list = [1,2,3,4]
       one +: tail = list
       ```

       ``` unison
       list = [1, 2, 3, 4]

       (one +: tail) = list
       ```
  }}

docs.languageReference.destructuringBinds.addBox : Box Nat -> Box Nat -> Nat
docs.languageReference.destructuringBinds.addBox boxA boxB =
  use Nat +
  (Box a) = boxA
  (Box b) = boxB
  a + b

docs.languageReference.destructuringBinds.addTwo : (Nat, Nat) -> Nat
docs.languageReference.destructuringBinds.addTwo = cases
  (one, two) -> one Nat.+ two

docs.languageReference.documentationLiterals : Doc
docs.languageReference.documentationLiterals =
  {{
  # Documentation literals

    Documentation blocks have type {type Doc} - documentation is a first-class
    value in the language. `{{` starts a documentation block and `}}` finishes
    it. For example:

        @source{addingAndRemoving}

    More specifically, some important Doc features are:

    * Links to definitions are done with single open and close braces.
      `{List.drop}` is a term link, and `{type List}` is a type link.
    * `@signature{List.take}` or `@inlineSignature{List.take}` expands to the
      type signature of List.take either as a block or inline, respectively.
    * `@source{List.map}` expands to the full source of List.map
    * To insert another Doc value into another Doc, use nested double braces.
      `{{I am a doc {{thisDocValueWillBeDisplayed}} }}`
    * `@eval{someDefinition}` expands to the result of evaluating
      `someDefinition`, which must be a pre-existing definition in the codebase
      (it can't be an arbitrary expression). You can evaluate multi-line
      codeblocks with the triple backtick syntax ''``` multipleLines ```''
  }}

docs.languageReference.escapeSequences : Doc
docs.languageReference.escapeSequences =
  {{
  # Escape sequences

    Text literals can include the following escape sequences:

    * `\0` = null character
    * `\a` = alert (bell)
    * `\b` = backspace
    * `\f` = form feed
    * `\n` = new line
    * `\r` = carriage return
    * `\t` = horizontal tab
    * `\v` = vertical tab
    * `\s` = space
    * `\\` = literal `\` character
    * {{ docCode {{ \' }} }} = literal {{ docCode {{ ' }} }} character
    * `\"` = literal `"` character
  }}

docs.languageReference.expressions : Doc
docs.languageReference.expressions =
  {{
  # Expressions

    This section describes the syntax and informal semantics of Unison
    expressions.

    Unison's evaluation strategy for expressions is
    [Applicative Order Call-by-Value](https://en.wikipedia.org/wiki/Evaluation_strategy#Applicative_order).
    See [Function application](./functionApplication) for details.
  }}

docs.languageReference.functionApplication : Doc
docs.languageReference.functionApplication =
  {{
  # Function application

    A function application `f a1 a2 an` applies the function `f` to the
    arguments `a1` through `an`.

    The above syntax is valid where `f` is a
    [regular identifier](./identifiers). If the function name is an operator
    such as `*`, then the syntax for application is infix : `a1 * a2`. Any
    operator can be used in prefix position by surrounding it in parentheses:
    `(*) a1 a2`.

    All Unison functions are of {{ docTooltip {{ arity }} glossary.arity }} 1.
    That is, they take exactly one argument. An n-ary function is modeled
    either as a unary function that returns a further function (a partially
    applied function) which accepts the rest of the arguments, or as a unary
    function that accepts a tuple.

    Function application associates to the left, so the expression `f a b` is
    the same as `(f a) b`. If `f` has type `T1 -> T2 -> Tn` then `f a` is well
    typed only if `a` has type `T1`. The type of `f a` is then `T2 -> Tn`. The
    type constructor of function types, `->`, associates to the right. So
    `T1 -> T2 -> Tn` parenthesizes as `T1 -> (T2 -> TN)`.

    The evaluation semantics of function application is applicative order
    [Call-by-Value](https://en.wikipedia.org/wiki/Evaluation_strategy#Call_by_value).
    In the expression `f x y`, `x` and `y` are fully evaluated in left-to-right
    order, then `f` is fully evaluated, then `x` and `y` are substituted into
    the body of `f`, and lastly the body is evaluated.

    An exception to the evaluation semantics is
    [Boolean expressions](./booleanExpressions), which have non-strict
    semantics.

    Unison supports
    [proper tail calls](https://en.wikipedia.org/wiki/Tail_call) so function
    calls in tail position do not grow the call stack.
  }}

docs.languageReference.functionTypes : Doc
docs.languageReference.functionTypes =
  {{
  # Function types

    The type `X -> Y` is a type for functions that take arguments of type `X`
    and yield results of type `Y`. Application of the binary type constructor
    `->` associates to the right, so the type `X -> Y -> Z` is the same as the
    type `X -> (Y -> Z)`.
  }}

docs.languageReference.guardPatterns : Doc
docs.languageReference.guardPatterns =
  {{
  # Guard patterns

    A __guard pattern__ has the form `p | g` where `p` is a pattern and `g` is
    a Boolean expression that may reference any variables bound in `p`. The
    pattern matches if `p` matches and `g` evaluates to ``true``.

    For example, the following expression evaluates to ``6``:

    ``` unison
    match 1 + 2 with
      x
        | x == 4     -> 0
        | x + 1 == 4 -> 6
      _              -> 42
    ```
  }}

docs.languageReference.hashes : Doc
docs.languageReference.hashes =
  {{
  # Hashes

    A __hash__ in Unison is a 512-bit SHA3 digest of a term or a type's
    internal structure, excluding all names. The textual representation of a
    hash is its
    [base32Hex](https://github.com/multiformats/multibase#multibase-table-v100-rc-semver)
    Unicode encoding.

    Unison attributes a hash to every term and type declaration, and the hash
    may be used to unambiguously refer to that term or type in all contexts. As
    far as Unison is concerned, the hash of a term or type is its
    __true name__.

    {{ literalHashReferences }}

    {{ shortHashes }}
  }}

docs.languageReference.hashQualifiedIdentifiers : Doc
docs.languageReference.hashQualifiedIdentifiers =
  {{
  # Hash-qualified identifiers

    Any identifier, including a namespace-qualified one, can appear
    __hash-qualified__. A hash-qualified identifier has the form `x#h` where
    `x` is an identifier and `#h` is a [hash literal](./literalHashReferences).
    The hash disambiguates names that may refer to more than one thing.
  }}

docs.languageReference.identifiers : Doc
docs.languageReference.identifiers =
  {{
  # Identifiers

    Unison identifiers come in two flavors:

    1. __Regular identifiers__ start with an alphabetic unicode character,
       emoji (which is any unicode character between 1F400 and 1FAFF
       inclusive), or underscore (''_''), followed by any number of
       alphanumeric characters, emoji, or the characters `_`, `!`, or `\`'. For
       example, `foo`, `_bar4`, `qux`', and `set!` are valid regular
       identifiers.
    2. {{ docTooltip {{ __Operators__ }} {{ {{ operators }} }} }} consist
       entirely of the characters `!$%^&*-=+<>~\\/|:`. For example, `+`, `*`,
       `<>`, and `>>=` are valid operators.

    {{ namespaceQualifiedIdentifiers }}

    {{ absolutelyQualifiedIdentifiers }}

    {{ hashQualifiedIdentifiers }}

    {{ reservedWords }}
  }}

docs.languageReference.kindsOfTypes : Doc
docs.languageReference.kindsOfTypes =
  {{
  # Kinds of Types

    Types are to values as __kinds__ are to type constructors. Unison
    attributes a kind to every type constructor, which is determined by its
    number of type parameters and the kinds of those type parameters.

    A type must be well kinded, just like an expression must be well typed, and
    for the same reason. However, there is currently no syntax for kinds and
    they do not appear in Unison programs (this will certainly change in a
    future version of Unison).

    Unison’s kinds have the following forms:

    * A nullary type constructor or ordinary type has kind `Type`.
    * A type constructor has kind `k1 -> k2` where `k1` and `k2` are kinds.

    For example {type List}, a unary type constructor, has kind `Type -> Type`
    as it takes a type and yields a type. A binary type constructor like `->`
    has kind `Type -> Type -> Type`, as it takes two types (it actually takes a
    type and yields a partially applied unary type constructor that takes the
    other type). A type constructor of kind `(Type -> Type) -> Type` is a
    __higher-order__ type constructor (it takes a unary type constructor and
    yields a type).
  }}

docs.languageReference.lexicalSyntaxOfBlocks : Doc
docs.languageReference.lexicalSyntaxOfBlocks =
  {{
  # The lexical syntax of blocks

    The standard syntax expects statements to appear in a line-oriented layout,
    where whitespace is significant.

    The opening keyword (''let'', `if`, `then`, or `else`, for example)
    introduces the block, and the position of the first character of the first
    statement in the block determines the top-left corner of the block. The
    beginning of each statement in the block must be lined up exactly with the
    left edge of the block. The first non-whitespace character that appears to
    the left of that edge (i.e. outdented) ends the block. Certain keywords
    also end blocks. For example, `then` ends the block introduced by `if`.

    A statement or expression in a block can continue for more than one line as
    long as each line of the statement is indented further than the first
    character of the statement or expression.

    For example, these are valid indentations for a block:

    ``` unison
    let
      x = 1
      y = 2
      x + y


    let x = 1
        y = 2
        x + y
    ```

    Whereas these are incorrect:

    ``` unison
    let x = 1
      y = 2
      x + y

    let x = 1
         y = 2
           x + y
    ```

    {{ syntacticalPrecedence }}
  }}

docs.languageReference.listPatterns : Doc
docs.languageReference.listPatterns =
  use List ++ +: :+
  {{
  # List patterns

    A __list pattern__ matches a `List t` for some type `t` and has one of four
    forms:

    1. `` head +: tail `` matches a list with at least one element. The pattern
       `head` is matched against the first element of the list and `tail` is
       matched against the suffix of the list with the first element removed.
    2. `` init :+ last `` matches a list with at least one element. The pattern
       `init` is matched against the prefix of the list with the last element
       removed, and `last` is matched against the last element of the list.
    3. A __literal list pattern__ has the form `[p1, p2, … pn]` where `p1`
       through `pn` are patterns. The patterns `p1` through `pn` are matched
       against the elements of the list. This pattern only matches if the
       length of the scrutinee is the same as the number of elements in the
       pattern. The pattern `` [] `` matches the empty list.
    4. `` part1 ++ part2 `` matches a list which composed of the concatenation
       of `part1` and `part2`. At least one of `part1` or `part2` must be a
       pattern with a known list length, otherwise it's unclear where the list
       is being split. For instance, `` [x, y] ++ rest `` is okay as is
       ``start ++ [x, y]``, but just `a ++ b` is not allowed.

    Examples:

    ``` raw
    first : [a] -> Optional a
    first = cases
      h +: _ -> Some h
      []     -> None
    last : [a] -> Optional a
    last = cases
      _ :+ l -> Some l
      []     -> None
    exactlyOne : [a] -> Boolean
    exactlyOne = cases
      [_] -> true
      _   -> false
    lastTwo : [a] -> Optional (a, a)
    lastTwo = cases
      start ++ [a, a2] -> Some (a, a2)
      _                -> None
    firstTwo : [a] -> Optional (a, a)
    firstTwo = cases
      [a, a2] ++ rest -> Some (a, a2)
      _               -> None
    ```
  }}

docs.languageReference.literalHashReferences : Doc
docs.languageReference.literalHashReferences =
  {{
  # Literal Hash References

    A term, type, data constructor, or ability constructor may be unambiguously
    referenced by hash. Literal hash references have the following structure:

    * A __term definition__ has a hash of the form `#x` where `x` is the
      base32Hex encoding of the hash of the term. For example `#a0v829`.
    * A term or type definition that’s part of a
      __cycle of mutually recursive definitions__ hashes to the form `#x.n`
      where `x` is the hash of the cycle and `n` is the term or type’s index in
      its cycle. A cycle has a canonical order determined by sorting all the
      members of the cycle by their individual hashes (with the cycle removed).
    * A data constructor hashes to the form `#x#c` where `x` is the hash of the
      data type definition and `c` is the index of that data constructor in the
      type definition.
    * A data constructor in a cyclic type definition hashes to the form
      `#x.n#c` where `#x.n` is the hash of the data type and `c` is the data
      constructor’s index in the type definition.
    * A __built-in reference__ to a Unison built-in term or type `n` has a hash
      of the form `##n`. `##Nat` is an example of a built-in reference.
  }}

docs.languageReference.literalPatterns : Doc
docs.languageReference.literalPatterns =
  use Nat +
  {{
  # Literal patterns

    A __literal pattern__ is a literal {type Boolean}, {type Nat}, {type Int},
    {type Char}, or {type Text}. A literal pattern matches if the scrutinee has
    that exact value.

    For example:

    ```
    match 2 + 2 with
      4 -> "Matches"
      _ -> "Doesn't match"
    ```
  }}

docs.languageReference.literals : Doc
docs.languageReference.literals =
  use Nat +
  {{
  # Literals

    A literal expression is a basic form of Unison expression. Unison has the
    following types of literals:

    * A __64-bit unsigned integer__ of type {type Nat} (which stands for
      ___natural number__) consists of digits from 0 to 9. The smallest
      {type Nat} is `` 0 `` and the largest is ``18446744073709551615``. * You
      can also write {type Nat} numbers in their hex format `0x`, as in `0x003`
      for ``3``. * A__64-bit signed integer___ of type {type Int} consists of a
      natural number immediately preceded by either `+` or `-`. For example,
      `4` is a {type Nat}, whereas `` +4 `` is an {type Int}. The smallest
      {type Int} is `` -9223372036854775808 `` and the largest is
      ``+9223372036854775807``.
    * A __64-bit floating point number__ of type {type Float} consists of an
      optional sign (''+''/''-''), followed by two natural numbers separated by
      `.`. Floating point literals in Unison are
      [IEEE 754-1985](https://en.wikipedia.org/wiki/IEEE_754-1985)
      double-precision numbers. For example `` 1.6777216 `` is a valid floating
      point literal.
    * A __text literal__ of type {type Text} is any sequence of Unicode
      characters between pairs of quotes,
      `""" Multi-line text literals are supported with the triple quote syntax """`.
      The escape character is `\`, so a quote character can be included in a
      text literal with the escape sequence {{ escapeQuoteLiteral }}. The full
      list of escape sequences is given in the
      [Escape Sequences]({escapeSequences}) section below. For example, ``
      "Hello, World!" `` is a text literal. A text literal can span multiple
      lines. Newlines do not terminate text literals, but become part of the
      literal text.
    * A __character literal__ of type {type Char} consists of a `?` character
      marker followed by a single Unicode character, or a single
      [escape sequence]({escapeSequences}). For example, ``?a``, `` ?🔥 `` or
      ``?\t``.
    * There are two
      ___Boolean literals__: `` true `` and ``false``, and they have type
      {type Boolean}. * A__byte literal___ starts with `0xs`. For example ``
      0xsdeadbeef ``
    * A __hash literal__ begins with the character `#`. See the section
      [Hashes]({hashes}) for details on the lexical form of hash literals. A
      hash literal is a reference to a term or type. The type or term that it
      references must have a definition whose hash digest matches the hash in
      the literal. The type of a hash literal is the same as the type of its
      referent. `#a0v829` is an example of a hash literal.
    * A __literal list__ has the general form `[v1, v2, … vn]` where `v1`
      through `vn` are expressions. A literal list may be empty. For example,
      ``[]``, ``["x"]``, and `` [1, 2, 3] `` are list literals. The expressions
      that form the elements of the list all must have the same type. If that
      type is `T`, then the type of the list literal is `.base.List T` or
      `[T]`.
    * A __function literal__ or lambda has the form `p1 p2 … pn -> e`, where
      `p1` through `pn` are [regular identifiers]({identifiers}) and `e` is a
      Unison expression (the **body** of the lambda). The variables `p1`
      through `pn` are local variables in `e`, and they are bound to any values
      passed as arguments to the function when it’s called (see the section
      [Function Application]({languageReference.functionApplication}) for
      details on call semantics). For example `` x -> x + 2 `` is a function
      literal.
    * A __tuple literal__ has the form `(v1,v2, …, vn)` where `v1` through `vn`
      are expressions. A value `` (a, b) `` has type `(A,B)` if `a` has type
      `A` and `b` has type `B`. The expression `(a)` is the same as the
      expression `a`. The nullary tuple `()` (pronounced "unit") is of the
      trivial type `()`. See [tuple types]({tupleTypes}) for details on these
      types and more ways of constructing tuples.
    * `termLink` or `typeLink` literal takes the form `termLink aUnisonTerm` or
      `typeLink Optional` where the argument to `termLink` is a Unison term and
      the argument to `typeLink` is a Unison type. `termLink` produces a value
      of type {type Link.Term} and typeLink produces a value of type
      {type Link.Type}
  }}

docs.languageReference.matchExpression : Nat
docs.languageReference.matchExpression = match 1 Nat.+ 1 with
  x@4 -> x Nat.* 2
  y@2 -> y Nat.+ 1
  _   -> 22

docs.languageReference.matchExpressionsAndPatternMatching : Doc
docs.languageReference.matchExpressionsAndPatternMatching =
  {{
  # Match expressions and pattern matching

    A __match expression__ has the general form:

    ``` unison
    match e with
      pattern_1 -> block_1
      pattern_2 -> block_2
      …
      pattern_n -> block_n
    ```

    Where `e` is an expression, called the __scrutinee__ of the match
    expression, and each __case__ has a
    [pattern to match against the value of the scrutinee]({blankPatterns}) and
    a [block]({blocksAndStatements}) to evaluate in case it matches.

    The evaluation semantics of match expressions are as follows:

    1. The scrutinee is evaluated.
    2. The first pattern is evaluated and matched against the value of the
       scrutinee.
    3. If the pattern matches, any variables in the pattern are substituted
       into the block to the right of its `->` (called the __match body__) and
       the block is evaluated. If the pattern doesn’t match then the next
       pattern is tried and so on.

    It's possible for Unison to actually evaluate cases in a different order,
    but such evaluation should always have the same observable behavior as
    trying the patterns in sequence.

    It is an error if none of the patterns match. In this version of Unison,
    the error occurs at runtime. In a future version, this should be a
    compile-time error.

    Unison provides syntactic sugar for match expressions in which the
    scrutinee is the sole argument of a lambda expression:

    ``` unison
    cases
      pattern_1 -> block_1
      pattern_2 -> block_1
      …
      pattern_n -> block_n

    -- equivalent to
    e -> match e with
      pattern_1 -> block_1
      pattern_2 -> block_1
      …
      pattern_n -> block_n
    ```

    A __pattern__ has one of the following forms:

    {{ blankPatterns }}

    {{ literalPatterns }}

    {{ variablePatterns }}

    {{ asPatterns }}

    {{ constructorPatterns }}

    {{ languageReference.listPatterns }}

    {{ tuplePatterns }}

    {{ abilityPatterns }}

    {{ guardPatterns }}
  }}

docs.languageReference.nameResolutionAndTheEnvironment : Doc
docs.languageReference.nameResolutionAndTheEnvironment =
  {{
  # Name resolution and the environment

    During typechecking, Unison substitutes free variables in an expression by
    looking them up in an environment populated from a __codebase__ of
    available definitions. A Unison codebase is a database of term and type
    definitions, indexed by [hashes](./hashes) and names.

    A name in the environment can refer to either terms or types, or both (a
    type name can never be confused with a term name).

    {{ _suffixedBasedNameResolution }}

    {{ _typeDirectedNameResolution }}
  }}

docs.languageReference.namespaceDeclaration : Doc
docs.languageReference.namespaceDeclaration =
  {{
  # Namespace declaration

    A __namespace declaration__ tells Unison that the terms and types inside a
    scratch file should be qualified with the given namespace prefix.

    ``` unison
    namespace exercise.part1

    foo = "abc"
    ```

    ``` ucm
    scratch/main> add

      ⍟ These new definitions are ok to `add`:

        exercise.part1.foo : Text
    ```

    Currently, namespace declarations are scoped to the entire scratch file.
    You cannot have more than one `namespace` declaration appearing in a single
    file.
  }}

docs.languageReference.namespaceQualifiedIdentifiers : Doc
docs.languageReference.namespaceQualifiedIdentifiers =
  {{
  # Namespace-qualified identifiers

    The [general reference for identifiers](./identifiers) describes
    __unqualified__ identifiers. An identifier can also be qualified. A
    qualified identifier consists of a qualifier or namespace, followed by a
    `.`, followed by either a regular identifier or an operator. The qualifier
    is one or more regular identifiers separated by `.` For example
    `Foo.Bar.baz` is a qualified identifier where `Foo.Bar` is the qualifier.

    The qualifier is one or more regular
  }}

docs.languageReference.operatorDefinitions : Doc
docs.languageReference.operatorDefinitions =
  {{
  # Operator definitions

    [Operator identifiers]({identifiers}) are valid names for Unison
    definitions, but the syntax for defining them is slightly different. For
    example, we could define a binary operator `**`:

    ``` unison
    (**) x y = Float.pow x y
    ```

    Or we could define it using infix notation:

    ``` unison
    x ** y = pow x y
    ```

    If we want to give the operator a qualified name, we put the qualifier
    inside the parentheses:

    ``` unison
    (MyNamespace.**) x y = Float.pow x y
    ```

    Or if defining it infix:

    ``` unison
    x MyNamespace.** y = pow x y
    ```

    The operator can be applied using either notation, no matter which way it's
    defined. See
    [function application]({languageReference.functionApplication}) for
    details.
  }}

docs.languageReference.parenthesizedExpressions : Doc
docs.languageReference.parenthesizedExpressions =
  {{
  # Parenthesized expressions

    Any expression can appear in parentheses, and an expression `(e)` is the
    same as the expression `e`. Parentheses can be used to delimit where an
    expression begins and ends. For example `(f : P -> Q) y` is an application
    of the function `f` of type `P -> Q` to the argument `y`. The parentheses
    are needed to tell Unison that `y` is an argument to `f`, not a part of the
    type annotation expression.
  }}

docs.languageReference.patternMatchingOnAbilityConstructors : Doc
docs.languageReference.patternMatchingOnAbilityConstructors =
  use Abort abort
  use Nat +
  use Store get put
  use toDefault! handler
  {{
  # Pattern matching on ability constructors

    Each constructor of an ability corresponds with a __pattern__ that can be
    used for pattern matching in ability handlers. The general form of such a
    pattern is:

    ``` unison
    {A.c p_1 p_2 p_n -> k}
    ```

    Where `A` is the name of the ability, `c` is the name of the constructor,
    `p_1` through `p_n` are patterns matching the arguments to the constructor,
    and `k` is a __continuation__ for the program. If the value matching the
    pattern has type `Request A T` and the constructor of that value had type
    `X ->{A} Y`, then `k` has type `Y -> {A} T`.

    The continuation will always be a function accepting the return value of
    the ability constructor, and the body of this function is the remainder of
    the `handle .. with` block immediately following the call to the
    constructor. See below for an example.

    A handler can choose to call the continuation or not, or to call it
    multiple times. For example, a handler can ignore the continuation in order
    to handle an ability that aborts the execution of the program:

        @source{type Abort}

        @source{handler}

    ```
    p : Nat
    p =
      handle
        x = 4
        abort
        x + 2
      with handler do 0
    p
    ```

    If we remove the {abort} call in the program `p`, it evaluates to ``6``.

    Note that although the ability constructor is given the signature `abort :
        ()`, its actual type is `{Abort} ()`.

    The pattern `{ Abort.abort -> _ }` matches when the {abort} call in `p`
    occurs. This pattern ignores its continuation since it will not invoke it
    (which is how it aborts the program). The continuation at this point is the
    expression `_ -> x + 2`.

    The pattern `{ x }` matches the case where the computation is pure (makes
    no further requests for the {type Abort} ability and the continuation is
    empty). A pattern match on a {type Request} is not complete unless this
    case is handled.

    When a handler calls the continuation, it needs describe how the ability is
    provided in the continuation of the program, usually with a recursive call,
    like this:

    ``` unison
    use base Request

    structural ability Store v where
      get : v
      put : v -> ()

    storeHandler : v -> Request (Store v) a -> a
    storeHandler storedValue = cases
      {Store.get -> k} ->
        handle k storedValue with storeHandler storedValue
      {Store.put v -> k} ->
        handle k () with storeHandler v
      {a} -> a
    ```

    Note that the `storeHandler` has a `with` clause that uses `storeHandler`
    itself to handle the ''Request`s'' made by the continuation. So it’s a
    recursive definition. The initial "stored value" of type `v` is given to
    the handler in its argument named `storedValue`, and the changing value is
    captured by the fact that different values are passed to each recursive
    invocation of the handler.

    In the pattern for {get}, the continuation `k` expects a `v`, since the
    return type of {get} is `v`. In the pattern for {put}, the continuation `k`
    expects `()`, which is the return type of {put}.

    It's worth noting that this is a mutual recursion between `storeHandler`
    and the various continuations (all named `k`). This is no cause for
    concern, as they call each other in tail position and the Unison compiler
    performs [tail call elimination](./functionApplication).

    An example use of the above handler:

    ``` raw
    modifyStore : (v -> v) ->{Store v} ()
    modifyStore f =
      v = get
      put (f v)
    ```

    Here, when the handler receives {get}, the continuation is
    `v -> Store.put (f v)`. When the handler receives {put}, the continuation
    is `_ -> ()`.
  }}

docs.languageReference.polymorphicTypes : Doc
docs.languageReference.polymorphicTypes =
  {{
  # Polymorphic types

    A __universally quantified__ or "polymorphic" type has the form
    `forall v1 v2 vn. t`, where `t` is a type. The type `t` may involve the
    variables `v1` through `vn`.

    The symbol `∀` is an alias for `forall`.

    A type like `forall x. F x` can be written simply as `F x` (the `forall x`
    is implied) as long as `x` is free in `F x` (it is not bound by an outer
    scope; see [Scoped type variables]({scopedTypeVariables}) below).

    A polymorphic type may be __instantiated__ at any given type. For example,
    the empty list `` [] `` has type `forall x. [x]`. So it's a
    type-polymorphic value. Its type can be instantiated at {type Int}, for
    example, which binds `x` to {type Int} resulting in `[Int]` which is also a
    valid type for the empty list. In fact, we can say that the empty list ``
    [] `` is a value of type `[x]` __for all__ choices of element type `e`,
    hence the type `forall x. [x]`.

    Likewise the identity function `(x -> x)`, which simply returns its
    argument, has a polymorphic type `forall t. t -> t`. It has type `t -> t`
    for all choices of `t`.
  }}

docs.languageReference.recordType : Doc
docs.languageReference.recordType =
  {{
  # Record types

    In the type declarations discussed above, the arguments to each data
    constructor are nameless. For example:

    ``` unison
    structural type Point = Point Nat Nat
    ```

    Here, the data type has one constructor, with two arguments, both of type
    {type Nat}. The arguments have no name, so they are identified
    positionally, for example when creating a value of this type, like
    `Point 1 2`.

    Types with a single data constructor can also be defined in the following
    style, in which case they are called __record types__.

    ``` unison
    Point2 = {x : Nat, y : Nat}
    ```

    This assigns names to each argument of the constructor. The effect of this
    is to generate some accessor methods, to help get, set, and modify each
    field.

    * @inlineSignature{Point2.x}
    * @inlineSignature{x.modify}
    * @inlineSignature{x.set}
    * @inlineSignature{y}
    * @inlineSignature{y.modify}
    * @inlineSignature{y.set}

    {{
    docCallout
      (Some {{ 👉 }})
      {{
      Note that {x.set} and {x.modify} are returning new, modified copies of
      the input record—there's no mutation of values in Unison.
      }} }}

    There's currently no special syntax for creating, pattern matching, or
    decomposing records. That works the same as for regular data types:

    ```
    p = Point2 1 2
    let
      (Point2 x _) = p
      x
    ```
  }}

docs.languageReference.recordType.examples.Point2.x : Point2 -> Nat
docs.languageReference.recordType.examples.Point2.x = cases Point x _ -> x

docs.languageReference.recordType.examples.Point2.x.modify :
  (Nat ->{g} Nat) -> Point2 ->{g} Point2
docs.languageReference.recordType.examples.Point2.x.modify f = cases
  Point x y -> Point (f x) y

docs.languageReference.recordType.examples.Point2.x.set :
  Nat -> Point2 -> Point2
docs.languageReference.recordType.examples.Point2.x.set x1 = cases
  Point _ y -> Point x1 y

docs.languageReference.recordType.examples.Point2.y : Point2 -> Nat
docs.languageReference.recordType.examples.Point2.y = cases Point _ y -> y

docs.languageReference.recordType.examples.Point2.y.modify :
  (Nat ->{g} Nat) -> Point2 ->{g} Point2
docs.languageReference.recordType.examples.Point2.y.modify f = cases
  Point x y -> Point x (f y)

docs.languageReference.recordType.examples.Point2.y.set :
  Nat -> Point2 -> Point2
docs.languageReference.recordType.examples.Point2.y.set y1 = cases
  Point x _ -> Point x y1

docs.languageReference.reservedWords : Doc
docs.languageReference.reservedWords =
  {{
  # Reserved words

    The following names are reserved by Unison and cannot be used as
    identifiers: `=`, `:`, `->`, {{ docCode {{ ' }} }}, `do`, `|`, `!`, ''`'',
    `if`, `then`, `else`, `forall`, `handle`, `unique`, `structural`, `where`,
    `use`, `&&`, `||`, `true`, `false`, `type`, `ability`, `alias`, `let`,
    `namespace`, `cases`, `match`, `with`, `termLink`, `typeLink`.
  }}

docs.languageReference.scopedTypeVariables : Doc
docs.languageReference.scopedTypeVariables =
  {{
  # Scoped type variables

    Type variables introduced by a type signature for a term remain in scope
    throughout the definition of that term.

    For example in the following snippet, the type annotation `temp:x` is
    telling Unison that `temp` has the type `x` which is bound in the type
    signature, so `temp` and `a` have the same type.

    ``` raw
    ex1 : x -> y -> x
    ex1 a b =
      temp : x
      temp = a
      a
    ```

    `temp : x` refers to the type `x` in the outer scope.

    To explicitly shadow a type variable in scope, the variable can be
    reintroduced in the inner scope by a `forall` binder, as follows:

    ``` unison
    ex2 : x -> y -> x
    ex2 a b =
    -- doesn’t refer to x in outer scope
    id : ∀ x . x -> x
    id v = v
    temp = id 42
    id a
    ```

    `id : ∀ x . x -> x ` doesn’t refer to x in outer scope

    Note that here the type variable `x` in the type of `id` gets instantiated
    to two different types. First `` Function.id 42 `` instantiates it to
    {type Nat}, then `id
                a`, instantiates it to the outer scope's type `x`.
  }}

docs.languageReference.shortHashes : Doc
docs.languageReference.shortHashes =
  {{
  # Short Hashes

    A hash literal may use a prefix of the base32Hex encoded SHA3 digest
    instead of the whole thing. For example the programmer may use a short hash
    like `#r1mtr0` instead of the much longer 104-character representation of
    the full 512-bit hash. If the short hash is long enough to be unambiguous
    given the [environment]({nameResolutionAndTheEnvironment}), Unison will
    substitute the full hash at compile time. When rendering code as text,
    Unison may calculate the minimum disambiguating hash length before
    rendering a hash.
  }}

docs.languageReference.structuralTypes : Doc
docs.languageReference.structuralTypes =
  {{
  # Structural types

    The structural keyword specifies that the type being defined is a
    structural type. Structural types may have different names but are
    equivalent if they share the same data constructor and type constructor
    structure. In Unison the following are the same:

    ``` unison
    structural type Optional a = None | Some a
    structural type Maybe x = None | Just x
    ```

    They can be referenced by either name in a codebase.

    The unique keyword introduces a unique type,
    [explained in the language reference here]({uniqueTypes}).
  }}

docs.languageReference.syntacticPrecedenceOperatorsPrefixFunctionApplication :
  Doc
docs.languageReference.syntacticPrecedenceOperatorsPrefixFunctionApplication =
  {{
  # Syntactic precedence of operators and function application

    Functions in Unison are applied using a space, like `f x y`. Operators are
    applied using infix notation, like `x + y`. The order in which functions
    and operators are applied is determined by their syntactic precedence.

    Any function with an unqualified name that consists of only operator
    characters is an operator. For example, `+`, `*`, `==`, `&&`, and `||` are
    all operators, as are `Nat.+`, `Int.*`, `Float.==`, etc.

    Technically speaking `&&` and `||` are not functions but reserved keywords,
    but they are treated syntactically as if they were operators.

    ## Operator precedence

       The Unison language has a fixed precedence for operators determined by
       the operator's name. A higher precedence means that the operator binds
       more tightly. For example, `*` has higher precedence than `+`, so
       `1 + 2 * 3` is parsed as `1 + (2 * 3)`. Operators with higher precedence
       are applied first.

       {{
       docTable
         [ [{{ **Operator** }}, {{ **Precedence** }}]
         , [{{ `^`, `^^`, and `**` }}, {{ 6 }}]
         , [{{ `*`, `/`, and `%` }}, {{ 5 }}]
         , [{{ `+` and `-` }}, {{ 4 }}]
         , [{{ `<`, `>`, `>=`, and `<=` }}, {{ 3 }}]
         , [{{ `==`, `===`, `!=`, and `!==` }}, {{ 2 }}]
         , [{{ `&&` and `&` }}, {{ 1 }}]
         , [{{ `||` and `|` }}, {{ 0 }}]
         , [ {{
             Any other combination of `"!$%^&*-=+<>~\\/|:"`
             }}
           , {{
             No precedence
             }}
           ]
         ] }}

       When two operators with the same precedence are used in the same
       expression, the associativity of the operator determines the order in
       which the operators are applied.

       When an operator with no precedence rule is used in an expression with
       operators that do have a precedence rule, the operator with no
       precedence **always just associates to the left.** For example,
       `1 + 2 * 3 $ 4 + 5` is parsed as `((1 + (2 * 3)) $ 4) + 5`. Another way
       to think of this is that the operator with no precedence rule has lower
       precedence than any operator to its left and higher precedence than any
       operator to its right. You are encouraged to split such expressions into
       smaller parts to aid readability, but this rarely comes up in practice.

       When your code is printed back to you by Unison, it will be displayed
       with minimal necessary parentheses. If Unison's precedence rules change,
       old definitions will get displayed with the parentheses needed for the
       new precedence rules.

    ## Function application

       Function application binds more tightly than any operator. So
       `f x + g y` is the same as `(f x) + (g y)`. Function application
       associates to the left, so `f x y z` is the same as `((f x) y) z`.

       Function application binds less tightly than keywords that introduce
       blocks. So `f let x` is the same as `f (let x)` and
       `f if b then p else q` is the same as `f (if b then p else q)`.

       Function application binds less tightly than `!` and {{ docCode {{ ' }}
       }} (see
       [delayed computations]({{ languageReference.delayedComputations }})), so
       `!f x y` is the same as `f () x y` and {{ docCode {{ 'f x y }} }} is the
       same as `(_ -> f) x y`.
  }}

docs.languageReference.termDeclarations : Doc
docs.languageReference.termDeclarations =
  {{
  # Term declarations

    A Unison term declaration (or "term binding") consists of an optional
    [type signature](languageReference.typeSignatures), and a
    [term definition]({termDefinition}). For example:

    ``` unison
    timesTwo : Nat -> Nat
    timesTwo x = x * 2
    ```

    The first line in the above is a [type signature]({typeSignatures}). The
    type signature `timesTwo : Nat -> Nat` declares that the term named
    `timesTwo` is a function accepting an argument of type {type Nat} and
    computes a value of type {type Nat}. The type {type Nat} is the type of
    64-bit natural numbers starting from zero. See [Unison types]({types}) for
    details.

    The second line is the term definition. The `=` sign splits the definition
    into a __left-hand side,__ which is the term being defined, and the
    __right-hand side,__ which is the definition of the term.

    The general form of a term binding is:

    ``` unison
    name : Type
    name p_1 p_2 … p_n = expression
    ```
  }}

docs.languageReference.termDefinition : Doc
docs.languageReference.termDefinition =
  use Nat ==
  {{
  # Term definition

    A term definition has the form `f p_1 p_2 … p_n = e` where `f` is the name
    of the term being defined. The parameters `p_1` through `p_n` are the names
    of parameters, if any (if the term is a function), separated by spaces. The
    right-hand side of the `=` sign is any [Unison expression]({expressions}).

    The names of the parameters as well as the name of the term are bound as
    local variables in the expression on the right-hand side (also known as the
    __body__ of the function). When the function is called, the parameter names
    are bound to any arguments passed in the call. See
    [function application](./functionApplication) for details on the call
    semantics of functions.

    If the term takes no arguments, the term has the value of the fully
    evaluated expression on the right-hand side and is not a function.

    The expression comprising the right-hand side can refer to the name given
    to the definition in the left-hand side. In that case, it’s a recursive
    definition. For example:

        @source{sumUpTo}

    The above defines a function {sumUpTo} that recursively sums all the
    natural numbers less than some number `n`. As an example, `` sumUpTo 3 ``
    is `1 + 2 + 3`, which is ``6``.

    Note: The expression `` n Nat.- 1 `` on line 4 above subtracts `` 1 `` from
    the natural number `n`. Since the natural numbers are not closed under
    subtraction (''n Nat.subtractInt 1'' is an {type Int}), we use the
    operation `-` which has the convention that `` 0 - n == 0 `` for all
    natural numbers `n`. Unison's type system saves us from having to deal with
    negative numbers here.
  }}

docs.languageReference.termDefinition.sumUpTo : Nat -> Nat
docs.languageReference.termDefinition.sumUpTo n =
  use Nat + - <
  if n < 2 then n
  else n + docs.languageReference.termDefinition.sumUpTo (n - 1)

docs.languageReference.theTypecheckingRuleForAbilities : Doc
docs.languageReference.theTypecheckingRuleForAbilities =
  {{
  # The typechecking rule for abilities

    The general typechecking rule used for abilities is this: calls to
    functions requiring abilities `{A1,A2}` must be in a context where
    __at least__ the abilities `{A1,A2}` are available, otherwise the
    typechecker will complain with an ability check failure. Abilities can be
    made available using a `handle` block (discussed below) or with a type
    signature: so for instance, within the body of a function
    `Text ->{IO} Nat`, `{IO}` is available and therefore:

    * We can call a function `f : Nat ->{} Nat`, since the ability requirements
      of f are `{}` which is a subset the available `{IO}` abilities.
    * We can also call a function `g : Text ->{IO} ()`, since the requirements
      of `g` are `{IO}` which is a subset of the available `{IO}` abilities.

    For functions accepting multiple arguments, it might seem we need a
    different rule, but the rule is the same: the body of the function can
    access the abilities attached to the corresponding function type in the
    signature. Here's an example that won't typecheck, since the function body
    must be pure according to the signature:

    ``` unison
    doesNotWork : Text ->{Exception,IO} Text ->{} Nat
    doesNotWork arg1 arg2 =
      printLine "Does not work!"
      42
    ```

    However, if we do the {type IO} before returning the pure function, it
    typechecks just fine:

    ``` unison
    doesWork : Text ->{IO, Exception} Text -> Nat
    doesWork arg1 =
      printLine "Works great!"
      arg2 -> 42
    ```

    For top-level definitions which aren't contained in a function body,
    __they are required to be pure__. For instance, this doesn't typecheck:

    ``` unison
    msg = printLine "hello"
    ```

    But if we say `msg = '(printLine "Hello")` that typechecks fine, since the
    {printLine} is now inside a function body whose requirements inferred as
    `{IO}` (try it!).

    🤓 This restriction on top level definitions needing to be pure might lifted
    in a future version of Unison.
  }}

docs.languageReference.topLevelDeclaration : Doc
docs.languageReference.topLevelDeclaration =
  {{
  # Top-level declarations

    A top-level declaration can appear at the top level or outermost scope of a
    Unison file. It can be one of the following forms:

    * [A term declaration]({termDeclarations}), like `x = 42`
    * [A type declaration]({userDefinedDataTypes}), like
          @source{type Optional}
    * [A use clause]({useClauses}), like `use base` or `use math sqrt`
    * [A namespace declaration]({{
      docLink (docEmbedTermLink do namespaceDeclaration)
      }}), like `namespace models.User`
  }}

docs.languageReference.tuplePatterns : Doc
docs.languageReference.tuplePatterns =
  use Nat +
  {{
  # Tuple patterns

    A __tuple pattern__ has the form `(p1, p2, … pn)` where `p1` through `pn`
    are patterns. The pattern matches if the scrutinee is a tuple of the same
    {{ docTooltip {{ arity }} glossary.arity }} as the pattern and `p1` through
    `pn` match against the elements of the tuple. The pattern `(p)` is the same
    as the pattern `p`, and the pattern `()` matches the literal value `()` of
    the trivial type {()} (both pronounced “unit”).

    For example, this expression evaluates to `4`:

    ```
    (a, _, c) = (1, 2, 3)
    a + c
    ```
  }}

docs.languageReference.tupleTypes : Doc
docs.languageReference.tupleTypes =
  {{
  # Tuple types

    The type `(A,B)` is a type for binary tuples (pairs) of values, one of type
    `A` and another of type `B`. The type `(A,B,C)` is a triple, and so on.

    The type `(A)` is the same as the type `A` and is not considered a tuple.

    The nullary tuple type `()` is the type of the unique value also written
    `()` and is pronounced “unit”.

    In the standard Unison syntax, tuples of {{
    docTooltip {{ arity }} glossary.arity }} 2 and higher are actually of a
    type `Tuple a b` for some types `a` and `b`. For example, `(X,Y)` is
    syntactic shorthand for the type `Tuple X (Tuple Y ())`.

    Tuples are either constructed with the syntactic shorthand `(a,b)` (see
    [tuple literals](./literals)) or with the built-in {Tuple.Cons} data
    constructor: {{ docExample 3 (_ a Tuple.Cons1 b -> (a, b)) }}.
  }}

docs.languageReference.typeAnnotations : Doc
docs.languageReference.typeAnnotations =
  {{
  # Type Annotations

    A type annotation has the form `e:T` where `e` is an expression and `T` is
    a type. This tells Unison that `e` should be of type `T` (or a subtype of
    type `T`), and Unison will check whether this is true. It's a type error
    for the actual type of `e` to be anything other than a type that conforms
    to `T`.
  }}

docs.languageReference.typeApplication : Doc
docs.languageReference.typeApplication =
  {{
  # Type application

    A type constructor is applied to a type or another type constructor,
    depending on its kind, similarly to how functions are applied to arguments
    at the term level. `C T` applies the type constructor `C` to the type `T`.
    Type application associates to the left, so the type `A B C` is the same as
    the type `(A B) C`.
  }}

docs.languageReference.typeConstructors : Doc
docs.languageReference.typeConstructors =
  {{
  # Type constructors

    Just as values are built using data constructors, types are built from
    __type constructors__. Nullary type constructors like {type Nat},
    {type Int}, {type Float} are already types, but other type constructors
    like {type List} and `->` (see
    [built-in type constructors]({{
    docLink (docEmbedTermLink do builtInTypeConstructors)
    }})) take type parameters in order to yield types. {type List} is a unary
    type constructor, so it takes one type (the type of the list elements), and
    `->` is a binary type constructor. `List Nat` is a type and `Nat -> Int` is
    a type.
  }}

docs.languageReference.types : Doc
docs.languageReference.types =
  use Nat + <
  {{
  # Types

    This section describes informally the structure of types in Unison. See
    also the section titled [User-defined types](./userDefinedTypes) for
    detailed information on how to define new data types.

    Formally, Unison’s type system is an implementation of the system described
    by Joshua Dunfield and Neelakantan R. Krishnaswami in their 2013 paper
    [Complete and Easy Bidirectional Typechecking for Higher-Rank Polymorphism](https://arxiv.org/abs/1306.6032).

    Unison extends that type system with,
    [pattern matching]({matchExpressionsAndPatternMatching}),
    [scoped type variables]({scopedTypeVariables}), __ability types__ (also
    known as __algebraic effects__). See the section on
    [Abilities]({abilitiesAndAbilityHandlers}) for details on ability types.

    Unison attributes a type to every valid expression. For example:

    * `` 4 < 5 `` has type {type Boolean}
    * `` 42 + 3 `` has type {type Nat},
    * `` "hello" `` has type {type Text}
    * the list `` [1, 2, 3] `` has type `[Nat]`
    * the function `(x -> x)` has type `forall a. a -> a`

    The meanings of these types and more are explained in the sections below.

    A full treatise on types is beyond the scope of this document. In short,
    types help enforce that Unison programs make logical sense. Every
    expression must be well typed, or Unison will give a compile-time type
    error. For example:

    * `` [1, 2, 3] `` is well typed, since lists require all elements to be of
      the same type.
    * `42 + "hello"` is not well typed, since the type of `+` disallows adding
      numbers and text together.
    * `printLine "Hello, World!"` is well typed in some contexts and not
      others. It's a type error for instance to use I/O functions where an
      {type IO} [ability]({abilitiesAndAbilityHandlers}) is not provided.

    Types are of the following general forms.

    {{ typeVariables }}

    {{ polymorphicTypes }}

    {{ scopedTypeVariables }}

    {{ typeConstructors }}

    {{ kindsOfTypes }}

    {{ typeApplication }}

    {{ functionTypes }}

    {{ tupleTypes }}

    {{ builtInTypes }}

    {{ builtInTypeConstructors }}

    {{ userDefinedTypes }}
  }}

docs.languageReference.typeSignatures : Doc
docs.languageReference.typeSignatures =
  {{
  # Type signatures

    `name : Type` is a type signature, where `name` is the name of the term
    being defined and `Type` is a [type]({types}) for that term. The `name`
    given in the type signature and the `name` given in the definition must be
    the same.

    Type signatures are optional. In the absence of a type signature, Unison
    will automatically infer the type of a term declaration. If a type
    signature is present, Unison will verify that the term has the type given
    in the signature.
  }}

docs.languageReference.typeVariables : Doc
docs.languageReference.typeVariables =
  {{
  # Type variables

    Type variables are [regular identifiers]({identifiers}) beginning with a
    lowercase letter. For example `a`, `x0`, and `foo` are valid type
    variables.
  }}

docs.languageReference.uniqueTypes : Doc
docs.languageReference.uniqueTypes =
  {{
  # Unique types

    A type declaration gives a name to a type, but Unison does not uniquely
    identify a type by its name. Rather, the hash of a type's definition
    identifies the type. The hash is based on the structure of the type
    definition, with all identifiers removed.

    For example, Unison considers these type declarations to declare the exact
    same type, even though they give different names to both the type
    constructor and the data constructors:

    ``` unison
    structural type Optional a = Some a | None

    structural type Maybe a = Just a | Nothing
    ```

    So a value `Some 10` and a value `Just 10` are in fact the same value and
    these two expressions have the same type. Even though one nominally has the
    `type Optional Nat` and the other `Maybe Nat,` Unison understands that as
    the type `#5isltsdct9fhcrvu ##Nat`.

    This is not always what you want. Sometimes you want to give meaning to a
    type that is more than just its structure. For example, it might be
    confusing that these two types are identical:

    ``` unison
    structural type Suit = Hearts | Spades | Diamonds | Clubs

    structural type Direction = North | South | East | West
    ```

    Unison will consider every unary type constructor with four nullary data
    constructors as identical to these declarations. So Unison will not stop us
    providing a Direction where a Suit is expected.

    The unique keyword solves this problem:

        @source{type Suit, type uniqueTypes.Direction}

    When compiling these declarations, Unison will generate a
    [universally unique identifier](https://en.wikipedia.org/wiki/Universally_unique_identifier)
    for the type and use that identifier when generating the hash for the type.
    As a result, the type gets a hash that is universally unique.
  }}

docs.languageReference.unit : Doc
docs.languageReference.unit =
  {{
  # Unit

    Unit is a special type in Unison with a single value, instatiated by `()`.
    Its representation in type signatures is also written `()`.

    Unit is used to represent the absence of a returned value, or a value that
    carries no information. It's often used as a return type for functions that
    perform effects. It signifies that something has been done, but that no
    meaningful value was otherwise produced.

    For example, @inlineSignature{printLine} returns Unit because it performs
    the effect of printing a line to the console, but the act of printing
    doesn't produce a value beyond the effect itself.
  }}

docs.languageReference.useClauses : Doc
docs.languageReference.useClauses =
  {{
  # Use clauses

    A __use clause__ tells Unison to allow [identifiers]({identifiers}) from a
    given [namespace]({identifiers}) to be used
    [unqualified]({namespaceQualifiedIdentifiers}) in the {{
    docTooltip {{ lexical scope }} {{ {{ lexicalScope }} }} }} where the use
    clause appears.

    In this example, the `use base.List` clause allows the definition that
    follows it to refer to `lib.base.List.take` as simply `take`:

    ``` unison
    oneTwo = List.take 2 [1, 2, 3]
    ```

    The general form of `use` clauses is as follows:

    ``` unison
    use pathToNamespace name_1 name_2 .. name_n
    ```

    Where `namespace` is the namespace from which we want to use names
    unqualified, and `name_1` through `name_n` are the names we want to use. If
    no names are given in the `use` clause, Unison allows all the names from
    the namespace to be used unqualified. There's no performance penalty for
    this, as `use` clauses are purely a syntactic convenience. When rendering
    code as text, Unison will insert precise `use` clauses that mention exactly
    the names it uses, even if the programmer omitted the list of names.

    See the section on [identifiers]({identifiers}) for more on namespaces as
    well as qualified and unqualified names.
  }}

docs.languageReference.userDefinedAbilities : Doc
docs.languageReference.userDefinedAbilities =
  use Store get put
  {{
  # User-defined abilities

    A user-defined ability is declared with an `ability` declaration such as:

        @source{type Store}

    Abilities need to be defined with either the `structural` or `unique`
    keyword. See the sections on [unique types]({uniqueTypes}) and
    [structural-types]({structuralTypes}) for more detail on the difference.

    This results in a new ability type constructor {type Store} which takes a
    type argument `a`. It also create two value-level constructors named {get}
    and {put}. The idea is that {get} provides the ability to "get" a value of
    type `a` from somewhere, and {put} allows "putting" a value of type `a`
    somewhere. Where exactly these values of type `a` will be kept depends on
    the handler.

    The {type Store} constructors {get} and {put} have the following types:

    * @inlineSignature{get}
    * @inlineSignature{put}

    The type `{Store v}` means that the computation which results in that type
    requires a `Store v` ability and cannot be executed except in the context
    of an __ability handler__ that provides the ability.
  }}

docs.languageReference.userDefinedDataTypes : Doc
docs.languageReference.userDefinedDataTypes =
  use Optional None
  {{
  # User-defined data types

    A user-defined data type is introduced with the `type` keyword and a
    modifier `unique` or `structural`. The modifier indicates if the type is
    unique by its name, or if it is unique only by its structure. (See
    [Types](./types) for an informal description of Unison's type system.)

    For example:

        @source{type Optional}

    or

        @source{type UserId}

    The `=` sign splits the definition into a __left-hand side__ and a
    __right-hand side__, much like term definitions.

    The left-hand side is the data type being defined. It gives a name for the
    data type and declares a new [type constructor]({typeConstructors}) with
    that name (here it's named {type Optional}), followed by names for any type
    arguments (here there is one and it’s called `a`). These names are bound as
    type variables in the right-hand side. The right-hand side may also refer
    to the name given to the type in the left-hand side, in which case it is a
    recursive type declaration. Note that the fully saturated type construction
    `Optional Nat` is a type, whereas `Optional` by itself is a type
    constructor, not a type (it requires a type argument in order to construct
    a type).

    The right-hand side consists of zero or more data constructors separated by
    `|`. These are __data constructors__ for the type, or ways in which values
    of the type can be constructed. Each case declares a name for a data
    constructor (here the data constructors are {None} and {Some}), followed by
    the **types** of the arguments to the constructor.

    When Unison compiles a type definition, it generates a term for each data
    constructor. Here they are the terms @inlineSignature{Some}, and
    @inlineSignature{None}. It also generates __patterns__ for matching on data
    (see [Pattern Matching]({matchExpressionsAndPatternMatching})).

    Note that these terms and patterns receive qualified names: if the type
    named `x.y.Z` has a data constructor `C`, the generated term and pattern
    for `C` will be named `x.y.Z.C`.

    The general form of a type declaration is as follows:

    ``` unison
    <unique|structural<[<regular-identifier>]?>?> type TypeConstructor p1 p2 … pn
      = DataConstructor_1
      | DataConstructor_2
      ..
      | DataConstructor_n
    ```
  }}

docs.languageReference.userDefinedTypes : Doc
docs.languageReference.userDefinedTypes =
  {{
  # User-defined types

    New types can be declared as described in detail in the
    [User-defined types]({userDefinedDataTypes}) section. These include
    ordinary [data types]({userDefinedDataTypes}),
    [unique types]({uniqueTypes}), and [record types]({recordType}). A type
    declaration introduces a type, a corresponding type constructor, one or
    more data constructors that (collectively) construct all possible values of
    the type, and (in the case of record types) accessors for the named
    arguments of the type's single data constructor.
  }}

docs.languageReference.variablePatterns : Doc
docs.languageReference.variablePatterns =
  {{
  # Variable patterns

    A __variable pattern__ is a [regular identifier]({identifiers}) and matches
    any expression. The expression that it matches will be bound to that
    identifier as a variable in the match body.

    For example:

    ``` unison
    match 1 + 1 with
      x -> x + 1
    ```
  }}

docs.languageReference._sidebar : Doc
docs.languageReference._sidebar =
  {{
  * [Top-level declarations]({topLevelDeclaration})
  * [Term declarations]({termDeclarations})
    * [Type signatures]({typeSignatures})
    * [Term definition]({termDefinition})
    * [Operator definitions]({operatorDefinitions})
  * [Ability declaration]({languageReference.abilityDeclaration})
  * [User-defined data types]({userDefinedDataTypes})
    * [Structural types]({structuralTypes})
    * [Unique types]({uniqueTypes})
    * [Record types]({recordType})
  * [Expressions]({expressions})
    * [Basic lexical forms]({basicLexicalForms})
    * [Identifiers]({identifiers})
  * [Name resolution and the environment]({nameResolutionAndTheEnvironment})
  * [Blocks and statements]({blocksAndStatements})
  * [Literals]({literals})
    * [Documentation literals]({documentationLiterals})
    * [Escape sequences]({escapeSequences})
  * [Comments]({comments})
  * [Type annotations]({typeAnnotations})
  * [Parenthesized expressions]({parenthesizedExpressions})
  * [Function application]({languageReference.functionApplication})
    * [Syntactic precedence of operators and prefix function application]({syntacticPrecedenceOperatorsPrefixFunctionApplication})
  * [Boolean expressions]({booleanExpressions})
  * [Delayed computations]({languageReference.delayedComputations})
    * [Syntactic precedence]({syntacticPrecedence})
  * [Destructuring binds]({destructuringBinds})
  * [Match expressions and pattern matching]({matchExpressionsAndPatternMatching})
    * [Blank patterns]({blankPatterns})
    * [Literal patterns]({literalPatterns})
    * [Variable patterns]({variablePatterns})
    * [As-patterns]({asPatterns})
    * [Constructor patterns]({constructorPatterns})
    * [List patterns]({languageReference.listPatterns})
    * [Tuple patterns]({tuplePatterns})
    * [Ability patterns (or `Request` patterns)]({abilityPatterns})
    * [Guard patterns]({guardPatterns})
  * [Hashes]({hashes})
  * [Types]({types})
    * [Type variables]({typeVariables})
    * [Polymorphic types]({polymorphicTypes})
    * [Scoped type variables]({scopedTypeVariables})
    * [Type constructors]({typeConstructors})
    * [Kinds of Types]({kindsOfTypes})
    * [Type application]({typeApplication})
    * [Function types]({functionTypes})
    * [Tuple types]({tupleTypes})
    * [Built-in types]({builtInTypes})
    * [Built-in type constructors]({builtInTypeConstructors})
    * [User-defined types]({userDefinedTypes})
    * [Unit]({languageReference.unit})
  * [Abilities and ability handlers]({abilitiesAndAbilityHandlers})
    * [Abilities in function types]({abilitiesInFunctionTypes})
    * [The typechecking rule for abilities]({theTypecheckingRuleForAbilities})
    * [User-defined abilities]({userDefinedAbilities})
    * [Ability handlers]({abilityHandlers})
    * [Pattern matching on ability constructors]({patternMatchingOnAbilityConstructors})
  * [Use clauses]({useClauses})
  }}

docs.languageReference._suffixedBasedNameResolution : Doc
docs.languageReference._suffixedBasedNameResolution =
  {{
  # Suffix-based name resolution

    If the list of __segments__ of a name (''base.List.map'' has the segments
    `[base,List,map]`) is a suffix of exactly one fully qualified name in the
    environment, Unison substitutes that name in the expression with a
    reference to the definition. For example, the fully qualified name
    `.base.List.map` could be referenced via `base.List.map`, `List.map` as
    long as no other definitions end in `base.List.map` or `List.map`. This
    reduces the number of [imports]({useClauses}) needed and cuts down on
    needing to remember the fully qualified names for definitions. ("Was it
    `base.List.map` or `util.List.map`?")

    [Hash literals](./hashes) in the program are substituted with references to
    the definitions in the environment whose hashes they match.

    If a free term variable in the program cannot be found in the environment
    and is not the name of another term in scope in the program itself, or if
    an free variable matches more than one name (it's ambiguous), Unison tries
    [type-directed name resolution](./_typeDirectedNameResolution).
  }}

docs.languageReference._typeDirectedNameResolution : Doc
docs.languageReference._typeDirectedNameResolution =
  {{
  # Type-directed name resolution

    During typechecking, if Unison encounters a free term variable that is not
    a term name in the environment, Unison attempts
    __type-directed name resolution__, which:

    1. Finds term definitions in the environment whose __unqualified__ name is
       the same as the free variable.
    2. If exactly one of those terms has a type that conforms to the expected
       type of the variable (the type system has always inferred this type
       already at this point), perform that substitution and resume
       typechecking.

    If name resolution is unable to find the definition of a name, or is unable
    to disambiguate an ambiguous name, Unison reports an error.
  }}

docs.projects : Doc
docs.projects =
  use wordle.utils.emojis hint learnMore
  {{
  # 🗄 Unison projects introduction

    A Unison project is a Unison codebase concept that represents a library,
    application, or other code package that can be shared, collaborated on, and
    versioned. You'll create and manipulate projects with a few simple UCM
    commands and can view your projects on Unison Share.

    One Unison codebase often houses multiple libraries, applications, works in
    progress, and prototypes with varying needs for sharing and structure.
    Given that Unison code isn't stored in files that can be grouped into git
    repositories or other conventional collaboration mechanisms, we need an
    additional codebase abstraction for a packageable unit of code. This is
    where Unison projects come in. Namespaces are for organizing your source
    code into a logical tree, whereas projects power developer workflows that
    are related to collaboration and dependency management.

    {{ docCallout
      (Some hint) {{
      Some things that you'll end up doing with projects include:

      * Specifying if a package is public or private
      * Working on a branch of a project without affecting the mainline
      * Creating a pull request that can be reviewed and merged by others
      * Adding a dependency on a library
      * Releasing a new version of a library
      }} }}

  # 🏁 Projects quickstart

    Let's walk through a quick example of how to navigate a Unison codebase
    with projects. We'll create a new project, add a project library
    dependency, create and merge a branch in our project, and push it to Unison
    Share.

    {{
    docCallout
      Optional.None
      {{
      If you've authored Unison libraries that are currently hosted on Unison
      share and want the 5 minute cheat-sheet for migrating your library,
      [see the quick migration guide here](/tooling/projects-library-migration/).
      }} }}

    Unison projects formalize many of the conventions you may be familiar with
    if you've been creating top-level namespaces for your libraries. Projects
    will live at the root of your codebase and dependencies will still be
    stored in a `lib` directory for the project.

    Let's create a new project called `helloProjects` now:

    ``` ucm
    scratch/main> project.create helloProjects

      🎉 I've created the project helloProjects.

      I'll now fetch the latest version of the base Unison library...

    helloProjects/main>
    ```

    In the UCM, your console prompt will be updated to indicate that you're in
    the `helloProjects` project; the segment prefixed by a slash, `/main`, is a
    __branch__ of the project. Branches are a new feature to Unison projects
    that allow for concurrent work streams, long-lived feature work, PR's, and
    more.

    Let's create a new branch instead of working on `main` directly.

    ``` ucm
    helloProjects/main> branch myNewBranch

      Done. I've created the myNewBranch branch based off of main

      Tip: Use `merge /myNewBranch /main` to merge your work back
           into the main branch.
    ```

    `branch` creates a new branch of the project from the current branch. In
    this case `myNewBranch` is a copy of `main` and contains all the same code
    and history. Take a look around at the branches of the current project with
    the `branches` command and we should see both `main` and `myNewBranch`.

    ``` ucm
    helloProjects/myNewBranch> branches

           Branch        Remote branch
      1.   main
      2.   myNewBranch
    ```

    Upon creating a new project, the UCM installs the `base` standard library
    as a dependency in the `lib` namespace for you. The UCM looks for project
    dependencies in a `lib` namespace located at the root of the project. Let's
    add another dependency on
    [the cloud project](https://share.unison-lang.org/@unison/cloud) with the
    `lib.install` command.

    {{
    docAside
      {{
      Users who have a version of Unison older than 0.5.21 should use the
      `pull` command.
      }} }}

    If you're ever wondering what the command looks like to download a given
    project, the Unison Share UI shows you the latest download command when you
    navigate to the project's home page.

    ``` ucm
    helloProjects/myNewBranch> lib.install @unison/cloud
    ```

    This will install the given latest version of the `cloud` project into the
    `lib` namespace of the current project.

    When we're __within__ a project, the existing UCM commands for navigating
    and viewing namespaces work as before. Let's take a look at the `cloud`
    project we just pulled in.

    ``` ucm
    helloProjects/myNewBranch> ls lib.unison_cloud_15_1_0

      1.  AccessToken        (type)
      2.  AccessToken/       (2 terms)
      3.  CHANGELOG          (base.Doc)
      4.  CHANGELOG/         (1 term)
    ```

    Open up a scratch.u file in a text editor window and add the following
    Unison code to it. Save the file when you're ready to add it to the
    codebase.

    ``` unison
    README = {{
      # Hello Projects

      This is a simple Unison project.
    }}

    helloWorld : '{IO, Exception} ()
    helloWorld = do
      printLine ("Hello " ++ "yourName")
    ```

    Use the `add` command in the UCM so the `helloWorld` function will be
    present in `myNewBranch`. In Unison, we don't have specific named
    "commits", just additions and updates to the codebase state.

    We'll merge this branch back into the `main` branch next.

    ``` ucm
    helloProjects/myNewBranch> add

      ⍟ I've added these definitions:

        README     : Doc
        helloWorld : '{IO, Exception} ()
    ```

    `merge` takes two arguments, the source and the destination, respectively.
    We can indicate that we are merging a branch into another branch by
    prefixing the branch name with a slash.

    ``` ucm
    helloProjects/myNewBranch> merge /myNewBranch /main

      Here's what's changed in helloProjects/main after the merge:

      Added definitions:

        1. README     : Doc
        2. helloWorld : '{IO, Exception} ()

      Tip: You can use `todo` to see if this generated any work to
           do in this namespace and `test` to run the tests. Or you
           can use `undo` or `reflog` to undo the results of this
           merge.
    ```

    {{
    docCallout
      (Some hint)
      {{
      The UCM commands for managing projects allow you to drop the project name
      from the command if you are referencing the same project that or branch
      your UCM prompt is currently located in.

      ``` ucm
      helloProjects/main> merge helloProjects/myNewBranch helloProjects/main
      ```

      The above command is equivalent to:

      ``` ucm
      helloProjects/main> merge /myNewBranch
      ```
      }} }}

    Switch back to the main branch with the `switch` command, and optionally
    delete your old feature branch. Now that we've merged our changes into the
    `main` branch, we can push our project to Unison Share.

    ``` ucm
    helloProjects/myNewBranch> switch main
    helloProjects/main> delete.branch myNewBranch
    ```

    First log into Unison Share with the `auth.login` command. Once logged in,
    we'll use the `push` command to do this. Pushing a project to Unison Share
    will automatically create a {{
    docTooltip {{ remote mapping }} remoteMapping }} between the local branch
    and the remote branch.

    ``` ucm
    helloProjects/main> push
    ```

    Head to the Unison Share url displayed by the UCM to view your project.
    You'll see that the `main` branch is hosted there and the project's welcome
    page includes your README. {{
    docAside
      {{
      Your projects will also be listed in your Unison share workspace at
      `https://share.unison-lang.org/@yourUsername`.
      }} }}

    Finally, view a list of your projects with the `projects` command. You can
    always get back to your project with the `switch` command.
    `switch helloProjects` will take you back to the last branch you were
    working on.

    ``` ucm
    helloProjects/main> projects

      1. anotherHypotheticalProject

    helloProjects/main> switch anotherHypotheticalProject
    ```

    Hooray! You have just created what we hope will be the first of many new
    Unison projects! Happy coding! 😎

  # More about projects in Unison

    {{ suggested }}
    [Full list of common workflows for projects]({projectWorkflows})

    {{ suggested }}
    [Migrating a library from namespaces to projects](/tooling/projects-library-migration)

    {{ learnMore }} [Projects FAQ's]({projectFAQs})

    {{ learnMore }}
    [Codebase organization](/tooling/projects-codebase-organization)
  }}

docs.quickstart : Doc
docs.quickstart =
  {{
  # ⏳ Three-minute quickstart guide

    This short guide will have you downloading and installing Unison and
    running your first program. There isn't much exposition here and the focus
    is on getting you up and running as quickly as possible.

    More in-depth guides follow this one.

    ## Step 1: Install Unison

       If you haven't already, please join the
       [`#general` and `#troubleshooting` channels on Discord](https://unison-lang.org/discord).

       We are really hoping that if you are trying out Unison you'll come talk
       to us, ask questions, and report bugs! We want you to have a welcoming
       and positive experience when getting started! 😊

       {{ installInstructions }}

    ## Step 2: Create your Unison codebase

       Run `ucm` to initialize a Unison codebase in `$HOME/.unison`. This is
       where Unison will store function definitions, types, namespaces, and so
       on.

    ## Step 3: Create the quickstart project

       A Unison codebase is subdivided into many
       {{ docTooltip {{ projects }} project }}. Unison projects represent the
       various libraries, applications, or programs that you might be working
       on. From the root of your codebase, represented with `.`, use the
       `project.create` command to make a new quickstart project. It will
       create a `main` branch for you to work in.

       ``` ucm
       scratch/main> project.create quickstart
       ```

       You'll see the UCM download the `base` standard library into a `lib`
       namespace. Namespaces help give structure to Unison code because a
       Unison codebase isn't saved to the file system. You can think of this as
       our analog to a directory structure. Namespace segments are separated
       with the `.` character. A project's dependencies are located in a
       special namespace called `lib`. The code for our quickstart project will
       be simple, so we only need the `base` library in scope. Check that the
       `base` library has been downloaded by running `ls lib.base` in the UCM.

       ``` ucm
       quickstart/main> ls lib.base
       ```

    ## Run your first program

       Head to the text editor of your choosing and create a new file called
       `scratch.u` in the directory where you launched `ucm` (so if you
       launched `ucm` from `~/myUnisonCode`, you'd create
       `~/myUnisonCode/scratch.u`). Add the following code to the file:

       ``` unison
       myTerm = List.map (x -> x * 10) [1,2,3,4,5,6]
       > myTerm
       ```

       The first line is defining a Unison term called `myTerm`. This one
       multiplies every element in a list by ``10``, using the
       {jsonschema.lib.base.data.List.map} function.

       The second, beginning with `>`, is a
       {{ docTooltip {{ watch expression }} {{ {{ watchExpression }} }} }}.

       The `ucm` monitors all the unison source files in the current directory
       for changes and evaluates any watch expressions:

       ``` ucm
       quickstart/main>

         I found and typechecked these definitions in ~/myUnisonCode/scratch.u. If you do an `add` or
         `update`, here's how your codebase would change:

           ⍟ These new definitions are ok to `add`:

             myTerm : [Nat]

         Now evaluating any watch expressions (lines starting with `>`)... Ctrl+C cancels.

           2 | > myTerm
                 ⧩
                 [10, 20, 30, 40, 50, 60]
       ```

       Congratulations, you ran your first Unison program!

    ## We want to hear from you!

       If you have any trouble with the process, or have ideas about how to
       improve this document,
       [come talk to us in the `#troubleshooting` Discord channel](https://unison-lang.org/discord)!

       {{ quickstart._nav }}
  }}

docs.quickstart._nav : Doc
docs.quickstart._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Take a longer tour of the UCM and Unison language features]({{
      (docLink (docEmbedTermLink do tour))
      }})

      {{ suggested }}
      [Come say hello in Discord, tell us what you thought about this guide,
      and ask questions 👋](https://unison-lang.org/discord)

      {{ suggested }}
      [A brief intro to the big idea behind Unison]({{
      (docLink (docEmbedTermLink do theBigIdea))
      }})

      {{ suggested }}
      [What problems does Unison solve]({whatProblemsDoesUnisonSolve})

      {{ wordle.utils.emojis.learnMore }}
      [Setting up your favorite editor for Unison]({editorSetup})
    }} }}
  }}

docs.theBigIdea : Doc
docs.theBigIdea =
  {{
  # 💡 The big idea

    {{ _bigTechnicalIdea }}

    {{ theBigIdea._nav }}
  }}

docs.theBigIdea._nav : Doc
docs.theBigIdea._nav =
  {{
  # Where to next?

    {{ suggested }}
    [Take a tour of the codebase manager and the Unison language]({{
    docLink (docEmbedTermLink do tour)
    }})

    {{ suggested }}
    [What problems does Unison solve?]({whatProblemsDoesUnisonSolve})

    {{ wordle.utils.emojis.learnMore }}
    [Watch some talks about Unison](../talks)
  }}

docs.todo.TODO : Doc
docs.todo.TODO =
  {{
  # {{ placeholder }} TODO 🚧🚧

    👋 Hi fellow Unizen! You've found a link to a doc section that is in
    progress! Don't worry, we're hard at work finishing it up.

    If there's anything you'd like some information on that hasn't been written
    yet, just check in with the
    [friendly slack community](https://unison-lang.org/slack)!

    We'd love to hear from you! 😊
  }}

docs.tooling.authorLicense : Doc
docs.tooling.authorLicense =
  {{
  # Creating an author and license

    If you intend to publish your code in a project for others to use, you'll
    want to specify a license at the root of your project laying out the
    conditions under which others may use it.

    First create an author with the [`create.author`]({create.author}) command.
    It's perfectly fine to create a new {type metadata.Author} term per
    project, but if your author term is already defined in a library dependency
    included in the project, you can refer to that instance in your license
    instead of creating a new one.

    ``` ucm
    project1/main> create.author aliceCoder "Alice Coder"
    ```

    This adds the following values to your codebase:

    ``` ucm
    1. metadata.authors.aliceCoder          : metadata.Author
    2. metadata.authors.aliceCoder.guid     : GUID
    3. metadata.copyrightHolders.aliceCoder : CopyrightHolder
    ```

    Next, create a License with a {type CopyrightHolder} and {type LicenseType}
    under which to publish your code. The license is an ordinary Unison value
    of type {type License}. In your scratch file, you'll create a license value
    like this:

    ``` unison
    LICENSE =
       License [copyrightHolders.aliceCoder] [Year 2023] licenseTypes.bsd3
    ```

    Your Unison authorship information is linked to the project via inclusion
    in this term.

    Add that to your project at the top-level of the project:

    ``` ucm
    project1/main> add
    ```
  }}

docs.tooling.codebaseOrganization : Doc
docs.tooling.codebaseOrganization =
  use ucmCommands pull
  {{
  # Organizing your codebase (deprecated)

    See [projects codebase organization]({projectsCodebaseOrganization}) for
    the latest documentation on organizing your codebase.

    Though the Unison namespace tree can be organized however you like, this
    document suggests handy conventions to keep things tidy even with multiple
    concurrent workstreams, pull requests, library releases, and external
    dependencies being added and upgraded. We like conventions that can be
    followed without much thought and which make things easy, so you can direct
    your brainpower to actually writing Unison code, not figuring out how to
    organize it. 😀

    We recommend using this exact same set of conventions for library
    maintainers, library contributors, and application developers. It makes it
    easy to follow the conventions regardless of which of these roles you are
    working in, and doesn't require reorganizing anything if you decide you
    want to publish your personal Unison repository as a library for others to
    build on.

    {{
    docCallout
      (Some placeholder)
      {{
      This documentation is still in draft form and these conventions are
      changing rapidly. Please help test out these conventions and let us know
      how they work for you. Also any general feedback or questions are
      welcome! See
      [this ticket](https://github.com/unisonweb/unison/issues/1409) or start a
      thread [in Slack #troubleshooting](https://unison-lang.org/slack).
      }} }}

    Here's what a namespace tree will look like that follows these conventions.
    This will be explained more below, and we'll also show how common workflows
    (like installing and upgrading libraries and opening pull requests) can be
    handled with a few UCM commands:

    ``` raw
    myProject
        main/
          Boolean/
          Nat/
          ...
          README : Doc
          releaseNotes : Doc
          lib/
            dependency1.v7/
            alice.mylib.v94/
            alice.mylib.v87/
            bob.somelib.main/

        latest/
          Boolean/
          Nat/
          README : Doc
          releaseNotes : Doc
          /lib
            dependency1.v7/
            ...

        releases/
          v1/
          v2/
          ...

        series/
          v1/
          v2/

        prs/
          myGreatPR
          anotherNewFeature
          ...
          ...
    ```

    Directly under the namespace root, we have a project called `myProject`
    with a `main` namespace for the project maintainers add their latest
    feature work in, a `latest` (sub-)namespace (for the latest stable
    version), a `releases` namespace containing released versions of main, a
    `series` namespace (for releases branches, forked off `main`), and a `prs`
    namespace, containing work that will eventually get merged to `main`.
    Additionally, if you contribute PRs to projects that aren't primarily your
    own, you might have a top-level `.prs` namespace which contains copies of
    the libraries and namespaces for new features.

    Its common to have multiple projects under the root of your codebase,
    representing the various libraries or applications you're writing in
    Unison.

    {{
    docAside
      {{
      The standard library, `base` is also downloaded to the root of the
      codebase.
      }} }}

    ## Upgrading libraries to the latest version

       There's no problem with having multiple versions of a library installed
       at once, though sometimes you want to upgrade to the latest version of a
       library and delete any references to the old version. There are a couple
       cases you can encounter here. If `alice.mylib.v6` is a superset of
       `alice.mylib.v5`, this is as simple as just deleting the `v5` after `v6`
       is installed.

       😎 Since references to definitions are by hash, not by name, any renaming
       of definitions done between `v5` and `v6` of a library won't break any
       of your code. Though we recommend reading the release notes to discover
       these sorts of changes, or using `diff.namespace somelib.v5 somelib.v6`
       for an overview.

       If `v6` replaced any definitions with new ones (using the {{
       docTooltip {{ `update` }} ucmCommands.update }} command or
       `replace.term` or `replace.type`), these are recorded in a __patch__
       which can be applied locally.

       {{
       docAside {{ More background on [refactoring in Unison]({updateCode}) }}
       }}

       As a norm, `alice.mylib.v6.releaseNotes` will cover how to apply patches
       to your local namespace. It will typically be commands like:

       ``` ucm
       myProject/main> branch main upgradeAliceLib
       myProject/upgradeAliceLib> patch external.mylib.v6.patches.v5_v6 upgradeAliceLib
       myProject/upgradeAliceLib> merge /upgradeAliceLib /main
       ```

    ## Day-to-day development: creating and merging pull requests

       Here's the basic workflow for drafting changes to `main` in
       __your own project.__ It's not much different than a typical Git
       workflow, where you create branches, hack on them, then merge them to
       `main` when done:

       1. `myProject/main> branch main myCoolPR`
       2. `myProject/myCoolPR>` Now hack away. Use
          `merge.preview main myCoolPR` at any time to see what you've changed.
       3. `myProject/myCoolPR> merge /myCoolPR /main` when you're done

       To propose changes to another Unison codebase works similarly. We'll use
       [the Unison base library](https://github.com/unisonweb/base/blob/master/CONTRIBUTING.md)
       as an example:

       1. `scratch/main> pull unison.public.base.main _base` you can do this
          both for initial fetch and for subsequent updates
       2. `scratch/main> fork _base .prs.base._mything` to create a copy of
          `_base`. You can create multiple forks in `.prs.base`, if you have
          multiple things you're working on.
       3. If you haven't already done so, set your default license for
          `.prs.base` to match the license of the codebase you're contributing
          to. For
          [base](https://github.com/unisonweb/base/blob/master/CONTRIBUTING.md)
          it's the MIT license.
       4. Now `cd .prs.base._mything` and hack away as before. At any time
          review what's changed between your namespace and `_base` with
          `diff.namespace ._base .prs. base._mything`.
       5. Push your forked version somewhere public with your
          [Unison Share account](https://share.unison-lang.org/).
          `prs.base._mything> push myUser.public.prs.base._mything`. No need to
          maintain a separate Git repo for every Unison library you want to
          contribute to.
       6. `.prs.base._mything> pull-request.create unison.public.base.latest myUser.public.prs.base._mything`
          and this will create some output. Copy that output to your clipboard.
          We don't literally use the GitHub pull request mechanism for Unison
          repositories, we use GitHub issues instead.
       7. Use the GitHub issue comments for coordinating the review. Once
          merged, the maintainer will close the issue.
       8. Next, create a GitHub issue in the repo you're submitting the code to
          (that's right, an __issue__, **not** a GitHub PR). Many Unison
          repositories will have
          [a GitHub issue template](https://github.com/unisonweb/base/issues/new?template=unison-pull-request-template.md)
          for this purpose. Make the issue title something descriptive, and for
          the issue body, paste in the output generated by
          '''
          pull-request.create` as well as some text describing the change, just like you would for any other pull request.

                                                                                                                                                                                                                                                                                                      This workflow also works fine even if the source and destination repository are the same, so you might use the above PR process when suggesting changes to a library  that you maintain with other people.

                                                                                                                                                                                                                                                                                                      ### Reviewing pull requests

                                                                                                                                                                                                                                                                                                      We'll use [this issue as an example](https://github.com/unisonweb/base/issues/12). The issue created for the PR will have a
          '''pull-request.load'' command to review the PR locally. We'll run
          that command in any empty namespace:

       ``` ucm
       .review.pr12> pull-request.load unison.public.base.main pchiusano.public.unisoncode.prs.random2
       ```

       If you `.review.pr12> ls` you'll see three or four sub-namespaces:
       `base` (the original namespace), `head` (the new namespace), `merged`
       (the result of `merge head base`) and potentially `squashed` (the same
       content as `merged` but without intermediate history). The following
       commands can be performed against either the `merged` or `squashed`
       namespace, depending on if preserving history is important to you:

       1. `.review.pr12> diff.namespace base merged` to see what's changed. The
          numbered entries in the diff can be referenced by subsequent
          commands, so `diff.namespace   base merged` might be followed by
          `view 1-7` to view the first 7 definitions listed there.
       2. You can use comments on the GitHub issue to coordinate if there's any
          changes you'd like the contributor to make before accepting the PR.
          You can also make changes directly in `merged`.
       3. `.review.pr12> push unison.public.base.main merged` to push `merged`
          to `main`
       4. `.review.pr12> history merged` and copy the top namespace hash.
          That's the Unison namespace hash as of the merged PR. Then close the
          GitHub issue with a comment like "Merged to main in hash #pjdnqduc38"
          and thank the contributor. 😀 If you ever want to go back in time, you
          can say `scratch/main> fork #pjdnqduc38 .pr12` to give the
          `#pjdnqduc38` namespace hash the name `.pr12` in your tree.
       5. If you like, `scratch/main> delete.namespace .review.pr12` to tidy up
          afterwards.

       ### Keeping in sync with `main`

           Periodically, you can {{ docTooltip {{ `pull` }} pull }} the latest
           `main` using:

           ``` ucm
           scratch/main> pull git(https://gitub.com/unisonorama/myproject) main
           ```

           If you have in-progress PRs that you want to sync with the latest,
           you can bring them up to date using `.prs._myPR> merge .main`.

    ## Using unreleased library versions

       Sometimes, you want to use some code that's only in `main` of a library
       but hasn't made its way into a release. No problem. The install process
       looks the same, just do a {{ docTooltip {{ `pull` }} pull }}:

       ``` ucm
       scratch/main> pull https://github.com/bob/mylib:.main .external.bob.mylib.main
       ```

       As often as you like, you can re-issue the above command to fetch the
       latest version of the library. After doing so, you should then apply
       patches from the library to your local namespace. Check the project's
       README for information on how to do this, but typically, for a
       namespace, `bob.mylib.main`, there will just be a patch called
       `bob.mylib.main.patch` which can be applied with:

       ``` ucm
       scratch/main> fork main prs.upgradeBob
       scratch/main> patch external.bob.mylib.main.patch prs.upgradeAliceLib
       ```

       Assuming all is well after that `patch`, you can
       `scratch/main> merge prs.upgradeBob main` (and then sync that with any
       other PRs being drafted, as discussed in the previous section).

       If you are feeling adventurous it's also possible to directly apply the
       patch to your in-progress PRs or even `main`.

    ## How to create a release

       Suppose you are creating `v12` of a library. The process is basically to
       `fork` a copy of `main`:

       0. Before getting started, we suggest reviewing the current patch in
          `main` with `scratch/main> view.patch main.patch`. The term and type
          replacements listed here should generally be bugfixes or critical
          upgrades that you expect users of your library to make as well. You
          can use `delete.term-replacement` and `delete.type-replacement` to
          remove any entries you don't want to force on library users. See
          below for more.
       1. Fork a copy of `main`: `scratch/main> fork main series._v12`
       2. The current dependencies in the release should be included in the
          library's `lib` namespace. This convention ensures that anyone who
          obtains the library also receives its dependencies and the naming for
          those definitions at the time.
       3. Create or update `series._v12.releaseNotes : Doc`. You can include
          the current namespace hash of `series._v12`, a link to previous
          release notes, like `releases. _v11 releaseNotes`, and if the release
          has a non-empty `patch`, give some guidance on upgrading. Are all the
          edits type-preserving? If no, what sort of refactoring will users
          have to do?
       4. `squash series._v12 releases._v12` to create the release. This
          squashed `releases._v12` will have no history and is more efficient
          for users to `pull` into their codebase.
       5. Reset the patch and release notes in `main`:
          `scratch/main> delete.patch patch` and
          `scratch/main> delete.term releaseNotes`. Anyone can upgrade from a
          past release `v3`, by applying the patches `releases._v4.patch`,
          `releases._v5.patch` up through `releases._v12.patch`.
          * If desired, you can also produce cumulative patches for skipping
            multiple versions. These can be published on an ad hoc basis. If
            publishing these, just include them in
            `releases._v12.patches.v4_to_v12`.
       6. Optional: you can add updated instructions for fetching the release
          to the the README on the repo's Unison Share page. You can also let
          folks know about the release via any other communication channels
          (Twitter, Slack, etc).

       We don't recommend any fancy numbering scheme for versioning, just
       increment the version number. Use the `releaseNotes` to convey metadata
       and additional nuance about each release.

       ### Backporting fixes

           Creating a bugfix release works the same way. Suppose the `v12`
           release has a bug. The bug has been fixed in the latest `trunk` and
           you'd like to backport it. Just backport the fix to the
           `series._v12` namespace and continue with the release steps as
           before, but this time create `releases._v12a` then `_v12b`, `_v12c`,
           etc.

       ### Patch management

           {{
           docAside
             {{
             🖋 This section is in draft form and undergoing revisions for
             clarity. Feedback and questions are welcome!
             }} }}

           Patches are collections of mappings from old hash to new hash (these
           entries are called "replacements"). We've seen above how these
           patches can be applied to upgrade a namespace using these
           replacements. The patches are built up via `update` or
           `replace.term` or `replace.type` commands which add replacements to
           a default patch (called "patch") that exists under each namespace in
           the tree. You can view this or any other patch using `view.patch`:

           ``` ucm
           mylib/trunk> view.patch patch

             Edited Terms: List.frobnicate#92jajfh197 -> List.frobnicate
             Edited Terms: CinnamonRoll#93jg10ba -> SugarCookie

             Tip: To remove entries from a patch, use delete.term-replacement or
                  delete.type-replacement, as appropriate.
           ```

           🤓 The `update` and `replace.term` and `replace.type` commands also
           take an optional patch name, if you want to build up a patch
           somewhere other than the default patch. This is handy for keeping
           logically unrelated patches separate. You can also `move.patch` and
           `delete.patch`.

           #### Release patches

                There are a lot of reasons you might add replacements to a
                patch during the course of development (see the development
                patches section below), but for patches published with a
                release, it's recommended to limit the replacements to cases
                where the old definition is invalid or would never be preferred
                the new version (generally just bugfixes for previously
                released definitions, performance improvements, and critical
                upgrades). Why do this? Because it makes things a lot easier
                for your users and avoids needless churn.

                In other languages, where definitions are identified by name
                and the codebase is just mutated in-place, every change to the
                codebase amounts to a forced upgrade for users. We don't often
                think of it this way, but by updating `List.frobnicate`, the
                old version of `List.frobnicate` is effectively __deleted__ and
                no one gets to reference the old definition of
                `List.frobnicate` (unless they literally go through the Git
                history and bring it back somehow). Very often this is done
                __not__ because the old version is wrong or should never be
                used, but because we don't feel like coming up with another
                name for the new definition and decide to just repurpose an
                existing name.

                When this name repurposing is done for definitions that have
                already been released, it generates work that often isn't
                necessary.

                In Unison, the decision to repurpose a name is
                __completely separate__ from the decision to force an upgrade
                on users. If you want to repurpose a name like
                `List.frobnicate` but the old definition is still valid (ask
                yourself "could someone reasonably still build on the old
                definition, or is the new definition always preferable?"), you
                can first delete the old definition (via `delete.term`), or
                archive it by moving it to
                `_archive.  y2020_m03_d24_frobnicate`, timestamped with the
                current date. Then create the new definition for
                `List.frobnicate`.

                If you've already done an `update`, no problem. Just use
                `delete.term-replacement` or `delete.type-replacement` to
                remove replacements from the patch before release.

                Here are a few common types of updates that won't usually be
                part of a release patch, but will instead be part of a
                development patch, covered next:

                * Adding a parameter to a function to make it more generic:
                  typically the less generic version is still perfectly valid
                * Changing the order of parameters: typically the previous
                  argument order is still perfectly valid
                * Changing the type of the function: generally, when this is
                  done, the function is actually doing something different

                Release patches typically contain bugfixes, performance
                improvements, or critical updates (say some code depends on an
                external service, and that external service has a different
                interface now, invalidating the old code).

           #### Development patches

                During development, new, unreleased definitions may get updated
                or refactored multiple times before making it into a release,
                for instance:

                * An unreleased definition may have a bug that gets fixed
                  before release. A patch records this bugfix.
                * An unreleased definition may be stubbed out (using the `todo`
                  function) then the stubbed definition later filled in. A
                  patch records this replacement.
                * Definitions may be refactored multiple times before being
                  released, and these refactorings are recorded in a patch so
                  all the developers on the release can easily stay up-to-date.

                With some simple steps, you can make it easy to keep your
                release patch clean so when it comes time to make a release,
                the default patch in `.main.  patch` is totally clean and just
                includes the replacements you want all users to make in their
                code:

                * When developing new definitions to be added to `main`, do it
                  in a separate namespace under `prs`, say `prs._myNewStuff`.
                  Within this namespace, use `update`, `replace.term` and
                  `replace.type` as much as you like. When you're ready to
                  merge, just `delete.patch prs._myNewStuff.patch`.
                * For other development patches, like bugfixing an unreleased
                  definition in `main`, or replacing a stub, use a separate
                  named development patch for it rather than the default patch
                  that becomes the release patch during the release process. We
                  recommend `update .main.patches.dev` for the default
                  development patch. Anyone with in-progress pull requests can
                  apply this patch to their work. It can be archived and reset
                  periodically.
                * When repurposing the name of a released definition, use the
                  repurposing names steps covered above rather than using
                  `update` on it.
                * For updates to released code that all users should make (like
                  bugfixes or performance improvements), go ahead and do an
                  `update` of the default patch. Note that if you
                  `fork trunk prs._somePR`, then do your updates in `_somePR`,
                  when that namespace is merged back into trunk, the updates
                  you made to the default patch will arrive there as well.
  }}

docs.tooling.localCodebaseUI : Doc
docs.tooling.localCodebaseUI =
  {{
  # Local Codebase UI

    You can navigate the Unison Codebase Manager (UCM) via the CLI with a
    [set of commands]({ucmCommands.index}) but the UCM also ships with a UI for
    viewing and navigating your local codebase.

    {{
    docCallout
      Optional.None
      {{
      To bring up the local codebase UI, enter [`ui`]({ui}) in the UCM. This
      will open the UI in your default browser.
      }} }}

    The UI supports several features which augment the local development
    process in Unison:

    ## 📝 Doc rendering

       If there are linked {type Doc}s for a Unison term or type, the codebase
       UI will fully render the docs with their enriched text features.
       {type Doc} elements like tooltips, links between docs and terms, and
       evaluated code examples will all be displayed when you open a Unison
       term.

       Try it out by searching for the {type Natural} type in the
       `🔍 find definition` query box. The linked documentation for using
       {type Natural} should render in the local UI.

    ## 👀 Click-through to source interactivity

       If you're ever curious about the source code of your favorite Unison
       library or functions, you can use the local UI to see the source of the
       code and all the preceding code that constitutes it.

       Any function, value, or type that highlights on mouse-over is a
       clickable link that will open a new source code panel.

    ## 🎹 Keyboard shortcuts

       With the UI open in your browser, enter `?` to pull up a few handy
       keyboard shortcuts to remember when using the UI.

       These keyboard shortcuts are also useful for navigating public codebases
       on Unison Share.

    ## 🔭 Namespace scoped searching

       In addition to the top-level `🔍 find definition` search functionality,
       the local codebase UI supports __scoped__ searching and namespace
       navigation.

       Say you're in a large codebase and you've been using the local UI to
       check out some of the functions under the {type List} data type
       namespace. If you'd like to scope your search to other terms which are
       only under the {type List} namespace in the `base` library, you can
       mouse-over the namespace path to the right of the type or term name, and
       from there you should see two options. The first opens a search query
       for finding other terms within the namespace, and the second allows you
       to refocus your navigation sidebar to the current namespace for a more
       granular view of the codebase.

       {{ localCodebaseUI._nav }}
  }}

docs.tooling.localCodebaseUI._nav : Doc
docs.tooling.localCodebaseUI._nav =
  use wordle.utils.emojis learnMore
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ learnMore }} [Read more about Unison documentation]({documentation})

      {{ learnMore }}
      [Read about Unison's public code exploration tool, Unison Share]({unisonShare})
    }} }}
  }}

docs.tooling.projectFAQs : Doc
docs.tooling.projectFAQs =
  {{
  # Projects FAQs

    {{
    docCallout
      (Some emojis.index)
      {{
      **Table of contents**

      * [Difference between projects and namespaces](#difference-between-projects-and-namespaces)
      * [Can I create a project within a project?](#can-i-create-a-project-within-a-project)
      * [How do projects interact with reflog history?](#projects-and-reflog-history)
      * [Multi-user organizations for projects](#organizations-and-projects)
      * [Multiple remote branches](#multiple-remote-branches)
      * [Are remote branches visible locally?](#remote-branches-visible-locally)
      * [How should I version my project?](#versioning-projects)
      * [Renaming remote projects and branches](#renaming-remote-branches)
      }} }}

    {{ SectionBreak }}

    {{
    Anchor
      "difference-between-projects-and-namespaces"
      {{
      **What's the difference between projects and namespaces?**
      }} }}

    Namespaces are used for organizing your source code whereas projects are
    for managing your code as a shareable package. Think about namespaces as a
    directory tree and projects as a git repository.

    {{
    Anchor
      "can-i-create-a-project-within-a-project"
      {{
      **Can I create a project within a project?**
      }} }}

    No, projects cannot be nested.

    {{
    Anchor
      "projects-and-reflog-history"
      {{
      **How do projects relate to the codebase reflog history?**
      }} }}

    The reflog and history is separated by project by default.
    [You can learn more about resetting codebase state here.]({resettingCodebaseState})

    {{
    Anchor
      "organizations-and-projects"
      {{
      **How do I contribute to an organization's project as a member of the
      organization?**
      }} }} Organizations are coming in the future! As a member of the
    organization, you'll be able to push to the main branch of the project but
    it's more common to create a feature branch for your work and merge it in.
    Currently, you can contribute to another persons project by cloning it and
    creating a contributor branch. See [making a pull request]({reviewingPrs})
    for more details.

    {{
    Anchor
      "multiple-remote-branches"
      {{
      **Can I push and pull from more than one remote branch?**
      }} }}

    Yes, one local branch can push and pull from many remote branches, but only
    one will be remembered by the UCM as the {{
    docTooltip {{ remote mapping }} remoteMapping }} shortcut.

    {{
    Anchor
      "remote-branches-visible-locally"
      {{
      **How can I see all the remote contributor branches for my project from
      the UCM command line?**
      }} }}

    Currently, this is not possible. In the future we're hoping to add tab
    completion to the `clone` command so you can enter the name of the project
    or branch and quickly find a specific remote branch. However, you can see
    all the contributor branches from the project's homepage by navigating to
    the branch name dropdown.

    {{ Anchor "versioning-projects" {{ **How should I version my project?** }}
    }}

    We recommend you use a semantic versioning scheme with digits to represent
    major, minor, and patch versions. Currently, Unison Share enforces that new
    releases are greater than the last released version by exactly one major,
    minor, or patch version. If your existing versioning scheme is not
    expressed in this format, when you migrate to a project, pick `1.0.0` as
    your first release version and increment by one from there.

    Support for hotfixes and pre-release versions is incoming.

    {{
    Anchor
      "renaming-remote-branches"
      {{
      **How do I rename a branch or project on Unison share?**
      }} }}

    Renaming a remote branch or project is a forthcoming feature! Currently you
    can push your local project or branch to a new name like this:

    ``` ucm
    oldName/main> project.rename newName
    newName/main> push @userHandle/newName
    ```

    Then confirm that the new repo exists and delete the old one using the
    Unison Share UI project settings tab.
  }}

docs.tooling.projectsCodebaseOrganization : Doc
docs.tooling.projectsCodebaseOrganization =
  {{
  # Organizing your codebase with projects

    One Unison codebase can house all your Unison code.
    [In the projects quickstart](../projects) we learned that your various
    libraries, applications, or other shareable, packageable work are described
    in separate {{ docTooltip {{ `projects` }} project }} within the codebase.

    You can switch between one project to the next with the `switch` command,
    and get back to the root of your codebase with `cd .`.

    A project can contain many branches to manage Unison work streams. Here's a
    sample project with some example branches and terms. We'll talk through
    what each of them mean next:

    ``` raw
    myProject
          /main
            README
            ReleaseNotes
            lib
              base
          /releases/1.0.0
            ReleaseNotes
          /releases/draft/1.1.0
          /featureInProgress
          /@contributor/coolContribution
            ...
            ...
    ```

    * The `/main` branch is the mainline branch for the project containing the
      codebase history of changes. It's the default branch that you clone when
      you want to contribute to a project.
      * Within the `main` branch you'll find the `README` term, which is a term
        that describes the project. If included at the top-level of the
        project, it will be displayed on the project's home page on
        [Unison Share](https://share.unison-lang.org).
      * `ReleaseNotes` is a special term that describes the changes the library
        or application since the last release. If included, they'll be linked
        with release version.
      * `lib` is a required namespace that contains the dependencies for the
        project. New dependencies are installed with the {{
        docTooltip {{ `pull` }} ucmCommands.pull }} command.
        * `base` is our standard library. It's downloaded automatically when
          you create a new project.
    * The `/releases/draft/X.Y.Z` branches are special branches created via the
      [UCM release process](/tooling/project-workflows/library-releases/), you
      shouldn't need to work within them directly.
    * Most of your Unison coding will be in branches like the
      `/featureInProgress` branch, which will later be merged into `main` once
      finished.
    * The `/@contributor/coolContribution` branch is a
      {{ docTooltip {{ contributor branch }} contributorBranch }}, which is a
      branch that someone else created from a clone of the project. As part of
      the [pull request process]({reviewingPrs}), you'll review the code in the
      contributor branch and merge it back into another branch.

    You can keep your local branch structure clean with the `branch.delete`
    command, to prune away branches that are no longer needed.

    {{
    docAside
      {{
      {{ reminder }} view your branches with the [`branches`]({listProjects})
      command and create them with [`branch`]({createBranches}).
      }} }}

    {{
    docCallout
      Optional.None
      {{
      **Summary**

      * A codebase is subdivided into many projects
      * Projects have a `main` branch for the mainline of development
      * Inside a project, "README" and "ReleaseNotes" can be associated with
        your project in the Unison Share UI, and `lib` houses your dependencies
      * Feature branches are created from `main` and merged back into `main`
        when finished
      * Contributor branches are created from a `clone` of the project and
        merged back into a branch of your choice
      }} }}

    {{ projectsCodebaseOrganization._nav }}
  }}

docs.tooling.projectsCodebaseOrganization._nav : Doc
docs.tooling.projectsCodebaseOrganization._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # Where to next?

      {{ suggested }}
      [Read more about code hosting with Unison Share](./unison-share/)

      {{ suggested }}
      [See the full set of projects workflows]({projectWorkflows})

      {{ wordle.utils.emojis.learnMore }}
      [Check out Unison's public code exploration tool, Unison Share](https://share.unison-lang.org/)
    }} }}
  }}

docs.tooling.projectsLibraryMigration : Doc
docs.tooling.projectsLibraryMigration =
  use wordle.utils.emojis learnMore
  {{
  # 📚 Projects library migration cheatsheet

    If you're migrating a Unison library from the old namespace-based model to
    the new project-based model, you'll want to follow these steps.

    Why migrate? Your library will be discoverable as a project via the search
    functionality on Unison Share. PRs and comments will be based on the
    project model, so projects-based libraries will have better UX support for
    maintainers. Projects are also evolving to support more advanced dependency
    management and versioning features, like automatically removing unused code
    in dependencies, better support for semantic versioning, and UCM commands
    for staging and preparing releases.

    {{
    docCallout
      (Some {{ ⏱ }})
      {{
      Migrating your library to a project is quick! These steps should only
      take 5 minutes.
      }} }}

    We'll be assuming your library has something like the following namespace
    structure:

    ``` raw
    libraryName
      main
      latest
      releases
        v1_0_0
        v1_1_0
        ...
    ```

    ## 1. Create your library as a project

       ``` ucm
       scratch/main> project.create-empty libraryName
       libraryName/main> merge .libraryName.main
       ```

       These commands create a project for your library without downloading the
       `base` standard library and then merge the contents of your library's
       main namespace into the project's main branch.

    ## 2. Create branches for previous library versions

       ``` ucm
       libraryName/main> branch .libraryName.releases.v1_0_0 /releases/drafts/1.0.0
       libraryName/main> branch .libraryName.releases.v1_1_0 /releases/drafts/1.1.0
       ```

       {{
       docCallout
         (Some {{ 🧠 }})
         {{
         Be sure to create the release branch with the namespace as the
         branch's source and the release draft branch as its destination.
         Without specifying the source and destination of the branch, your
         release branch would be created as a child of `main`. Including the
         namespace as the source ensures that the new branch is created without
         establishing a parent-child relationship between the "offshoot" branch
         and the branch you're currently in.
         }} }}

       It's important to respect the three-part semantic versioning scheme for
       these branches. If your previous namespace is versioned differently,
       it's ok, just pick version `1.0.0` as an initial release version and
       increment by one major, minor, or patch version from there as
       appropriate.

       We used to recommend that library authors maintain a namespace called
       `latest` that forked the latest released version of your library. With
       projects, you do not need to create and continually update a branch to
       represent the `latest` released version of your namespace. Unison Share
       will suggest the latest version of your project when users search for
       it.

    ## 3. Push your branches to Unison Share

       Push each of the branches of your project to Unison Share.

       ``` ucm
       libraryName/main> push
       libraryName/main> push /releases/drafts/1.0.0
       libraryName/main> push /releases/drafts/1.1.0
       ```

    ## 4. Create library releases

       Because your branches are formatted with the `releases/drafts/X.Y.Z`
       convention, Unison Share will recognize this branch as a potential
       release. Click on the "Releases" tab for the project on Unison Share and
       check out the list of "draft" releases at the top. Starting at the
       __lowest versioned release number__, click the "Publish" button and
       confirm the version number on the modal that pops up.

    ## 5. Help others discover your project

       On the Unison Share project home page, click "Settings" and make sure
       your library is set to "Public" for all to see! The project home page
       also has a field in the UI where you can add a quick summary of your
       library or application. Congrats! Your library is now a project! 🎉

  # More about projects in Unison

    {{ suggested }}
    [Full list of common workflows for projects]({projectWorkflows})

    {{ learnMore }} [Projects FAQ's]({projectFAQs})

    {{ learnMore }} [Codebase organization]({projectsCodebaseOrganization})
  }}

docs.tooling.projectSyntax : Doc
docs.tooling.projectSyntax =
  {{
  # Project and branch naming conventions

    The most basic form of a project in the UCM is:

    ``` ucm
    projectName/branchName>
    ```

    Slashes indicate branches to the various UCM commands for managing
    projects.

    {{
    docCallout
      (Some important)
      {{
      when you want to reference a branch in the UCM, remember to prefix your
      branch name with the slash, `/` to distinguish it from a project name or
      namespace.
      }} }}

    Projects created by you will have this form in the UCM, but when
    contributing to a shared project you'll use the `clone` command to download
    a copy of the project. Cloned projects will look like this in the UCM
    console:

    ``` ucm
    @unison/base/main>
    ```

    Usernames are prefixed by the `@` symbol and are used to identify the owner
    of a project or branch.

    Let's say I want to contribute a feature

    For example if I clone a project from @unison, I may end up creating a
    branch called `/@myUser/featureBranch`.

    Another person could then clone my contributor branch at
    `@unison/projectName/@myUser/featureBranch`.

    If you have forked another person's project, you'll do your work on
    "contributor branches" which take this form.

    -- TODO figure out the utility of this doc.
  }}

docs.tooling.projectWorkflows : Doc
docs.tooling.projectWorkflows =
  {{
  # Project workflows

    {{
    docCallout
      (Some emojis.index)
      {{
      **Table of contents**

      * [Create a new project](#create-a-new-project)
      * [Create a project from an existing library](#create-a-project-from-an-existing-library-with-releases)
      * [Create a project from an existing namespace](#create-a-project-from-an-existing-namespace)
      * [List the projects in a codebase](#list-all-projects-in-your-codebase)
      * [Rename a project](#renaming-a-project)
      * [Switch between projects](#switch-between-branches-or-projects)
      * [Create branches](#create-branches)
      * [List the branches of a project](#list-the-local-branches-of-a-project)
      * [Delete a project or a branche](#delete-a-project-or-a-branch)
      * [Install a project as a dependency](#install-a-project-as-a-dependency)
      * [Update a project dependency](#how-to-update-a-library-dependency)
      * [Clone a project or branch](#clone-a-project-from-unison-share)
      * [Push a project to Unison Share](#push-a-project-or-branch-to-unison-share)
      * [Merge project branches](#merges-for-projects)
      * [Release a library version](#publishing-a-release-of-a-project)
      * [Review a pull request](#reviewing-a-pr)
      * [Create a pull request](#creating-a-pr)
      * [Deleting remote branches](#deleting-a-remote-branch-from-unison-share)
      }} }}

    {{ SectionBreak }}

    {{ createNewProject }}

    {{ SectionBreak }}

    {{ createFromLibrary }}

    {{ SectionBreak }}

    {{ createProjectFromNamespace }}

    {{ SectionBreak }}

    {{ listProjects }}

    {{ SectionBreak }}

    {{ renameProject }}

    {{ SectionBreak }}

    {{ switchProjectsBranches }}

    {{ SectionBreak }}

    {{ createBranches }}

    {{ SectionBreak }}

    {{ viewBranches }}

    {{ SectionBreak }}

    {{ projectWorkflows.delete }}

    {{ SectionBreak }}

    {{ installDependency }}

    {{ SectionBreak }}

    {{ updateDependencyLibInstall }}

    {{ SectionBreak }}

    {{ cloneLib }}

    {{ SectionBreak }}

    {{ cloneBranch }}

    {{ SectionBreak }}

    {{ projectWorkflows.push }}

    {{ SectionBreak }}

    {{ projectWorkflows.merge }}

    {{ SectionBreak }}

    {{ libraryReleases }}

    {{ SectionBreak }}

    {{ reviewingPrs }}

    {{ SectionBreak }}

    {{ creatingPrs }}

    {{ SectionBreak }}

    {{ deletingRemoteBranches }}
  }}

docs.tooling.projectWorkflows.cloneBranch : Doc
docs.tooling.projectWorkflows.cloneBranch =
  {{
  # Clone a branch of a project from Unison Share

    If you want to clone a branch other than `main`, use the same `clone`
    command but include the branch name after the project name.

    ``` ucm
    scratch/main> clone @unison/projectName/branch
    ```

    If you already have the project locally, but wish to clone an additional
    branch from the remote repository, you can leave off the project name
    prefix.

    ``` ucm
    @unison/base/main> clone /releases/2.0.0
    ```

    Branches may also include a path segment for the contributor's Unison Share
    handle, indicating that the branch is a
    {{ docTooltip {{ contributor branch }} contributorBranch }}.

    ``` ucm
    scratch/main> clone @unison/projectName/@contributor/branch
    ```

    {{
    docCallout
      Optional.None
      {{
      Cloning is for contributing to a project. If you want to use a project as
      a dependency, see [pulling a project]({projectWorkflows.pull})
      }} }}
  }}

docs.tooling.projectWorkflows.cloneLib : Doc
docs.tooling.projectWorkflows.cloneLib =
  {{
  # Clone a project from Unison Share

    Cloning is used to download a project or branch for contributing to it. (To
    install a project dependency, use the `pull` command.) Unlike with Git
    workflows, where you clone a project and can download all the project's
    branches (stale or otherwise,) in Unison you clone specific branches of a
    project.

    To clone a project from Unison Share, use the `clone` command. The first
    path segment is the user's Unison Share handle and the second is the name
    of the project.

    ``` ucm
    scratch/main> clone @unison/projectName
    ```

    Unless otherwise specified, the cloned project will only include the `main`
    branch.
  }}

docs.tooling.projectWorkflows.createBranches : Doc
docs.tooling.projectWorkflows.createBranches =
  {{
  # Create branches

    To create a new branch, use the `branch` command with one or two arguments.
    You might create branches to work on a new feature in one of your own
    projects, or to contribute to a project that you've cloned. Branches have a
    parent-child relationship, so the new branch will be a child of the current
    branch.

    {{
    docCallout
      Optional.None
      {{
      Branch arguments are optionally preceded by a slash to disambiguate them
      from other codebase entities. This creates a copy of the `main` branch in
      `aNewBranch` and switches to it.

      ``` ucm
      myProject/main> branch /aNewBranch
      ```

      You might also see branch arguments prefixed by the contributor's Unison
      Share handle.

      ``` ucm
      myProject/main> branch /@contributor/aNewBranch
      ```

      You cannot otherwise have multiple slashes in a branch name.
      }} }}

    ``` ucm
    myProject/main> branch /myNewBranch
    @unison/base/main> branch /myNewFeature
    ```

    It is also possible to create a branch with two arguments. The first is the
    source, or parent branch, and the second is the new branch being created.

    ``` ucm
    myProject/main> branch /srcBranch /destBranch
    ```
  }}

docs.tooling.projectWorkflows.createFromLibrary : Doc
docs.tooling.projectWorkflows.createFromLibrary =
  {{
  # Create a project from an existing library with releases

    If your existing namespace is a mature library with `main`, `latest`, and
    `releases` namespaces, you'll will...

    1. merge the `main` subnamespace into the `main` branch of the project
    2. Create a branch called `/latest` with the `branch` command and merge the
       `latest` namespace into it
    3. Each release is a branch with the special form
       `/releases/releaseVersion`. Each of the released version namespaces are
       merged into their respective branches.
  }}

docs.tooling.projectWorkflows.createNewProject : Doc
docs.tooling.projectWorkflows.createNewProject =
  {{
  # Create a new project

    To create a new project, use the `project.create` command at the root of
    your codebase.

    ``` ucm
    scratch/main> project.create myProject
    ```

    This will create a new, empty project with the name, `myProject` with a
    `main` branch inside of it as a default. Your console will look something
    like this:

    ``` ucm
    myProject/main>
    ```

    {{
    docCallout
      (Some {{ 🪅 }})
      {{
      Fun fact: the `project.create` command optionally accepts zero arguments,
      in which case the UCM will create a random project name for you!
      }} }}

    **See also:**

    * [Creating a project from a namespace]({{
      docLink (docEmbedTermLink do createProjectFromNamespace)
      }})
    * [Creating a project for an existing published library]({createFromLibrary})
    * [Viewing a list of your projects]({{
      docLink (docEmbedTermLink do listProjects)
      }})
  }}

docs.tooling.projectWorkflows.createProjectFromNamespace : Doc
docs.tooling.projectWorkflows.createProjectFromNamespace =
  {{
  # Create a project from an existing namespace

    Say you have simple un-versioned namespace that you want to turn into a
    project. First, create a new project with the `project.create` command.

    ``` ucm
    scratch/main> project.create myProject
    ```

    Then, merge the namespace into the project with the `merge` command.

    ``` ucm
    myProject/main> merge .myExternalNamespace
    ```

    {{
    docCallout
      Optional.None
      {{
      You cannot `fork` a namespace from outside of a project into a project.
      You must use the `merge` command.
      }} }}

    **See also:**

    * [Creating a project from a previously published library]({createFromLibrary})
  }}

docs.tooling.projectWorkflows.creatingPrs : Doc
docs.tooling.projectWorkflows.creatingPrs =
  use Optional None
  {{
  # Creating a PR

    Assuming you have `cloned` another users project, you can create a PR by
    creating a branch with your Unison Share handle as a prefix. This branch
    should contain your suggested changes. This is called a
    {{ docTooltip {{ contributor branch }} contributorBranch }}.

    ``` ucm
    @libraryAuthor/project/main> branch /@yourHandle/featureBranch
    ```

    Next, push your branch to Unison Share. You'll see a link to the branch url
    in the UCM.

    ``` ucm
    @libraryAuthor/project/@yourHandle/featureBranch> push
    ```

    Head to the project's "contributions" tab click on the "submit
    contribution" button.

    {{
    Image
      {{
      Image of the contributions page with a "submit contributions" button at
      the top.
      }}
      {{
      /assets/learn/projects/submitContributions.png
      }}
      None }}

    Select the branch containing your change and the target branch for your
    desired PR, then add a title and description of your changes.

    {{
    Image
      {{
      Image of the create contribution modal with form fields for title and
      description.
      }}
      {{
      /assets/learn/projects/saveContribution.png
      }}
      None }}

    Hit submit and you should see your PR in the list of contributions added to
    the main contributions page.

    Finally, you can message our library authors in the #library channel in
    [the community slack](https://unison-lang.org/slack) to make sure they see
    your PR! In the future, we'll be adding automated notifications for PRs.
  }}

docs.tooling.projectWorkflows.delete : Doc
docs.tooling.projectWorkflows.delete =
  {{
  # Delete a project or a branch

    To delete a project use the `delete.project` command. This will delete the
    project from your local codebase.

    ``` ucm
    myProject/main> delete.project myProject
    scratch/main>
    ```

    Deleting a branch can be done with the `delete.branch` command. This will
    delete the branch from your local codebase.

    ``` ucm
    myProject/main> delete.branch /myBranch
    ```

    ## Deleting a project from Unison Share

       You can delete a project from
       [Unison Share](https://share.unison-lang.org/) by heading to your
       project's settings page.

       {{
       Doc.Callout
         (Some {{ 👉 }})
         {{
         Deleting a project from Unison Share cannot be reversed.
         }} }}
  }}

docs.tooling.projectWorkflows.deletingRemoteBranches : Doc
docs.tooling.projectWorkflows.deletingRemoteBranches =
  {{
  # Deleting a remote branch from Unison Share

    Deleting a remote branch from Unison Share can only be done via the Unison
    Share UI. Head to the project's home page and click on the drop-down menu
    where the current branch name is displayed. You'll see a short list of all
    the remote branches for the project. At the bottom of the drop down menu
    head to "View all branches" and from there you can delete your desired
    branch. You cannot delete branches that you do not own.
  }}

docs.tooling.projectWorkflows.installDependency : Doc
docs.tooling.projectWorkflows.installDependency =
  {{
  # Install a project as a dependency

    To install a project as a dependency, use the `install` command in the UCM.
    The `install` command will add the project to your `lib` directory.

    ``` ucm
    myProject/main> install @user/project
    ```

    This command can be copied into your clipboard from the Unison Share UI
    when you click the "Use Project" button on a project page.

    If you want to install a specific version of a project, specify the version
    like this:

    ``` ucm
    myProject/main> install @user/project/releases/1.2.3
    ```

    {{
    docCallout
      (Some reminder)
      {{
      Users who have a version of Unison older than 0.5.21 should use
      [the `pull` command.]({{
      (docLink (docEmbedTermLink do projectWorkflows.pull))
      }})
      }} }}
  }}

docs.tooling.projectWorkflows.libraryReleases : Doc
docs.tooling.projectWorkflows.libraryReleases =
  use Optional None
  {{
  # Publishing a release of a project

    Releases are like immutable snapshots of a given branch. They do not
    contain the history of the project so other libraries can depend upon them
    without using additional space in their codebase.

    There are two ways to create a release of a project, the recommended option
    is to use the Unison Share UI to create a release, and the other is using
    the `release.draft` command.

    ## Creating a release from the Unison Share UI

       If you are intending to create a release using only the Unison Share UI
       and you'd like to associate release notes with the new version, make
       sure your `ReleaseNotes` document term is up to date with the latest
       changes to your library. Push `main` up to Unison Share and head to the
       "releases" tab for the project.

       {{
       Image
         {{
         Image of the releases page with a "cut a release" button at the top.
         }}
         {{
         /assets/learn/projects/releaseDraft.png
         }}
         None }}

       Click the "Cut a release" button to open the release version modal.

       You'll have some options for how to version the next release. Increment
       your release by one major, minor, or patch version.

       {{
       Image
         {{
         Image of the release version modal.
         }}
         {{
         /assets/learn/projects/releaseModal.png
         }}
         None }}

       Hit publish and Unison Share will create a new release for you! The
       release process will squash the unneeded codebase history when it
       creates the release, so users of your library will have a compact
       version to depend on.

    ## Creating a release draft in the UCM

       You can create a release from any branch of a project, but it's common
       to create a release from the `main` branch in the UCM. To start a
       release, use the `release.draft` command and enter the version number of
       the release you want to create.

       ``` ucm
       myProject/main> release.draft 1.0.0
       ```

       This will create a new branch called `/releases/drafts/1.0.0`.

       You may want to `add` a Doc term called "ReleaseNotes" to this branch at
       this point to describe the changes in this version. Upon publication, if
       Unison Share finds a term called "ReleaseNotes" in a release branch, it
       will display the notes for others to benefit from.

       ``` unison
       ReleaseNotes = {{

         * Added function {List.map}
         * Updated function {List.filter}
         ...

       }}
       ```

       After you're done adding the release notes, `push` the branch to Unison
       Share and head to the project url given in the console.

       ``` ucm
       myProject/releases/drafts/1.0.0> push
       ```

       The "releases" tab for the project has a special section for "draft"
       releases at the top if a branch matching the release draft naming
       conventions is found. Click publish for the release draft in question to
       open up a modal for confirming the desired version. Otherwise you can
       use the "cut a release" button found in the "releases" page to make a
       release at any time.

       {{
       Image
         {{
         Image of the releases page with a draft release at the top.
         }}
         {{
         /assets/learn/projects/releaseDraft.png
         }}
         None }}

       Unison Share supports semantic versioning for releases, so pick one of
       the options given in the modal.

       {{
       Image
         {{
         Image of the release version modal.
         }}
         {{
         /assets/learn/projects/releaseModal.png
         }}
         None }}

       {{
       docAside
         {{
         You can learn more about semantic versioning
         [here](https://semver.org/).

         Support for hotfixes and pre-release versions is something we hope to
         add in the future.
         }} }}

       When you're ready, hit "Publish" and Unison Share will add your new
       version to the list of releases for a project.
  }}

docs.tooling.projectWorkflows.listProjects : Doc
docs.tooling.projectWorkflows.listProjects =
  {{
  # List all projects in your codebase

    To list all projects in your codebase, use the `projects` command.

    ``` ucm
    scratch/main> projects
    ```
  }}

docs.tooling.projectWorkflows.merge : Doc
docs.tooling.projectWorkflows.merge =
  {{
  # Merges for projects

    The `merge` command is used to combine branch contents or namespace
    contents. You might `merge` a namespace into a branch as a part of moving
    your code into a project, or you might `merge` two branches together as
    part of a pull request. The existing ability to `merge` two namespaces
    together is still supported as well. Let's look at each of these cases.

    ## Preview a merge

       Before performing a large merge you may want to view the terms that will
       be changed with the `merge.preview` command

       ``` ucm
       myProject/main> merge.preview /featureBranch
       myProject/main> merge.preview /featureBranch /otherBranch
       ```

       This will produce a list of terms that will be changed. You can view
       this list in the UCM or in the browser.

    ## Merging two branches together

       To merge two branches together, your arguments can be prefixed with a
       slash, `/` indicating that they are branches.

       ``` ucm
       myProject/main> merge /featureBranch
       myProject/main> merge /featureBranch /featureBranch2
       ```

       If you're reviewing a pull request, the contributor will have created a
       branch for their work. Their branch will start with their user handle
       from Unison Share.

       ``` ucm
       myProject/main> merge /@contributor/featureBranch
       myProject/main> merge /@contributor/featureBranch /featureBranch2
       ```

       You can also merge a different project's branch into your project's
       current branch by supplying the full project name as an argument.

       ``` ucm
       myProject/main> merge @unison/differentProject/featureBranch
       ```

    ## Merging a namespace into a branch

       From within the project, you can merge a fully qualified namespace into
       the current branch, by calling merge with one argument, or specify a
       target branch with the optional second argument to `merge`.

       ``` ucm
       myProject/main> merge .feature.from.namespace
       myProject/main> merge .feature.from.namespace /featureBranch
       ```
  }}

docs.tooling.projectWorkflows.pull : Doc
docs.tooling.projectWorkflows.pull =
  {{
  # Pull a project or branch from Unison Share as a library

    `pull` is used to include remotely hosted Unison code in your local
    codebase.

    **If you're using Unison version 0.5.21 or newer and you want to install a
    dependency, you should use the `lib.install` command**

    Pull is still used to download Unison code into the local codebase if the
    code is meant to function as a template project.

    ``` ucm
    cloud-start/main> pull @unison/cloud-start/releases/latest
    ```
  }}

docs.tooling.projectWorkflows.push : Doc
docs.tooling.projectWorkflows.push =
  {{
  # Push a project or branch to Unison Share

    To push a project or branch to Unison Share, use the `push` command.

    Pushing a project to Unison Share automatically establishes a remote
    mapping between your local project and the project on Unison Share. We can
    even run `push` with no arguments on a project that we own.

    ``` ucm
    myProject/main> push

    Pushing to https://share.unison-lang.org/@myuser/myproj/branches/main...
    ```

    You can also push a specific branch to Unison Share. The following command
    will push `someOtherBranch` to the `main` branch of the project.

    ``` ucm
    myProject/main> push @myUser/myProject/main /someOtherBranch
    ```

    You can still `push` a namespace to your `public` namespace in Unison
    Share, but if you push a project to Unison Share, it will get special UI
    treatment and functionality, like branch based browsing and versioning.
  }}

docs.tooling.projectWorkflows.renameProject : Doc
docs.tooling.projectWorkflows.renameProject =
  {{
  # Renaming a project

    To rename a project, use the `rename.project` command from within the
    project you're trying to rename.

    ``` ucm
    myProject/main> rename.project myNewProject
    myNewProject/main>
    ```

    ## Renaming a branch

       Renaming a branch follows the same pattern

       ``` ucm
       myProject/feature1> rename.branch myNewBranch
       myProject/myNewBranch>
       ```
  }}

docs.tooling.projectWorkflows.reviewingPrs : Doc
docs.tooling.projectWorkflows.reviewingPrs =
  {{
  # Reviewing a PR

    Once a contributor has created a {{
    docTooltip {{ contributor branch }} contributorBranch }} and pushed it to
    Unison Share, their contribution will show up in the project's Unison Share
    contributions page.

    {{
    Image
      {{
      Image of the contributions page with a "submit contributions" button at
      the top.
      }}
      {{
      /assets/learn/projects/submitContributions.png
      }}
      Optional.None }}

    Click on the contribution you'd like to review and you can see a
    description of the changes and a panel showing the impacted code across the
    two branches.

    If the merge can be performed safely, you can click the green "Merge"
    button to bring the change set into the parent branch.

    Otherwise, you may need to clone the branch locally to review and merge it
    in.

    ``` ucm
    myProject/main> clone /@contributor/featureBranch
    myProject/@contributor/featureBranch> switch main
    myProject/main> merge /@contributor/featureBranch
    ```

    Resolve the conflicts and push your changes back to Unison Share to make
    them available to others or [create a release!]({libraryReleases})
  }}

docs.tooling.projectWorkflows.switchProjectsBranches : Doc
docs.tooling.projectWorkflows.switchProjectsBranches =
  {{
  # Switch between branches or projects

    The `switch` command is used to change between branches or projects.

    Both of these commands will switch to the default `main` branch of the
    `otherProject`. The absence of a slash preceding the argument to `switch`
    means that the UCM will look for a __project__ to switch to.

    ``` ucm
    myProject/aBranch> switch otherProject
    myProject/aBranch> switch otherProject/main
    ```

    Switching to a contributor branch of another project contains the
    contributor's Unison Share handle in the branch name.

    ``` ucm
    myProject/aBranch> switch otherProject/@contributor/contributorsWork
    ```

    To switch to a branch within the __same__ project, omit the project name,
    leaving slash and the branch name to indicate that the argument is a
    branch. The slash can help distinguish a branch name from a project name
    when there is a project with the same name as a branch.

    ``` ucm
    myProject/aBranch> switch /anotherBranch
    myProject/aBranch> switch anotherBranch
    ```
  }}

docs.tooling.projectWorkflows.viewBranches : Doc
docs.tooling.projectWorkflows.viewBranches =
  {{
  # List the local branches of a project

    To view the branches of a project, use the `branches` command.

    ``` ucm
    myProject/main> branches
    ```

    This shows the local branches and their {{
    docTooltip {{ remote mappings }} remoteMapping }} (if any) on Unison Share.

    Currently you cannot view the remote cloned instances of your project.
  }}

docs.tooling.transcripts : Doc
docs.tooling.transcripts =
  {{
  # Transcripts

    Transcripts provide a way to script interactions between Unison code and
    the Unison Codebase Manager ( {{ docTooltip {{ UCM. }} {{ {{ ucm }} }} }})
    They are written as markdown documents containing fenced codeblocks that
    define the Unison code and UCM commands to be performed.

    {{ docCallout
      (Some emojis.index) {{
      **What's in this document?**

      * [Components of a transcript](#components-of-a-transcript)
      * [Expecting failures](#expecting-failures)
      * [Hiding output](#hiding-output)
      * [State between stanzas](#stateful-stanzas)
      * [Transcript codebase options](#transcript-codebase-options)
      }} }}

    ## Components of a transcript

       Transcript files are `.md` files that contain a series of interactions,
       called "stanzas". Stanzas are evaluated starting from the top of the
       file down.

       When writing Unison code in a transcript, start a code block with triple
       backticks followed by "unison":

       ```` markdown
       ``` unison
       myTerm = "Hello world"
       ```
       ````

       Let's say you want to add this term to a Unison codebase. You can
       describe that in a fenced code block started by triple backticks
       followed by the word "ucm":

       ```` markdown
       ``` ucm
       scratch/main> add myTerm
       ```
       ````

       The `scratch/main>` is a prompt indicator that you'll use to separate
       the project/branch indicator on the left and the ucm commands on the
       right. The project and branch will be created automatically if they
       don't exist. `scratch/main` is the de facto standard for transcripts. To
       the right of the prompt, you can issue UCM commands to interact with the
       codebase.

       {{
       docCallout
         Optional.None
         {{
         To run a transcript when you start up the UCM, provide the
         `transcript` option and a path to the markdown file like so:

         `ucm transcript path/to/transcript.md`
         }} }}

       By default, transcripts are run against a new codebase each time. When a
       transcript is run it creates a temporary file to house the new codebase
       and deletes it upon finishing the run. Note that unlike the default
       behavior of initializing a new codebase with the UCM `codebase-create`
       argument, transcripts **do not** contain the `base` library. It's common
       to start your transcripts with a ''``` ucm'' block which contains the
       command `builtins.merge` so that you have a minimal set of built-ins to
       work with (these are things like {type Nat} and {type List}). {{
       docAside
         {{
         Similarly, the command `builtins.mergeio` brings in a set of unison
         built-ins capable of supporting IO.
         }} }}

       ```` markdown
       ``` ucm :hide
       scratch/main> builtins.merge
       ```
       ````

       If you would like your codebase to run against a codebase with the
       `base` library in scope, you can add a `ucm` block which issues a `pull`
       command for your desired `base` library.

       Also… be prepared to grab a cup of tea 🫖 - pulling `base` in a
       transcript adds a few seconds to the runtime of the transcript.

       If a transcript can be successfully executed, the UCM will create an
       output file which captures the results of the interactions being
       described. The output of the transcript run will be written in a
       `.output` suffixed file with the same name and file path as the
       original.

       {{
       docCallout
         (Some {{ 👉 }})
         {{
         Did you know? Transcripts can help project maintainers triage and fix
         bugs! Simply write your reproduction as a transcript and attach the
         markdown file to your bug report.
         }} }}

    ## Expecting failures

       There are two ways to communicate that a stanza will fail, the `:error`
       tag or `:bug` tag. These tags are useful to communicate if an error is
       expected or unexpected when filing bug tickets.

       Add the `:error` tag to a fenced code block to indicate that the UCM
       should __expect a failure__ when running the enclosed block.

       ```` markdown
       ``` ucm :error
       scratch/main> add failureExpected
       ```
       ````

       `error` will enable the transcript runner to continue with subsequent
       stanzas in the script.

       Add the `:bug` tag to the fenced codeblock if the Unison stanza
       __should succeed__, but doesn't.

       ```` markdown
       ``` ucm :bug
       scratch/main> add shouldSucceed
       ```
       ````

       If a stanza succeeds where you think it should fail, combine the two
       with `:error :bug` for reporting:

       ```` markdown
       ``` unison :error :bug
       aTerm = "imagine this should fail but succeeds mysteriously"
       ```
       ````

    ## Hiding output

       If there's ever an interaction which is too noisy to be included in the
       `.output` file, you can append the `:hide` modifier to any stanza.

       ```` markdown
       ``` ucm :hide
       scratch/main> builtins.merge
       ```

       ``` unison :hide
       scratch/main> List.range 0 99
       ```
       ````

    ## Stateful stanzas

       In some circumstances, the stanzas of a transcript might entail a
       back-and-forth interaction between the UCM and a scratch file. An
       example of this would be if a bug surfaces upon updating an edited term,
       but not during the initial typechecking. To do this you need to "edit"
       the term, but by default, stanzas don't reflect "re-opened" unison
       terms.

       If you need to save and edit terms to a transcript codebase, the UCM
       [`edit`]({edit}) command will open your `scratch.u` file and render the
       terms to it. You can mimic the back-and-forth of editing terms by
       `load`ing the file to bring it into the transcript codebase's scope.

       ```` markdown
       ``` unison
       myTerm = "hi"
       ```

       ``` ucm
       scratch/main> add myTerm
       scratch/main> edit myTerm
       ```

       At this point the scratch.u file contains ''myTerm'' at the top.

       ``` ucm
       scratch/main> load scratch.u
       ```

       ``` unison
       myTerm = "hi there!"
       ```
       ````

    ## Transcript codebase options

       * You can save the codebase that your transcript produced with the
         `--save-codebase` flag for debugging and sharing. At the end of the
         transcript run, the UCM will print out the location of the directory
         where you can find your codebase and give you instructions for how to
         open it!
       * If you would like to run your transcript against a particular
         codebase, use the `transcript.fork` option. Here's an example of how
         it might be called:
         `ucm transcript.fork path/to/transcript.md --codebase aParticularCodebase`
         This will make a copy of the codebase given as an argument and run the
         transcript against it. Don't worry—your original codebase will remain
         unaltered.
  }}

docs.tooling.unisonShare : Doc
docs.tooling.unisonShare =
  use Optional None
  {{
  # Unison Share code hosting

    [Unison Share](https://share.unison-lang.org/) is Unison's own code hosting
    service. Unison's unique code format and tooling enables different
    strategies for remote repositories. We created Unison Share to support code
    hosting, library discovery, collaboration, source code viewing, and
    documentation rendering. This document describes a few common workflows and
    best practices for hosting your code on Unison Share.

    {{
    docAside
      {{
      The concept for code repositories in Unison is called "projects."
      Projects help organize your codebase into applications, libraries, and
      other shareable, packageable work.
      [Learn more about projects here]({{
      (docLink (docEmbedTermLink do docs.projects))
      }}). Unison Share can also warehouse public {{
      (docTooltip {{ namespaces }} _namespace) }} unattached from a project.
      Your `public` namespace is typically for unstructured work.
      }} }}

    {{
    docCallout
      (Some emojis.index)
      {{
      **What's in this document?**

      * [Publish a project](#publish-a-project-to-unison-share)
      * [Project visibility and branch permissions](#project-visibility-and-branch-permissions)
      * [Library structure conventions](#library-structure-conventions)
        * [Inside the `main` branch](#inside-the-main-branch)
        * [Release branches](#release-branches)
      * [Unison Share Catalog and search](#unison-share-catalog-and-search)
      * [Installing a dependency](#installing-a-dependency)
      }} }}

    ## Publish a project to Unison Share

       First, You'll want to make sure you're logged in to the Unison Share
       platform. Run `auth.login` in the UCM locally.

       ``` ucm
       myProject/main> auth.login
       ```

       This will open your default web browser and prompt you to log into
       Unison Share.

       To push your own project to Unison Share, use the `push` command from
       inside the project and optionally include the branch you're hoping to
       publish. This pushes the `main` branch to @username/myProject/main.

       ``` ucm
       myProject/main> push
       ```

       Finally, head to the Unison Share url displayed by the UCM to view your
       hosted project. Enter something for the "Project Description" so users
       will know at a glance what your library is about! 🥳

       It's uncommon in now that Unison supports projects, but if you need to
       to push a __namespace__ outside of a project, use the `push` command
       from inside the namespace you're hoping to share, or use a fully
       qualified name (one which starts with a dot, `.`) as the second argument
       to the command. The destination needs to include your username and the
       `public` namespace.

       ``` ucm
       scratch/main> push myUser.public.myCode .myCode
       ```

    ## Project visibility and branch permissions

       Any project that you create and push to Unison Share after having logged
       in will show up in your Unison Share workspace at
       "https://share.unison-lang.org/@yourShareHandle". By default, the
       projects that you host on Unison Share are private. If you want to
       enable other users to consume or view your project, be sure to adjust
       the visibility settings in the Project Settings page.

       {{
       Image
         {{
         Image of the Project settings page with a visibility option.
         }}
         {{
         /assets/learn/projects/projectSettings.png
         }}
         None }}

       Currently, Unison Share does not have the concept of "organizations" but
       projects can still be collaborated on by multiple individuals. Fellow
       maintainers should
       [`clone`]({{ docLink (docEmbedTermLink do cloneLib) }}) the project to
       keep in sync with active development and should create {{
       docTooltip {{ contributor branches }} contributorBranch }} instead of
       pushing directly to the `main` branch. Your teammates can then
       [submit their PRs to the project via the contributions workflow]({creatingPrs}).

    ## Library structure conventions

       For the best experience hosting a library on Unison Share, we recommend
       [creating a project]({{
       docLink (docEmbedTermLink do createNewProject)
       }}) where the `main` branch represents the latest work in progress,
       feature branches are used for concurrent workstreams, and release
       branches or release drafts are snapshots of the `main` branch at a given
       point in time.

       Note, the `main` and `releases/X.Y.Z` branches are special branches that
       are created for you when you initialize or publish a project,
       repsectively.

       ``` raw
       myProject
          /main
            README
            ReleaseNotes
            lib
              dependencies
          /featureBranch
            -- branch off of main
          /releases/X.Y.Z
          /releases/draft/X.Y.Z
            -- snapshots of main
       ```

       {{
       docAside
         {{
         An older version of this document recommended a library structure
         where versions, releases, and projects were all represented within
         your `public` namespace. This is no longer recommended.
         [See this migration guide if your library is structured as a
         namespace.]({{
         (docLink (docEmbedTermLink do projectsLibraryMigration))
         }})
         }} }}

       [Read more the recommended project structure here.]({projectsCodebaseOrganization})

       ### Inside the `main` branch

           Within the `main` branch of your project, located just under the
           project root, you should have a `lib` namespace to contain your
           library's dependencies. Optionally you can include a `README`
           [document]({{ docLink (docEmbedTermLink do documentation) }}) at the
           root of your project code. If present, Unison Share will
           automatically render the README as the landing page of the project.

           Another special document you can include at the root of your project
           is `ReleaseNotes`, which will be rendered as the release notes for
           the latest release of your library. This is a good place to include
           information about how to upgrade from previous versions, or any
           other details you'd like to convey to users of your library. If
           Unison Share detects a `ReleaseNotes` term in your project, it will
           automatically attach it as the release notes for the latest version
           of your library.

       ### Release branches

           Consumers of your library hoping to obtain the most recent released
           version of the library would pull `@user/project/releases/X.Y.Z`,
           whereas Once a new release is ready, you can hit the "release"
           button in the Unison Share UI to create a release from `main`.

           The `releases/X.Y.Z` branch is a special branch that is created by
           Unison Share which squashes the history of the `main` branch into a
           simple snapshot.

           [Read more about creating library releases here.]({libraryReleases})

    ## Unison Share Catalog and search

       The [front page of Unison Share](https://share.unison-lang.org/) is
       referred to as the Catalog. The catalog is a __subset__ of the public
       projects hosted on Unison Share, but by no means is it a conclusive
       list! You can also search for projects by name or by author. The search
       bar will also look in project descriptions for keywords. In fact, some
       of the most fun and surprising projects can be found by exploring the
       public projects of other Unison programmers.

       {{
       docCallout
         (Some {{ 💡 }})
         {{
         You should consider featuring your own work on the Unison Share
         front-page catalog! Head to the
         [#libraries channel in the Unison slack](https://unison-lang.org/slack)
         and ping `@hojberg` with a link to your project.
         }} }}

    ## Installing a dependency

       Unison Share automatically helps users download the latest release of a
       library. Clicking the "Use Project" button will open a modal with
       commands for users to copy. The `install` command listed in the modal
       will be auto-populated with the latest release version of the project
       but you can also browse the project's releases and `install` a different
       version.

       {{
       Image
         {{
         Image of the Use Project modal.
         }}
         {{
         /assets/learn/projects/useProject.png
         }}
         None }}

       {{
       docAside
         {{
         Users who have a version of Unison older than 0.5.21 should use
         [the `pull` command.]({{
         (docLink (docEmbedTermLink do projectWorkflows.pull))
         }})
         }} }}

       [Read more about installing dependencies here.]({{
       docLink (docEmbedTermLink do installDependency)
       }})

       {{ unisonShare._nav }}
  }}

docs.tooling.unisonShare._nav : Doc
docs.tooling.unisonShare._nav =
  {{
  {{
  Style
    navStyleTag
    {{
    # What next?

      {{ suggested }} [See other project-based workflows]({projectWorkflows})

      {{ wordle.utils.emojis.learnMore }}
      [Visit the Unison Share catalogue](https://share.unison-lang.org/catalog)
    }} }}
  }}

docs.tour : Doc
docs.tour =
  use List foldLeft reverse
  use test verify
  use ucmCommands view
  {{
  # 🗺 A tour of Unison

    This document walks through the basics of using the Unison codebase manager
    and writing Unison code. We will introduce bits and pieces of the core
    Unison language and its syntax as we go.
    [The Unison language documentation](https://www.unison-lang.org/docs/) is a
    more in-depth resource if you have questions or want to learn more.

    {{ docCallout
      (Some emojis.index) {{
      This tour is separated into several parts! Revisit them as needed:

      * [Part 1: Hello to the Unison codebase manager](#part-1-tour)
      * [Part 2: Creating a project](#part-2-tour)
      * [Part 3: Navigating a Unison codebase](#part-3-tour)
      * [Part 4: Writing Unison code](#part-4-tour)
      * [Part 5: Adding and updating code](#part-5-tour)
      * [Part 6: Sharing code and installing Unison libraries](#part-6-tour)
      }} }}

    If you want to follow along with this document (highly recommended), this
    guide assumes you've already gone through the steps in
    [the quickstart guide](./quickstart) and skimmed through
    [the big idea](./theBigIdea).

    ## {{ Anchor "part-1-tour" {{ Part 1: 👋 to the Unison codebase manager }}
    }}

       The Unison Codebase Manager, or UCM for short, is the command line tool
       that runs the Unison programming language and allows you to interact
       with the Unison code you've written. Put differently, the UCM is the
       interface to your Unison codebase.

       Its many responsibilities include:

       * Typechecking and compiling new code
       * Organizing, navigating, and finding Unison definitions
       * Storing the state of your codebase
       * Running Unison programs and Unison binaries
       * Publishing and installing Unison libraries

       💡 Remember: Unison code is not saved as text-based file content. That's
       why we need a tool that lets us change and run Unison programs.

       ### Running the UCM

           By default, running `ucm` in a directory will interact with any `.u`
           suffixed file in the directory where the command was issued while
           opening the default codebase in your home directory. You'll get a
           message in the UCM like:

           ``` ucm
           Now starting the Unison Codebase Manager (UCM)...

           […]

           Get started:

             📖 Type help to list all commands, or help <cmd> to view help for one command
             🎨 Type ui to open the Codebase UI in your default browser
             📚 Read the official docs at https://www.unison-lang.org/docs/
             🌏 Visit Unison Share at https://share.unison-lang.org to discover libraries
             👀 I'm watching for changes to .u files under ~/unisonCode

            scratch/main>
           ```

           What's happening here? This is the Unison Codebase Manager starting
           up and initializing a fresh codebase. We're used to thinking about
           our codebase as a bag of text files that's mutated as we make
           changes to our code, but in Unison the codebase is saved and updated
           programatically, with the aid of this CLI.

           The Unison codebase format has a few key properties:

           * Terms and types are identified by their implementation, not just
             their name. The codebase stores a hash of the syntax tree of a
             term or type.
           * It is __append-only__: all changes to the codebase, including
             actions like deleting a term or deleting a branch, are appended to
             a log representing the codebase state.
           * As a result, a Unison codebase has its own notion of versioning
             and synchronization independent of git, and
             [a robust set of tools](https://www.unison-lang.org/docs/tooling/unison-share/)
             has been developed for managing and viewing changes in Unison code
             over time.

           If you have never used UCM before, or are creating a new codebase,
           it will drop you into the “main” branch of a fresh project called
           “scratch”. This is represented by the `scratch/main` in the prompt,
           `scratch/main>`. Most of the time your prompt will be prefixed with
           the name of the most recent project you've worked on.

    ## {{ Anchor "part-2-tour" {{ Part 2: 🗂 Creating a project }} }}

       Rather than creating multiple codebases for each application you're
       working on, Unison subdivides the codebase into "projects". Unison {{
       docTooltip {{ projects }} project }} are analogous to source code
       repositories. They help organize your codebase into applications,
       libraries, and other work that you may want to collaborate with others
       on. Projects are further divided into {{
       docTooltip {{ branches }} glossary.branch }} for representing
       independent work streams. We'll introduce the concept of projects by
       creating one for this `tour` and establishing some conventions for
       organizing it.

       Inside a project, your code is further organized into Unison
       {{ docTooltip {{ namespaces }} _namespace }}. Namespaces are mappings
       from human-readable names to their definitions. Names in Unison are
       things like: `math.sqrt`, `base.Optional.Some`, `base.Nat`,
       `base.Nat.*`, `++`, or `foo`. That is one or more segments separated by
       a `.`, with the last segment allowed to be an operator name like `*` or
       `++`.

       We often think of these name segments as forming a tree, much like a
       directory of files. You'll be working with your prompt at the root of
       your project most of the time in Unison.

       In the codebase manager console, create a `tour` project with the
       `project.create` command. This is where you'll be adding code for the
       remainder of this guide.

       ``` ucm
       scratch/main> project.create tour

          🎉 I've created the project tour.


          I'll now fetch the latest version of the base Unison library...


          🎨 Type `ui` to explore this project's code in your browser.
          🌏 Discover libraries at https://share.unison-lang.org
          📖 Use `help-topic projects` to learn more about projects.

          Write your first Unison code with UCM:

            1. Open scratch.u.
            2. Write some Unison code and save the file.
            3. In UCM, type `add` to save it to your new project.

          🎉 🥳 Happy coding!

       tour/main>
       ```

       Notice the prompt changes to `tour/main>`, indicating your current
       project is now `tour` and your current branch is `/main`. When editing
       Unison code, and interacting with the UCM your UCM commands and code are
       "scoped" to this project and branch.

       When you create a new project, the UCM automatically installs the `base`
       standard library for you. It's located in a special namespace called
       `lib`.

       {{
       docCallout
         (Some important)
         {{
         Unison looks for project dependencies directly under the
         __project root__. The `lib` directory in our `tour` project will
         contain all the dependencies necessary for running the code in the
         project.
         }} }}

       Let's explore the `base` library that was just downloaded and get used
       to navigating a Unison codebase next.

    ## {{ Anchor "part-3-tour" {{ Part 3: ⛵️ Navigating a Unison codebase }} }}

       You can view the terms and types in a namespace with the {{
       docTooltip {{ `ls` }} ls }} ucm command.

       ``` ucm
       tour/main> ls lib.base.data.List
       ```

       The output should be a numbered list of definitions and their associated
       signatures.

       ``` ucm
       tour/main> ls lib.base.data.List

       1.   ++                    ([a] -> [a] -> [a])
       2.   +:                    (a -> [a] -> [a])
       3.   :+                    ([a] -> a -> [a])
       4.   Nonempty              (type)
       […]
       ```

       Because of the nature of the codebase format, we can cache all sorts of
       interesting information about definitions in the codebase and
       __never have to worry about cache invalidation__. For instance, Unison
       is a statically-typed language and we know the type of all definitions
       in the codebase, so you can search for definitions in the codebase by
       their type. Try out the following two `find` commands (new syntax is
       explained below):

       ``` ucm
       tour/main> find reverse

       1.  lib.base.data.Graph.reverse : Graph v ->{Exception} Graph v
       2.  lib.base.data.Graph.tests.reverse : [Result]
       3.  lib.base.data.List.Nonempty.reverse : List.Nonempty a -> List.Nonempty a
       4.  lib.base.data.List.reverse : [a] -> [a]
       ```

       The `find` command here is searching for definitions whose names include
       `reverse`. It searches first within our own code in the project, and
       then in the dependencies in `lib`.

       ``` ucm
       tour/main> find : [a] -> [a]

        1. lib.base.data.deprecated.Heap.sortDescending : [a] -> [a]
        2. lib.base.data.deprecated.Heap.sort : [a] -> [a]
        3. lib.base.data.List.distinct : [a] -> [a]
        4. lib.base.data.List.sort : [a] -> [a]
        5. lib.base.data.List.dropLast : [a] -> [a]
        6. lib.base.data.List.reverse : [a] -> [a]

       tour/main> view 6

         lib.base.data.List.reverse : [a] -> [a]
         lib.base.data.List.reverse as =
            List.foldLeft (acc a -> a +: acc) [] as
       ```

       Here, we did a type-based search, with `find` followed by a colon, `:`,
       to search for functions of type `[a] -> [a]`. We got a list of results,
       and then used the {{ docTooltip {{ `view` }} view }} command to look at
       the nicely formatted source code of one of these results. Let's
       introduce some Unison syntax:

       * @inlineSignature{reverse} is the syntax for giving a type signature to
         a definition. We pronounce the `:` symbol as "has type", as in,
         "reverse has the type `[a] -> [a]`".
       * `[Nat]` is the syntax for the type consisting of lists of natural
         numbers (terms like `` [0, 1, 2] `` and `` [] `` will have this type),
         and more generally `[Foo]` is the type of lists whose elements have
         some type `Foo`.
       * A lowercase variable in a type signature is a generic placeholder
         repsenting some other type. The type signature `[a] -> [a]` is saying
         that this is a function which takes a list of elements of some type
         and returns a list of elements of the same type.
       * `List.reverse as` takes one argument, called `as`. The stuff after the
         `=` is the __body__ of the function, and here it's a
         [block]({blocksAndStatements}), which is demarcated by whitespace.
       * `acc a -> ..` is the syntax for an anonymous function.
       * Function arguments are separated by spaces and function application
         binds tighter than any {{ docTooltip {{ operator }} operators }}, so
         `f x y + g p q` parses as `(f x y) + (g p q)`. You can always use
         parentheses to control grouping more explicitly.

       {{
       docCallout
         (Some wordle.utils.emojis.hint)
         {{
         Enter the `view` command without any arguments to open up a
         [fzf search](https://github.com/junegunn/fzf) interface for finding
         definitions in your codebase. It's a quick way to explore the codebase
         and find definitions by name.
         }} }}

       ### Names are stored separately from definitions so renaming is fast and
       100% accurate

           The Unison codebase, in its definition for {reverse}, doesn't store
           names for the definitions it depends on (like the {foldLeft}
           function); it references these definitions via their hash. As a
           result, changing the name(s) associated with a definition is easy.

           Let's try this out. {reverse} is defined using {foldLeft}. Let's
           rename that to `List.foldl` temporarily. Try out the following
           command (you can use tab completion here if you like):

           ``` ucm
           tour/main> move lib.base.data.List.foldLeft lib.base.data.List.foldl

             Done.

           tour/main> view lib.base.data.List.reverse

             lib.base.data.List.reverse : [a] -> [a]
             lib.base.data.List.reverse as =
                use base.data.List +:
                base.data.List.foldl (acc a -> a +: acc) [] as
           ```

           Notice that {{ docTooltip {{ `view` }} view }} shows the `foldl`
           name now, so the rename has taken effect. Nice!

           {{
           docCallout
             Optional.None
             {{
             Unison __isn't__ doing a bunch of text mutation on your behalf,
             updating possibly thousands of files, generating a huge textual
             diff, and also breaking a bunch of downstream library users who
             are still expecting that definition to be called by the old name.
             The two names are, to Unison, the same thing.
             }} }}

           So rename and move things around as much as you want! Don't worry
           about picking a perfect name the first time. Naming things is hard
           enough, renaming them shouldn't be a trial.

           The fact that Unison codebases are immutable and append-only means
           that we can "rewind" our project to an earlier point in time. Use
           the {{ docTooltip {{ `reflog` }} ucmCommands.reflog }} command to
           see a log of changes to the project. You should see some help text
           and a numbered list of hashes.

           ``` ucm
                Branch      When          Hash          Description
           1.   tour/main   39 secs ago   #ijqrr5987q   move tour/main:lib.base.data.List.foldLeft tour/main:lib.bas...
           2.   tour/main   18 mins ago   #a1vh3f0sa1   Include latest base library
           3.   tour/main   18 mins ago   #sg60bvjo91   Project Created
           ```

           A reflog keeps track of the history of a particular project, changes
           to the project like renames, updates, or deletions, form a log of
           hashes representing the codebase state. When we renamed {foldLeft},
           conceptually, the "state" of the codebase changed, but the log-based
           format of the project history means those changes are retrievable.

           Let's try to undo the rename action. Use the {{
           docTooltip {{ `reset` }} ucmCommands.reset }} command to pick a
           prior project state to return to. We'll give it the hash of the
           project state from just before the `move` command was issued.

           ``` ucm
           tour/main> reset #a1vh3f0sa1

             Done.
           ```

           Great! OK, go drink some water, 🚰 and then let's start writing some
           Unison code!

    ## {{ Anchor "part-4-tour" {{ Part 4: 📝 Writing Unison code }} }}

       {{ _scratchFiles }}

       ### Testing your code

           Next let's add a test for our `square` function:

           ``` unison
           square : Nat -> Nat
           square x = x * x

           test> square.tests.ex1 =
            verify '(ensureEqual (square 4) 16)
           ```

           Save the file, and Unison comes back with:

           ``` ucm
           8 | test> square.tests.ex1 = check (square 4 == 16)

           ✅ Passed : Proved.
           ```

           Some syntax notes:

           * The `test>` prefix tells Unison that what follows is a test watch
             expression. Note that we're also giving a name to this expression,
             `square.tests.ex1`.
           * There's nothing special about the name `square.tests.ex1`; we
             could call those bindings anything we wanted. Here we use the
             convention that tests for a definition `foo` go in `foo.tests`.

           The {verify} function has the signature @inlineSignature{verify}. It
           handles the {type Each}, {type Random} and {type Exception}
           abilities. These are common [abilities]({abilities.index}) used in
           testing. The {test.ensureEqual} function raises an {type Exception}
           if the two values are not equal, failing the test. In this case, the
           two values were equal, so the test passes.

       ### A property-based test

           Let's test this a bit more thoroughly. `square` should have the
           property that `square a * square b == square (a * b)` for all
           choices of `a` and `b`. The testing library supports writing
           property-based tests like this. There's some new syntax here,
           explained afterwards:

           ``` unison
           use base

           square : Nat -> Nat
           square x = x * x

           use test

           test> square.tests.ex1 = verify '(ensureEqual (square 4) 16)

           test> square.tests.prop1 =
              verify do
                Each.repeat 100
                a = Random.natIn 0 100
                b = Random.natIn 0 100
                ensure (square a * square b == square (a * b))
           ```

           ``` ucm
           10 |               verify do

           ✅ Passed
           ```

           This will test our function with a bunch of different inputs using
           the {type Each} and {type Random} abilities. {type Each} is being
           used to generate 100 {type Random} numbers, which the the test then
           verifies the property holds for.

           #### Syntax notes

                * The Unison block, which begins after an `=`, can have any
                  number of __bindings__ (like `a = …`) all at the same
                  indentation level, terminated by a single expression (here
                  `ensure (square ..)`), which is the result of the block.
                * The both the single quote {{ docCode {{ ' }} }} syntax and
                  the `do` keyword are ways of introducing a
                  [delayed computation]({{
                  docLink
                    (docEmbedTermLink do valuesAndFunctions.delayedComputations)
                  }}). A delayed computation is one in which the result is not
                  computed right away. The signature for a delayed computation
                  can be thought of as a function with no arguments, returning
                  the eventual result: `() -> a`.

    ## {{ Anchor "part-5-tour" {{ Part 5: ➕➖ Adding and updating code }} }}

       The `square` function and the tests we've written for it are not yet
       part of the codebase. So far they only exist in our scratch file. Let's
       add them now. Switch to the UCM and type
       {{ docTooltip {{ `add` }} ucmCommands.add }}. You should get something
       like:

       ``` ucm
       tour/main> add

         ⍟ I've added these definitions:

           square             : Nat -> Nat
           square.tests.ex1   : [Result]
           square.tests.prop1 : [Result]
       ```

       Try typing `view square` or `view square.tests.prop1`. Notice that
       Unison inserts precise {{ docTooltip {{ `use` }} useClause }} statements
       when rendering your code. A minimal set of `use` statements is inserted
       automatically by the code printer upon viewing or editing definitions.

       If you type `test` at the Unison prompt, it will "run" your test suite:

       ``` ucm
       tour/main> test

         Cached test results (`help testcache` to learn more)

         ◉ square.tests.ex1      : Passed
         ◉ square.tests.prop1    : Passed

         ✅ 2 test(s) passing

         Tip: Use view square.tests.ex1 to view the source of a test.
       ```

       But actually, it didn't need to run anything! All the tests had been run
       previously and cached according to their Unison hash. In a purely
       functional language like Unison, tests like these are deterministic
       won't actually rerun until the code they depend on changes!

       ### Moving and renaming terms

           When we added `square`, we were at the `tour` namespace, so `square`
           and its tests are at `tour.square`. We can also move the terms and
           namespaces to different locations in our codebase with the `move`
           command. `move` is recursive, so it will move the term and all the
           things inside the `square` namespace to the new name.

           ``` ucm
           tour/main> move square mySquare

             Done.
           ```

           When you're done shuffling some things around, you can use `find`
           with no arguments to view all the definitions under the current
           namespace:

           ``` ucm
           tour/main> find

             1. mySquare : Nat -> Nat
             2. mySquare.tests.ex1 : [Result]
             3. mySquare.tests.prop1 : [Result]
           ```

           Also notice that we don't need to rerun our tests after this
           reshuffling.

           ``` ucm
           tour/main> test

             Cached test results (`help testcache` to learn more)

             ◉ mySquare.tests.ex1       : Passed
             ◉ mySquare.tests.prop1     : Passed

             ✅ 2 test(s) passing

             Tip:  Use view square.tests.ex1 to view the source of a test.
           ```

           The tests are still cached because the test cache is keyed by the
           hash of the test itself, not by what the test happens to be called.

           When you're starting out writing some code, sometimes it's nice to
           put it in a temporary namespace, perhaps called `temp` or `wip`.
           Later, without breaking anything, you can move that namespace or
           bits and pieces of it elsewhere, using the `move` command.

       ### Updating existing definitions

           Here we'll make a change to the implementation of our `mySquare`
           function.

           Try entering `edit mySquare` in the UCM:

           ``` ucm
           tour/main> edit mySquare
             ☝️

             I added these definitions to the top of ~/unisoncode/scratch.u

               mySquare : Nat -> Nat
               mySquare x =
                 use Nat *
                 x * x

             You can edit them there, then do `update` to replace the definitions currently in this branch.
           ```

           This copies the pretty-printed definition of `mySquare` into your
           scratch file "above the fold." That is, it adds a line starting with
           `---` and puts whatever was already in the file below this line.
           Unison ignores any file contents below the fold.

           Let's edit `mySquare` and instead define `mySquare x` (just for fun)
           as the sum of the first `x` odd numbers (here's a
           [nice geometric illustration of why this gives the same results](https://math.stackexchange.com/a/639079)):

           ``` unison
           use base

           mySquare : Nat -> Nat
           mySquare x =
             sum (map (x -> x * 2 + 1) (range 0 x))

           sum : [Nat] -> Nat
           sum = foldLeft (+) 0
           ```

           ``` ucm
           ✅

           I found and typechecked these definitions in ~/unisoncode/scratch.u. If you do an
           ''add'' or ''update'' , here's how your codebase would change:

               ⍟ These new definitions are ok to `add`:

                 sum : [Nat] -> Nat

               ⍟ These names already exist. You can `update` them to your new definition:

                 mySquare : Nat -> Nat
           ```

       ### Adding an updated definition to the codebase

           Notice the message says that `mySquare` is ok to
           {{ docTooltip {{ `update` }} ucmCommands.update }}. Let's try that:

           ``` ucm
           tour/main> update

             ⍟ I've added these definitions:

               sum : [Nat] -> Nat

             ⍟ I've updated these names to your new definition:

               mySquare : Nat -> Nat
           ```

       ### Only affected tests are rerun on `update`

           If we rerun the tests, the tests won't be cached this time, since
           one of their dependencies has actually changed:

           ``` ucm
           tour/main> test

             ✅

               New test results:

             ◉ mySquare.tests.ex1      : Passed
             ◉ mySquare.tests.prop1    : Passed

             ✅ 2 test(s) passing

             Tip: Use view mySquare.tests.ex1 to view the source of a test.
           ```

           The dependency tracking for determining whether a test needs
           rerunning is 100% accurate and is tracked at the level of individual
           definitions. You'll only rerun a test if one of the individual
           definitions it depends on has changed.

    ## {{
    Anchor
      "part-6-tour"
      {{
      Part 6: 🤝 Sharing code and installing Unison libraries
      }} }}

       {{
       docCallout
         (Some {{ 🎉 }})
         {{
         The last you'll need to do to get set up to write Unison code is to
         sign up for Unison-share! Unison Share is the place to publish and
         discover Unison libraries. Head to
         [Unison Share](https://share.unison-lang.org/) and follow the
         instructions there to link your local codebase for code hosting!
         }} }}

       Code is published to Unison's own code hosting solution,
       [Unison Share]({{ docLink (docEmbedTermLink do unisonShare) }}), using
       the {{ docTooltip {{ `push` }} ucmCommands.push }} command and libraries
       are installed via the {{ docTooltip {{ `lib.install` }} libInstall }}
       command. There's no separate tooling needed for managing dependencies or
       publishing code. It's all built into the UCM.

       Congratulations on completing the tour of Unison! You're ready to get
       writing Unison code. We're excited to see what you build! 🥳

       {{ tour._nav }}
  }}

docs.tour.bigTechnicalIdea._hashCollisionNote : Doc
docs.tour.bigTechnicalIdea._hashCollisionNote =
  {{
  Unison uses 512-bit SHA3 hashes, which have unimaginably small chances of
  collision.

  If we generated one million unique Unison definitions every second, we should
  expect our first hash collision after roughly 100 quadrillion years! ⏳
  }}

docs.tour.square : Nat -> Nat
docs.tour.square x =
  use Nat *
  x * x

docs.tour._bigTechnicalIdea : Doc
docs.tour._bigTechnicalIdea =
  use Nat +
  {{
  Here's the big idea behind Unison, which we'll explain along with some of its
  benefits:

  {{
  docCallout
    (Some {{ 🧠 }})
    {{
    Each Unison definition is identified by a **hash** **of** **its**
    **syntax tree.**

    Put another way, Unison code is __content-addressed.__
    }} }}

  Here's an example, the `increment` function on {type Nat}:

  ``` unison
  increment : Nat -> Nat
  increment n = n + 1
  ```

  While we've given this function a human-readable name (and the function {+}
  also has a human-readable name), names are just separately stored metadata
  that don't affect the function's hash. The syntax tree of `increment` that
  Unison hashes looks something like:{{ docAside _hashCollisionNote }}

  ``` unison
  increment = (#arg1 -> #a8s6df921a8 #arg1 1)
  ```

  So all named arguments are replaced by positionally-numbered variable
  references, and all dependencies (in this case the {+} function) are replaced
  by their hashes. Thus, the hash of `increment` uniquely identifies its exact
  implementation and pins down all its dependencies.

  **An analogy:** Each Unison definition has a unique and deterministic address
  (its hash) in this vast immutable address space. Names are like pointers to
  addresses in this space. We can change what address a name points to, but the
  contents of each address are forever unchanging.

  # Benefits

    This starting assumption provides some surprising benefits: it simplifies
    distributed programming, eliminates builds and dependency conflicts,
    supports typed durable storage, structured refactorings, enables better
    tools for working with code, and lots more.

    {{
    docCallout
      (Some suggested)
      {{
      This isn't just theory and speculation—we created the
      [Unison Cloud Platform](https://www.unison.cloud/) to operationalize
      these benefits for anyone who wants to write and deploy Unison code.
      }} }}

    Let's go over how each of these benefits emerges. {{
    docAside
      {{
      This [Strange Loop talk](https://www.youtube.com/watch?v=gCWtkvDQ2ZI)
      covers many of these ideas as well, though some of the details are out of
      date.
      }} }}

    ## Simplifying distributed programming

       Programming languages today are generally based around the idea that a
       program is a thing that describes what a single OS process does, on a
       single computer. Any interaction with things outside the program
       boundary is done very indirectly, by sending bytes over a socket, say.
       You can't "just" run a computation elsewhere, you have to send bytes
       over the network, and then (somehow?) make sure the other end is running
       a separate program that is listening for those bytes and will
       deserialize them and hopefully run the computation you want.

       With this existing paradigm, distributed computations are described not
       with one program, but many separate programs stitched together with a
       morass of glue, duct tape, YAML files, and blobs of JSON being sent over
       the network.

       Moreover, it's complicated to set up all your compute resources to
       ensure that overall, they act to execute the overall computation you're
       interested in, and you get none of the niceties of programming languages
       to help you along the way. When programming for a single machine, you
       generally have a typechecker that helps ensure all the pieces fit
       together, and you can abstract over things however you like, introduce
       reusable components, and so on. This support is notably missing when
       assembling the correct layer of __stuff__ needed to get lots of
       computers to do something useful in concert.

       In Unison, since definitions are identified by a content hash, arbitrary
       computations can just be moved from one location to another, with
       missing dependencies deployed on the fly. The basic protocol is
       something like: the sender ships the bytecode tree to the recipient, who
       inspects the bytecode for any hashes it's missing. If it already has all
       the hashes, it can run the computation; otherwise, it requests the ones
       it's missing and the sender syncs them on the fly. They'll be cached for
       next
       time.{{
       docAside
         {{
         Of course, there's a lot of engineering that goes into making this
         work nicely, but the basic idea is simple and robust.
         }}
       }}

       This ability to relocate arbitrary computations subsumes the more
       limited notions of code deployment, remote procedure calls, and more,
       and lets us build powerful distributed computing components as ordinary
       Unison libraries.

       {{
       docCallout
         (Some {{ 📕 }})
         {{
         [Spark-like datasets in under 100 lines of Unison](https://www.unison-lang.org/articles/distributed-datasets/)
         shows how distributed programming libraries can be built up with
         minimal code in Unison
         }} }}

       It is a freeing thing to not have to do any setup in advance of just
       __running__ your program which can describe whole distributed systems.
       Rather than having to do a bunch of work "out of band" to ensure your
       compute resources are ready to run the code they need (like building
       containers, uploading a container image or jarfile somewhere, or
       whatever else), in the Unison model of distributed computing, you just
       run the code and whatever dependencies are missing can be sync'd on the
       fly.

       Of course, distributed programming can still be challenging, and
       distributed programs are different than sequential, single-machine
       programs. But distributed programming should not be
       __needlessly tedious.__ Let's spend our time on the things that actually
       __matter__ about distributed programs, not on deployment, setup, and
       tedious encoding and decoding to move values and computations around!

    ## No builds

       In Unison, you're almost never waiting around for your code to build.
       Why is that?

       Because Unison definitions are identified by their hash, they never
       change. We may change which __names__ are associated with which hashes
       (and this is used for Unison's approach to refactoring and code
       evolution), but the definition associated with a hash never changes.

       Thus, we can parse and typecheck definitions once, and then store the
       results in a cache which is __never invalidated.__ Moreover, this cache
       is not just some temporary state in your IDE or build tool (which gets
       mysteriously inconsistent on occasion), it's part of the Unison codebase
       format. Once anyone has parsed and typechecked a definition and added it
       to the codebase, no one has to do that ever again.

       This idea also applies to caching test results for pure computations
       (deterministic tests that don't use I/O). There's no need to rerun a
       deterministic test if none of its dependencies have changed!

       The result of this pervasive caching is you spend your time writing
       code, not waiting around for the compiler.

    ## No dependency conflicts

       Dependency conflicts are, fundamentally, due to different definitions
       "competing" for the same names. But why do we care if two different
       definitions use the same name? We shouldn't. The limitation only arises
       because definitions are referenced by name. In Unison, definitions are
       referenced by hash (and the names are just separately stored metadata),
       so dependency conflicts and the diamond dependency problem are just not
       a thing.

       Instead, what we now think of as a dependency conflict is instead just a
       situation where there are multiple terms or types that serve a similar
       purpose. Consider an `Email` type, one from v1 of Alice's library, and
       another from v2 of Alice's library (perhaps included transitively from a
       different library). We're accustomed to having to stop the world to fix
       a "broken" build from such a dependency "conflict", but in Unison, it's
       perfectly fine to have two different `Email` types floating around the
       codebase. They exist as different types, with different hashes, and you
       can work with both at the same time (and even write ordinary functions
       to convert between one and the other).

       Of course, over time, you may wish to consolidate those two `Email`
       types that you have in your codebase, but you can do so at your leisure,
       rather than your codebase being in a broken state and you being unable
       to run any code or do anything until this conflict is resolved.

       Having multiple versions of "the same" function or type floating around
       is not really much different than other sorts of duplication that might
       arise in your codebase, like a handful of similar-looking functions that
       you notice could all be defined in terms of some common abstraction.
       When the time is right, you consolidate that duplication away, but
       there's no need for this natural process to always take precedence over
       literally all other work.

    ## Typed, durable storage

       There are two aspects to storing values persistently. One is the
       interesting part: what sort of schema or data structure should I use for
       a large collection of data, such that certain queries or computations on
       it are efficient?

       The uninteresting part is all the serialization and deserialization that
       one deals with at these boundaries between your program and the
       underlying storage layer, be it SQL, NoSQL, or something else.

       In Unison, any value at all (including functions or values that contain
       functions) can be persisted and unpersisted at a later time, without the
       programmer needing to manually specify a serialization format or write
       an encoder and decoder.

       One reason people often resort to writing manual encoding/decoding
       layers is because it's assumed that the codebase doing the serialization
       at time 0 might be different than the codebase doing the deserialization
       months or years later. What if the newer codebase has different versions
       of libraries? Then I won't be able to read my data back! So I'd better
       write some tedious code on either side of the persistence boundary to
       convert to and from some stable format such as rows in SQL, a JSON blob,
       etc.

       Serializing a definition identified by content hash avoids this
       difficulty. Definitions never change, and deserialization will always
       yield a value that has the same meaning as when it was first serialized.

       Moreover, this idea makes it possible for a storage layer to be
       __typed__, not with a separate type system that your program doesn't
       know about (as in SQL), but as part of your Unison program. That is,
       values persisted by your program give you back typed references to the
       storage layer, and you're assured by Unison's type system that when
       loading that reference you'll get back a value of the expected type.

       Stay tuned for an article about writing a distributed storage layer in
       Unison.

    ## Richer codebase tools

       The Unison codebase is a proper database which knows the type of
       everything it stores, has a perfect compilation cache, perfect knowledge
       of dependencies, indices for type-based search, and more. This lets us
       easily build much richer tools for browsing and interacting with your
       code. For instance, [Unison Share](https://share.unison-lang.org/) lets
       you browse
       [fully hyperlinked Unison code](https://share.unison-lang.org/@unison/distributed)
       for libraries in the ecosystem, as well as rendering rich documentation
       with hyperlinked [embedded code samples]({List.range.doc}).

       By storing the codebase in this more structured way, it's much simpler
       to support these features. The first version of Unison Share was written
       in just a few months, by a single person, using the rich information
       already available in Unison's codebase API.

       Code is, fundamentally, structured information. We currently edit code
       as text for convenience, but just about anything you want to do with it
       can be done better by first converting to a more structured form.

       Let's look at a simple example: __renaming a definition.__ When the code
       is represented as a bag of mutable text files, renaming a definition
       accurately involves first converting those text files to some syntax
       tree which respects the scoping rules of the language and where
       dependencies are made explicit. This lets us determine which parts of
       the syntax tree are referencing the thing being renamed, and which parts
       contain that substring but where it's bound to something else (say, a
       local variable), or is within a string literal, a comment, etc.

       Once the renaming is complete, the revised syntax tree then needs to be
       serialized back to text, generating a huge textual diff and possibly
       lots of conflicts if you're working on the code concurrently with other
       developers. Furthermore, if the renaming is done on a definition in a
       published library, all your downstream users will have a broken codebase
       when they go to upgrade. Isn't this silly?

       Another example: consider the ephemeral compilation caches of build
       tools and IDEs. These tools go to great lengths to try to avoid
       recompiling code needlessly, processing the textual code into some
       richer form that they can cache, but it's quite difficult, especially
       when the underlying text files are perpetually getting mutated out from
       underneath the build tool.

       Unison represents your codebase as a proper "database of code",
       sidestepping many of these difficulties. You still __edit__ and
       __author__ code using your favorite text editor, but once your code is
       slurped into the codebase, it's stored in a nicely processed form that
       provides benefits like instant non-breaking renames, type-based search,
       hyperlinked code, and more. And it's one command to get any definition
       back into your text buffer (pretty-printed, and using the latest names
       for definitions) for easy editing.

       On the one hand, text files and text-based tools have a large ecosystem
       that already exists and that people are used to. But text as a way of
       storing code loses out on huge advantages that Unison gets "for free"
       with a more structured representation of what a codebase is. And we are
       just scratching the surface: Unison's tools for working with code will
       just keep getting better and better, with entirely new possibilities
       opening up that are be difficult or impossible using text-based
       codebases.

    ## Structured refactoring

       Even if Unison's underlying model is that definitions never change, we
       do sometimes want to change what definitions our human-readable names
       are mapped to. You might need to fix bugs, improve performance, or
       simply repurpose an existing name for a new definition.

       In Unison, changing what names are mapped to which hashes is done with
       structured refactoring sessions, rather than the typical approach of
       just mutating text files in place and then fixing a long list of
       misleading compile errors and failed tests. A Unison codebase is never
       in a broken state, even midway through a refactoring.

       If your codebase is like a skyscraper, the typical approach to
       refactoring is like ripping out one of the foundational columns. The
       skyscraper collapses in a pile of rubble (a long list of misleading
       compile errors), and you attempt to rebuild a standing skyscraper from
       that rubble.

       The Unison approach is to keep the existing skyscraper around and just
       copy bits of it over to a new skyscraper, using a magic cloning tool.
       The codebase is never in a broken state. All your code is runnable. It's
       just that, midway through, you may not have fully constructed the second
       skyscraper and cut over all the names. Unison keeps track of that and
       gives you a tidy todo list to work through.

  # Conclusions

    The longer you spend with this idea of content-addressed code, the more it
    starts to take hold of you. It's not arbitrary or strange, but a logical
    and sensible choice with tremendous practical benefits. You start to
    appreciate the simplicity of the idea and see the need for it everywhere
    ("this would be a lot easier if the code were content-addressed..."). Is it
    really feasible, though, to build a programming language around this idea?
    Yes!

    Part of the fun in building Unison was in working through the implications
    of what seemed like a great core idea. A big question that arose: even if
    definitions themselves are unchanging, we do sometimes want to change which
    definitions we are interested in and assign nice names to. So how does that
    work? How do you refactor or upgrade code? Is the codebase still just a
    mutable bag of text files, or do we need something else?

    We __do__ need something else to make it nice to work with
    content-addressed code. In Unison we call this something else the
    __Unison Codebase Manager__.
  }}

docs.tour._nav : Doc
docs.tour._nav =
  use wordle.utils.emojis learnMore
  {{
  {{
  Style
    navStyleTag
    {{
    # What next?

      {{ suggested }}
      [Configure UCM to set author and license information]({authorLicense})

      {{ suggested }} [Learn more about Unison projects]({docs.projects})

      {{ suggested }}
      [Take a look at the language documentation and get started writing Unison
      code]({{ (docLink (docEmbedTermLink do terms)) }})

      {{ suggested }}
      [Learn how to update Unison code and resolve conflicts]({updateCode})

      {{ learnMore }}
      [Explore the Unison Share catalogue](https://share.unison-lang.org/catalog)

      {{ learnMore }}
      [A mental model for Abilities in Unison covers a unique aspect of
      Unison's type system]({abilities.index})

      {{ learnMore }} [Learn how to write Unison docs]({documentation})
    }} }}
  }}

docs.tour._scratchFiles : Doc
docs.tour._scratchFiles =
  {{
  # Unison's interactive scratch files

    The codebase manager listens for changes to any file ending in `.u` in the
    current directory. When any such file is saved (which we call a "scratch
    file"), Unison parses and typechecks that file. Let's try this out.

    Keep your `ucm` terminal running and open up a file, `scratch.u` (or
    `foo.u`, or whatever you like) in your preferred text editor. {{
    docAside
      {{
      (if you want syntax highlighting for Unison files,
      [follow this link]({editorSetup}) for instructions on setting up your
      editor).
      }} }}

    Now put the following in your scratch file:

    ``` unison
    square : Nat -> Nat
    square x =
      use Nat *
      x * x
    ```

    This defines a function called `square`. It takes an argument called `x`
    and it returns `x` multiplied by itself.

    When you save the file, Unison replies:

    ``` ucm
    ✅

    I found and typechecked these definitions in ~/unisoncode/scratch.u. If you do an
    `add` or `update` , here's how your codebase would change:

      ⍟ These new definitions are ok to `add`:

        square : Nat -> Nat

    Now evaluating any watch expressions (lines starting with `>`)… Ctrl+C cancels.
    ```

    It typechecked the `square` function and tells us that `square` is "ok to
    `add`." We'll do that shortly, but first, let's try calling our function
    right in the `scratch.u` file, just by starting a line with `>`:

    ``` unison
    square : Nat -> Nat
    square x =
      use Nat *
      x * x

    > square 4
    ```

    And Unison prints:

    ``` ucm
    6 | > square 4
          ⧩
          16
    ```

    The `> square 4` on line 6 is called a "watch expression". Unison uses
    these watch expressions instead of having a separate read-eval-print-loop
    (REPL). The code you are editing can be run interactively as you go, with a
    full text editor at your disposal, with the same definitions all in scope,
    without needing to switch to a separate tool.

    The `use Nat *` is a __use clause__ which specifies which "*" operator we
    want to use. This one is from the `Nat` namespace in our `lib.base`
    standard library. Use clauses mean we can refer to `base.Nat` as simply
    `Nat` and can refer to `*` without prefixing it `Nat.*`.

    __Question:__ do we really want to reevaluate all watch expressions on
    every file save? What if they're expensive? Luckily, Unison keeps a cache
    of results for expressions it evaluates, keyed by the hash of the
    expression, and you can clear this cache at any time without ill effects.
    If a result for a hash is in the cache, Unison returns that instead of
    evaluating the expression again. So you can think of and use your `.u`
    scratch files a bit like spreadsheets, which only recompute the minimal
    amount when dependencies change.

    {{
    docCallout
      (Some {{ 🤓 }})
      {{
      There's one more ingredient that makes this work effectively, and that's
      functional programming. When an expression has no side effects, its
      result is {{ (docTooltip {{ deterministic }} deterministic) }}, and you
      can cache it as long as you have a good key to use for the cache, like
      the Unison content-based hash. Unison's type system won't let you do I/O
      inside one of these watch expressions or anything else that would make
      the result change from one evaluation to the next.
      }} }}

    Let's try out a few more
    {{ docTooltip {{ watch expressions }} watchExpression }}:

    ``` unison
    -- A comment, ignored by Unison

    > List.reverse [1,2,3,4]
    > 4 + 6
    > 5.0 / 2.0
    > not true
    ```

    ``` ucm
    ✅

    ~/unisoncode/scratch.u changed.

    Now evaluating any watch expressions (lines starting with
    `>`)… Ctrl+C cancels.

      6 | > List.reverse [1,2,3,4]
            ⧩
            [4, 3, 2, 1]

      7 | > 4 + 6
            ⧩
            10

      8 | > 5.0 / 2.0
            ⧩
            2.5

      9 | > not true
            ⧩
            false
    ```
  }}

docs.ucmCommands.add : Doc
docs.ucmCommands.add =
  name = {{ add }}
  body =
    {{
    Adds all the definitions from the most recently typechecked file to the
    codebase.

    # FAQ about the {{ name }} command

      ## I got an error about "these definitions failed" on add

         This message happens when some of the definitions couldn't be added to
         the codebase. Most commonly this is because you are trying to `add` a
         term that already exists in the codebase with the same namespace and
         name.

         ``` ucm
         x These definitions failed:

         Reason
         needs update   myFunction : Doc
         ```

         Entering [`update`]({ucmCommands.update}) instead of add will turn
         this failure into a successful update.
    }}
  _make name add._cmd body

docs.ucmCommands.add._cmd : Doc
docs.ucmCommands.add._cmd =
  {{
  ``` ucm
  myProject/main> add
  ```

  ``` ucm
  myProject/main> add myNewTerm
  ```
  }}

docs.ucmCommands.addPreview : Doc
docs.ucmCommands.addPreview =
  title = {{ add.preview }}
  cmd =
    {{
    ``` ucm
    scratch/main> add.preview
    ```
    }}
  body =
    {{
    Previews additions to the codebase from the most recently typechecked file.
    This command only displays cached typechecking results. Use `load` to
    reparse & typecheck the file if the context has changed.
    }}
  _make title cmd body

docs.ucmCommands.addRun : Doc
docs.ucmCommands.addRun =
  title = {{ add.run }}
  cmd =
    {{
    ``` ucm
    scratch/main> run main
    scratch/main> add.run resultMain
    ```
    }}
  body =
    {{
    Adds the result of calling the most recent `run` command back into the
    codebase as a Unison term with the given name.
    }}
  _make title cmd body

docs.ucmCommands.aliaz.many : Doc
docs.ucmCommands.aliaz.many =
  title = {{ alias.many }}
  cmd =
    {{
    ``` ucm
    scratch/main> alias.many foo.foo bar.bar bazNamespace
    ```
    }}
  body =
    {{
    `alias.many <relative1> [relative2...] <namespace>` creates aliases
    `relative1`, `relative2`, ... in the namespace `namespace`.
    }}
  _make title cmd body

docs.ucmCommands.aliaz.term : Doc
docs.ucmCommands.aliaz.term =
  name = {{ alias.term }}
  body =
    {{
    `alias.term foo bar` creates the name `bar` as an alias for the term `foo`.
    The term can then be referenced by both names. Metadata linked to `foo` is
    copied over to bar (use `unlink` if this isn't what you want). `foo` and
    `bar` can be any term names including {{
    docTooltip {{ operators }} operators }} and hash qualified names.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> alias.term existingName newName
    scratch/main> alias.term frobnicate#2jdk10 zonk.betterName
    scratch/main> alias.term Nat.drop .utils.Nat.-
    ```
    }}
  _make name cmd body

docs.ucmCommands.aliaz.term._cmd : Doc
docs.ucmCommands.aliaz.term._cmd =
  {{
  ``` ucm
  scratch/main> alias.term existingName additionalName
  ```
  }}

docs.ucmCommands.aliaz.typez : Doc
docs.ucmCommands.aliaz.typez =
  name = {{ alias.type }}
  body =
    {{
    `alias.type foo bar` creates the name `bar` as an alias for the type `foo`.
    Metadata linked to `foo` is copied over to `bar` (use `unlink` if this
    isn't what you want). `foo` and `bar` can be any type names.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> alias.type ExistingName NewName
    scratch/main> alias.type Employee#2jdk10 v1.Employee
    scratch/main> alias.type List.map .utils.List.map
    ```
    }}
  _make name cmd body

docs.ucmCommands.api : Doc
docs.ucmCommands.api =
  title = {{ api }}
  cmd =
    {{
    ``` ucm
    scratch/main> api
    ```
    }}
  body = {{ Provides details about the Unison Codebase Manager API. }}
  _make title cmd body

docs.ucmCommands.auth.login : Doc
docs.ucmCommands.auth.login =
  name = {{ auth.login }}
  body =
    {{
    Obtains an authentication session with
    [Unison Share](https://share.unison-lang.org). Also authenticates the user
    for running programs using the
    [Unison Cloud library](https://share.unison-lang.org/@unison/code/latest/namespaces/public/cloud/main).

    Will open with your default browser.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> auth.login
    ```
    }}
  _make name cmd body

docs.ucmCommands.back : Doc
docs.ucmCommands.back =
  title = {{ back }}
  cmd =
    {{
    ``` ucm
    scratch/main> switch /feature1
    scratch/feature1> back
    scratch/main>
    ```
    }}
  body = {{ Undoes the last `switch` command. }}
  _make title cmd body

docs.ucmCommands.branch : Doc
docs.ucmCommands.branch =
  title = {{ branch }}
  cmd =
    {{
    ``` ucm
    scratch/main> branch feature1
    ```

    ``` ucm
    scratch/main> branch /feature1 feature2
    ```
    }}
  body =
    {{
    `branch feature1` forks the current project branch to a new branch called
    "feature1"

    `branch /feature1 feature2` forks the branch `feature1` to a new branch
    called `feature2`.

    More info about creating branches
    [can be found in the project workflows documentation]({createBranches})
    }}
  _make title cmd body

docs.ucmCommands.branchEmpty : Doc
docs.ucmCommands.branchEmpty =
  title = {{ branch.empty }}
  cmd =
    {{
    ``` ucm
    scratch/main> branch.empty newBranch
    ```
    }}
  body =
    {{
    Creates a new empty branch. The newly created branch will not have a
    parent-child relationship with the branch it was created from.
    }}
  _make title cmd body

docs.ucmCommands.branches : Doc
docs.ucmCommands.branches =
  title = {{ branches }}
  cmd =
    {{
    ``` ucm
    scratch/main> branches
    ```

    ``` ucm
    scratch/main> branches base
    ```
    }}
  body =
    {{
    Lists the branches in the current project or in the given project argument
    }}
  _make title cmd body

docs.ucmCommands.cd : Doc
docs.ucmCommands.cd =
  name = {{ cd (Deprecated) }}
  body =
    {{
    {{ docCode {{ {{ name }} }} }} is used to move to a different namespace in
    the codebase. It accepts relative or absolute paths. Also known as
    `namespace` or `j`.
    }}
  _make name cd._cmd body

docs.ucmCommands.cd._cmd : Doc
docs.ucmCommands.cd._cmd =
  {{
  ``` ucm
  scratch/main> cd .base.Bag
  scratch/main> cd base.List
  ```

  ``` ucm
  scratch/main> cd ..
  scratch/main> cd back
  ```
  }}

docs.ucmCommands.clear : Doc
docs.ucmCommands.clear =
  title = {{ clear }}
  cmd =
    {{
    ``` ucm
    scratch/main> clear
    ```
    }}
  body = {{ Clears the UCM terminal screen }}
  _make title cmd body

docs.ucmCommands.clone : Doc
docs.ucmCommands.clone =
  title = {{ clone }}
  cmd =
    {{
    ``` ucm
    scratch/main> clone @unison/json/topic json/my-topic
    @unison/json/my-topic>
    ```

    ``` ucm
    scratch/main> clone /feature /my-feature
    scratch/my-feature>
    ```
    }}
  body =
    {{
    Clones a remote project and branch from Unison Share into a local codebase.
    Use this command instead of `pull` or `lib.install` if you would like to
    bring code locally to work on.
    }}
  _make title cmd body

docs.ucmCommands.codebaseCreate : Doc
docs.ucmCommands.codebaseCreate =
  name = {{ `--codebase-create` }}
  body =
    {{
    Creates a new codebase at the given path. Opens an existing codebase when
    the path supplied already contains a `.unison` directory.
    }}
  _make name codebaseCreate._cmd body

docs.ucmCommands.codebaseCreate._cmd : Doc
docs.ucmCommands.codebaseCreate._cmd =
  {{ `ucm --codebase-create my/new/codebase/path` }}

docs.ucmCommands.compile : Doc
docs.ucmCommands.compile =
  name = {{ compile }}
  body =
    {{
    `compile myMain myFile` creates a file called `myFile.uc` in the directory
    where the codebase lives from the Unison program `myMain`. This file can be
    run by the UCM when given as an argument to the `run.compiled` command line
    option.

    # See also

      [run.compiled]({compiled})
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> compile myMain myMainFile
    ```

    ``` bash
    $ ucm run.compiled myMainFile.uc
    ```
    }}
  _make name cmd body

docs.ucmCommands.create.author : Doc
docs.ucmCommands.create.author =
  name = {{ create.author }}
  body =
    {{
    {{ name }} creates an {type metadata.Author} value in `metadata.authors`
    and `metadata.copyrightHolders`.
    }}
  _make name author._cmd body

docs.ucmCommands.create.author._cmd : Doc
docs.ucmCommands.create.author._cmd =
  {{
  ``` ucm
  scratch/main> create.author alicecoder "Alice McGee"
  ```
  }}

docs.ucmCommands.debug.clearCache : Doc
docs.ucmCommands.debug.clearCache =
  name = {{ debug.clear-cache }}
  body =
    {{
    Used for clearing the UCM cache of previous test or watch expression runs.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> debug.clear-cache
    ```
    }}
  _make name cmd body

docs.ucmCommands.debugDocToMarkdown : Doc
docs.ucmCommands.debugDocToMarkdown =
  title = {{ debug.doc-to-markdown }}
  cmd =
    {{
    ``` ucm
    scratch/main> debug.doc-to-markdown term.doc
    ```
    }}
  body =
    {{ Prints a {type Doc} element into a markdown text snippet in the UCM. }}
  _make title cmd body

docs.ucmCommands.del : Doc
docs.ucmCommands.del =
  name = {{ delete }}
  body =
    {{
    Deletes the given term or type name from the codebase. If the term or type
    is still in use, the UCM will render an error indicating where it is
    referenced.
    }}
  cmd =
    {{
    ``` ucm
    delete myTerm
    ```

    ``` ucm
    delete Optional
    ```
    }}
  _make name cmd body

docs.ucmCommands.del.namespc : Doc
docs.ucmCommands.del.namespc =
  name = {{ delete.namespace }}
  body =
    {{
    {{ name }} deletes the namespace and the terms it contains from the
    codebase. If the definitions in the namespace are still in use, the UCM
    will not perform the deletion. Previously deleted namespaces are still in
    the codebase's history and can be retrieved with the
    [`reflog`]({{ docLink (docEmbedTermLink do ucmCommands.reflog) }}) command.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> delete.namespace foo
    ```
    }}
  _make name cmd body

docs.ucmCommands.del.namespc.force : Doc
docs.ucmCommands.del.namespc.force =
  name = {{ delete.namespace.force }}
  body =
    {{
    Removes the namespace even if the terms within that namespace are used in
    the codebase. The code dependencies will contain hash references of the
    deleted terms and types.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> delete.namespace.force foo
    ```
    }}
  _make name cmd body

docs.ucmCommands.del.patch : Doc
docs.ucmCommands.del.patch =
  name = {{ delete.patch }}
  body =
    {{
    Use `delete.patch foo.patch` to remove the patch in the `foo` namespace.
    The argument to this must be a patch.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> delete.patch foo.patch
    ```
    }}
  _make name cmd body

docs.ucmCommands.delBranch : Doc
docs.ucmCommands.delBranch =
  name = {{ delete.branch }}
  body = {{ Deletes the branch with the given name }}
  cmd =
    {{
    ``` ucm
    myProject/main> delete.branch /myBranch
    ```
    }}
  _make name cmd body

docs.ucmCommands.dependencies : Doc
docs.ucmCommands.dependencies =
  name = {{ dependencies }}
  body =
    {{
    Lists the dependencies of the specified definition. Accepts a term name or
    hash.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> dependencies myTerm

    Dependencies of #myTermHash:

    Reference   Name
    1.  #hash1 dependent1
    2.  #hash2 dependent2
    ```
    }}
  _make name cmd body

docs.ucmCommands.dependents : Doc
docs.ucmCommands.dependents =
  name = {{ dependents }}
  body =
    {{
    The {{ name }} command lists all the terms that make use of the given term
    or type in their implementation. This can be useful for understanding the
    impact of a change to a term or for finding out where a type is used in a
    project.
    }}
  cmd =
    {{
    ``` unison
    foo : Nat
    foo = 42

    bar = foo + 1
    ```

    ``` ucm
    scratch/main> dependents foo

      Dependents of: foo

      Terms:

      1. bar
    ```
    }}
  _make name cmd body

docs.ucmCommands.display : Doc
docs.ucmCommands.display =
  name = {{ display }}
  body =
    {{
    Displays a rendered version of the given term to the console. If called
    with no arguments, {{ name }} invokes a search to select a definition to
    display, requiring that `fzf` be found within your PATH. {{
    docCode {{ {{ name }} }} }} is often used for reading documentation in the
    command line. Currently this command works for __terms__ in a codebase but
    does not display types or abilities. This may change in an upcoming release
    of the UCM.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> display myTerm
    ```

    ``` ucm
    scratch/main> display
    ```
    }}
  _make name cmd body

docs.ucmCommands.display.to : Doc
docs.ucmCommands.display.to =
  name = {{ display.to }}
  body =
    {{
    {{ docCode {{ {{ name }} <filename> foo }} }} prints a rendered version of
    the term `foo` to the given file.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> display.to myFile myTerm
    ```
    }}
  _make name cmd body

docs.ucmCommands.docs : Doc
docs.ucmCommands.docs =
  title = {{ docs }}
  body =
    {{
    {{ docCode {{ {{ title }} }} }} prints the docs for the given term in the
    UCM if a corresponding `.doc` term exists.

    In the example above, the UCM is looking for a term called
    `Exception.bracket.doc`
    }}
  _make title docs._cmd body

docs.ucmCommands.docs._cmd : Doc
docs.ucmCommands.docs._cmd =
  {{
  ``` ucm
  scratch/main> docs Exception.bracket
  ```
  }}

docs.ucmCommands.edit : Doc
docs.ucmCommands.edit =
  title = {{ edit }}
  cmd =
    {{
    ``` ucm
    scratch/main> edit myTerm
    ```

    ``` ucm
    scratch/main> ls base.List
    scratch/main> edit 4
    scratch/main> edit 1-5
    ```
    }}
  body =
    {{
    {{ title }} prepends the definition of the given argument(s) to the top of
    the most recently saved file.

    Often used in conjunction with {ucmCommands.update}.
    }}
  _make title cmd body

docs.ucmCommands.editNamespace : Doc
docs.ucmCommands.editNamespace =
  title = {{ edit.namespace }}
  cmd =
    {{
    ``` ucm
    scratch/main> edit.namespace foo.bar
    ```

    ``` ucm
    scratch/main> edit.namespace foo bar.baz
    ```
    }}
  body =
    {{
    Brings the contents of an entire namespace (and its sub-namespaces) inside
    a scratch file for editing. Accepts multiple namespace arguments.
    }}
  _make title cmd body

docs.ucmCommands.editNew : Doc
docs.ucmCommands.editNew =
  title = {{ edit.new }}
  cmd =
    {{
    ``` ucm
    scratch/main> edit.new foo.bar
    ```

    Commonly used with `ls` and numbered arguments.

    ``` ucm
    scratch/main> ls
    scratch/main> edit.new 1-n
    ```
    }}
  body =
    {{
    Brings the arguments into a scratch file above a fold `---` to provide a
    new workspace for working on Unison code. Everything below the fold is
    ignored by the UCM.
    }}
  _make title cmd body

docs.ucmCommands.find : Doc
docs.ucmCommands.find =
  title = {{ find }}
  body =
    {{
    {{ docCode {{ {{ title }} foo bar baz }} }} searches the current namespace
    tree for the given argument(s), excluding the `lib` directory.

    If no arguments are supplied, {{ docCode {{ {{ title }} }} }} will either
    list the definitions in the current namespace or, if `fzf` is installed on
    your machine, `find` will delegate to `fzf` for fuzzy search.
    [See the `fzf` github](https://github.com/junegunn/fzf) for more details.

    To search for terms including the `lib` directory, use
    [`find.all`]({find.all})

    # Type driven search

      If {{ docCode {{ {{ title }} }} }} is followed by a colon, the ucm will
      search the codebase for definitions which match the given type signature.
    }}
  _make title find._cmd body

docs.ucmCommands.find.all : Doc
docs.ucmCommands.find.all =
  name = {{ find.all }}
  body =
    {{
    The {{ name }} command behaves identically to the `find` command, except
    that it includes the `*.lib` namespace, by default, in its search.

    While it is possible for the namespaces inside of the `lib` directory to
    contain their own `lib` namespaces, this command does not recursively
    search through all `lib` sub-namespaces.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> find.all List.reverse

    1. lib.base.List.reverse : [a] -> [a]
    ```
    }}
  _make name cmd body

docs.ucmCommands.find.verbose : Doc
docs.ucmCommands.find.verbose =
  name = {{ find.verbose }}
  body =
    {{
    The {{ name }} command behaves identically to [`find`]({ucmCommands.find}),
    except that it includes hashes and aliases in its output
    }}
  cmd =
    {{
    ``` ucm
    .myProject> find.verbose emp

    1. -- #bs08eqa1ukvve64fh71sqp406jf73c8s6c3v8ltg1ucqre10lcq32qk45sf8pgrfrctstbldlm4m7mscnk9vkra2ohcpmqqhtprb9jo
      isEmpty : [a] -> Boolean
    ```
    }}
  _make name cmd body

docs.ucmCommands.find._cmd : Doc
docs.ucmCommands.find._cmd =
  {{
  ``` ucm
  .myProject> find
  ```

  ``` ucm
  .myProject> find myTerm
  ```

  ``` ucm
  .myProject> find Map List
  ```

  ``` ucm
  .myProject> find : [a] -> [[a]]
  ```
  }}

docs.ucmCommands.findIn : Doc
docs.ucmCommands.findIn =
  title = {{ find-in }}
  cmd =
    {{
    `find-in` can be used with a namespace argument to list all definitions in
    the specified sub-namespace

    ``` ucm
    scratch/main> find-in foo.bar
    ```

    ``` ucm
    scratch/main> find-in foo.bar term1 term2
    ```
    }}
  body =
    {{
    Lists all definitions with a name similar to the given arguments inside the
    namespace argument.
    }}
  _make title cmd body

docs.ucmCommands.fork : Doc
docs.ucmCommands.fork =
  name = {{ fork }}
  body =
    {{
    Creates a copy of the given source namespace at the a new destination.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> fork src destination
    ```

    Fork a namespace across projects and branches with the following syntax:

    ``` ucm
    project0/main> fork project0/branch0:a.path project1/branch1:foo
    ```

    You can also create a namespace from the contents of an entire branch of a
    given project:

    ``` ucm
    srcproject/main> fork srcproject/srcbranch dest
    ```
    }}
  _make name body cmd

docs.ucmCommands.gist : Doc
docs.ucmCommands.gist =
  body =
    {{
    Pushes the contents of the namespace in which it is called to the given
    remote repository. Used for sharing quick snippets of code. The UCM will
    return a `pull` command that others can use to retrieve your gist.
    }}
  name = {{ gist }}
  cmd =
    {{
    ``` ucm
    .myNamespace> gist git(git@github.com:myUser/myUnisonRepo)
    Gist created. Pull via:

    pull git(git@github.com:myUser/myUnisonRepo)#hashReference
    ```
    }}
  _make name cmd body

docs.ucmCommands.global.reflog : Doc
docs.ucmCommands.global.reflog =
  name = {{ global.reflog }}
  body =
    {{
    `global.reflog` or `reflog.global` lists the changes to the codebase across
    all projects and branches.

    For viewing changes that are scoped to the current project branch, use the
    `reflog` command.

    For viewing changes across multiple branches in a project, use the
    `project.reflog` command.
    }}
  cmd =
    {{
    ``` ucm
    myProject/main> global.reflog

    Branch                              When                Hash          Description
    1.    tour/main                     an hour ago         #a1vh3f0sa1   reset a1vh3f0sa1
    2.    tour/main                     an hour ago         #ijqrr5987q   move tour/main:.a tour/main:.b
    5.    anotherProject/aBranch        about 2 hours ago   #6tfcojje2h   reset 6tfcojje2h aBranch
    ```
    }}
  _make name cmd body

docs.ucmCommands.help : Doc
docs.ucmCommands.help =
  title = {{ help }}
  cmd =
    {{
    ``` ucm
    scratch/main> help add.run
    ```
    }}
  body =
    {{ Prints usage information and patterns about the given UCM command. }}
  _make title cmd body

docs.ucmCommands.helpTopics : Doc
docs.ucmCommands.helpTopics =
  title = {{ help-topics }}
  cmd =
    {{
    Enter `help-topics` with no arguments to see a list of topics:

    ``` ucm
    scratch/main> help-topics
    ```

    ``` ucm
    scratch/main> help-topics projects
    ```
    }}
  body = {{ Displays information about the given UCM topic. }}
  _make title cmd body

docs.ucmCommands.history : Doc
docs.ucmCommands.history =
  name = {{ history }}
  cmd =
    {{
    ``` ucm
    scratch/main> history

    Note: The most recent namespace hash is immediately below this message.

    ⊙ 1. #6tfcojje2h

      - Deletes:

        deploy

    ⊙ 2. #f85r0fefal

      + Adds / updates:

        testNewFunction
    ```
    }}
  body =
    {{
    The {{ docCode name }} command displays the history of changes (such as
    additions, updates, and deletes) to the current branch. The history is a
    more detailed view of the changes that have been made to the codebase than
    the [`reflog`](ucmCommands.reflog) command, including the names of terms
    that have been changed.
    }}
  _make name cmd body

docs.ucmCommands.index : Doc
docs.ucmCommands.index =
  use create author
  {{
  # UCM Command Reference

    You can always type `help` into the {{ docTooltip {{ UCM }} ucm }} to get a
    full list of supported commands, or type `help <desiredCommand>` to get
    more information about a particular command.

    {{ SectionBreak }}

    {{ ucmCommands.add }}

    {{ addPreview }}

    {{ addRun }}

    {{ aliaz.many }}

    {{ aliaz.term }}

    {{ aliaz.typez }}

    {{ api }}

    {{ login }}

    {{ author }}

    {{ back }}

    {{ ucmCommands.branch }}

    {{ branchEmpty }}

    {{ branches }}

    {{ ucmCommands.clear }}

    {{ ucmCommands.clone }}

    {{ codebaseCreate }}

    {{ compile }}

    {{ author }}

    {{ clearCache }}

    {{ debugDocToMarkdown }}

    {{ del }}

    {{ delBranch }}

    {{ namespc }}

    {{ namespc.force }}

    {{ ucmCommands.dependencies }}

    {{ dependents }}

    {{ ucmCommands.display }}

    {{ display.to }}

    {{ ucmCommands.docs }}

    {{ toHtml }}

    {{ edit }}

    {{ editNamespace }}

    {{ editNew }}

    {{ ucmCommands.find }}

    {{ find.all }}

    {{ findIn }}

    {{ verbose }}

    {{ ucmCommands.fork }}

    {{ help }}

    {{ helpTopics }}

    {{ ucmCommands.history }}

    {{ ioTest }}

    {{ ioTestAll }}

    {{ libInstall }}

    {{ ls }}

    {{ ucmCommands.load }}

    {{ ucmCommands.merge }}

    {{ mergeCommit }}

    {{ move }}

    {{ namespace_ }}

    {{ move.term }}

    {{ move.typez }}

    {{ projectCreate }}

    {{ projectRename }}

    {{ ucmCommands.projects }}

    {{ ucmCommands.pull }}

    {{ pullWithoutHistory }}

    {{ ucmCommands.push }}

    {{ quit }}

    {{ ucmCommands.reflog }}

    {{ project.reflog }}

    {{ global.reflog }}

    {{ ucmCommands.reset }}

    {{ ucmCommands.run }}

    {{ compiled }}

    {{ runNative }}

    {{ switch }}

    {{ ucmCommands.test }}

    {{ testAll }}

    {{ textFind }}

    {{ textFindAll }}

    {{ todoUCM }}

    {{ ui }}

    {{ undo }}

    {{ unsafeForcePush }}

    {{ ucmCommands.update }}

    {{ upgrade }}

    {{ upgradeCommit }}

    {{ ucmCommands.version }}

    {{ ucmCommands.view }}
  }}

docs.ucmCommands.ioTest : Doc
docs.ucmCommands.ioTest =
  name = {{ io.test }}
  body =
    {{
    io.test can execute a single test which performs I/O. The argument to
    io.test should be a delayed computation which performs the {type IO}
    ability and returns a {type test.Result}.
    }}
  cmd =
    {{
    ``` unison
    myTest : '{IO, Exception} [Result]
    myTest _ =
    printLine "hi"
    check (1 == 1)
    ```

    ``` ucm
    scratch/main> io.test myTest
    ```
    }}
  _make name cmd body

docs.ucmCommands.ioTestAll : Doc
docs.ucmCommands.ioTestAll =
  name = {{ io.test.all }}
  body =
    {{
    Runs all the unit tests for the current branch that use IO. Each test
    should be a delayed computation which performs the {type IO} ability and
    returns a {type test.Result}.
    }}
  cmd =
    {{
    ``` unison
    myTest : '{IO, Exception} [Result]
    myTest _ =
    printLine "hi"
    check (1 == 1)
    ```

    ``` ucm
    scratch/main> io.test.all
    ```
    }}
  _make name cmd body

docs.ucmCommands.learn._cmd : Doc
docs.ucmCommands.learn._cmd =
  {{
  ``` ucm
  .> docs Exception.bracket
  ```
  }}

docs.ucmCommands.libInstall : Doc
docs.ucmCommands.libInstall =
  name = {{ lib.install }}
  body =
    {{
    The {{ docCode {{ {{ name }} }} }} command is used to install a library
    from Unison Share, as of Unison version 0.5.21. If you are using an older
    Unison version, use the `pull` command to install libraries.
    }}
  command =
    {{
    Downloads the latest release of the specified library:

    ``` ucm
    myProject/main> lib.install @unison/base
    ```

    To install a specific version of a library, use the name of the libray
    followed by "release/versionNumber":

    ``` ucm
    myProject/main> lib.install @unison/base/releases/1.0.0
    ```
    }}
  _make name command body

docs.ucmCommands.load : Doc
docs.ucmCommands.load =
  name = {{ load }}
  body =
    {{
    Parses, typechecks and evaluates the given `.u` suffixed scratch file. Once
    typechecked and evaluated, you can [add]({ucmCommands.add}) the terms to
    your codebase, so {{ name }} is often used in transcripts.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> load myScratch.u
    ```

    Without an argument, {{ name }} parses, typechecks, and evaluates the most
    recent scratch file.

    ``` ucm
    scratch/main> load
    ```
    }}
  _make name cmd body

docs.ucmCommands.ls : Doc
docs.ucmCommands.ls =
  name = {{ ls }}
  body =
    {{
    {{ docCode {{ {{ name }} }} }} displays the terms, types, and
    sub-namespaces in the given namespace. {{ docCode {{ name }} }} accepts
    both absolute and relative namespace paths.
    }}
  _make name body ls._cmd

docs.ucmCommands.ls._cmd : Doc
docs.ucmCommands.ls._cmd =
  {{
  ``` ucm
  scratch/main> ls base.List
  ```

  ``` ucm
  scratch/main> ls .base.Bag
  ```
  }}

docs.ucmCommands.merge : Doc
docs.ucmCommands.merge =
  name = {{ merge }}
  cmd =
    {{
    merges the source namespace into the destination

    ``` ucm
    scratch/main> merge src dest
    ```

    merges the source namespace into the current namespace

    ``` ucm
    scratch/main> merge src
    ```
    }}
  body =
    {{
    Use the `merge` command to merge two namspaces with the following behavior:

    * If a function is added in the `source` namespace, it will be present in
      the resulting `destination` namespace
    * If a function is updated in the `source` namespace, the UCM will use the
      updated version in the resulting `destination`
    * If the `destination` namespace has additional functions that the `source`
      namespace does not contain, the destination namespace will retain the
      functions in the resulting namespace
    }}
  _make name cmd body

docs.ucmCommands.mergeCommit : Doc
docs.ucmCommands.mergeCommit =
  name = {{ merge.commit }}
  body =
    {{
    Merges a temporary branch created by the {ucmCommands.merge} command back
    into its parent branch, and removes the temporary branch.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> merge topic
    ```

    At this point, the merge may require you to fix issues in a scratch file.
    Then run:

    ``` ucm
    scratch/merge-topic-into-main> update
    scratch/merge-topic-into-main> merge.commit
    scratch/main>
    ```
    }}
  _make name cmd body

docs.ucmCommands.move : Doc
docs.ucmCommands.move =
  name = {{ move }}
  cmd =
    {{
    ``` ucm
    scratch/main> move foo bar
    ```
    }}
  body =
    {{
    Move is a general command for renaming terms, types, and namespaces.
    `move foo bar` renames the term, type, and namespace foo to bar.
    }}
  _make name cmd body

docs.ucmCommands.move.namespace_ : Doc
docs.ucmCommands.move.namespace_ =
  name = {{ move.namespace }}
  cmd =
    {{
    ``` ucm
    scratch/main> move.namespace old.name new.name
    ```
    }}
  body =
    {{
    Renames the path of the old namespace to the desired new namespace. All the
    terms and sub-namespaces can be found under the new name.
    }}
  _make name cmd body

docs.ucmCommands.move.term : Doc
docs.ucmCommands.move.term =
  name = {{ move.term }}
  body = {{ {{ docCode {{ {{ name }} old new }} }} renames an existing term }}
  _make name move.term._cmd body

docs.ucmCommands.move.term._cmd : Doc
docs.ucmCommands.move.term._cmd =
  {{
  ``` ucm
  scratch/main> move.term oldName newName
  ```
  }}

docs.ucmCommands.move.typez : Doc
docs.ucmCommands.move.typez =
  name = {{ move.type }}
  body = {{ {{ docCode {{ {{ name }} old new }} }} renames an existing type }}
  _make name typez._cmd body

docs.ucmCommands.move.typez._cmd : Doc
docs.ucmCommands.move.typez._cmd =
  {{
  ``` ucm
  scratch/main> move.type oldName newName
  ```
  }}

docs.ucmCommands.project.reflog : Doc
docs.ucmCommands.project.reflog =
  name = {{ project.reflog }}
  body =
    {{
    {{ docCode {{ {{ name }} }} }} is used for viewing changes to the codebase
    across multiple branches in a project.

    For viewing changes that are scoped to the current branch in a project, see
    the `reflog` command.
    }}
  cmd =
    {{
    ``` ucm
    myProject/main> project.reflog

    Branch                   When          Hash          Description
    1.   myProject/aBranch   1 min ago     #44hhv8v9bk   move myProject/aBranch:loadApiKey jobs.loadA...
    2.   myProject/aBranch   2 mins ago    #d4h0k49ng3   delete myProject/aBranch:.deploy
    3.   myProject/aBranch   2 mins ago    #0d5om21ev5   Branch created from myProject/main
    4.   myProject/main      7 mins ago    #0d5om21ev5   add
    ```
    }}
  _make name cmd body

docs.ucmCommands.projectCreate : Doc
docs.ucmCommands.projectCreate =
  title = {{ project.create }}
  cmd =
    {{
    Create a project with a random, friendly name by giving the command no
    argument:

    ``` ucm
    scratch/main> project.create
    happy-starfish/main>
    ```

    ``` ucm
    scratch/main> project.create myCloudService
    ```
    }}
  body =
    {{
    Creates a new project and `/main` branch with the given name. By default,
    `project.create` creates a `lib` namespace and installs the standard lib,
    `base` for you.
    }}
  _make title cmd body

docs.ucmCommands.projectRename : Doc
docs.ucmCommands.projectRename =
  title = {{ project.rename }}
  cmd =
    {{
    ``` ucm
    scratch/main> project.rename temp
    temp/main>
    ```
    }}
  body = {{ Renames the currently active project to the given name. }}
  _make title cmd body

docs.ucmCommands.projects : Doc
docs.ucmCommands.projects =
  title = {{ projects }}
  cmd =
    {{
    ``` ucm
    scratch/main> projects
    ```
    }}
  body = {{ Lists all the projects in the current codebase. }}
  _make title cmd body

docs.ucmCommands.pull : Doc
docs.ucmCommands.pull =
  name = {{ pull }}
  body =
    {{
    **For Unison version 0.5.21 and later, use {{
    docLink (docEmbedTermLink do libInstall) }} to install libraries.**

    The {{ docCode {{ {{ name }} }} }} command is used to pull definitions from
    another codebase into the current codebase. Commonly used to download
    Unison dependencies.

    You can pull Unison code from unison's own code-hosting platform,
    [unison share](https://share.unison-lang.org/) or from a git repo using the
    {{ docTooltip {{ git url format }} gitUrls }}.

    The first argument to {{ name }} is any Git URL that identifies the
    namespace to pull from and the second argument (if given) identifies a
    namespace that the remote codebase will be merged into. If a second
    argument is not supplied, then the remote codebase will be merged into the
    current namespace.

    To optionally pull from a Git branch, the repository name is followed by
    `:` and the name of the branch.
    }}
  _make name pull._cmd body

docs.ucmCommands.pull._cmd : Doc
docs.ucmCommands.pull._cmd =
  {{
  Downloading a project dependency:

  ``` ucm
  myProject/main> pull @unison/base/releases/X.Y.Z lib.base
  ```

  Pulling a public namespace:

  ``` ucm
  scratch/main> pull unison.public.base.latest lib.base
  ```

  Using git urls:

  ``` ucm
  scratch/main> pull git(git@github.com:unisonweb/base).latest .base
  scratch/main> pull git(https://github.com/org/repo:some-branch).some.path
  ```
  }}

docs.ucmCommands.pullWithoutHistory : Doc
docs.ucmCommands.pullWithoutHistory =
  title = {{ pull.without-history }}
  cmd =
    {{
    ``` ucm
    scratch/main> pull.without-history @unison/base/main
    ```
    }}
  body =
    {{
    Merges a remote namespace into a local branch without including the
    remote's history. This usually results in smaller codebase sizes but
    branches will no longer be able to find common ancestors for issuing pull
    requests. Use `clone` or `pull` if you are hoping to contribtue to a
    branch.
    }}
  _make title cmd body

docs.ucmCommands.push : Doc
docs.ucmCommands.push =
  name = {{ push }}
  body =
    {{
    The {{ docCode {{ {{ name }} }} }} command is used to push definitions from
    a local codebase to a remote codebase.

    The first argument to {{ name }} is any hosted project or remote namespace
    path that identifies the location to push to and the second argument (if
    given) identifies a namespace or project in the local codebase that should
    be applied to the remote repo. If a second argument is not supplied, then
    the current namespace or project will be pushed to the given remote
    namespace.
    }}
  _make name push._cmd body

docs.ucmCommands.push._cmd : Doc
docs.ucmCommands.push._cmd =
  {{
  Pushing from within a project:

  ``` ucm
  myProject/branch> push
  @othersProject/feature> push /@myUser/feature
  ```

  Pushing a namespace to a remote namespace:

  ``` ucm
  scratch/main> push git(git@github.com:myUser/myCodebase).releases.v1 .update.v1
  scratch/main> push myUser.public.myProject .myProject
  ```
  }}

docs.ucmCommands.quit : Doc
docs.ucmCommands.quit =
  title = {{ quit }}
  cmd =
    {{
    ``` ucm
    scratch/main> quit
    ```
    }}
  body = {{ Exits the current UCM session. }}
  _make title cmd body

docs.ucmCommands.reflog : Doc
docs.ucmCommands.reflog =
  name = {{ reflog }}
  body =
    {{
    {{ docCode {{ {{ name }} }} }}, also known as `branch.reflog` or
    `reflog.branch` lists the changes that have affected the current project
    branch.

    Often used in tandem with [`reset`]({ucmCommands.reset}) to rewind a branch
    to a previous state.

    For viewing changes across multiple branches in a project, use the
    [`project.reflog`]({{ docLink (docEmbedTermLink do project.reflog) }})
    command.

    For viewing changes across the entire codebase, use the
    [`global.reflog`]({{ docLink (docEmbedTermLink do global.reflog) }})
    command.
    }}
  _make name reflog._cmd body

docs.ucmCommands.reflog._cmd : Doc
docs.ucmCommands.reflog._cmd =
  {{
  ``` ucm
  myProject/main> reflog

       Branch      When          Hash          Description
  1.   tour/main   an hour ago   #a1vh3f0sa1   Include latest base library
  2.   tour/main   an hour ago   #sg60bvjo91   Project Created
  ```

  The `reflog` command takes an optional branch name argument.

  ``` ucm
  myProject/main> reflog /anotherBranch
  ```
  }}

docs.ucmCommands.reset : Doc
docs.ucmCommands.reset =
  name = {{ reset }}
  body =
    {{
    Resets a branch of the project (along with its history) to that of the
    specified hash or numbered argument. This is useful for undoing changes to
    the project, often used in tandem with `reflog`.

    Differs from the deprecated `reset-root` command in that it only affects
    the current project, not the entire codebase.
    }}
  cmd =
    {{
    This `reset` command will undo the `add` that happened in the reflog:

    ``` ucm
    myProject/main> reflog
      Branch                When         Hash          Description
      1.   myProject/main   1 secs ago   #0d5om21ev5   add
      2.   myProject/main   9 mins ago   #6tfcojje2h   delete myProject/main:.deploy
    myProject/main> reset #6tfcojje2h
    ```

    `reset` accepts an optional target branch to reset. If no branch is
    provided, the current branch is reset.

    ``` ucm
    myProject/main> project.reflog

    Branch                   When          Hash          Description
    1.   myProject/aBranch   1 min ago     #44hhv8v9bk   move myProject/aBranch:loadApiKey jobs.loadA...
    2.   myProject/aBranch   2 mins ago    #d4h0k49ng3   delete myProject/aBranch:.deploy
    3.   myProject/aBranch   2 mins ago    #0d5om21ev5   Branch created from myProject/main
    4.   myProject/main      7 mins ago    #0d5om21ev5   add
    myProject/main> reset #d4h0k49ng3 /aBranch
    ```
    }}
  _make name cmd body

docs.ucmCommands.resetRoot : Doc
docs.ucmCommands.resetRoot =
  name = {{ reset-root (Deprecated) }}
  body =
    {{
    Deprecated in favor of [`reset`]({ucmCommands.reset}).

    Resets the root namespace (along with its history) to that of the specified
    namespace. The argument to reset-root can be a hash or a namespace
    }}
  _make name resetRoot._cmd body

docs.ucmCommands.resetRoot._cmd : Doc
docs.ucmCommands.resetRoot._cmd =
  {{
  ``` ucm
  scratch/main> reset-root #6psnlk5i02
  ```

  ``` ucm
  scratch/main> reset-root .foo
  ```
  }}

docs.ucmCommands.run : Doc
docs.ucmCommands.run =
  name = {{ run }}
  cmd =
    {{
    ``` unison
    myProgram : '{IO, Exception} ()
    myProgram = '(printLine "Hello World")

    myProgramWithArgs : '{IO, Exception} ()
    myProgramWithArgs = 'let
      printLine ("Hello " ++ Optional.getOrElse "World" (List.head !getArgs) ++ "!")
    ```

    ``` ucm
    scratch/main> run myProgram
    scratch/main> run myProgramWithArgs Rebecca
    ```
    }}
  body =
    {{
    The `run` command is used to evaluate terms that require the IO ability
    within ucm. A program that performs IO cannot be evaluated in a watch
    expression but can be executed with `run`.

    Run takes a delayed computation and performs `!myProgram`, where
    `myProgram` is searched for in the most recent typechecked file, or in the
    codebase. The function provided to the {{ name }} command can return any
    type, and may perform the IO and {type Exception} abilities.

    Any arguments following the `run` command will be passed as program
    arguments.
    }}
  _make name cmd body

docs.ucmCommands.run.compiled : Doc
docs.ucmCommands.run.compiled =
  name = {{ run.compiled }}
  body =
    {{
    {{ name }} is a command line option to the UCM which runs a binary
    executable unison program. It is used in tandem with the
    [`compile`](./compile) command.
    }}
  cmd =
    {{
    ``` bash
    $ ucm run.compiled myProgram.uc
    ```
    }}
  _make name cmd body

docs.ucmCommands.runNative : Doc
docs.ucmCommands.runNative =
  title = {{ run.native }}
  cmd =
    {{
    ``` ucm
    scratch/main> run.native main args
    ```
    }}
  body =
    {{
    Executes the `main` function using native compilation via scheme. Currently
    in beta-testing.
    }}
  _make title cmd body

docs.ucmCommands.switch : Doc
docs.ucmCommands.switch =
  title = {{ switch }}
  cmd =
    {{
    ``` ucm
    scratch/main> switch otherProject
    otherProject/main>
    ```

    ``` ucm
    scratch/main> switch /feature1
    scratch/feature1>
    ```
    }}
  body =
    {{
    Switches between projects or branches. Branches are indicated with a
    leading slash for disambiguation.

    Switch with no arguments opens an interactive selector to pick a project
    and open a branch.
    }}
  _make title cmd body

docs.ucmCommands.test : Doc
docs.ucmCommands.test =
  name = {{ test }}
  body =
    {{
    Runs unit tests for the given namespace argument. If no argument is given,
    the command runs all the tests in the current project.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> test foo.bar

    1.  foo.bar.test1          ◉ Passed
    ```

    ``` ucm
    scratch/main> test

    1.  foo.bar.test1          ◉ Passed
    2.  foo.baz.test1          ◉ Passed
    2.  foo.baz.test2          ◉ Passed
    ```
    }}
  _make name cmd body

docs.ucmCommands.testAll : Doc
docs.ucmCommands.testAll =
  title = {{ test.all }}
  cmd =
    {{
    ``` ucm
    scratch/main> test.all
    ```
    }}
  body =
    {{
    Runs all the unit tests inside the current branch (including the `lib`
    namespace)
    }}
  _make title cmd body

docs.ucmCommands.textFind : Doc
docs.ucmCommands.textFind =
  title = {{ text.find }}
  cmd =
    {{
    ``` ucm
    scratch/main> text.find token123 "99" tokenABC
    ```
    }}
  body =
    {{
    Finds terms with literals (text or numeric) or documentation containing the
    given token arguments. Partial string matches are supported.

    Numeric literals must be quoted (ex: "42") but single words need not be
    quoted.

    Does not search through `lib` namespace. Use `text.find.all` to search
    through dependencies.
    }}
  _make title cmd body

docs.ucmCommands.textFindAll : Doc
docs.ucmCommands.textFindAll =
  title = {{ text.find.all }}
  cmd =
    {{
    ``` ucm
    scratch/main> text.find.all token123 "99" tokenABC
    ```
    }}
  body =
    {{
    Like [`text.find`]({textFind}) but searches through the `lib` namespace
    dependencies of a project.
    }}
  _make title cmd body

docs.ucmCommands.todoUCM : Doc
docs.ucmCommands.todoUCM =
  name = {{ todo }}
  cmd =
    {{
    ``` ucm
    scratch/newFeature> update
    scratch/newFeature> todo

    🚧

    The namespace has 1 transitive dependent(s) left to upgrade.
    Your edit frontier is the dependents of these definitions:

    unique type Box

    I recommend working on them in the following order:

    1. toText : Box -> Text
    ```
    }}
  body =
    {{
    Lists the current namespace's outstanding issues, including conflicted
    names, dependencies with missing names, and merge precondition violations.
    }}
  _make name cmd body

docs.ucmCommands.toHtml : Doc
docs.ucmCommands.toHtml =
  title = {{ docs.to-html }}
  body =
    {{
    {{ docCode {{ {{ title }} namespace output/file }} }} creates a html
    representation from the {type Doc} terms in the given namespace. The
    namespace argument can be either a relative or absolute namespace. The
    output file path is created relative to the root of the folder where the
    UCM command was issued from.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> docs.to-html base.List website/base/listDocs
    ```

    ``` ucm
    scratch/main> docs.to-html .base.Set setDocsFolder
    ```
    }}
  _make title cmd body

docs.ucmCommands.ui : Doc
docs.ucmCommands.ui =
  title = {{ ui }}
  body =
    {{
    Opens the local codebase UI for the UCM. Can be run from any namespace in
    the codebase.
    }}
  cmd =
    {{
    ``` ucm
    scratch/main> ui
    ```
    }}
  _make title cmd body

docs.ucmCommands.undo : Doc
docs.ucmCommands.undo =
  name = {{ undo }}
  body =
    {{
    Use {{ docCode {{ {{ name }} }} }} to revert the most recent change to the
    codebase. You can use the
    [reflog]({{ docLink (docEmbedTermLink do ucmCommands.reflog) }}) and
    [reset]({ucmCommands.reset}) commands to move farther back in your codebase
    state.
    }}
  _make name undo._cmd body

docs.ucmCommands.undo._cmd : Doc
docs.ucmCommands.undo._cmd =
  {{
  ``` ucm
  scratch/main> undo
  ```
  }}

docs.ucmCommands.unsafeForcePush : Doc
docs.ucmCommands.unsafeForcePush =
  title = {{ unsafe.force-push }}
  cmd =
    {{
    ``` ucm
    scratch/main> unsafe.force-push
    ```
    }}
  body =
    {{
    Like `push`, but forcibly overwrites the remote namespace. You should use
    this command with caution, since there is no way to recover the remote
    namespace's state once this command has been applied.
    }}
  _make title cmd body

docs.ucmCommands.update : Doc
docs.ucmCommands.update =
  name = {{ update }}
  body =
    {{
    Adds everything in the most recently typechecked file to the namespace,
    replacing existing definitions having the same name, and attempts to update
    all the existing dependents accordingly. If the process can't be completed
    automatically, the dependents will be added back to the scratch file for
    your review.
    }}
  cmd =
    {{
    ``` ucm
    myProject/main> update
    ```

    ``` ucm
    myProject/main> update aTerm
    ```
    }}
  _make name cmd body

docs.ucmCommands.upgrade : Doc
docs.ucmCommands.upgrade =
  name = {{ upgrade }}
  body =
    {{
    Upgrades the given dependency to a newer version. You need to have both the
    old and new version of the library in your `lib` namespace for the upgrade
    command to run. Once issued, it will initiate an `update` process for all
    the terms that depend on the upgraded library. If there are
    non-type-preserving changes, the impacted terms will be edited to a scratch
    file. Otherwise, the library upgrade will auto-propagate and the old
    version of the library will be removed.
    }}
  cmd =
    {{
    ``` ucm
    myproject/main> upgrade base_1_0_0 base_1_1_0
    ```
    }}
  _make name cmd body

docs.ucmCommands.upgradeCommit : Doc
docs.ucmCommands.upgradeCommit =
  name = {{ upgrade.commit }}
  body =
    {{
    `upgrade.commit` merges a temporary branch created by the `upgrade` command
    back into its parent branch, and removes the temporary branch. Also known
    as `commit.upgrade`
    }}
  cmd =
    {{
    ``` ucm
    scratch/upgrade_x_to_y> update
    scratch/upgrade_x_to_y> upgrade.commit
    scratch/main>
    ```
    }}
  _make name cmd body

docs.ucmCommands.version : Doc
docs.ucmCommands.version =
  name = {{ version }}
  body = {{ Prints the version of Unison that you are running }}
  cmd =
    {{
    ``` ucm
    myProject/main> version
    ```
    }}
  _make name cmd body

docs.ucmCommands.view : Doc
docs.ucmCommands.view =
  name = {{ view }}
  body =
    {{
    {{ docCode {{ {{ name }} }} }} displays the source code of the given Unison
    term or type.
    }}
  _make name view._cmd body

docs.ucmCommands.view._cmd : Doc
docs.ucmCommands.view._cmd =
  {{
  ``` ucm
  myproject/main> view .base.List.map
  ```
  }}

docs.ucmCommands._make : Doc -> Doc -> Doc -> Doc
docs.ucmCommands._make name commandExample body =
  {{
  # {{ name }}

    {{ commandExample }}

    {{ body }}
  }}

docs.ucmCommands._sidebar : Doc
docs.ucmCommands._sidebar =
  use create author
  {{
  * [add]({{ docLink (docEmbedTermLink do ucmCommands.add) }})
  * [add.preview]({addPreview})
  * [add.run]({addRun})
  * [alias.many]({aliaz.many})
  * [alias.term]({aliaz.term})
  * [alias.type]({aliaz.typez})
  * [api]({api})
  * [author]({author})
  * [auth.login]({login})
  * [back]({back})
  * [branch]({{ docLink (docEmbedTermLink do ucmCommands.branch) }})
  * [branch.empty]({branchEmpty})
  * [branches]({branches})
  * [clear]({ucmCommands.clear})
  * [codebase-create]({codebaseCreate})
  * [compile]({compile})
  * [create.author]({author})
  * [debug.clear-cache]({clearCache})
  * [debug.doc-to-markdown]({debugDocToMarkdown})
  * [delete]({del})
  * [delete.branch]({delBranch})
  * [delete.namespace]({namespc})
  * [delete.namespace.force]({namespc.force})
  * [delete.patch]({del.patch})
  * [dependencies]({ucmCommands.dependencies})
  * [dependents]({dependents})
  * [display]({ucmCommands.display})
  * [display.to]({display.to})
  * [docs]({ucmCommands.docs})
  * [docs.to-html]({toHtml})
  * [edit]({edit})
  * [edit.namespace]({editNamespace})
  * [edit.new]({editNew})
  * [find]({ucmCommands.find})
  * [find.all]({find.all})
  * [find-in]({findIn})
  * [find.verbose]({verbose})
  * [fork]({ucmCommands.fork})
  * [help]({help})
  * [help-topics]({helpTopics})
  * [history]({ucmCommands.history})
  * [io.test]({ioTest})
  * [io.test.all]({ioTestAll})
  * [lib.install]({libInstall})
  * [ls]({ls})
  * [load]({Value.load})
  * [merge]({ucmCommands.merge})
  * [merge.commit]({mergeCommit})
  * [move]({move})
  * [move.term]({move.term})
  * [move.type]({move.typez})
  * [project.create]({projectCreate})
  * [pull]({ucmCommands.pull})
  * [pull.without-history]({pullWithoutHistory})
  * [push]({ucmCommands.push})
  * [reflog]({ucmCommands.reflog})
  * [project.reflog]({project.reflog})
  * [global.reflog]({global.reflog})
  * [project.rename]({{ docLink (docEmbedTermLink do projectRename) }})
  * [projects]({ucmCommands.projects})
  * [run]({ucmCommands.run})
  * [run.compiled]({compiled})
  * [run.native]({{ docLink (docEmbedTermLink do runNative) }})
  * [switch]({{ docLink (docEmbedTermLink do switch) }})
  * [test]({ucmCommands.test})
  * [test.all]({testAll})
  * [text.find]({textFind})
  * [text.find.all]({textFindAll})
  * [todo]({{ docLink (docEmbedTermLink do todoUCM) }})
  * [ucmCommands]({ui})
  * [undo]({undo})
  * [unsafe.force-push]({unsafeForcePush})
  * [update]({ucmCommands.update})
  * [upgrade]({upgrade})
  * [upgrade.commit]({upgradeCommit})
  * [version]({ucmCommands.version})
  * [view]({ucmCommands.view})
  }}

docs.usageTopics.bibliography : Doc
docs.usageTopics.bibliography =
  {{
  # An annotated bibliography

    {{
    docCallout
      (Some placeholder)
      {{
      This page is still very much under construction. Please
      [get in touch with us on Discord](https://unison-lang.org/discord) if
      you'd like to help fill it out.
      }} }}

    This page is for those curious about Unison's background. It covers some of
    the research backing Unison and lists related work and influences.
    **You don't need to know about any of this to use Unison** but we like to
    acknowledge that Unison is part of a big world where lots of interesting
    work happens. We are standing on the shoulders of giants!

    ## Influences

       The core Unison language was influenced primarily by
       [Haskell](https://haskell.org) for its ideas on purely functional
       programming, [Erlang](https://www.erlang.org/) (for its ideas on
       distributed execution and handling of failures), and
       [a research language by Lindley, McBride et. al called Frank](https://arxiv.org/abs/1611.09259)
       (for its approach to working with effects / abilities).

       We also have looked at and taken inspiration from lots of other
       languages, like Smalltalk, Scala, Elm, and many more.

    ## Programming language theory

       Formally, Unison's type system is an implementation of the system
       described by Joshua Dunfield and Neelakantan R. Krishnaswami in their
       2013 paper
       [Complete and Easy Bidirectional Typechecking for Higher-Rank
       Polymorphism](https://arxiv.org/abs/1306.6032).

       Unison's system of abilities is based on
       [the Frank language by Sam Lindley, Conor McBride, and Craig McLaughlin](https://arxiv.org/pdf/1611.09259.pdf).
       Unison diverges slightly from the scheme detailed in this paper. In
       particular, Unison's ability polymorphism is provided by ordinary
       polymorphic types, and a Unison type with an empty ability set
       explicitly disallows any abilities. In Frank, the empty ability set
       implies an ability-polymorphic type.

       The
       [effects bibliography](https://github.com/yallop/effects-bibliography)
       is a good resource for additional background on algebraic effects.
       Related languages with this feature are
       [Eff](https://www.eff-lang.org/learn/) and
       [Koka](https://www.microsoft.com/en-us/research/publication/algebraic-effects-for-functional-programming/).

       Other references:

       * [Sound and Complete Bidirectional Typechecking for Higher-Rank
         Polymorphism with Existentials and Indexed Types](https://arxiv.org/abs/1601.05106)
         extends the earlier paper to include GADTs and existential types. This
         will likely be implemented by a future version of Unison

    ## Functional programming

       🚧 Almost too many things to cite here, would focus on references that
       provide good background on FP and then specific work that is notable

    ## Distributed systems

       🚧 A few categories of work to cite here ...

       * "classics" establishing the nature of distributed systems, "Time,
         Clocks, and the ordering of events"
       * consensus protocols like Paxos, Raft
       * work on things like vector clocks, causal consistency
       * CRDTs work
       * Distributed hash tables, overlay networks
       * Modern systems work
  }}

docs.usageTopics.docker : Doc
docs.usageTopics.docker =
  {{
  # Running Unison in Docker

    Unison publishes a
    [Docker Image](https://hub.docker.com/r/unisonlang/unison) containing the
    Unison Codebase Manager, which can be used to:

    * Give unison a try without having to install it locally
    * Run a (possibly compiled) Unison program in a container
    * Run the local UI for a codebase
    * Experiment with running unison programs under the native runtime.

    ## Running UCM in docker against a local codebase

       If you have your codebase in `~/.unison`. You could run the following
       command to start the UCM in a container:

       ``` raw
       docker run  -it --rm -v ~/.unison:/codebase -p 5757:5757 -p 8080:8080 unisonlang/unison
       ```

       In this command:

       * `-p 5757:5757` makes the LSP server available
       * `-p 8080:8008` makes the local UI available so that you can point a
         browser at
         [http://127.0.0.1:8080/public/ui/](http://127.0.0.1:8080/public/ui/).
         To view the local ui, or run `ui` within UCM to get a link directly to
         a project/branch in the ui.
       * `-v ~/.unison:/codebase` mounts your local codebase to the container.
         if you omit this part, you'll get a UCM that is looking at the empty
         codebase in the container located in `/codebase`.

    ## Running a Unison program in a container

       You can run a Unison program in a docker container either by compiling
       it to a `.uc` file and running the program with `run.compiled` or by
       adding the codebase to the container, and running the program with `run`

       ### Running a program from a codebase

           If you have a codebase in `~/.unison` and a program named `program`
           in the `main` branch of the `hello` project

           ``` raw
             docker run --rm -v ~/.unison:/codebase unisonlang/unison:latest run hello/main:.program`
           ```

       ### Running a compiled program

           {{
           docCallout
             (Some headsUp)
             {{
             NOTE: You must run a compiled unison program (''.uc'') using the
             same version of ucm that compiled it!
             }} }}

           If you have a compiled program named `./program.uc`:

           ``` raw
             docker run --rm -v ./program.uc:/program.uc unisonlang/unison:latest run.compiled /program.uc
           ```

           Or you can create a `Dockerfile` which will create a docker image
           with your compiled program:

           ``` raw
             FROM unisonlang/unison:0.5.29
             COPY program.uc /program.uc
             CMD ["run.compiled", "/program.uc"]
           ```
  }}

docs.usageTopics.documentation : Doc
docs.usageTopics.documentation =
  use documentation _mermaid1
  use ucmCommands docs
  {{
  # Documenting Unison Code

    Unison comes with a powerful documentation format which makes it easy to
    write rich, correct documentation. In addition to basic Markdown-like
    syntax and formatting, Unison documentation also supports inline
    evaluation, typechecked code snippets, and embedding docs within other
    docs. We'll walk through these features below.

    {{
    docCallout
      (Some emojis.index)
      {{
      **What's in this document?**

      * [The basics](#the-basics)
      * [Evaluating and including code](#evaluating-and-including-code)
      * [Basic text formatting cheat sheet](#basic-text-formatting-cheat-sheet)
      * [Link syntax cheat sheet](#link-syntax-cheat-sheet)
      * [Tables in documents](#tables-in-documents)
      * [Diagrams in documents](#diagrams-in-documents)
      * [LaTeX in documents](#latex-in-documents)
      * [Suggested documentation conventions](#suggested-documentation-conventions)
      }} }}

    ## The basics

       Documentation blocks start with `{{` and end with a matching `}}`. This
       syntax creates an expression of type {type Doc} and it can be used
       anywhere in your code where an expression can be written.

       ``` unison
       aDocDefinition : Doc
       aDocDefinition = {{This is a simple documentation block.}}
       ```

       Anonymous documentation blocks are blocks that are created immediately
       before the definitions in your code. This means we don't need to assign
       our documentation block to a value; instead, the doc is automatically
       created with the same name as the definition, followed by `doc`:

       ``` unison
       {{Maya Angelou was an acclaimed poet, director, essayist, and novelist.}}
       poet = "Maya Angelou"
       ```

       In the UCM we should see:

       ``` ucm
       ⍟ These new definitions are ok to `add`:

           poet.doc       : Doc
           poet           : Text
       ```

       Here our anonymous doc is automatically linked to `poet` as the term
       `poet.doc`.

       To read a term's documentation, use the `docs` command in the UCM like
       this:

       ``` ucm
       scratch/main> docs poet

         Maya Angelou is an acclaimed poet, director, essayist, and novelist.
       ```

       A UCM command taking the form [`docs myTermName`]({docs}) will look for
       a term called `myTermName.doc` in the file or codebase, so we do not
       need to explicitly link our docs to our code if we respect that naming
       convention.

       To recap the basics:

       * Start a documentation block with `{{ double curly braces }}`
       * Anonymous docs link a definition to its documentation and are placed
         immediately above a definition
       * Read the docs in the UCM using the [`docs`]({docs}) command followed
         by a definition name

    ## Evaluating and including code

       Let's write some documentation which demonstrates how Unison can
       evaluate code.

       ``` unison
       {{
         ``repeat n text`` is a function which will
         repeat the provided text a specified number of times.
       }}
       repeat : Nat -> Text -> Text
       repeat n text =
         go i acc =
           use Nat >=
           if i >= n then acc
           else
             use Nat +
             use Text ++
             go (i + 1) (text ++ acc)
         go 0 ""
       ```

       We've introduced a new Unison documentation feature with the double
       backtick syntax. Double backticks are how we include inlined snippets of
       Unison code. These snippets are typechecked, so you know the code in
       your documentation is going to accurately represent your codebase. If we
       were to rename `repeat` to `echo` the docs would reflect that
       automatically.

       Unison docs also support evaluating entire blocks of code. This can be
       useful for specifying longer examples and use cases. Let's add one to
       our `repeat` documentation block:

       ```` unison
       {{
           ''repeat'' is a function which will repeat the provided text a specified number of times.

           Examples:

           ```
           (repeat 2 "rose is a ") ++ "rose"
           ```
       }}
       ````

       Note, the blank line after "Examples:" and before the code block is
       important, otherwise the example may not render properly.

       The documentation will render both the source code and the result of
       evaluating the code for anything between triple backticks.

       ``` ucm
       scratch/main> docs repeat

         `repeat` is a function which will repeat the provided text a specified number of times.

         Examples:

             repeat 2 "rose is a " Text.++ "rose"
             ⧨
             "rose is a rose is a rose"
       ```

       Let's imagine our docs would really benefit from displaying the full
       source code of the function they're describing. We can do that with the
       `@source{myTerm}` syntax.

       ```` unison
       {{
           `repeat` is a function which will repeat the provided text a specified number of times.

           Source:

           @source{repeat}

           Examples:

           ```
           (repeat 2 "rose is a ") ++ "rose"
           ```
       }}
       ````

       The full implementation of `repeat` is now on display:

       ``` ucm
       scratch/main> docs repeat

         `repeat` is a function which will repeat the provided text a specified number of times.

         Source:

             repeat n text =
               go i acc =
                 if i >= n then acc
                 else
                   use Nat +
                   use Text ++
                   go (i + 1) (text ++ acc)
               go 0 ""

         Examples:

             repeat 2 "rose is a " Text.++ "rose"
             ⧨
             "rose is a rose is a rose"
       ```

       Maybe our documentation is better served by just including the signature
       of a function. Let's try that with `@signature{myTerm}`:

       ```` unison
       {{
           @signature{repeat}

           `repeat` is a function which will repeat the provided text a specified number of times.

           Examples:

           ```
           (repeat 2 "rose is a ") ++ "rose"
           ```
       }}
       ````

       ``` ucm
       scratch/main> docs repeat

         repeat : Nat -> Text -> Text

         `repeat` is a function which will repeat the provided text a specified number of times.

         Examples:

             repeat 2 "rose is a " Text.++ "rose"
             ⧨
             "rose is a rose is a rose"
       ```

       We used `@signature{myTerm}` to include the signature on its own
       separate line, but we needed to inline it in a doc, we can use
       `@inlineSignature{myTerm}` instead.

       It's common for Unison docs to be composed of smaller components. We can
       combine {type Doc} values using the `{{ subdoc }}` syntax. In our
       `repeat.doc` code we might extract the "Examples" portion of our
       documentation into a separate term if it grows too long.

       ```` unison
       {{
           @signature{repeat}

           `repeat` is a function which will repeat the provided text a specified number of times.

           {{ repeat.doc.examples }}
       }}

       repeat.doc.examples : Doc
       repeat.doc.examples = {{
           Examples:

           ```
           (repeat 2 "rose is a ") ++ "rose"
           ```

           ```
           repeat 0 "zero"
           ```
       }}
       ````

       When we want to read the docs for `repeat`, the entire docs block will
       be rendered to the user.

       ``` ucm
       scratch/main> docs repeat

         `repeat : Nat -> Text -> Text`

         `repeat` is a function which will repeat the provided text a specified number of times.

         Examples:

             repeat 2 "rose is a " Text.++ "rose"
             ⧨
             "rose is a rose is a rose"

             repeat 0 "zero"
             ⧨
             ""
       ```

       To summarize, Unison docs can execute and embed code in the following
       ways:

       * ''``double backticks``'' are used to inline Unison code
       * ''```triple backticks```'' wrap executable code blocks
       * `@source{myTerm}` is used for displaying the source code
       * `@signature{myTerm}` includes a signature in the docs
       * `@inlineSignature{myTerm}` includes a signature with inline styling in
         a doc block
       * `{{ subdoc }}` will display another doc's content within the enclosing
         doc

       {{
       docAside
         {{
         when using the triple backtick syntax, a newline must be present
         before and after the fenced codeblock to be considered a valid Unison
         doc element
         }} }}

    ## Basic text formatting cheat sheet

       Unison supports the following text formatting features:

       {{
       docTable
         [ [{{ Text Formatting }}, {{ Docs Syntax }}]
         , [{{ italicized }}, {{ `*asterisks*` or `_single underscore_` }}]
         , [{{ bold }}, {{ `__double underscore__` or `**double asterisk**` }}]
         , [{{ strikethrough }}, {{ `~~double tilde~~` }}]
         , [{{ monospace }}, {{ `two single quotes` }}]
         , [{{ bullet list }}, {{ `*` }}]
         , [{{ numbered list }}, {{ `1. My List` }}]
         , [{{ heading }}, {{ `# Heading` }}]
         , [ {{
             image
             }}
           , {{
             `{{ Doc.Image {{ some alt text }} {{ http://img.com }} (Some {{ A caption }}) }}`
             }}
           ]
         , [ {{
             video
             }}
           , {{
             `{{ Special (Embed (Any (Video [(MediaSource "test.mp4" None)] [("poster", "test.png")]))) }}`
             }}
           ]
         ] }}

    ## Link syntax cheat sheet

       Linking to both external URLs and definitions in your codebase can be
       done in several ways:

       {{
       docTable
         [ [{{ Link type }}, {{ Docs Syntax }}, {{ Purpose }}]
         , [ {{
             external url
             }}
           , {{
             `[An external url](https://unison-lang.org)`
             }}
           , {{
             Links to an external URL, used for including relevant resources
             }}
           ]
         , [ {{
             term/type link
             }}
           , {{
             `{Some}` is a term link and `{type Optional}` is a type link
             }}
           , {{
             Links to a term or type in the codebase, documentation UI's like
             the one on [unison share](https://share.unison-lang.org) may
             enable click-through linking
             }}
           ]
         , [ {{
             named term/type link
             }}
           , {{
             `[a named term link]({Some})` and
             `[A named type link]({type Optional})`
             }}
           , {{
             Links to a term or type in the codebase but gives the link the
             name in square brackets for readability
             }}
           ]
         ] }}

    ## Tables in documents

       Unison docs can also include tables to organize information.

       Inside a doc block elment, start a table with the `{{ docTable }}`
       syntax and then provide a nested list of doc elements. The first row of
       the list will be used as the table's header. Subsequent rows will be
       used as the table's body. There is currently no way to skip or merge
       cells in a table, so the number of cells in a row should not change.

       ``` unison
       {{ docTable
           [
             [{{ Header 1 }}, {{ Header 2 }}],
             [{{ row1 }}, {{ row2 }}]
           ]
         }}
       ```

    ## Diagrams in documents

       Unison docs are capable of rendering
       [mermaid diagrams](https://mermaid.js.org/intro/) in fenced codeblock
       elements. Mermaid enables you to write markdown-like syntax to generate
       diagram types like flowcharts, state diagrams, and sequence diagrams.
       Inside a doc element, open up a fenced codeblock with the triple
       backtick syntax followed by "mermaid" as the language type,
       ''``` mermaid''. This will tell the Unison doc renderer that the next
       bit of code should be treated as a drawing.

       {{
       docAside
         {{
         You can learn more about writing mermaid syntax
         [here](https://mermaid.js.org/intro/n00b-syntaxReference.html).
         }} }}

       The following mermaid fenced codeblock will render the diagram below:

       {{ docSource [docSourceElement (docEmbedTermLink do _mermaid1) []] }}

       {{ _mermaid1 }}

    ## LaTeX in documents

       Fenced codeblocks can also be used to render
       [LaTeX](https://www.latex-project.org/). The triple backtick syntax
       followed by "latex" as the language type, ''``` latex'', will tell the
       Unison doc renderer that the next bit of code should be treated as
       LaTeX.

       ``` latex
          f(\relax{x}) = \int_{-\infty}^\infty
          \hat{f}(\xi)\,e^{2 \pi i \xi x}
          \,d\xi
       ```

    ## Suggested documentation conventions

       Although documentation values don't require any particular structure you
       might try writing your docs according to a few guidelines:

       * Start with a brief one sentence or short paragraph overview, then
         optionally include a longer description, include some examples which
         illustrate common cases and edge cases, and finally link to related
         definitions and further reading.
       * Follow sensible naming conventions for documentation and examples. For
         a definition `Jabberwock.whiffle`, for example:
         * Its primary documentation should be called `Jabberwock.whiffle.doc`,
           and secondary docs could be in the `Jabberwock.whiffle.doc`
           namespace. I.e. a document called
           `Jabberwock.whiffle.doc.advancedUsages` could show advanced usages
           of the term.
         * Non-inlined documentation examples could be in the
           `Jabberwock.whiffle.doc.examples` namespace. For instance:
           `Jabberwock.whiffle.doc.examples.ex1` and
           `Jabberwock.whiffle.doc.examples.ex2`.

       We hope you enjoy writing documentation in Unison! More details on
       Unison documentation can be found in a
       [transcript describing the full feature set.](https://github.com/unisonweb/unison/blob/ca951f36dbdc8a32e267acb9f8051ef64b90ec97/unison-src/transcripts-using-base/doc.output.md)
       😃
  }}

docs.usageTopics.documentation._mermaid1 : Doc
docs.usageTopics.documentation._mermaid1 =
  {{
  ``` mermaid
  sequenceDiagram
  Note left of Client: Sends SYN
  Client->>Server: SYN
  Note right of Server: Receives SYN
  Note right of Server: Sends SYN + ACK
  Server->>Client: SYN + ACK
  Note left of Client: Receives SYN + ACK
  Note left of Client: Sends ACK
  Client->>Server: ACK
  Note right of Server: Receives ACK
  ```
  }}

docs.usageTopics.editorSetup : Doc
docs.usageTopics.editorSetup =
  {{
  # Set up your editor for Unison

    This document is a collection of user-submitted instructions for setting up
    a text editor for Unison development.

    ## LSP Integration

       As of UCM version M4a, the UCM supports the Language Server Protocol.
       Features like in-editor error reporting, show-type-on-hover, and
       autocompletion are implemented, with more to come! Instructions for
       installing the UCM with LSP support
       [are available here](https://github.com/unisonweb/unison/blob/trunk/docs/language-server.markdown)

    ## Vim

       Using [vim-plug](https://github.com/junegunn/vim-plug):

       1. Install [vim-plug](https://github.com/junegunn/vim-plug) if you
          haven't already.
       2. Add the following to your .vimrc:

       ``` raw
       Plug 'unisonweb/unison', { 'branch': 'trunk', 'rtp': 'editor-support/vim' }
       ```

       3. Issue the vim command `:PlugInstall`.

       For more information run `:help unison` from within vim or view the
       [online help doc](https://github.com/unisonweb/unison/blob/trunk/editor-support/vim/doc/unison.txt).

    ## NeoVim

       Using [lazy.nvim](https://github.com/folke/lazy.nvim/):

       1. Install [lazy.nvim](https://github.com/folke/lazy.nvim/) if you
          haven't already.
       2. Add the following to your init.lua:

       ``` raw
       require("lazy").setup({
         {
           -- Unison
           "unisonweb/unison",
           branch = "trunk",
           config = function(plugin)
               vim.opt.rtp:append(plugin.dir .. "/editor-support/vim")
               require("lazy.core.loader").packadd(plugin.dir .. "/editor-support/vim")
           end,
           init = function(plugin)
                require("lazy.core.loader").ftdetect(plugin.dir .. "/editor-support/vim")
           end,
         }
       })
       ```

       3. Issue the vim command `:Lazy`.

       Optionally you can
       [setup an LSP Server](https://github.com/unisonweb/unison/blob/trunk/docs/language-server.markdown#neovim).

    ## Atom

       From the console, run:

       ``` bash
       apm install unisonweb/atom-unison
       ```

    ## VS Code

       1. Install the
          [Unison extension for VS Code](https://marketplace.visualstudio.com/items?itemName=unison-lang.unison)

    ## Emacs

       There are currently two different ways to use Unison in Emacs. Both work
       with Unison’s
       [LSP integration](https://github.com/unisonweb/unison/blob/trunk/docs/language-server.markdown#emacs).

       ### [Unison Tree-sitter mode](https://github.com/fmguerreiro/unison-ts-mode)

           This package is generally better all around, but isn’t in
           [MELPA](https://melpa.org) yet, and thus requires more setup.

           If you don’t have Emacs 29 or newer, this also requires
           [installing `tree-sitter`](https://emacs-tree-sitter.github.io/installation/).

       ### [`unisonlang-mode`](https://github.com/dariooddenino/unison-mode-emacs)

           This package is unsupported, incomplete, and out of date, but it
           __is__ in [MELPA](https://melpa.org), so you can enable it how you
           would any other Emacs package, and you’re done.
  }}

docs.usageTopics.generalFaqs : Doc
docs.usageTopics.generalFaqs =
  {{
  # General Unison FAQ's

    {{
    docAside {{ We've collected [FAQ's specific to Abilities here]({faqs}). }}
    }}

    ## Language

       ### Does Unison have Haskell-style type classes?

           No, or at least, not yet. We're considering our options for how to
           allow people to express bounded polymorphism. See
           [this post](https://www.unison-lang.org/blog/writeup-of-our-first-unison-meetup/)
           for some initial observations.

           Currently there are two ideas which have been developed at least to
           some extent.

           1. Like this: `mconcat : [a] ->{Monoid a} a`, where `Monoid a` is an
              ability.
           2. Like this: `mconcat : Monoid a -> [a] -> a`, where `Monoid a` is
              a record type.

           Both of these would require a set of supporting language
           enhancements, for example to supply the `Monoid a` handlers/values
           automatically.

       ### How similar is Unison to Haskell?

           As a programming language, Unison can be viewed as a descendant of
           Haskell, with many similarities including

           * type inference
           * pattern matching
           * ADTs
           * purity (i.e. no side effects).

           Some key differences...

           * As a new language, Unison is a good deal smaller and simpler than
             Haskell. The flip side of this is that it's currently missing a
             number of conveniences which Haskell users take for granted.
           * Unison supports algebraic effects, which it calls
             [abilities]({abilities.index}), which replace monads and monad
             transformers for writing effectful code.
           * Unison uses a strict evaluation model, whereas Haskell's model is
             lazy.
           * The `do` keyword in Unison starts a codeblock as a delayed
             computation, it does not match Haskell's "do notation" for any
             monads.
           * The `let` keyword in Unison starts a codeblock. It is not the
             start of a variable definition.

           🌻 While there are similarities between the two languages, it is not
           an expectation that people know Haskell in order to program in
           Unison.

       ### Does Unison have an FFI?

           Unison does not currently support a Foreign Function Interface, for
           invoking code written in other languages.

           Your programs can interact with the outside world via the {type IO}
           ability, and this includes interaction via network sockets - so you
           can interact with code written in other languages if that code can
           expose a network interface, for example as a web service. We'd like
           to improve on this position in the future.

           The sketch design for how it will work is as follows.

           * A foreign API, let's say one for working with the GPU, will be
             exposed through a top-level ability, let's say `GPU`.
           * The Unison runtime will let you run a program of type {{
             docCode {{ '{GPU} () }} }} just as it lets you run a
             {{ docCode {{ '{IO} () }} }}.
           * There will be an extensible binding mechanism for defining new
             such abilities and forwarding their operations to external APIs.

           There's still plenty to work out, for example in

           * designing the binding mechanism
           * managing `ucm` linkage dependencies to external binaries
           * making it play nicely with distribution, so computations can jump
             between nodes, and make use of the varying FFI abilities on each
             one.

           Note how using the ability mechanism gives a great story for
           testing. You can define a test handler, in pure Unison, to handle
           your `GPU` ability, and use it to add regular Unison tests for your
           GPU code, that can run anywhere regardless of whether the right GPU
           is installed.

    ## Distributed computing

       ### Is there a way to run Unison on my own cluster?

           Currently we don't have an easy way for folks to run and manage a
           distributed Unison program on their own cloud computing cluster but
           you can run the Cloud on your own computer locally and the Unison
           Cloud also offers a free tier for users.

           The Unison team has developed
           [Unison Cloud Platform](https://www.unison.cloud/) to provide cloud
           computing as a service. Local simulation of the Cloud is supported
           via the [cloud client](https://share.unison-lang.org/@unison/cloud).

           [Sign up for access to the Cloud here](https://www.unison.cloud/).
           Unison Cloud is our platform as a service product and we hope its
           success sustainably funds the open source development of the Unison
           language, tooling, and ecosystem as a whole.

       ### How can Unison's distributed execution be made secure?

           There are actually a bunch of questions here - some are listed
           below. Some aspects of this need more research, but overall we
           believe that it will be possible to build secure systems using
           Unison.

           How can a Unison node ensure that a peer which sends it a
           computation (a) is who it says it is, (b) is authorized to consume
           compute resources on the node, (c) is authorized to access data or
           perform effects on the node?

           Computations from remote notes will be sandboxed, with resource and
           capability permissions applied to the sandbox. There will be a
           system for authenticating remote nodes and authorizing them for a
           given usage.

           How can a Unison node know that code which it syncs in from a peer
           is safe to run, and will only use resources or privileges that the
           sender is authorized for?

           Resource usage will be limited dynamically through the sandbox
           mechanism, with code execution throttled or cancelled if it breaches
           the limits. A program will only be able to use effects and I/O if
           the sandbox explicitly provides it the ability to do so. Unison's
           type system enforces that programs only have access to the abilities
           they're given.

           How can a piece of Unison code/data be kept private to a node - so
           it doesn't get synced to other nodes?

           For data, there is a plan to add a "pinned data" facility, see issue
           [#798](https://github.com/unisonweb/unison/issues/798).

           For code, this is an active topic of research - see issue
           [#799](https://github.com/unisonweb/unison/issues/799).

           Given that Unison transfers code and data to peers, are any special
           code patterns required in Unison to prevent vulnerabilities?

           Certainly yes, and it will be fun to build out our understanding of
           these patterns as we gain experience with the distributed execution
           API!

       ### What does each node need to run to enable distributed execution?

           A Unison runtime environment must be running on each node. This
           environment will accept network connections from Unison peers, and
           run the code syncing and distributed evaluation protocol.

           Details on how this environment looks are TBD.

       ### Where can I learn more about Unison's support for distributed
       computation?

           This area of Unison has had plenty of thought and research and is in
           active development. Here are some resources to give you a preview.

           * The
             [README for the distributed library contains examples and
             information](https://share.unison-lang.org/@unison/distributed).
           * Paul's
             [Scale By The Bay 2018 talk](https://www.youtube.com/watch?v=v7L-5AQQkbM),
             from about 8 minutes in.
           * The 2015
             [blog post](https://github.com/unisonweb/oldblog/blob/master/_posts/2015-06-02-distributed-evaluation.markdown)
             on distributed evaluation.
           * The current
             [API sketch](https://github.com/unisonweb/unison/blob/trunk/docs/distributed-programming-rfc.markdown).
           * Read our article,
             [Spark-like distributed datasets in Unison](https://www.unison-lang.org/articles/distributed-datasets/)
           * A preview of what
             [microservices might look like in Unison](https://www.unison-lang.org/blog/unison-services-preview/)

    ## Build/install

       ### Is there a nix expression for Unison?

           Check out the
           [unison-nix repository](https://github.com/ceedubs/unison-nix/).

           Nix is not officially supported, but there seems to be a substantial
           overlap between nix enthusiasts and Unison enthusiasts, so feel free
           to give it a try and ask on [slack](https://unison-lang.org/slack)
           if you get stuck.

       ### I get `error while loading shared libraries: libtinfo.so.5`

           Some people see the following error when they try to run the `ucm`
           executable for the first time.

           ``` raw
           ucm: error while loading shared libraries: libtinfo.so.5: cannot
           open shared object file: No such file or directory
           ```

           As a workaround try the following:

           ``` raw
           -- assumes APT is your package manager
           sudo apt-get install libtinfo5
           ```

           This issue is tracked under
           [#602](https://github.com/unisonweb/unison/issues/682).

       ### When I save my scratch file, `ucm` doesn't react

           On Linux, this can happen if your system has run out of
           `inotify watches`. (Backup applications often use a lot of these.)

           You can see if this is the case by running `tail -f <file>` on a
           file of your choice, and looking out for the following output.

           ``` raw
           tail: inotify cannot be used, reverting to polling: Too many open files
           ```

           If so you can up the limit by doing

           ``` raw
           echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p
           ```

           Search stackoverflow for more tips or get in touch with us in the
           community slack if that command doesn't work for you.

    ## Codebase model

       ### If definitions never change, how do you fix a bug or refactor an old
       definition?

           {{
           docCallout
             Optional.None
             {{
             You can also check out Paul's
             [Scale By The Bay 2019 talk](https://www.youtube.com/watch?v=IvENPX0MAZ4)
             on the Unison codebase model for an explanation!
             }} }}

           Definitions never change, but the names we give them do. Suppose I
           have a term with hash `#1krif5`, and I've given it the name `foo`.
           We can draw that as follows.

           ``` raw
           foo   ->   #1krif5
           ```

           Then I decide my code for `foo` is bugged, so I present Unison with
           a new definition for it. Then Unison will work out the hash of the
           **new** definition for `foo`, say `#amrl61`, and change the name
           `foo` to point to it. We end up with the following.

           ``` raw
           #1krif5

             foo   ->   #amrl61
           ```

           So, no terms have
           ***changed**, but a new term has been added, and a**name*** has
           changed to point to a different term.

           #### Propagation

                So that's all good, but what about the function `bar` which
                called `foo`?

                Suppose we actually originally started with the following - one
                term referencing (calling out to) another, those terms being
                called `bar` and `foo` respectively.

                ``` raw
                foo   ->   #1krif5
                                ↑
                  bar   ->   #doq7s1
                ```

                Then our edit to `foo` actually left the codebase (for a
                moment) in the following situation, with `bar` still
                referencing the __old__ version of `foo`.

                ``` raw
                #1krif5
                               ↑
                  bar   ->   #doq7s1

                  foo   ->   #amrl61
                ```

                However, Unison assumes that this is not where you want to end
                up, and that actually, you want to **propagate** the updated
                definition of `foo` to the set of **transitive dependents** of
                the old term `#1krif5`.

                As long as the old `foo` and the new `foo` have the same (or
                compatible) types, then Unison does this propagation
                automatically and leaves you with the following.

                ``` raw
                (unused)   #1krif5

                  bar   ->   #doq7s1
                                ↓
                  foo   ->   #amrl61
                ```

                This propagation works recursively, so it deals with dependents
                of `bar` as well, and their dependents in turn, and so on.

                If the types aren't compatible, then Unison can't automatically
                propagate the change. Let's suppose the old definition of `bar`
                had type {type Int}, the new one has type {type Nat}, and `bar`
                requires `foo` to be an {type Int}. Then the `todo` command in
                ucm reports the following:

                ``` raw
                scratch/main> todo

                  🚧

                  The namespace has 1 transitive dependent(s) left to upgrade. Your edit frontier is the dependents
                  of these definitions:

                    foo#1krif5 : .base.Int

                  I recommend working on them in the following order:

                    bar : .base.Int
                ```

                This is your cue to resolve the type discrepancy by editing
                `bar` (or rather, switching the name `bar` to refer to some new
                definition) so that it copes with `foo` being a `Nat`. If that
                edit to `bar` preserves its type, then Unison can take it from
                there and continue the propagation process automatically.

                Notice that even while we were in the transient state as
                reported by `todo`, our codebase was still valid, and all our
                tests would still pass - it's just that at least some of them
                would still refer to the old definitions of `foo` and `bar`.
                And at no stage did we have to wade through a mass of compile
                errors: instead, the `todo` command leads us through a
                structured refactoring process, in which everything is valid
                and well-typed at all times.

                Another thing: the instruction to 'replace `#1krif5` with
                `#amrl61` gets recorded by Unison in a `patch`. Suppose you
                publish `foo` in a library for other people to use. Then your
                library users can take advantage of your patch to help them
                update their own code.

                See our document about
                [resolving conflicts for more information]({{
                docLink (docEmbedTermLink do updateCode)
                }}).

       ### What happens if I hit a hash collision?

           Your name will go down in history!

           Unison uses 512-bit SHA3 digests to hash terms and types. The chance
           of two Unison objects hashing to the same digest is unimaginably
           small. If we wrote one billion unique Unison terms every second, we
           could expect a hash collision roughly every 100 trillion years.

           If it did happen, you could simply tweak your term so it gets a
           different hash. For example, you could wrap it in a call to the
           identity function (which does nothing), or add a document literal to
           the term like `{{wow this is unlikely!}}`

       ### Is it inefficient to have the codebase be a purely functional data
       structure? Won't that involve a lot of copying?

           Since the codebase is an immutable data structure where the elements
           of the structure never change, we can get the same kind of
           structural sharing we’re used to getting with data structures in
           functional programming.

           In fact, Unison may waste a lot less disk space than traditional
           languages, since Unison does not have builds and therefore doesn’t
           generate build artifacts.

       ### Does the codebase always keep getting bigger over time? Is there any
       way to remove code?

           The codebase stores its complete history - the same as git does.
           That gives you a complete view of the operations that brought the
           codebase to its current state. It also means that you can refer to a
           given definition in the codebase, by hash, and be sure that that
           reference will never become undefined.

           In the future, we may introduce a "prune" operation to allow you to
           remove definitions which have no inward references (from within the
           codebase).

       ### How do I share my code?

           If you want to share your code (or look at code that others have
           shared), check out [Unison Share](https://share.unison-lang.org/).

           You use the Unison Codebase Manager's `push` command, to write it to
           your remotely hosted repository.

           (There's also always the option of zipping up your `.unison`
           directory! Its contents are free-standing and portable.)

       ### How does hashing work for mutually recursive definitions?

           We treat a set of mutually recursive definitions as a single "cycle"
           for hashing purposes.

           For example:

           ``` unison
           f x = g (x - 1)
           g x = f (x / 2)
           ```

           First we replace any recursive calls in the cycle with the De Bruijn
           index of the cycle itself, like this (not valid Unison syntax):

           ``` raw
           $0 =
             f x = $0 (x - 1)
             g x = $0 (x / 2)
           ```

           Nested cycles will get higher De Bruijn indices, but a top-level
           cycle will have index ``0``.

           This transformation makes the elements of the cycle independent of
           any names. Then we hash each element of this new structure
           individually. Let's say `f` gets the hash `#222` and `g` get the
           hash `#111`. We then sort them to get a canonical order that is
           independent of their order in the source. This yields something
           like:

           ``` raw
           $0 =
             $0.0 x = #111
             $0.1 x = #222
           ```

           We then hash this structure. Let's say that hash is `#ccc`. Each
           definition gets a hash `#ccc.n` where `n` is the position of that
           definition in the cycle. Here `g` gets `#ccc.0` and `f` gets
           `#ccc.1`. The final cycle will be:

           ``` raw
           #ccc =
             $0 x = $1 (x / 2)
             $1 x = $0 (x - 1)
           ```

           This creates two new hashes, `#ccc.0` and `#ccc.1`. Note that their
           definitions don't refer to each other by hash, but by position in
           the overall cycle.

    ## General

       ### How do I run a program that uses `IO`?

           In `ucm`, you can type ''run myProgram`, where ''myProgram'' is some
           term of type {{ docCode {{ '{IO, Exception} () }} }}.

           [Check out this document about the ways to run Unison programs]({{
           docLink (docEmbedTermLink do runningPrograms)
           }})

       ### Does Unison have IDE support? Editor support? Language Server
       Protocol (LSP) support?

           Unison has an LSP integration.
           [Here's how to set it up.](https://github.com/unisonweb/unison/blob/trunk/docs/language-server.markdown)

           We have editor support for the Unison syntax in Vim, Atom, and VS
           Code - see our document about
           [setting up your editor]({{
           docLink (docEmbedTermLink do editorSetup)
           }}).

           No editors currently understand the Unison codebase format, or offer
           functionality like "find references", "extract function", etc. You
           can use `ucm` commands to get some of these abilities, for example
           `find`.

           Unison ships with a [local UI]({localCodebaseUI}) to browse your
           codebase. Libraries can be explored and published on
           [Unison Share](https://share.unison-lang.org)

           Since the Unison codebase is a structured object containing full
           type information and metadata, we expect it will be possible to
           build developer tooling which beats that which exists for today's
           languages!

           A previous incarnation of the Unison project actually started with a
           structural editor, meaning that the "input some freeform text" stage
           is bypassed entirely. This is a direction we hope to come back to in
           the future.

       ### Does Unison compile to LLVM?

           Not yet! But a native compilation is coming to for Unison soon. For
           the moment, we have a nice, clean, but un-optimized interpreter in
           Haskell.

       ### Are you looking for help with developing Unison?

           Yes! Please come and get involved 😊

           The first step is to play with the language, and get familiar with
           writing Unison code. Also come join the Discord, and browse through
           the issue tracker to see what's going on.

           #### Contributing Unison code

                You can contribute to the Unison ecosystem directly by cloning
                a library from Unison Share and creating a branch with your
                feature or change. The Unison library author will be notified
                of your changes and can merge them into their library. (Be sure
                to ping them on Discord in the #libraries channel as a heads
                up!)

                Is there a library you could write in Unison? That's a way to
                contribute which requires very little coordination with the
                compiler team, and can have a big impact on the usability of
                the overall Unison ecosystem. There's a catalog of libraries
                [on the front page of Unison Share](https://share.unison-lang.org/)
                - do add yours! Let us know what you're working on in the
                Discord (channel #libraries). 😎

                You could also try fixing some omissions from the base library.
                See
                [here](https://github.com/unisonweb/base/blob/master/CONTRIBUTING.md#contributions-that-are-most-welcome)
                for the contributions that would be most welcome.

           #### Contributing to the Unison language/compiler/toolchain

                You can dip your toes by finding small ways to contribute a
                little piece:

                * take a look at the issues labelled
                  [good first issue](https://github.com/unisonweb/unison/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)
                  and
                  [help wanted](https://github.com/unisonweb/unison/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)
                * see if you can find any tidying or refactoring you think
                  needs doing in the parser-typechecker source (chat to us on
                  slack before spending much time)
                * are there any contributor docs you'd like to see which you
                  could make a start on?

                Once you've had your first PR merged and gotten to know how we
                work, have a think whether you want to take on a bigger
                project! There's lots of cool stuff to do. Get in touch with
                Paul Chiusano via the Discord and give him an idea of your
                areas of interest and level of experience. If you have your own
                suggestions for what you could work on then let him know!
  }}

docs.usageTopics.resettingCodebaseState : Doc
docs.usageTopics.resettingCodebaseState =
  {{
  # ⏪ Resetting codebase state

    The Unison Codebase Manager has a powerful set of commands for managing the
    state of your codebase. Other programming languages will make use of
    version control systems like Git (or spamming Ctrl-Z) to manage history,
    but in Unison changes to the codebase, such as updating terms or deleting
    them, are automatically preserved as a log of hashes in the UCM itself. One
    of the UCM's useful features is the ability to view and rewind the log of
    your codebase to a previous point in time.

    {{
    docCallout
      (Some {{ 🗂️ }})
      {{
      **Codebase state cheat sheet**

      * [`reflog`]({ucmCommands.reflog}) - Displays a log of changes to the
        current branch
      * [`reflog.project`]({project.reflog}) - Displays a log of changes to the
        current project
      * [`reflog.global`]({global.reflog}) - Displays a log of changes to the
        entire codebase
      * [`reset`]({ucmCommands.reset}) - Reverts a branch to a given hash
      * [`undo`]({undo}) - Reverts the most recent change to the current branch
      * [`history`]({ucmCommands.history}) - Displays the project history,
        including the names of updated terms
      }} }}

    ## A walk-through

       What does it actually look like when we say that the UCM creates a log
       of changes to the codebase? Let's walk through a simple example.

       ### Viewing changes to a branch

           Say we have the Unison term `magicNumber = 40` that we {{
           docTooltip {{ `add` }} ucmCommands.add }} to a fresh project.

           ``` ucm
           scratch/main> add

             ⍟ I've added these definitions:

             magicNumber : Nat
           ```

           Realizing that our magic number is actually 42 and that we're
           missing another term, we can make those changes in our scratch.u
           file and then {{ docTooltip {{ `update` }} ucmCommands.update }} the
           codebase.

           ``` unison
           magicNumber = 42
           magicWord = "please"
           ```

           Let's inspect the `reflog` to see what it looks like:

           ``` ucm
           scratch/main> reflog

           Below is a record of recent changes, you can use
           `reset #abcdef` to reset the current branch to a previous
           state.

           Tip: Use `diff.namespace 1 7` to compare between points in
                history.

                Branch         When   Hash          Description
           1.   scratch/main   now    #8lffaev34c   update
           2.   scratch/main   now    #cr3um0rgg1   add
           3.   scratch/main   now    #sg60bvjo91   Project Created
           ```

           The `reflog` command displays a log of changes to the current branch
           along with the UCM command that produced that change.

       ### Resetting the state

           If we want to revert the latest update, we have two options, `undo`
           and `reset`.

           `undo` rewinds the most recent change to the current branch:

           ``` ucm
           scratch/main> undo

           Here are the changes I undid

           Updates:

             1. magicNumber : Nat
                ↓
             2. magicNumber : Nat

           Added definitions:

             3. magicWord : Text
           ```

           Because changes to a Unison codebase form an immutable log, this
           command also shows up in the reflog:

           ``` ucm
           scratch/main> reflog

             Below is a record of recent changes, you can use
             `reset #abcdef` to reset the current branch to a previous
             state.

             Tip: Use `diff.namespace 1 7` to compare between points in
                  history.

                  Branch         When   Hash          Description
             1.   scratch/main   now    #cr3um0rgg1   undo
             2.   scratch/main   now    #8lffaev34c   update
             3.   scratch/main   now    #cr3um0rgg1   add
             4.   scratch/main   now    #sg60bvjo91   Project Created
           ```

           If we need to move farther backward in the log, we can use the
           `reset` command with the hash of the state we want to return to:

           ``` ucm
           scratch/main> reset #cr3um0rgg1
           ```

           {{
           docCallout
             (Some wordle.utils.emojis.hint)
             {{
             `reset` can also take a numbered argument instead of a hash, so
             it's common to issue `reflog` to see the list of changes and then
             enter something like `reset 3` in the UCM without needing to copy
             and paste the hash.
             }} }}

       ### Viewing changes across multiple branches in a project

           Let's create a feature branch for this example and make some new
           changes.

           ``` ucm
           scratch/main> branch addFeature
           ```

           ``` unison
           magicNumber = 1
           magicWorld = "pretty please"
           ```

           `reflog.project` will show the changes across all branches in the
           project:

           ``` ucm
           scratch/addFeature> reflog.project

           Below is a record of recent changes, you can use
           `reset #abcdef` to reset the current branch to a previous
           state.

           Tip: Use `diff.namespace 1 7` to compare between points in
                history.

                Branch               When   Hash          Description
           1.   scratch/addFeature   now    #4lotqj3cbo   update
           2.   scratch/addFeature   now    #8lffaev34c   Branch created from scratch/main
           3.   scratch/main         now    #8lffaev34c   update
           4.   scratch/main         now    #cr3um0rgg1   add
           5.   scratch/main         now    #sg60bvjo91   Project Created
           ```

           Compare this to the `history` command output, which includes the
           name of the terms that were changed in the project across its
           branches:

           ``` ucm
           scratch/addFeature> history

             Note: The most recent namespace hash is immediately below this
                   message.

             ⊙ 1. #4lotqj3cbo

               + Adds / updates:

                 magicNumber magicWorld

             ⊙ 2. #8lffaev34c

               + Adds / updates:

                 magicNumber magicWord

             □ 3. #cr3um0rgg1 (start of history)
           ```

           {{
           docCallout
             (Some important)
             {{
             The `history` command shows a log of the project's states (across
             all its branches) and the names of the terms or types that
             changed. It does not include the UCM commands that produced those
             changes.

             For folks who are used to Git, `history` is akin to `git log` and
             `reflog.project` is akin to `git reflog`.
             [Here's a quick explainer, if you're curious.](https://gitprotect.io/blog/how-to-use-git-reflog-reflog-vs-log/)
             }} }}

       ### Global codebase state

           This is less common, but if you need to view changes across the
           entire codebase, you can use the `reflog.global` command.

           The deprecated `reset-root` command had the ability to move
           backwards across the entire codebase state, but this is not
           recommended as it can lead to rewinding changes in unintended
           projects.
  }}

docs.usageTopics.runningPrograms : Doc
docs.usageTopics.runningPrograms =
  {{
  # Running Unison Programs

    {{ docCallout
      (Some emojis.index) {{
      **What's in this document?**

      * [Running a main function](#running-a-main-function)
      * [Arguments to main functions](#arguments-to-main-functions)
      * [Stand-alone binaries](#stand-alone-binaries)
      }} }}

    ## Running a main function

       Unison programs can be executed within the {{ docTooltip {{ UCM }} ucm
       }} with the [`run`]({ucmCommands.run}) command. This command is used to
       execute the "main" entry point to your Unison code.

       {{
       docCallout
         (Some important)
         {{
         Runnable main functions have this signature:
         `main : '{IO, Exception} someTypeHere`.
         }} }}

       The `run` command expects a
       [delayed computation]({valuesAndFunctions.delayedComputations})
       returning any type. The `run` command provides a handler for the `IO`
       and {type Exception} abilities, so programs which perform IO and bubble
       up top-level failures can be executed by the UCM.

       ### Arguments to main functions

           To accept arguments to the entry point of your Unison program, you
           can use the {getArgs} function: @inlineSignature{getArgs}.

           {getArgs} returns a list of {type Text} representing the arguments
           of the program in a thunk or delayed computation. Remember to force
           the thunk with the `!` when you actually want the arguments to work
           with.

           {{
           docCallout
             (Some wordle.utils.emojis.hint)
             {{
             It might be tempting to represent the fact that your main function
             accepts a list of arguments in its type signature, like
             `main : [Text] -> '{IO,Exception}()`, but {getArgs}
             __effectfully__ reads command line arguments, which is why it's
             expressed in IO.
             }} }}

           The following function will print out the given main function
           arguments:

           {{
           docSource
             [docSourceElement (docEmbedTermLink do runningPrograms.myMain) []]
           }}

           In the UCM, you can call it with `run` like

           ``` ucm
           project/main> run myMain a b c
           ```

           And it will return the following to the console:

           ``` ucm
           project/main> run myMain a b c
           Hello a b c
           ```

    ## Stand-alone binaries

       The UCM can produce standalone binary executables for when you want to
       run a Unison program without entering into the CLI! These binary
       executables contain all the Unison code for the program in question
       **AND** its essential dependencies in a single, lightweight bytecode
       file.

       To __produce__ the binary file run the `compile` command from within the
       UCM:

       ``` ucm
       scratch/main> compile myMain myRadExecutable
       ```

       The first argument is the entry point to your Unison program (the "main"
       method described above), and the second argument is the name of the
       executable file that the UCM should produce.

       Unison executable files have the suffix `.uc` so the above command will
       write a file called `myRadExecutable.uc` in the folder where the
       codebase lives.

       To __run__ the binary executable, you can then issue the following
       command from the terminal of your choice:

       ``` bash
       $ ucm run.compiled myRadExecutable.uc
       ```

       You can supply arguments to the executable in a space-separated list.
       They'll be accessible in your Unison program via the {getArgs} function.

       🌻 Your Unison program is now up and running!
  }}

docs.usageTopics.runningPrograms.myMain : '{IO, Exception} ()
docs.usageTopics.runningPrograms.myMain _ =
  use Text ++
  args : [Text]
  args = getArgs()
  printLine ("Hello " ++ Text.join " " args)

docs.usageTopics.testing : Doc
docs.usageTopics.testing =
  use Each repeat
  use Nat *
  use Result Fail
  use Text ++ head reverse
  use arbitrary nats
  use test ensureEqual raiseFailure verify
  use ucmCommands test
  {{
  # Testing your Unison code

    We write tests in Unison as special {{
    docTooltip {{ watch expressions }} watchExpression }} in
    [scratch files]({_scratchFiles}). They're added to the codebase using the
    {{ docTooltip {{ `add` or `update` }} ucmCommands.update }} commands, and
    re-run using the {{ docTooltip {{ `test namespace.to.test` }} test }}
    command in the UCM.

    {{ docCallout
      (Some emojis.index) {{
      **What's in this document?**

      * [What's special about Unison tests?](#whats-special-about-unison-tests)
      * [Basic unit test workflow](#basic-unit-test-workflow)
      * [Richer test-runner functionality](#richer-test-runner-functionality)
      * [Writing test expectations](#writing-test-expectations)
      * [Generating test cases](#generating-test-cases)
      * [Labels for test failures](#scoped-labels-for-test-failures)
      }} }}

    ## What's special about Unison tests?

       Unison caches test results unless the functions in a particular test's
       dependency graph receive a new hash! When you issue the
       [`test` command]({test}) any tests that have been run before will simply
       report the cached results. For this reason, regular unit tests can't
       access any [abilities]({abilities.index}) that would cause the test to
       give different results each time it's run, like {type IO}. {{
       docAside
         {{ See [`io.test`]({ioTest}) for a way to test code that uses IO. }}
       }}

    ## Basic unit test workflow

       Here's a simple test in a scratch file:

       ``` unison
       square : Nat -> Nat
       square x = x * x

       test> square.tests.ex1 = check (square 4 == 16)
       ```

       The `test>` line is called a "test watch expression." Like other {{
       docTooltip {{ watch expressions }} watchExpression }} it will get
       evaluated (or looked up in the evaluation cache) on every file save.
       You'll see the results for simple tests in the console:

       ``` ucm
       ⍟ These new definitions are ok to `add`:

        square.tests.ex1 : [Test.Result]

       1 | test> square.tests.ex1 = check (square 4 == 16)

       ✅ Passed
       ```

       {{
       docCallout
         (Some {{ 🤓 }})
         {{
         The `check` function turns a {type Boolean} expression into a list of
         {type test.Result}. A test can be `` Ok `` or ``Fail``.

         Any test watch expression must have the type `[Result]`.
         }} }}

       Tests are regular Unison terms, so the name following the watch
       expression `square.tests.ex1` is what the test will be saved as in the
       UCM. By convention, tests for a definition called `square` are placed in
       the `square.tests` namespace.

       To run only the tests within the `square.tests` namespace, you can use
       the `test` command with a namespace argument:

       ``` ucm
       scratch/main> test square.tests

       Cached test results (`help testcache` to learn more)

        1. square.tests.ex1   ◉ Passed

        ✅ 1 test(s) passing
       ```

    ## Richer test-runner functionality

       You can also write tests that run multiple times with different inputs,
       or tests that fail if an {type Exception} is thrown, or tests with
       scoped labels. All of these are handled by the {verify} function.

           @signature{verify}

       This function takes a block of code that generates test cases and checks
       that the property holds for all of them. For example:

       @typecheck ```
       verify do
         repeat 100
         n = Random.nat()
         ensureEqual (Nat.fromText (Nat.toText n)) (Some n)
       ```

       This will generate 100 test cases, each consisting of a new random
       number, and check that the number is equal to itself when converted to
       {type Text} and back. If the property fails for any of the test cases,
       the test will return {Fail} containing the failing test case.

       The test passed to {verify} can use various abilities:

       * {type Random} for generating random test cases.
       * {type Each} for generating a range of test cases or repeating a test a
         certain number of times.
       * {type Exception} for failing a test.
       * {type Label} for adding scoped labels to tests that will be displayed
         in the results of failing tests.

    ## Writing test expectations

       {verify} will return a {Fail} if the computation passed to it raises an
       {type Exception}.

       You can use {raiseFailure} to fail a test explicitly:

       @typecheck ```
       verify do
         b = Random.boolean()
         when b do raiseFailure "This test sometimes fails" b
       ```

       The first argument to {raiseFailure} is a message that will be displayed
       in the test results, and the second argument is a payload that will be
       displayed in the test results if the test fails.

       There are also functions for checking properties that give more detailed
       information about the failure:

       * {ensure} - check that a value is true.
       * {ensureWith} - check that a value is true, with a custom payload for
         the failure.
       * {ensureEqual} - check that two values are equal.
       * {ensureNotEqual} - check that two values are not equal.
       * {ensureLess} - check that the first value is less than the second.
       * {ensureLessOrEqual} - check that the first value is at most the
         second.
       * {ensureGreater} - check that the first value is greater than the
         second.
       * {ensureGreaterOrEqual} - check that the first value is at least the
         second.
       * {ensuring} - check that a given computation returns ``true``.
       * { ensuringWith} - check that a given computation returns ``true``,
         with a custom payload for the failure case.

       For example, here is a test that the Base library uses for the {head}
       function:

           @source{head.tests}

    ## Generating test cases

       Use a combination of the {type Random} and {type Each} abilities to
       generate test cases for use by {verify}.

       Use {repeat} to repeat a test a certain number of times. This is
       particularly useful for tests that generate random test cases:

       @typecheck ```
       verify do
         use Random natIn
         repeat 100
         size1 = natIn 0 100
         size2 = natIn 0 100
         text1 = ofChars unicode size1
         text2 = ofChars unicode size2
         ensureEqual
           (reverse text1 ++ reverse text2) (reverse (text2 ++ text1))
       ```

       The above test generates 100 random test cases, each consisting of two
       random {type Text} values, and checks that reversing the concatenation
       of the two values is equal to the concatenation of the reversed values.
       It's using {test.gen.natIn} for the size of the {type Text} values, and
       {ofChars} to generate the {type Text} values themselves.

       We can also use {type Each} to generate test cases that cover a range or
       list of values instead of random values. For example, here's a test that
       checks that converting a number to base 16 gives the expected result:

       @typecheck ```
       verify do
         (n, c) = each (List.zip (Nat.range 10 16) (toCharList "ABCDEF"))
         ensureEqual (Nat.toTextBase 16 n) (Some (Char.toText c))
       ```

       See {type Random} for more information on generating random values and
       {type Each} for more on repetition and ranges.

       A few convenience functions are provided for common test case generation
       patterns:

       * {arbitrary.ints} - generate a specific number of random integers,
         checking corner cases like 0, 1, -1, {maxInt}, and {minInt} first,
         then generating random integers.
       * {nats} - generate a specific number of random natural numbers,
         checking corner cases like 0, 1, and {maxNat} first, then generating
         random natural numbers.
       * {arbitrary.floats} - generate a specific number of random
         floating-point numbers, checking corner cases like 0.0, 1.0, -1.0,
         {maxFloat}, {minFloat}, {Infinity}, and {NaN} first, then generating
         random floating-point numbers.
       * {unspecialFloats} - generate a specific number of random
         floating-point numbers that are not NaN or infinity. Checks corner
         cases first, then generates random floating-point numbers.

    ## Scoped labels for test failures

       You can use the {type Label} ability to add scoped labels to tests that
       will be displayed in the results of failing tests. For example, here is
       an erroneous test that fails where the labels help to identify the
       problem:

       @typecheck ```
       verify do
         labeled "Tests for empty Text" do
           labeled "head" do ensureEqual (head "") Optional.None
           labeled "isEmpty" do ensure (Text.isEmpty "")
           labeled "size" do ensureEqual (Text.size "") 1
       ```

       This test fails with:

       ``` raw
       🚫 FAILED
       Tests for empty Text:
         size:
           elements not equal
           (0, 1)
       ```

       Within a test you can use {label} to add a label to the test. The labels
       will be displayed in the results of failing tests. For example:

       @typecheck ```
       verify do
         labeled "check multiplication" do
           x = nats 100
           y = nats 100
           label "x * y should be greater than x" (x, y)
           ensureGreater (x * y) x
       ```

       Due to a false assumption in the test, it fails with:

       ``` raw
       🚫 FAILED
       check multiplication:
         x * y should be greater than x: (0, 0)
         0 is not greater than 0
       ```
  }}

docs.usageTopics.workflowHowTos.resolveConflictsProjects : Doc
docs.usageTopics.workflowHowTos.resolveConflictsProjects =
  {{
  # How to update code and resolve resulting conflicts in a branch

    Sometimes you'll need to make a change in the codebase that can't
    automatically be propagated to dependent functions, for example: if you
    alter a data constructor for a type or change the arguments to a function.
    Unison can programmatically guide you through the edits that you need to
    make in these cases. {{
    docAside
      {{
      This document uses the new `branch` based workflow. If you are looking
      for the namespace based workflow, check out
      [this document](resolve-conflicts-update-old).
      }} }}

    {{
    docAside
      {{
      The user experience for matching old hash references to updated names is
      a known pain point. Even now, the fix of prefixing the updated type name
      with a hash of its branch is a temporary stop-gap. We're actively working
      on improving the update experience! In the meantime, follow the workflow
      here to help make those pesky hash references less of a problem!
      }} }}

    Note, your code which calls the old versions of a function will not be
    __broken__ (it'll still run as originally implemented) but it might refer
    to the old version by hash reference, which is how you end up with cryptic
    terms that look like this:

    ``` unison
    exclaim : Text
    exclaim =
        use Text ++
        #7i0ceb20mm 4 ++ "!!"
    ```

    This document walks through a workflow for making changes to your codebase
    and resolving the resulting conflicts in a way that helps to preserve the
    human readable names for your functions. 🤖

    {{
    docCallout
      (Some {{ ⏱ }})
      {{
      Suggested workflow summary:

      1. `branch` off of the project branch you'd like to edit before making
         the change.
      2. make your changes in the branch
      3. `update` the codebase
      4. run `todo` to see dependencies to update
      5. `edit` and `update` the functions that the UCM suggests
      6. `merge` the forked branch back
      }} }}

    ## Walk through an example

       Let's say we have a simple type and a function which makes use of that
       type in our codebase:

       ``` unison
       unique type Box = Box Nat

       Box.toText : Box -> Text
       Box.toText box = match box with
         Box.Box nat -> Nat.toText nat
       ```

       Later, we may realize its data constructor should be changed. The first
       thing we should do is `branch` from our working branch so we have a nice
       environment to make our changes in.

       ``` ucm
       myProject/main> branch updateMyType
       ```

       In our new branch, let's {{ docTooltip {{ edit }} edit }} the type:

       ``` ucm
       myProject/updateMyType>
       myProject/updateMyType> edit Box
       ```

       We've changed the data constructor from taking a value of type
       {type Nat} to {type Int}.

       ``` unison
       unique type Box = Box Int
       ```

       After making the change to the type we'll {{
       docTooltip {{ `update` }} ucmCommands.update }} the codebase, and see if
       we have any functions or types to adjust given our change with the {{
       docTooltip {{ `todo` }} todoUCM }} command. Remember, we're making these
       updates in a branch.

       ``` ucm
       myProject/updateMyType> update
       myProject/updateMyType> todo

       🚧

       The namespace has 1 transitive dependent(s) left to upgrade.
       Your edit frontier is the dependents of these definitions:

         unique type Box

       I recommend working on them in the following order:

       1. toText : Box -> Text
       ```

       We only have one todo item here, but in a more complicated codebase the
       suggested edit order from the UCM can be extremely helpful in prompting
       you to work from the "edges" of your codebase, working up the function
       call chain.

       {{
       docCallout
         (Some {{ 💡 }})
         {{
         You can tackle your "todo's" one by one, but did you know, you can
         also update all of your dependencies at once with the `edit 1-n`
         syntax.

         Maybe you want to edit a grouping of connected functions, but they
         aren't contiguous in the numbered list? You can combine the `edit 1-n`
         syntax with a space separated list of terms you'd like to edit, for
         example `edit 2-4 6 8` or `edit 1 4 7-9`.
         }} }}

       In this case, it looks like the `toText` function will need to be
       changed to point to the __updated__ type in this branch and a few names
       and functions should be changed to handle the {type Int}. Because we've
       kept around a copy of the old data type the old branch, the UCM renders
       it with the hash of its project prefixed before the name of the type
       (this is a temporary stop-gap) instead of an entirely cryptic hash.

       ``` unison
       -- old code
       Box.toText : <projectsHash>.Box -> Text
       Box.toText = cases <projectsHash>.Box.Box nat -> Nat.toText nat

       -- new version ✨
       Box.toText : Box -> Text
       Box.toText = cases Box.Box int -> Int.toText int
       ```

       When you're satisfied with the changes in your forked namespace and
       there are no more {{ docTooltip {{ `todo` }} todoUCM }} items, you can
       {{ docTooltip {{ `merge` }} ucmCommands.merge }} the new branch into the
       old branch to fully replace the old implementation. We can clean up our
       branch structure with the {{ docTooltip {{ `delete.branch` }} delBranch
       }} command

       ``` ucm
       myProject/updateType> merge /updateType /main
       myProject/updateType> switch /main
       myProject/main> delete.branch /updateType
       ```

       There you have it! You've updated your codebase with the help of the
       UCM! 🌻
  }}

docs.usageTopics.workflowHowTos.resolveConflictsUpdateOld : Doc
docs.usageTopics.workflowHowTos.resolveConflictsUpdateOld =
  {{
  # How to update code and resolve resulting conflicts

    **Note, this workflow is deprecated**

    See [this document](/resolve-conflicts-projects) for the new workflow.

    Sometimes you'll need to make a change in the codebase that can't
    automatically be propagated to dependent functions, for example: if you
    alter a data constructor for a type or change the arguments to a function.
    Unison can programmatically guide you through the edits that you need to
    make in these cases.

    {{
    docAside
      {{
      The user experience for matching old hash references to updated names is
      a known pain point. We're actively working on it! In the meantime, follow
      the workflow here to help make those pesky hash references less of a
      problem!
      }} }}

    Note, your code which calls the old versions of a function will not be
    __broken__ (it'll still run as originally implemented) but it might refer
    to the old version by hash reference, which is how you end up with cryptic
    terms that look like this:

    ``` unison
    exclaim : Text
    exclaim =
        use Text ++
        #7i0ceb20mm 4 ++ "!!"
    ```

    This document walks through a workflow for making changes to your codebase
    and resolving the resulting conflicts in a way that helps to preserve the
    human readable names for your functions. 🤖

    {{ docCallout
      (Some {{ ⏱ }}) {{
      Suggested workflow summary:

      1. `fork` the namespace you'd like to edit
      2. make your changes in the forked namespace
      3. `update.old` the codebase
      4. run `todo` to see dependencies to update
      5. `edit` and `update.old` the functions that the UCM suggests
      6. `merge` the forked namespace back
      }} }}

    ## Walk through an example

       Let's say we have a simple type and a function which makes use of that
       type:

       ``` unison
       unique type Box = Box Nat

       Box.toText : Box -> Text
       Box.toText box = match box with
         Box.Box nat -> Nat.toText nat
       ```

       We {{ docTooltip {{ `add` }} ucmCommands.add }} it to the codebase, and
       then later, we may realize its data constructor should be changed. The
       first thing we should do is {{ docTooltip {{ `fork` }} ucmCommands.fork
       }} the namespace to create a new namespace where we'll be making our
       changes.

       ``` ucm
       scratch/main> cd myWork
       myWork.> add
       myWork.> fork .myWork .newFeature
       ```

       In our new namespace, let's {{ docTooltip {{ edit }} edit }} the type:

       ``` ucm
       myWork.> cd .newFeature
       .newFeature> edit Box
       ```

       We've changed the data constructor from taking a value of type
       {type Nat} to {type Int}.

       ``` unison
       unique type Box = Box Int
       ```

       After making the change to the type we'll update the codebase with
       `update.old`, and see if we have any functions or types to adjust given
       our change with the {{ docTooltip {{ `todo` }} todoUCM }} command.
       Remember, we're making these updates in our forked copy of the original
       namespace.

       ``` ucm
       .newFeature> update.old
       .newFeature> todo

       🚧

       The namespace has 1 transitive dependent(s) left to upgrade.
       Your edit frontier is the dependents of these definitions:

         unique type .myWork.Box

       I recommend working on them in the following order:

       1. toText : myWork.Box -> Text
       ```

       We only have one todo item here, but in a more complicated codebase the
       suggested edit order from the UCM can be extremely helpful in prompting
       you to work from the "edges" of your codebase, working up the function
       call chain.

       {{
       docCallout
         (Some {{ 💡 }})
         {{
         You can tackle your "todo's" one by one, but did you know, you can
         also update all of your dependencies at once with the `edit 1-n`
         syntax.

         Maybe you want to edit a grouping of connected functions, but they
         aren't contiguous in the numbered list? You can combine the `edit 1-n`
         syntax with a space separated list of terms you'd like to edit, for
         example `edit 2-4 6 8` or `edit 1 4 7-9`.
         }} }}

       In this case, it looks like the `toText` function will need to be
       changed to point to the __updated__ type in this namespace and a few
       names and functions should be changed to handle the {type Int}. Because
       we've kept around a copy of the old data type the old namespace, the UCM
       renders it with its name instead of a cryptic hash.

       ``` unison
       -- old code
       Box.toText : myWork.Box -> Text
       Box.toText = cases myWork.Box.Box nat -> Nat.toText nat

       -- new version ✨
       Box.toText : newFeature.Box -> Text
       Box.toText = cases newFeature.Box.Box int -> Int.toText int
       ```

       When you're satisfied with the changes in your forked namespace and
       there are no more {{ docTooltip {{ todo }} todoUCM }} items, you can {{
       docTooltip {{ merge }} ucmCommands.merge }} the new namespace into the
       old namespace to fully replace the old implementation

       ``` ucm
       scratch/main> merge newFeature myWork
       ```

       There you have it! You've updated your codebase with the help of the
       UCM! 🌻
  }}

docs.usageTopics.workflowHowTos.updateCode : Doc
docs.usageTopics.workflowHowTos.updateCode =
  {{
  # Common workflows for updating Unison code

    The process of applying a potentially breaking change to your code need not
    be stressful. Here's how Unison handles that process in a few common cases:

    {{ docCallout
      (Some emojis.index) {{
      **Update workflows**

      * [Updating your own code](#updating-your-own-code)
      * [Updating a library dependency](#how-to-update-a-library-dependency)
      * [Merging changes from a branch](#updates-from-merging)
      }} }}

    ## Updating your own code

       Sometimes you'll need to make a change in the codebase that can't
       automatically be propagated to dependent functions, for example: if you
       alter a data constructor for a type or change the arguments to a
       function. Unison can programmatically guide you through the edits that
       you need to make in these cases.

       {{ docCallout
         (Some {{ ⏱ }}) {{
         Suggested workflow summary:

         1. enter `update` in the UCM to save your changes
         2. The UCM opens up non-typechecking code in your editor
         3. Fix the impacted terms and save the file
         4. run `update` to commit your changes.
         }} }}

       ### Walk through an example

           Let's say we have a simple type and a few functions which make use
           of that type in our codebase:

           ``` unison
           unique type Box = Box Nat

           Box.toText : Box -> Text
           Box.toText box = match box with
             Box.Box nat -> Nat.toText nat

           Box.print : Box -> {IO,Exception} ()
           Box.print box =
             Box.toText box |> printLine
           ```

           ``` ucm
           myProject/main> add
           ```

           We add it to the codebase but later, we may realize its data
           constructor should be changed.

           ``` ucm
           myProject/main> edit Box
           ```

           ``` unison
           unique type Box = Box Int
           ```

           We've changed the data constructor from taking a value of type
           {type Nat} to {type Int}. Upon saving the file and running `update`
           again, the UCM will open up the impacted terms in your editor.

           ``` ucm
           myProject/main> update

           Okay, I'm searching the branch for code that needs to be
           updated...


           That's done. Now I'm making sure everything typechecks...


           Typechecking failed. I've updated your scratch file with the
           definitions that need fixing. Once the file is compiling, try
           `update` again.
           ```

           All impacted terms, including indirect dependents, will be opened in
           your scratch file.

           ``` unison
           Box.print : Box ->{IO, Exception} ()
           Box.print box = Box.toText box |> printLine

           Box.toText : Box -> Text
           Box.toText = cases Box nat -> Nat.toText nat

           unique type Box = Box Int
           ```

           ``` ucm
           The 1st argument to `Nat.toText`

                   has type:  Int
             but I expected:  Nat

             5 | Box.toText = cases Box nat -> Nat.toText nat
             6 |
             7 | unique type Box = Box Int
           ```

           The UCM will start printing typechecking errors to the console
           starting from the top of the file so you know what to tackle first.
           In our example, the function `Box.print` is opened in the editor
           even though the change we need to make is in the `Box.toText`
           function. That's because resolving larger, more complicated updates
           can involve propagating changes to many terms, all the way up the
           function call chain. With this workflow, you can be assured that
           your change will leave your codebase in a consistent state. Once all
           the errors are fixed, you can run `update` again to commit your
           changes.

           {{ updateDependencyLibInstall }}

    ## Updates from merging

       Merging two branches together can also prompt an update workflow. The
       [merge]({ucmCommands.merge}) commands below are all valid ways to merge
       changes from one branch to another.

       ``` ucm
       scratch/main> merge /featureBranch
       scratch/main> merge /featureBranch /featureBranch2
       scratch/main> merge /@contributor/featureBranch
       ```

       If a term has been updated on the parent branch __and__ the child branch
       being merged into it the UCM will do two things:

       1. It will create a branch with the name `merge-child-into-parent` for
          the merge to take place in.
       2. It will open up the impacted terms in a scratch file. Conflicting
          terms are prefixed by their branch name in a comment for resolution.

       ``` unison
       -- tmp/main
       term1 : base.Nat
       term1 =
         use base.Nat +
         1 + 2 + 4000

       -- tmp/updateTerm1
       term1 : base.Nat
       term1 =
         use base.Nat +
         1 + 2 + 5000
       ```

       Delete the term that is no longer up-to-date or combine the changes into
       one term, then run `update` to apply the change to the merge resolution
       branch.

       ``` ucm
       tmp/merge-updateTerm1-into-main> update
       ```

       Once the codebase changes are resolved, run `merge.commit` to commit the
       changes into the parent branch. `merge.commit` will also delete the
       merge resolution branch.

       ``` ucm
       tmp/merge-updateTerm1-into-main> merge.commit
       ```
  }}

docs.usageTopics.workflowHowTos.updateDependency : Doc
docs.usageTopics.workflowHowTos.updateDependency =
  {{
  # How to update a dependency

    ** Note: this process is deprecated. See
    [this document]({{
    docLink (docEmbedTermLink do updateDependencyLibInstall)
    }}) for the latest workflow. **

    This doc walks through the process of updating a dependency, using Unison's
    standard library, `base`, as an example.

    {{
    docCallout
      (Some {{ ⏱ }})
      {{
      Suggested workflow summary:

      1. `pull` the latest version of the dependency into your codebase so that
         it is a sibling of your current library version
         * `.myProject> pull unison.public.base.latest lib.newBase`
      2. Apply the `patch` from the new version of the library to the project
         * `patch lib.newBase.patch`
      3. Check if there are `todo` items in your project as a result of
         applying the patch
         * `.myProject> todo`
      4. Delete the old version of base from your codebase.
         * `.myProject> delete.namespace lib.base`
      5. Rename the new version of base to `base`
         * `.myProject> move.namespace lib.newBase lib.base`
      }} }}

    First, {{ docTooltip {{ `pull` }} ucmCommands.pull }} the new version of
    the library into the `lib` namespace of your project. It should __not__ be
    pulled into the same namespace as your existing library version. Instead,
    give the new version a distinct name, like `baseV2` or `newBase`. We can
    change the name later.

    Then apply the the patch from the new library version to the project.
    Assuming your UCM console is located at the top of your project, you can
    use the patch command like so:

    ``` ucm
    .myProject> patch lib.newBase.patch
    ```

    Patches map old term references to new references in a namespace; they're
    part of what helps Unison automatically propagate changes when functions
    get updated. Patch entries are created automatically when the library
    author runs `update`.

    Next you should check if there are `todo` items in your project as a result
    of applying the patch. At the root of your project, run `todo`:

    ``` ucm
    .myProject> todo
    ```

    {{
    docAside
      {{
      This process is closely related to the process of updating your own code
      and resolving the resulting conflicts.
      [This doc]({{ (docLink (docEmbedTermLink do resolveConflictsProjects)) }})
      walks through the process of updating your local codebase for
      non-type-preserving edits.
      }} }}

    Todo items can happen if a function in your project depends on a function
    in the library whose type signature has changed in the new version. If
    there are `todo` items after applying the patch, the UCM should supply a
    suggested order to tackle them in. You'll want to edit the terms into a
    scratch file, resolve the conflicts and then `update` the terms.

    Once there are no `todo` items it's safe to delete the old library version
    from the `lib` namespace of the project. You may want to rename your new
    library version to `base` again so that it's easier to refer to in the
    future.

    ``` ucm
    .myProject> delete.namespace lib.base
    .myProject> rename.namespace lib.newBase lib.base
    ```

    It's done! Your project is now using the latest version of the dependency!
  }}

docs.usageTopics.workflowHowTos.updateDependencyLibInstall : Doc
docs.usageTopics.workflowHowTos.updateDependencyLibInstall =
  {{
  # How to update a library dependency

    Upgrading a library is very similar to the regular process of updating
    Unison code. It involves one additional simple command. The following
    workflow uses Unison's standard library, `base`, as an example.

    ## Upgrade workflow:

       1. `lib.install` the latest version of the dependency into your codebase
          so that it is a sibling of your current library version.
          * `myProject/main> lib.install @unison/base`
       2. Run the `upgrade` command, indicating which library you'd like to
          upgrade
          * `myProject/main> upgrade unison_base_1_0_0 unison_base_2_0_0`
       3. The UCM will create a new branch for the upgrade to take place in, so
          if something goes wrong and you want to back out of your changes, you
          can easily switch back to the branch you were on before the upgrade.
       4. If there are conflicts to resolve, the UCM will open up the affected
          terms in your editor. Resolve the conflicts and enter `update` again
          once the file typechecks.
       5. Run `upgrade.commit` to merge the temporary branch created by the
          `upgrade` command back into its parent branch. It will delete the
          temporary branch.

       {{
       docCallout
         (Some wordle.utils.emojis.hint)
         {{
         You do not need to remember the exact versions of the libraries you
         are upgrading from and to. Enter `upgrade` with no arguments to pick
         from the list of libraries in your project.
         }} }}
  }}

docs.usageTopics.workflowHowTos.updateDependencyNamespaces : Doc
docs.usageTopics.workflowHowTos.updateDependencyNamespaces =
  {{
  # How to update a dependency (deprecated)

    This doc walks through the process of updating a
    __non-projects based dependency__. Newer libraries or libraries which have
    migrated their dependencies to the projects based ecosystem will be
    upgraded with a set of similar commands, but the arguments will take the
    new
    `@username/project/branchName/ format instead. [Take a look at the new workflow here!](./updateDependency) The following workflow uses Unison's standard library, `base'',
    as an example.

    {{
    docCallout
      (Some {{ ⏱ }})
      {{
      Suggested workflow summary:

      1. `pull` the latest version of the dependency into your codebase so that
         it is a sibling of your current library version
         * `.myNamespace> pull unison.public.base.latest lib.newBase`
      2. Apply the `patch` from the new version of the library to the project
         * `patch lib.newBase.patch`
      3. Check if there are `todo` items in your project as a result of
         applying the patch
         * `.myNamespace> todo`
      4. Delete the old version of base from your codebase.
         * `.myNamespace> delete.namespace lib.base`
      5. Rename the new version of base to `base`
         * `.myNamespace> move.namespace lib.newBase lib.base`
      }} }}

    First, {{ docTooltip {{ `pull` }} ucmCommands.pull }} the new version of
    the library into the `lib` namespace of your project. It should __not__ be
    pulled into the same namespace as your existing library version. Instead,
    give the new version a distinct name, like `baseV2` or `newBase`. We can
    change the name later.

    Then apply the the patch from the new library version to the project.
    Assuming your UCM console is located at the top of your project, you can
    use the patch command like so:

    ``` ucm
    .myNamespace> patch lib.newBase.patch
    ```

    Patches map old term references to new references in a namespace; they're
    part of what helps Unison automatically propagate changes when functions
    get updated. Patch entries are created automatically when the library
    author runs `update`.

    Next you should check if there are `todo` items in your project as a result
    of applying the patch. At the root of your project, run `todo`:

    ``` ucm
    .myNamespace> todo
    ```

    {{
    docAside
      {{
      This process is closely related to the process of updating your own code
      and resolving the resulting conflicts.
      [This doc]({{ (docLink (docEmbedTermLink do resolveConflictsProjects)) }})
      walks through the process of updating your local codebase for
      non-type-preserving edits.
      }} }}

    Todo items can happen if a function in your project depends on a function
    in the library whose type signature has changed in the new version. If
    there are `todo` items after applying the patch, the UCM should supply a
    suggested order to tackle them in. You'll want to edit the terms into a
    scratch file, resolve the conflicts and then `update` the terms.

    Once there are no `todo` items it's safe to delete the old library version
    from the `lib` namespace of the project. You may want to rename your new
    library version to `base` again so that it's easier to refer to in the
    future.

    ``` ucm
    .myNamespace> delete.namespace lib.base
    .myNamespace> rename.namespace lib.newBase lib.base
    ```

    It's done! Your project is now using the latest version of the dependency!
  }}

docs.usageTopics.workflowHowTos.updateProjectDependency : Doc
docs.usageTopics.workflowHowTos.updateProjectDependency =
  {{
  # How to update a dependency

    This doc walks through the process of updating a dependency which has been
    released as a {{ docTooltip {{ Unison project }} project }}. The following
    workflow uses Unison's standard library, `base`, as an example. {{
    docAside
      {{
      If you are looking for instructions on how to update a non-project based
      dependency,
      [those instructions can be found here.]({{
      (docLink (docEmbedTermLink do updateDependencyNamespaces))
      }})
      }} }}

    {{
    docCallout
      (Some {{ ⏱ }})
      {{
      Suggested workflow summary:

      0. (Optionally) create a new `branch` for the update process so that you
         can easily revert if something goes wrong
         * `myProject/main> branch myProject/upgradeBase`
      1. `pull` the latest version of the dependency into your codebase so that
         it is a sibling of your current library version.
         * `myProject/upgradeBase> pull @unison/base/releases/X.Y.Z lib.newBase`
      2. Apply the `patch` from the new version of the library to the project
         * `patch lib.newBase.patch`
      3. Check if there are `todo` items in your project as a result of
         applying the patch
         * `myProject/upgradeBase> todo`
      4. Delete the old version of base from your codebase.
         * `myProject/upgradeBase> delete.namespace lib.base`
      5. Rename the new version of base to `base`
         * `myProject/upgradeBase> move.namespace lib.newBase lib.base`
      }} }}

    First, {{ docTooltip {{ `pull` }} ucmCommands.pull }} the new version of
    the library into the `lib` namespace of your project. It should __not__ be
    pulled into the same namespace as your existing library version. Instead,
    give the new version a distinct name, like `baseV2` or `newBase`. We can
    change the name later. The exact version number of library you want to
    install can be found by visiting the project's home page on
    [Unison Share](https://share.unison-lang.org/catalog). Click the big green
    button called "Use Project" to get a copy of the command to run.

    ``` ucm
    myProject/upgradeBase> pull @unison/base/releases/X.Y.Z lib.newBase
    ```

    Then apply the the patch from the new library version to the project.
    Assuming your UCM console is located at the top of your project, you can
    use the patch command like so:

    ``` ucm
    myProject/upgradeBase> patch lib.newBase.patch
    ```

    Patches map old term references to new references in a namespace; they're
    part of what helps Unison automatically propagate changes when functions
    get updated. Patch entries are created automatically when the library
    author runs `update`.

    Next you should check if there are `todo` items in your project as a result
    of applying the patch. At the root of your project, run `todo`:

    ``` ucm
    myProject/upgradeBase> todo
    ```

    {{
    docAside
      {{
      This process is closely related to the process of updating your own code
      and resolving the resulting conflicts.
      [This doc]({{ (docLink (docEmbedTermLink do resolveConflictsProjects)) }})
      walks through the process of updating your local codebase for
      non-type-preserving edits.
      }} }}

    Todo items can happen if a function in your project depends on a function
    in the library whose type signature has changed in the new version. If
    there are `todo` items after applying the patch, the UCM should supply a
    suggested order to tackle them in. You'll want to edit the terms into a
    scratch file, resolve the conflicts and then `update` the terms.

    Once there are no `todo` items it's safe to delete the old library version
    from the `lib` namespace of the project. You may want to rename your new
    library version to `base` again so that it's easier to refer to in the
    future.

    ``` ucm
    myProject/upgradeBase> delete.namespace lib.base
    myProject/upgradeBase> rename.namespace lib.newBase lib.base
    ```

    Finally, merge the `upgradeBase` branch into `main` and delete your upgrade
    branch.

    ``` ucm
    myProject/upgradeBase> merge /upgradeBase /main
    myProject/upgradeBase> delete.branch /upgradeBase
    ```

    It's done! Your project is now using the latest version of the dependency!
  }}

docs.utils.emojis.exercise : Doc
docs.utils.emojis.exercise = {{ 📓 }}

docs.utils.emojis.headsUp : Doc
docs.utils.emojis.headsUp = {{ 👋 }}

docs.utils.emojis.important : Doc
docs.utils.emojis.important = {{ 🧠 }}

docs.utils.emojis.index : Doc
docs.utils.emojis.index = {{ 📑 }}

docs.utils.emojis.placeholder : Doc
docs.utils.emojis.placeholder = {{ 🏗️ }}

docs.utils.emojis.reminder : Doc
docs.utils.emojis.reminder = {{ 📌 }}

docs.utils.emojis.style : Doc
docs.utils.emojis.style = {{ 🎨 }}

docs.utils.emojis.suggested : Doc
docs.utils.emojis.suggested = {{ 🌟 }}

docs.utils.navStyleTag : Text
docs.utils.navStyleTag = "navigation"

docs.utils.navStyleTag.doc : Doc
docs.utils.navStyleTag.doc =
  {{
  This term is used by the front-end for styling the "where to next?" elements
  on each doc page. It should be changed in sync with a class tag change on the
  front-end.
  }}

docs.whatProblemsDoesUnisonSolve : Doc
docs.whatProblemsDoesUnisonSolve =
  {{
  # 🧰 What problems does Unison solve?

    {{
    docTable
      [ [{{ **The problem** }}, {{ **Our remedy** }}]
      , [ {{
          **Cloud infrastructure management overhead:** Managing cloud
          infrastructure is complicated and not all teams have the expertise or
          desire to do it themselves. Furthermore, managing cloud
          infrastructure isn't done with a nicely typed program; instead, it's
          lots of ad hoc tooling, shell scripts and YAML files.
          }}
        , {{
          **Unison code deploys itself.**
          [Our cloud computing platform, Unison Cloud,](https://www.unison.cloud/)
          makes deploying long-running services, serverless functions, and
          batch jobs to the cloud as easy as calling a regular function.
          Infrastructure management is written as a typed Unison program.
          }}
        ]
      , [ {{
          **Inter-service communication boilerplate:** Writing encoders and
          decoders at service boundaries is part of the tedious overhead we've
          accepted for microservice architectures.
          }}
        , {{
          **Native service calls** in Unison eliminate the need for
          intermediaries.
          [Service calls are typechecked function calls.](https://www.unison-lang.org/whats-new/unison-services-preview/)
          }}
        ]
      , [ {{
          **Database communication boilerplate:** Translating your typed domain
          models to something the database understands is tedious and loses
          type information.
          }}
        , {{
          **Unison supports native, typed, transactional storage in the Cloud.**
          That means no writing sql adapters, no special query languages, just
          store and access Unison data.
          }}
        ]
      , [ {{
          **Testing and profiling distributed systems:** Testing the
          integration of an entire distributed system often involves setup and
          teardown of resources or copious data mocking.
          }}
        , {{
          **Unison's effect system separates your business logic from its
          implementation.**
          [Our model for distributed computation](https://share.unison-lang.org/@unison/cloud)
          can run against test backends that focus on observability, tracing or
          performance.
          }}
        ]
      , [ {{
          **Unnecessary merge conflicts:** Dealing with semantically
          unimportant merge conflicts is at best a papercut and at worst a big
          waste of development time.
          }}
        , {{
          **Semantic version control.** Unison's version control is
          language-aware. There are no conflicts due to code formatting or
          whitespace, order of imports, order of definitions in a file, or any
          other differences that aren't semantically meaningful.
          }}
        ]
      , [ {{
          **Dependency management nightmares:** Finding compatible sets of
          library versions can be difficult or impossible due to dependency
          conflicts. Dependency upgrade tasks often snowball in scope to
          include far more work than originally intended.
          }}
        , {{
          **Unison eliminates name conflicts.** Many dependency conflicts are
          caused by different versions of a library "competing" for the same
          names. Unison references defintions by hash, not by name, and
          multiple versions of the same library can be used within a project.
          }}
        ]
      , [ {{
          **Look, programming's no fun sometimes:** When programming tasks are
          needlessly complicated, tedious, or
          [just plain weird](https://www.destroyallsoftware.com/talks/wat), it
          can be demoralizing. Can't things be better?
          }}
        , {{
          **Redesign what's needed to make things awesome.** We've built Unison
          with love and care on [new foundations](/the-big-idea) to make the
          developer experience better.
          }}
        ]
      ] }}
  }}

docs._sidebar : Doc
docs._sidebar =
  {{
  # Welcome

    * [Welcome]({{ docLink (docEmbedTermLink do docs.index) }})
    * [Quickstart]({{ docLink (docEmbedTermLink do quickstart) }})
    * [What problems does Unison solve]({{
      docLink (docEmbedTermLink do whatProblemsDoesUnisonSolve)
      }})
    * [The big idea]({{ docLink (docEmbedTermLink do theBigIdea) }})
    * [Unison syntax at a glance]({{ docLink (docEmbedTermLink do atAGlance) }})
    * [A tour of the Unison workflow]({{ docLink (docEmbedTermLink do tour) }})

    * [Exercises](https://exercism.org/tracks/unison/)

  # Language fundamentals

    * Values and functions
      * [Terms]({{ docLink (docEmbedTermLink do terms) }})
      * [Common collections]({{
        docLink (docEmbedTermLink do commonCollectionTypes)
        }})
      * [Functions]({{ docLink (docEmbedTermLink do functions) }})
      * [Reading type signatures]({{
        docLink (docEmbedTermLink do readingTypeSignatures)
        }})
      * [Defining operators]({{
        docLink (docEmbedTermLink do definingOperators)
        }})
      * [Operators for function application]({{
        docLink (docEmbedTermLink do functionApplicationOperators)
        }})
      * [Delayed computations]({{
        docLink (docEmbedTermLink do valuesAndFunctions.delayedComputations)
        }})
    * Control flow
      * [If, then, and else]({ifThenAndElse})
      * [Pattern matching part 1]({{
        docLink (docEmbedTermLink do patternMatching)
        }})
      * [Pattern matching part 2]({{
        docLink (docEmbedTermLink do patternMatching2)
        }})
      * [Looping]({{ docLink (docEmbedTermLink do looping) }})
      * [Error handling with data types]({{
        docLink (docEmbedTermLink do exceptionHandling)
        }})
    * Data types
      * [Unique and structural types]({{
        docLink (docEmbedTermLink do uniqueAndStructuralTypes)
        }})
      * [Record types]({recordTypes})
    * Abilities
      * [Mental model]({abilities.index})
      * [Using abilities part 1]({{
        docLink (docEmbedTermLink do usingAbilitiesPt1)
        }})
      * [Using abilities part 2]({{
        docLink (docEmbedTermLink do usingAbilitiesPt2)
        }})
      * [Error handling with abilities]({{
        docLink (docEmbedTermLink do errorHandling)
        }})
      * [Writing ability handlers]({{
        docLink (docEmbedTermLink do writingAbilities)
        }})
      * [Abilities for monadically inclined users]({forMonadicallyInclined})
      * [Ability FAQ's]({{ docLink (docEmbedTermLink do faqs) }})

  # Usage Topics

    * [Updating code and dependencies]({{
      docLink (docEmbedTermLink do updateCode)
      }})
    * [Resetting codebase state]({resettingCodebaseState})
    * [Running a program]({{ docLink (docEmbedTermLink do runningPrograms) }})
    * [Documentation]({{ docLink (docEmbedTermLink do documentation) }})
    * [Testing]({{ docLink (docEmbedTermLink do testing) }})
    * [Transcripts]({transcripts})
    * [Docker]({{ docLink (docEmbedTermLink do docker) }})
    * [Structural find and replace](https://unison-lang.org/learn/structured-find)
    * [FAQ's]({{ docLink (docEmbedTermLink do generalFaqs) }})
    * [Bibliography]({{ docLink (docEmbedTermLink do bibliography) }})

  # Unison Codebase Manager

    * Codebase organization
      * [Projects quickstart]({docs.projects})
      * [Projects library migration]({projectsLibraryMigration})
      * [Unison project workflows]({projectWorkflows})
      * [Project FAQ's]({projectFAQs})
      * [Codebase organization]({projectsCodebaseOrganization})
    * Workspace setup
      * [Editor setup]({{ docLink (docEmbedTermLink do editorSetup) }})
      * [Code hosting with Unison Share]({unisonShare})
      * [Using the local codebase UI]({{
        docLink (docEmbedTermLink do localCodebaseUI)
        }})
      * [Add your author and license]({authorLicense})
      * [UCM command reference]({ucmCommands.index})

  # Language Reference

    {{ languageReference._sidebar }}

  # Learning Labs

    * [Wordle clone]({intro})
      * [Codebase setup]({codebaseSetup})
      * [Lab breakdown]({breakdown})
      * [Core logic]({coreLogic})
      * [Colorize results]({colorizeResult})
      * [Validation]({validation})
      * [Game loop]({docs.gameLoop})
      * [Challenge task]({hard})
      * [Other challenges]({challenges})
    * [Unison Cloud modules](https://www.unison.cloud/learn/)
      * [Deploy a simple HTTP service](https://www.unison.cloud/learn/http-hello-world/)
      * [Write, deploy, and call typed functions](https://www.unison.cloud/learn/native-services/)
      * [Write a blog with Storage](https://www.unison.cloud/learn/microblogging/)
      * [Add Auth to a web-service](https://www.unison.cloud/learn/auth/)
  }}

metadata.authors.bbarker : metadata.Author
metadata.authors.bbarker =
  metadata.Author.Author bbarker.guid "Brandon Elam Barker"

metadata.authors.bbarker.guid : GUID
metadata.authors.bbarker.guid =
  GUID 0xs38f83b6183e6a92bf4ae33530a9ca2e9adccc253ffaab4edc8a9fb31b7d302e7

metadata.authors.h22roscoe : metadata.Author
metadata.authors.h22roscoe =
  metadata.Author.Author h22roscoe.guid "Harry Roscoe"

metadata.authors.h22roscoe.guid : GUID
metadata.authors.h22roscoe.guid =
  GUID 0xs3e6daabbad6e6484eff78d340c282cae89891c07c9ef6bb485829359bbdde8fc

metadata.copyrightHolders.bbarker : CopyrightHolder
metadata.copyrightHolders.bbarker =
  CopyrightHolder bbarker.guid "Brandon Elam Barker"

metadata.copyrightHolders.h22roscoe : CopyrightHolder
metadata.copyrightHolders.h22roscoe =
  CopyrightHolder h22roscoe.guid "Harry Roscoe"

pages.community.codeOfConduct : Doc
pages.community.codeOfConduct =
  {{
  # 🤝 Code of Conduct

    Unison community spaces are welcoming environments where everyone can seek
    help and discussion on any Unison-related topic. To ensure that our
    community remains as friendly and safe as possible, this Code of Conduct
    documents our rules, values, and expectations.

    **TL;DR:** just be kind. 💖

    The members and moderators of Unison community spaces are committed to
    providing a friendly, safe and welcoming environment for all, regardless of
    age, disability, gender, nationality, race, religion, sexuality, or similar
    personal characteristic. We do not tolerate harassment or abuse in any
    form.

    As participants of this community we pledge to:

    * Be friendly, welcoming, and inclusive.
    * Be helpful and patient.
    * Give the most accurate and informative technical advice we can.
    * Help each other overcome misunderstandings.
    * Be respectful and considerate.
    * Avoid negative behavior, snark, and insults.
    * Avoid offering political opinions, engaging in gossip, or rallying
      negative sentiment against a particular individual or group.
    * Refrain from posting derogatory or offensive content, or language and
      imagery that is inappropriate in a professional setting.

    Everyone can make a valuable contribution to this community. We may not
    always agree, but disagreement is no excuse for poor behavior and poor
    manners. We might all experience some frustration now and then, but we
    cannot allow that frustration to turn into personal attacks. It's important
    to remember that an environment where people feel uncomfortable or
    threatened is not a productive one.

    Sometimes misunderstandings and conflicts are inevitable, but resist the
    urge to be defensive or assign blame. Try not to take offense where no
    offense was intended. Give people the benefit of the doubt. Even if the
    intent was to provoke, do not rise to it.

    We are committed to making participation in this community a
    **harassment-free experience for everyone.** As such, moderators reserve
    the right to remove or reject comments and other assets that are not
    aligned to this Code of Conduct, or to ban temporarily or permanently, with
    or without warning, any participant for behaviors that they deem
    inappropriate, threatening, offensive, or harmful.

    ## Reporting issues and concerns

       To report issues of abusive, harassing, threatening, or otherwise
       unacceptable behavior you can get in touch with the moderators
       (currently Rebecca Mark, Rúnar Bjarnason, Paul Chiusano, and Arya Irani)
       by emailing [mods@unison.cloud](mailto:mods@unison.cloud:)

       Moderators are committed to maintaining confidentiality with regard to
       the reporter of an incident.

       {{ evaluatingIncidents }}

    ## Acknowledgements

       This Code of Conduct is adapted from
       [the Elm Code of Conduct](https://github.com/elm-community/discussions/blob/master/code-of-conduct.md).
  }}

pages.community.evaluatingIncidents : Doc
pages.community.evaluatingIncidents =
  {{
  # How We're Evaluating Incidents

    We're committed to transparency and accountability in our enforcement of
    the Code of Conduct.

    ## Jurisdiction

       * **Is this a Code of Conduct violation?** Is this behavior on our list
         of inappropriate behavior? Is it borderline inappropriate behavior?
         Does it violate our community norms?
       * **Did this occur in a space that is within our Code of Conduct's
         scope?** If the incident occurred outside the community, but a
         community member's mental health or physical safety may be negatively
         impacted if no action is taken, the incident may be

       __in scope__. Private conversations in community spaces are also in
       scope.

    ## Impact

       * **Did this incident occur in a private conversation or in a public
         space?** Incidents that all community members can see will have more
         negative impact.
       * **Does this behavior negatively impact a marginalized group in our
         community?** Is the reporter a person from a marginalized group in our
         community? How is the reporter being negatively impacted by the
         reported person's behavior? Are members of the marginalized group
         likely to disengage with the community if no action was taken on this
         report?
       * **Does this incident involve a community leader?** Community members
         often look up to community leaders to set the standard of acceptable
         behavior.

    ## Risk

       * **Does this incident include sexual harassment?**
       * **Does this pose a safety risk?** Does the behavior put a person's
         physical safety at risk? Will this incident severely negatively impact
         someone's mental health?
       * **Is there a risk of this behavior being repeated?** Does the reported
         person understand why their behavior was inappropriate? Is there an
         established pattern of behavior from past reports?
         * More on how will we evaluate
           [if a person should be allowed to return to the community or
           community event.](https://the-orbit.net/almostdiamonds/2014/07/05/returning-to-the-scene-or-coming-back-after-harassment/)

       Reports which involve higher risk or higher impact may face more severe
       consequences than reports which involve lower risk or lower impact.

       This guide is adapted from from
       https://policies.python.org/python.org/code-of-conduct/Enforcement-Procedures/
  }}

pages.community.index : Doc
pages.community.index =
  {{
  # 😃 Community

    Hello and thanks for joining us!

    We're committed to creating inclusive, friendly spaces where people of all
    backgrounds and experience levels feel welcome. Respect and kindness are
    the foundation of this community. For more details, please see
    [our code of conduct]({codeOfConduct}).

    Join the conversation, ask questions, and connect with other Unison
    enthusiasts in these spaces:

    * The
      [Unison Discord is our primary community organizing hub.](https://unison-lang.org/discord)
      Be sure to join us in the Discord for all the latest tips, news, and
      discussion.
    * The [Calendar](https://www.unison-lang.org/calendar) has upcoming Unison
      events. If you have a Unison-related event you'd like listed there, you
      can mention it in [`#general`](https://unison-lang.org/discord) of
      Discord.
    * The [Unison blog](https://www.unison-lang.org/blog/) contains posts about
      special topics in Unison and language updates. We would love to feature
      your contributions so email
      [community@unison.cloud](mailto:community@unison.cloud) with your topic
      ideas.
    * Development happens on the
      [Unison GitHub repo](https://github.com/unisonweb/unison/), and there's
      also regular discussion in the
      [#toolchain-development channel](https://unison-lang.org/discord) on
      Discord.

    ## Some common community questions and topics

       ### How do I share my code?

           If you want to __publicly__ share your code (or look at code that
           others have shared), check out
           [Unison Share](https://share.unison-lang.org/).

           You use the Unison Codebase Manager's
           [`push`](https://www.unison-lang.org/docs/ucm-commands/push/)
           command, to write it to your own remotely hosted repository.

           (There's also always the option of zipping up your `.unison`
           directory! Its contents are free-standing and portable.)

       ### Are you looking for help with developing Unison?

           Yes! Please come and get involved 😊

           The first step is to play with the language, and get familiar with
           writing Unison code. Also, come join the Discord, and browse through
           the issue tracker to see what's going on.

           #### Contributing Unison code

                Is there a library you could write in Unison? That's a way to
                contribute which requires very little coordination with the
                compiler team, and can have a big impact on the usability of
                the overall Unison ecosystem. There's a catalog of libraries
                [here](https://share.unison-lang.org/catalog) - do add yours!
                Let us know in the Discord (channel #libraries) what you're
                working on 😎

                You could also try fixing some omissions from the base library
                - check out the
                [tickets tab in the Base project](https://share.unison-lang.org/@unison/base/tickets)
                for the contributions that would be most welcome.

           #### Contributing to the Unison language/compiler/toolchain

                You can dip your toes by finding small ways to contribute a
                little piece: - take a look at the issues labelled
                [`good first issue`](https://github.com/unisonweb/unison/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)
                and
                [`help wanted`](https://github.com/unisonweb/unison/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)
                - see if you can find any tidying or refactoring you think
                needs doing in the parser-typechecker source (chat to us on
                Discord before spending much time) - are there any contributor
                docs you'd like to see which you could make a start on?

                Once you've had your first PR merged and gotten to know how we
                work, have a think whether you want to take on a bigger
                project! There's lots of cool stuff to do. Get in touch with
                Paul Chiusano via the Discord and give him an idea of your
                areas of interest and level of experience. If you have your own
                suggestions for what you could work on then let him know!
  }}

pages.home.examples.distributedEx : Seq k Nat ->{Remote} Nat
pages.home.examples.distributedEx dseq =
  use Nat + ==
  dseq
    |> Seq.map (x -> x + 1)
    |> Seq.filter (x -> Nat.mod x 7 == 0)
    |> Seq.reduce 0 (+)

pages.home.examples.helloWorld : '{IO, Exception} ()
pages.home.examples.helloWorld _ = printLine "Hello World"

pages.home.examples.httpEx : '{IO, Exception} HttpResponse
pages.home.examples.httpEx =
  do Http.run do Http.get (parseOrBug "https://www.unison-lang.org")

pages.home._examples : Doc
pages.home._examples =
  {{
  {{
  Style
    "hello-world"
    {{
    # 👋 Hello World

      The classic Hello World program in Unison is as simple as a call to
      printLine.

          @source{helloWorld}

      `{IO, Exception}` indicates which abilities the program needs to do I/O
      and throw exceptions. {{ (Style "delayed-computation" (Code (Word "'")))
      }} is used to denote a delayed computation.

      [Learn more about Abilities](/learn/fundamentals/abilities/).
    }} }}

  {{
  Style
    "distributed-map-reduce"
    {{
    # Distributed map-reduce

      With a few lines of code, you can perform a distributed map-reduce using
      the {type Remote} ability.

          @source{examples.distributedEx}

      Learn more about Remote and working with
      [distributed datasets in Unison](/articles/distributed-datasets).
    }} }}

  {{
  Style
    "http-request"
    {{
    # HTTP request

      Perform effectful code, like HTTP requests with
      [Abilities](/learn/fundamentals/abilities/using-abilities-pt1) and
      [Ability handlers](/learn/fundamentals/abilities/using-abilities-pt2/).

      Checkout more HTTP examples in the
      [http library](https://share.unison-lang.org/@unison/http).

          @source{httpEx}
    }} }}
  }}

pages.jobs.index : Doc
pages.jobs.index =
  {{
  # Jobs at Unison Computing

    {{
    docCallout
      Optional.None
      {{
      Our mission: advance what's possible with software and work to make
      software creation simpler and more accessible to all.
      }} }}

  # Working at Unison Computing

    Unison Computing is a seed stage startup and a
    [public benefit corp](/whats-new/benefit-corp-report/). You can read more
    about the company's background and our mission
    [in this post](/whats-new/benefit-corp-report/). See the
    [Unison Strange Loop talk](https://www.youtube.com/watch?v=gCWtkvDQ2ZI) for
    an introduction to the core ideas behind Unison and also
    [the Unison documentation site](/docs) for more about the Unison language.

    We love statically-typed functional languages such as Elm, PureScript,
    Scala, Haskell, and Unison itself. We hope that you'll be excited to learn
    about them if you haven't already.

    We're committed to building a friendly, welcoming, and diverse community of
    Unison programmers, and it's important to us that you'd commit to this as
    well.

    And probably the most important thing we are looking for: enthusiasm for
    making computing better, a belief that the (computing) world is what we
    make of it, and an ability and willingness to learn whatever is necessary
    to make a new vision of computing a reality. Regardless of your past
    experience, you will often find yourself in uncharted territory. We think
    that's part of the fun and hope you will too!

    ## Logistics

       We are based in
       [Somerville, MA](https://en.wikipedia.org/wiki/Davis_Square), but we are
       a remote-first company and nobody has even been to the office since the
       start of the coronavirus pandemic. Our hiring is not limited to United
       States based applicants. Although we ask that some working hours overlap
       with a 9-5 [ET](https://www.timeanddate.com/time/zones/et) work day, we
       also recognize that our team members are also parents, hobbyists, family
       members, and community members, and we are happy that our flexibility
       allows us to flourish both professionally and personally.

       The company offers competitive benefits, paid parental leave, and a
       vacation policy that emphasizes work/life balance.

    ## Open Positions

       We're not currently looking to hire for any roles right now, but even
       when we're not trying to fill a specific position, we love to hear from
       folks who are excited about what we're trying to accomplish and want to
       help make it happen. So check out the __How to Apply__ section, drop us
       a line, and we'll contact you first whenever we do have an opening that
       seems like a good fit.

    ## How to Apply

       Send an email to [jobs@unison.cloud](mailto:jobs@unison.cloud). Here's
       what to include:

       * Tell us who you are and why you want to work on Unison.
       * Include your résumé/CV or a link to it (LinkedIn is fine).
       * If you have any past work that you'd like to share with us—open-source
         projects, publications, talks, articles, blog posts; or something else
         you're proud of—we'd love to see it!
       * Let us know where you are currently based.
       * What questions do you have about the role?

       We look forward to hearing from you!

       **Paul, Rúnar, Arya**
  }}

pages.talks.index : Doc
pages.talks.index =
  {{
  # Talks about Unison

    Unison started years ago as an experimental project to revisit all aspect
    of the programming experience. There have been lots of changes to it over
    the years, so some of the content here in the older talks might be
    increasingly out of date. When in doubt, the [Docs](/docs) site will have
    the latest information about the project.

    Here are the talks, newest first:

    * [Scale By the Bay 2019, by Paul Chiusano](https://www.youtube.com/watch?v=IvENPX0MAZ4)
      This is a 32 minute talk that briefly covers the core ideas of Unison and
      talks about Unison's approach to refactoring.
    * [Strange Loop 2019, by Paul Chiusano](https://www.youtube.com/watch?v=gCWtkvDQ2ZI)
      This is a longer (40 min) introduction to the core ideas of Unison and
      probably the best talk to start with.
    * [Scale By the Bay 2018, by Paul Chiusano](https://www.youtube.com/watch?v=v7L-5AQQkbM).
    * [Lambda World 2018, by Rúnar Bjarnason](https://www.youtube.com/watch?v=rp_Eild1aq8)
      also presented at [Øredev 2018](https://vimeo.com/311512465).
    * [Scala World 2017, by Paul Chiusano](https://www.youtube.com/watch?v=knqlWboqf_U).
    * [Full Stack Fest 2016, by Paul Chiusano](https://www.youtube.com/watch?v=f6yA3t0dO-k)

    If you've given a talk on Unison and would like to add a link to it here,
    [open a pull request](https://github.com/unisonweb/unisonweb-org/edit/master/src/data/supplemental-pages/talks.md)!
    Also if you are thinking of giving a talk on Unison somewhere and would
    like ideas or support, feel free to
    [come chat with us in Slack](https://unisonlanguage.slack.com).
  }}

pages.unisonComputing.index : Doc
pages.unisonComputing.index =
  {{
  # About Unison Computing

    Unison Computing is a
    [public benefit corp](https://en.wikipedia.org/wiki/Public-benefit_corporation),
    cofounded by Paul Chiusano, Rúnar Bjarnason, and Arya Irani. We work
    alongside other
    [amazing open source contributors](https://github.com/unisonweb/unison/blob/trunk/CONTRIBUTORS.markdown)
    on the Unison language. 💜

    Our overall mission: advance what's possible with software and work to make
    software creation simpler and more accessible to all. The company does
    research and development into new, free, open source software technologies
    like Unison, and builds useful products and services (like
    [the Unison Cloud Platform](http://unison.cloud)) to help capitalize this
    mission.

    You can
    [read more here about the company, our mission, and our history](/whats-new/benefit-corp-report/).
  }}

README : Doc
README =
  {{
  # Unison Language Docs Website

    This repo is the home for the Unison language website content. The Unison
    website is authored in the {type Doc} format. With live code snippets and
    dynamic term and type linking.

    ## Tips when working with the website repo

       The website repo has an unusual structure. Each top-level namespace has
       its own lib namespace for dependencies. CD' into each of the following
       top level namespaces as it's own "project" to work within it:

       ``` raw
       /learn
         /lib
       /pages
         /lib
       /feed
         /lib
       ```

       {{ contributeDocs }}
  }}

test> square.tests.ex1 =
  use Nat ==
  check (square 4 == 16)
